[
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#thursday-april-17",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#thursday-april-17",
    "title": "Data Cleaning & Manipulation",
    "section": "Thursday, April 17",
    "text": "Thursday, April 17\nToday we will…\n\nNew Material\n\nExtend dplyr verbs to have more functionality.\nDiscuss data ethics.\n\nLab 3: Teacher Evaluations"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#reminder-example-data-cereal",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#reminder-example-data-cereal",
    "title": "Data Cleaning & Manipulation",
    "section": "Reminder: Example Data Cereal",
    "text": "Reminder: Example Data Cereal\n\nlibrary(liver)\ndata(cereal)\nhead(cereal, n = 5)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10\n5\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2\n8\n8\n135\n0\n3\n1\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9\n7\n5\n320\n25\n3\n1\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14\n8\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1\n14\n8\n-1\n25\n3\n1\n0.75\n34.38484"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#more-dplyr",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#more-dplyr",
    "title": "Data Cleaning & Manipulation",
    "section": "More dplyr",
    "text": "More dplyr\n\nWe have already covered a lot, but not everything you might want…\nToday we will cover functions that help with the following tasks:\n\nextract a variable as a vector\nsimple frequency table of a categorical variable\ncreating a categorical variable from levels of a quantitatie variable\napplying slice to groups and multiple variables\nmutating or summarizing many variables at once"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#pull",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#pull",
    "title": "Data Cleaning & Manipulation",
    "section": "pull()",
    "text": "pull()\nWhat is the mean potassium for cold cereals?\n\nYou can’t use the $ operator in a pipeline\npull() to the rescue!\npull() extracts a data frame column as a vector\n\n\n\ncereal |&gt; \n  filter(type == \"cold\") |&gt; \n  pull(potass) |&gt; \n  mean(na.rm = T)\n\n[1] 97.21622"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#reminder-count-with-summarize",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#reminder-count-with-summarize",
    "title": "Data Cleaning & Manipulation",
    "section": "Reminder: count with summarize()",
    "text": "Reminder: count with summarize()\nHow many cereals does each manuf have in this dataset?\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  summarize(n = n())\n\n\n\n\n\n\n\nmanuf\nn\n\n\n\n\nA\n1\n\n\nG\n22\n\n\nK\n23\n\n\nN\n6\n\n\nP\n9\n\n\nQ\n8\n\n\nR\n8"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#count-with-count",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#count-with-count",
    "title": "Data Cleaning & Manipulation",
    "section": "Count with count()",
    "text": "Count with count()\nHow many cereals does each manuf have in this dataset?\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  count()\n\n\n\n\n\n\n\nmanuf\nn\n\n\n\n\nA\n1\n\n\nG\n22\n\n\nK\n23\n\n\nN\n6\n\n\nP\n9\n\n\nQ\n8\n\n\nR\n8"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#if_else",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#if_else",
    "title": "Data Cleaning & Manipulation",
    "section": "if_else()",
    "text": "if_else()\nFor each cereal, label the potass as “high” or “low”.\n\nOne if-else statement:\n\n\nif_else(&lt;CONDITION&gt;, &lt;TRUE OUTPUT&gt;, &lt;FALSE OUTPUT&gt;)\n\n\n\n\n\ncereal |&gt; \n  mutate(po_category = if_else(potass &lt;= 100, \"low\", \"high\"),\n         .after = potass)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\npo_category\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\nhigh\n25\n3\n1.00\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\nhigh\n0\n3\n1.00\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\nhigh\n25\n3\n1.00\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\nhigh\n25\n3\n1.00\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\nlow\n25\n3\n1.00\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\nlow\n25\n1\n1.00\n0.75\n29.50954\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\nlow\n25\n2\n1.00\n1.00\n33.17409\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\nlow\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\nhigh\n25\n1\n1.00\n0.67\n49.12025\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\nhigh\n25\n3\n1.00\n0.67\n53.31381\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\nlow\n25\n2\n1.00\n0.75\n18.04285\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\nhigh\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\nlow\n25\n2\n1.00\n0.75\n19.82357\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\nhigh\n25\n3\n1.00\n0.50\n40.40021\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\nlow\n25\n2\n1.00\n1.00\n22.73645\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\nlow\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\nlow\n25\n1\n1.00\n1.00\n45.86332\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\nlow\n25\n2\n1.00\n1.00\n35.78279\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\nlow\n25\n2\n1.00\n1.00\n22.39651\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\nhigh\n25\n3\n1.00\n0.50\n40.44877\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\nlow\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\nlow\n25\n3\n1.00\n1.00\n46.89564\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\nhigh\n25\n3\n1.00\n0.75\n36.17620\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\nlow\n25\n3\n1.00\n0.75\n44.33086\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\nlow\n25\n2\n1.00\n1.00\n32.20758\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\nlow\n25\n1\n1.00\n0.75\n31.43597\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\nlow\n25\n2\n1.00\n0.80\n58.34514\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\nhigh\n25\n3\n1.25\n0.67\n40.91705\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\nhigh\n25\n3\n1.33\n0.67\n41.01549\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\nlow\n25\n2\n1.00\n0.75\n28.02576\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\nlow\n25\n1\n1.00\n0.88\n35.25244\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\nlow\n25\n2\n1.00\n0.75\n23.80404\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\nlow\n25\n3\n1.00\n0.88\n52.07690\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\nlow\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\nlow\n25\n3\n1.00\n0.33\n45.81172\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\nlow\n25\n2\n1.00\n1.00\n21.87129\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\nlow\n25\n1\n1.00\n0.75\n31.07222\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\nlow\n25\n1\n1.00\n1.33\n28.74241\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\nlow\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\nlow\n100\n3\n1.30\n0.75\n36.47151\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\nlow\n25\n2\n1.00\n1.50\n39.24111\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\nlow\n25\n2\n1.00\n0.67\n45.32807\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\nlow\n25\n2\n1.00\n1.00\n26.73451\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\nlow\n25\n2\n1.00\n1.00\n54.85092\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\nhigh\n25\n3\n1.00\n1.00\n37.13686\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\nhigh\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\nhigh\n25\n3\n1.50\n0.67\n30.31335\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\nlow\n25\n1\n1.00\n1.00\n40.10596\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\nlow\n25\n2\n1.00\n0.67\n29.92429\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\nhigh\n25\n3\n1.33\n0.67\n40.69232\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\nlow\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\nhigh\n25\n3\n1.25\n0.50\n30.45084\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\nhigh\n25\n3\n1.33\n0.67\n37.84059\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\nlow\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\nlow\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\nlow\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\nhigh\n25\n3\n1.00\n0.50\n49.51187\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\nhigh\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\nhigh\n25\n2\n1.33\n0.75\n39.25920\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\nhigh\n25\n3\n1.00\n0.50\n39.70340\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\nhigh\n25\n3\n1.00\n0.50\n55.33314\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\nlow\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\nlow\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\nlow\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\nhigh\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\nhigh\n0\n1\n1.00\n0.67\n72.80179\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\nlow\n25\n2\n1.00\n0.75\n31.23005\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\nlow\n25\n1\n1.00\n1.00\n53.13132\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\nlow\n25\n2\n1.00\n1.00\n59.36399\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\nlow\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\nhigh\n100\n3\n1.50\n1.00\n28.59278\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\nhigh\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\nlow\n25\n3\n1.00\n0.75\n39.10617\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\nlow\n25\n2\n1.00\n1.00\n27.75330\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\nhigh\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\nhigh\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\nlow\n25\n1\n1.00\n0.75\n36.18756\n\n\n\n\n\n\n\n.after – specifies the location of the newly created column"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#case_when",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#case_when",
    "title": "Data Cleaning & Manipulation",
    "section": "case_when()",
    "text": "case_when()\nFor each cereal, label the amount of sugar as “low”, “medium”, “high”, or “very high”.\n\nA series of if-else statements.\n\ncereal |&gt; \n  mutate(sugar_level = case_when(sugars == -1 ~ NA_character_,\n                                 sugars &lt; 2   ~ \"low\",\n                                 sugars &lt; 5   ~ \"medium\",\n                                 sugars &lt; 10  ~ \"high\",\n                                 TRUE         ~ \"very high\")) |&gt; \n  select(name, sugars, sugar_level)\n\n\n\n\n\n\n\nname\nsugars\nsugar_level\n\n\n\n\n100% Bran\n6\nhigh\n\n\n100% Natural Bran\n8\nhigh\n\n\nAll-Bran\n5\nmedium\n\n\nAll-Bran with Extra Fiber\n0\nlow\n\n\nAlmond Delight\n8\nhigh\n\n\nApple Cinnamon Cheerios\n10\nhigh\n\n\nApple Jacks\n14\nvery high\n\n\nBasic 4\n8\nhigh\n\n\nBran Chex\n6\nhigh\n\n\nBran Flakes\n5\nmedium\n\n\nCap'n'Crunch\n12\nvery high\n\n\nCheerios\n1\nlow\n\n\nCinnamon Toast Crunch\n9\nhigh\n\n\nClusters\n7\nhigh\n\n\nCocoa Puffs\n13\nvery high\n\n\nCorn Chex\n3\nmedium\n\n\nCorn Flakes\n2\nlow\n\n\nCorn Pops\n12\nvery high\n\n\nCount Chocula\n13\nvery high\n\n\nCracklin' Oat Bran\n7\nhigh\n\n\nCream of Wheat (Quick)\n0\nlow\n\n\nCrispix\n3\nmedium\n\n\nCrispy Wheat & Raisins\n10\nhigh\n\n\nDouble Chex\n5\nmedium\n\n\nFroot Loops\n13\nvery high\n\n\nFrosted Flakes\n11\nvery high\n\n\nFrosted Mini-Wheats\n7\nhigh\n\n\nFruit & Fibre Dates; Walnuts; and Oats\n10\nhigh\n\n\nFruitful Bran\n12\nvery high\n\n\nFruity Pebbles\n12\nvery high\n\n\nGolden Crisp\n15\nvery high\n\n\nGolden Grahams\n9\nhigh\n\n\nGrape Nuts Flakes\n5\nmedium\n\n\nGrape-Nuts\n3\nmedium\n\n\nGreat Grains Pecan\n4\nmedium\n\n\nHoney Graham Ohs\n11\nvery high\n\n\nHoney Nut Cheerios\n10\nhigh\n\n\nHoney-comb\n11\nvery high\n\n\nJust Right Crunchy Nuggets\n6\nhigh\n\n\nJust Right Fruit & Nut\n9\nhigh\n\n\nKix\n3\nmedium\n\n\nLife\n6\nhigh\n\n\nLucky Charms\n12\nvery high\n\n\nMaypo\n3\nmedium\n\n\nMuesli Raisins; Dates; & Almonds\n11\nvery high\n\n\nMuesli Raisins; Peaches; & Pecans\n11\nvery high\n\n\nMueslix Crispy Blend\n13\nvery high\n\n\nMulti-Grain Cheerios\n6\nhigh\n\n\nNut&Honey Crunch\n9\nhigh\n\n\nNutri-Grain Almond-Raisin\n7\nhigh\n\n\nNutri-grain Wheat\n2\nlow\n\n\nOatmeal Raisin Crisp\n10\nhigh\n\n\nPost Nat. Raisin Bran\n14\nvery high\n\n\nProduct 19\n3\nmedium\n\n\nPuffed Rice\n0\nlow\n\n\nPuffed Wheat\n0\nlow\n\n\nQuaker Oat Squares\n6\nhigh\n\n\nQuaker Oatmeal\n-1\nNA\n\n\nRaisin Bran\n12\nvery high\n\n\nRaisin Nut Bran\n8\nhigh\n\n\nRaisin Squares\n6\nhigh\n\n\nRice Chex\n2\nlow\n\n\nRice Krispies\n3\nmedium\n\n\nShredded Wheat\n0\nlow\n\n\nShredded Wheat 'n'Bran\n0\nlow\n\n\nShredded Wheat spoon size\n0\nlow\n\n\nSmacks\n15\nvery high\n\n\nSpecial K\n3\nmedium\n\n\nStrawberry Fruit Wheats\n5\nmedium\n\n\nTotal Corn Flakes\n3\nmedium\n\n\nTotal Raisin Bran\n14\nvery high\n\n\nTotal Whole Grain\n3\nmedium\n\n\nTriples\n3\nmedium\n\n\nTrix\n12\nvery high\n\n\nWheat Chex\n3\nmedium\n\n\nWheaties\n3\nmedium\n\n\nWheaties Honey Gold\n8\nhigh"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#group_by-slice",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#group_by-slice",
    "title": "Data Cleaning & Manipulation",
    "section": "group_by() + slice()",
    "text": "group_by() + slice()\nFor each manuf, find the cereal with the most fiber.\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  slice_max(order_by = fiber)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15\n6\n125\n25\n1\n1.00\n0.67\n49.12025"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#multiple-variables-in-slice",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#multiple-variables-in-slice",
    "title": "Data Cleaning & Manipulation",
    "section": "Multiple Variables in slice()",
    "text": "Multiple Variables in slice()\nFind the 3 cereals with the highest fiber and potass.\n\n\nIf you are ordering by multiple variables, wrap them in a data.frame!\n\n\ncereal |&gt; \n  slice_max(order_by = data.frame(fiber, potass),\n            n = 3)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14\n8\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10\n5\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9\n7\n5\n320\n25\n3\n1\n0.33\n59.42551"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns",
    "title": "Data Cleaning & Manipulation",
    "section": "Summarize multiple columns",
    "text": "Summarize multiple columns\nFor each type of cereal, calculate the mean nutrient levels.\n\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarize(mean_calories = mean(calories, na.rm = T),\n            mean_protein  = mean(protein, na.rm = T),\n            mean_fat      = mean(fat, na.rm = T),\n            mean_sodium   = mean(sodium, na.rm = T),\n            . . .,\n            mean_vitamins = mean(vitamins, na.rm = T))\n\n\n\n\n\n\n\n\n\nSO MUCH COPY-PASTE!\n\n\nThere are 9 different nutrient columns in the dataset! There has to be a better way…"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across",
    "title": "Data Cleaning & Manipulation",
    "section": "Summarize multiple columns with across()",
    "text": "Summarize multiple columns with across()\nFor each type of cereal, calculate the mean nutrient levels.\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarise(across(.cols = calories:potass, \n                   .fns = ~ mean(.x, na.rm = T)))\n\n\n\n\n\n\n\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\n\n\n\n\ncold\n107.1622\n2.486486\n1.013513\n165.06757\n2.189189\n14.7027\n7.1756757\n97.21622\n\n\nhot\n100.0000\n4.000000\n1.000000\n26.66667\n1.233333\n12.0000\n0.6666667\n68.00000\n\n\n\n\n\n\n\n\n\n\n\n\n\nSo much better!"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across-1",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Summarize multiple columns with across()",
    "text": "Summarize multiple columns with across()\nWithin the summarize() function, we use the across() function, with three arguments:\n\n.cols – to specify the columns to apply functions to.\n.fns – to specify the functions to apply.\n.x – as a placeholder for the variables being passed into the function.\n\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarise(across(.cols = calories:potass, \n                   .fns = ~ mean(.x, na.rm = T)))\n\nUse lambda functions: ~ &lt;FUN_NAME&gt;(.x, &lt;ARGS&gt;)"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across-2",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across-2",
    "title": "Data Cleaning & Manipulation",
    "section": "Summarize multiple columns with across()",
    "text": "Summarize multiple columns with across()\n\nTo choose columns, you can use the same options as with select()\n\n\nFor each type of cereal, calculate the means of all numeric variables.\n\n\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarise(across(.cols = where(is.numeric),\n                   .fns = ~ mean(.x, na.rm = T)))\n\n\n\n\n\n\n\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\ncold\n107.1622\n2.486486\n1.013513\n165.06757\n2.189189\n14.7027\n7.1756757\n97.21622\n29.054054\n2.229730\n1.030811\n0.8182432\n42.09522\n\n\nhot\n100.0000\n4.000000\n1.000000\n26.66667\n1.233333\n12.0000\n0.6666667\n68.00000\n8.333333\n1.666667\n1.000000\n0.8900000\n56.73771"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#if-you-are-struggling-with-across",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#if-you-are-struggling-with-across",
    "title": "Data Cleaning & Manipulation",
    "section": "If you are struggling with across()",
    "text": "If you are struggling with across()\n\nBreak it down:\n\nthink about what the code would be for one column\n\n\nsummarize(calories = mean(calories, na.rm = T))\n\n\nreplace the column name with the placeholder .x and add a ~ in front for the .fns argument. You have created a lambda function!\n\n\nsummarize(across(.cols = ,\n                 .fns  = ~mean(.x, na.rm = T)))\n\n\nthink about which columns you want to apply this to for the .cols argument\n\n\nsummarize(across(.cols = calories:potass,\n                 .fns  = ~mean(.x, na.rm = T)))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot",
    "title": "Data Cleaning & Manipulation",
    "section": "Piping into ggplot()",
    "text": "Piping into ggplot()\nPlot the mean protein per cup for each manuf.\n\n\ncereal |&gt; \n  mutate(manuf = case_when(manuf == \"A\" ~ \"American Home Food Products\", \n                           manuf == \"G\" ~ \"General Mills\", \n                           manuf == \"K\" ~ \"Kelloggs\", \n                           manuf == \"N\" ~ \"Nabisco\", \n                           manuf == \"P\" ~ \"Post\", \n                           manuf == \"Q\" ~ \"Quaker Oats\", \n                           manuf == \"R\" ~ \"Ralston Purina\"))  |&gt; \n  filter(type == \"cold\") |&gt; \n  mutate(pro_per_cup = protein / cups) |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_pro_per_cup = mean(pro_per_cup)) |&gt;  \n  ggplot(aes(x = manuf, \n             y = mean_pro_per_cup)) +\n  geom_point(size = 6) +\n  labs(x = \"Manufacturer\",\n       subtitle = \"Mean Protein per Cup\") +\n  theme_bw() +\n  theme(axis.title.y = element_blank(),\n        axis.title.x  = element_text(size = 24),\n        plot.subtitle = element_text(size = 24),\n        axis.text = element_text(size = 20),\n        axis.text.x = element_text(angle = 13)) +\n  scale_y_continuous(limits = c(0,6))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot-1",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Piping into ggplot()",
    "text": "Piping into ggplot()\nPlot the mean protein per cup for each manuf.\n\ncereal |&gt; \n  mutate(manuf = case_when(manuf == \"A\" ~ \"American Home Food Products\", \n                           manuf == \"G\" ~ \"General Mills\", \n                           manuf == \"K\" ~ \"Kelloggs\", \n                           manuf == \"N\" ~ \"Nabisco\", \n                           manuf == \"P\" ~ \"Post\", \n                           manuf == \"Q\" ~ \"Quaker Oats\", \n                           manuf == \"R\" ~ \"Ralston Purina\"))  |&gt; \n  filter(type == \"cold\") |&gt; \n  mutate(pro_per_cup = protein / cups) |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_pro_per_cup = mean(pro_per_cup)) |&gt;  \n  ggplot(aes(x = manuf, \n             y = mean_pro_per_cup)) +\n  geom_point(size = 6) +\n  labs(x = \"Manufacturer\",\n       subtitle = \"Mean Protein per Cup\") +\n  theme_bw() +\n  theme(axis.title.y = element_blank(),\n        axis.title.x  = element_text(size = 24),\n        plot.subtitle = element_text(size = 24),\n        axis.text = element_text(size = 20),\n        axis.text.x = element_text(angle = 13)) +\n  scale_y_continuous(limits = c(0,6))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot-1-output",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot-1-output",
    "title": "Data Cleaning & Manipulation",
    "section": "Piping into ggplot()",
    "text": "Piping into ggplot()"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#putting-it-all-together---lets-practice",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#putting-it-all-together---lets-practice",
    "title": "Data Cleaning & Manipulation",
    "section": "Putting it all Together - Let’s Practice!",
    "text": "Putting it all Together - Let’s Practice!\nHow would you make this plot from the diamonds dataset in ggplot2?\n\n\nCode\ndiamonds |&gt; \n  mutate(category = case_when(price &lt; 1000 ~ \"&lt;$1k\",\n                              price &lt;= 5000 ~ \"$1k-$5k\",\n                              .default = \"&gt;$5k\")) |&gt;\n  ggplot(mapping = aes(x = cut,\n                       fill = cut)) +\n  geom_bar() +\n  facet_wrap(vars(category)) +\n  labs(subtitle = \"Number of Diamonds\",\n       x = \"Cut\",\n       y = \"\",\n       fill = \"Cut\") +\n  theme(axis.text.x = element_blank(),\n        axis.title = element_text(size = 14),\n        legend.title = element_text(size = 14),\n        legend.text = element_text(size = 14),\n        strip.text = element_text(size = 14),\n        title = element_text(size = 14))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#creating-a-game-plan-1",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#creating-a-game-plan-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Creating a Game Plan",
    "text": "Creating a Game Plan\nJust like when creating graphics with ggplot, wrangling data with dplyr involves thinking through many steps and writing many layers of code.\n\nTo help us think through a wrangling problem, we are going to create a game plan before we start writing code.\n\n\nThis might involve…\n\na sketch or flowchart.\na list of dplyr verbs and variable names.\nannotating the head of the dataframe."
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#answering-a-research-question",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#answering-a-research-question",
    "title": "Data Cleaning & Manipulation",
    "section": "Answering a Research Question",
    "text": "Answering a Research Question\n\nThe QuestionThe CodeFormatting Code Output\n\n\nWhat is the median grams of sugars per shelf and the number of cereals per shelf, when we drop the missing values (coded as sugars = -1)?\n\nThe person with the nearest birthday: explain out loud to your neighbor how you would do this manipulation.\n\n\n\ncereal |&gt; \n  select(sugars, shelf) |&gt; \n  filter(sugars != -1) |&gt; \n  group_by(shelf) |&gt; \n  summarise(med_sugars = median(sugars),\n            n_cereal = n())\n\n# A tibble: 3 × 3\n  shelf med_sugars n_cereal\n  &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;\n1     1          3       19\n2     2         12       21\n3     3          6       36\n\n\n\n\nUse kable() from the knitr package and the kableExtra package to format tables in Quarto.\n\ncereal |&gt; \n  select(sugars, shelf) |&gt; \n  filter(sugars != -1) |&gt; \n  group_by(shelf) |&gt; \n  summarise(med_sugars = median(sugars),\n            n_cereal = n()) |&gt; \n  kable()\n\n\n\n\n\n\n\nshelf\nmed_sugars\nn_cereal\n\n\n\n\n1\n3\n19\n\n\n2\n12\n21\n\n\n3\n6\n36"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#data-ethics",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#data-ethics",
    "title": "Data Cleaning & Manipulation",
    "section": "Data Ethics",
    "text": "Data Ethics\n1. What do we mean by data ethics?\n\n\n\n2. Why do we (as statisticians, data scientists, folks working with data) need to think about data ethics?"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#data-ethics-1",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#data-ethics-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Data Ethics",
    "text": "Data Ethics\n1. What do we mean by data ethics?\n\nThe process of evaluating data collection, processing, analysis, and dissemination practices for their adverse impacts on individuals, systems, and society.\n\n2. Why do we (as statisticians, data scientists, folks working with data) need to think about data ethics?\n\nWe have a lot of power to declare truth and fact, hiding behind the black box of data science methods."
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#principles-of-data-ethics",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#principles-of-data-ethics",
    "title": "Data Cleaning & Manipulation",
    "section": "Principles of Data Ethics",
    "text": "Principles of Data Ethics\n\n\nI will not be ashamed to say, “I don’t know”\nI will respect the privacy of my data subjects\nI will remember that my data are not just numbers without meaning or context, but represent real people and situations\nI will interrogate how my work may lead to unintended societal consequences or perpetuate inequity"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#asa-ethical-guidelines",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#asa-ethical-guidelines",
    "title": "Data Cleaning & Manipulation",
    "section": "ASA Ethical Guidelines",
    "text": "ASA Ethical Guidelines\n\nThe American Statistical Association’s Ethical Guidelines for Statistical Practice are intended to help statistics practitioners make decisions ethically.\nThey aim to promote accountability by informing those who rely on statistics of the standards they should expect."
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#additional-resources",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#additional-resources",
    "title": "Data Cleaning & Manipulation",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nMore Data Feminism\nCritical Quantitative Research\n\nResource 1\nResource 2\n\n\n\nI would love to discuss these with you in office hours!"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#lab-3-teacher-evaluations",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#lab-3-teacher-evaluations",
    "title": "Data Cleaning & Manipulation",
    "section": "Lab 3: Teacher Evaluations",
    "text": "Lab 3: Teacher Evaluations"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#dplyr-cheatsheet",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#dplyr-cheatsheet",
    "title": "Data Cleaning & Manipulation",
    "section": "dplyr cheatsheet",
    "text": "dplyr cheatsheet\n\nggplot2 cheatsheet"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#using-kable-for-formatting-in-labs",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#using-kable-for-formatting-in-labs",
    "title": "Data Cleaning & Manipulation",
    "section": "Using kable() for formatting in labs",
    "text": "Using kable() for formatting in labs\n\nWhen printing rows of a data frame or tibble\nneed to load the knitr package at the beginning of your file\nkable() outputs a markdown version of your data\nshould only be used to nicely format data you are printing\n\n\n\ne.g.\n\ncereal_clean &lt;- cereal |&gt; \n  mutate(ratio = sugars / potass)\n  \ncereal_clean |&gt; \n  slice_head(n = 3) |&gt; \n  kable()\n\n\nNOT\n\ncereal_clean &lt;- cereal |&gt; \n  mutate(ratio = sugars / potass) |&gt; \n  slice_head(n = 3) |&gt; \n  kable()"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#to-do",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#to-do",
    "title": "Data Cleaning & Manipulation",
    "section": "To do…",
    "text": "To do…\n\nLab 3: Teacher Evaluations\n\nDue Monday, 4/21 at 11:59pm\n\nRead Chapter 4: Data Joins and Transformations\n\nCheck-in 4.1 + 4.2 due Tuesday 4/22 before class"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#tuesday-april-8",
    "href": "slides/week-2/w2-import-ggplot.html#tuesday-april-8",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Tuesday, April 8",
    "text": "Tuesday, April 8\nToday we will…\n\nStyle Note of the Day\nNew Material\n\nWelcome to the Tidyverse\nLoad External Data\nGraphics (and ggplot2)\nGame Planning\n\nPA 2: Using Data Visualization to Find the Penguins"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#style-note-of-the-day---function-calls",
    "href": "slides/week-2/w2-import-ggplot.html#style-note-of-the-day---function-calls",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Style Note of the Day - Function Calls",
    "text": "Style Note of the Day - Function Calls\n\n\n\n\n\n\nTip\n\n\nName arguments in function calls\nOnly include necessary arguments! (If you are using any default values, no need to repeat them in your function call.)\n\n\n\nGood\n\nmean(1:10, na.rm = TRUE)\nseq(from = 1, to = 100, by = 5)\n\n\nBad\n\nmean(1:10, , TRUE)\nmean(1:10, trim = 0, na.rm = TRUE)\n\nseq(1, 100, 5)"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#tidywho",
    "href": "slides/week-2/w2-import-ggplot.html#tidywho",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Tidywho?",
    "text": "Tidywho?\n\n\n\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.1\n\n\n\n\n\n\nMost of the functionality you will need for an entire data analysis workflow with cohesive grammar\n\n\nhttps://www.tidyverse.org/"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#core-packages",
    "href": "slides/week-2/w2-import-ggplot.html#core-packages",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Core Packages",
    "text": "Core Packages\nThe tidyverse includes functions to:\n\n\n\nRead in data\nreadr\n\n\nVisualize data\nggplot2\n\n\nManipulate rectangular data\ntidyr, dplyr, tibble\n\n\nHandle special variable types\nstringr, forcats , lubridate\n\n\nSupport functional programming\npurrr"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#tidyverse-and-stat-331",
    "href": "slides/week-2/w2-import-ggplot.html#tidyverse-and-stat-331",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Tidyverse and STAT 331",
    "text": "Tidyverse and STAT 331\n\n\nThis version of the course will primarily use tidyverse packages and grammar\nReasoning:\n\nthe tidyverse is as reputable and ubiquitous as base R at this point (in my opinion)\nthe tidyverse is specifically designed to help programmers produce easy-to-read and reproducible analyses and to reduce errors\nthere is excellent documentation!\nI like it!"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#using-the-tidyverse-package",
    "href": "slides/week-2/w2-import-ggplot.html#using-the-tidyverse-package",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Using the tidyverse package",
    "text": "Using the tidyverse package\n\nInstalling/loading the tidyverse package installs/loads all of the “tidyverse” packages\nAvoid redundantly installing or loading packages!\n\n\nDo this:\n\nlibrary(tidyverse)\n\nor\n\nlibrary(readr)\n\n\n\nNot this:\n\nlibrary(tidyverse)\nlibrary(readr)"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#tidy-data",
    "href": "slides/week-2/w2-import-ggplot.html#tidy-data",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Tidy Data",
    "text": "Tidy Data\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#data-science-workflow",
    "href": "slides/week-2/w2-import-ggplot.html#data-science-workflow",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Data Science Workflow",
    "text": "Data Science Workflow"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#common-types-of-data-files",
    "href": "slides/week-2/w2-import-ggplot.html#common-types-of-data-files",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Common Types of Data Files",
    "text": "Common Types of Data Files\nLook at the file extension for the type of data file.\n\n\n\n.csv : “comma-separated values”\n\nName, Age\nBob, 49\nJoe, 40\n\n\n\n.xls, .xlsx: Microsoft Excel spreadsheet\n\nCommon approach: save as .csv\nNicer approach: use the readxl package\n\n\n\n.txt: plain text\n\nCould have any sort of delimiter…\nNeed to let R know what to look for!"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#common-types-of-data-files-1",
    "href": "slides/week-2/w2-import-ggplot.html#common-types-of-data-files-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Common Types of Data Files",
    "text": "Common Types of Data Files\n\nFile AFile BFile CSources\n\n\n\n\n\n\n\n\n\n\n\n\nFile A\nFile B\nFile C"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#loading-external-data",
    "href": "slides/week-2/w2-import-ggplot.html#loading-external-data",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Loading External Data",
    "text": "Loading External Data\nUsing base R functions:\n\nread.csv() is for reading in .csv files.\nread.table() and read.delim() are for any data with “columns” (you specify the separator)."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#loading-external-data-1",
    "href": "slides/week-2/w2-import-ggplot.html#loading-external-data-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Loading External Data",
    "text": "Loading External Data\nThe tidyverse has some cleaned-up versions in the readr and readxl packages:\n\nread_csv() is for comma-separated data.\nread_tsv() is for tab-separated data.\nread_table() is for white-space-separated data.\nread_delim() is any data with “columns” (you specify the separator). The above are special cases.\nread_excel() is specifically for dealing with Excel files.\n\nRemember to load the readr and readxl packages first!"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#take-a-look-at-the-documentation",
    "href": "slides/week-2/w2-import-ggplot.html#take-a-look-at-the-documentation",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Take a look at the documentation",
    "text": "Take a look at the documentation"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#reminder-notebooks-and-file-paths",
    "href": "slides/week-2/w2-import-ggplot.html#reminder-notebooks-and-file-paths",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Reminder: Notebooks and File Paths",
    "text": "Reminder: Notebooks and File Paths\n\nYou have to tell R where to “find” the data you want to read in using a file path.\nQuarto automatically sets the working directory to the be directory where the Quarto document is for any code within the Quarto document\nThis overrides the directory set by an .Rproj\n\n\n\n\n\nPay attention to this when setting relative filepaths\n\nTo “backout” of one directory, use \"../\"\ne.g.: \"../data/dat.csv\""
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#why-do-we-create-graphics",
    "href": "slides/week-2/w2-import-ggplot.html#why-do-we-create-graphics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Why Do We Create Graphics?",
    "text": "Why Do We Create Graphics?"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#grammar-of-graphics-1",
    "href": "slides/week-2/w2-import-ggplot.html#grammar-of-graphics-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\nThe Grammar of Graphics (GoG) is a principled way of specifying exactly how to create a particular graph from a given data set. It helps us to systematically design new graphs.\n\n\nThink of a graph or a data visualization as a mapping…\n\nFROM variables in the data set (or statistics computed from the data)…\nTO visual attributes (or “aesthetics”) of marks (or “geometric elements”) on the page/screen."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#why-grammar-of-graphics",
    "href": "slides/week-2/w2-import-ggplot.html#why-grammar-of-graphics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Why Grammar of Graphics?",
    "text": "Why Grammar of Graphics?\n\nIt’s more flexible than a “chart zoo” of named graphs.\nThe software understands the structure of your graph.\nIt easily automates graphing of data subsets."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#components-of-grammar-of-graphics",
    "href": "slides/week-2/w2-import-ggplot.html#components-of-grammar-of-graphics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Components of Grammar of Graphics",
    "text": "Components of Grammar of Graphics\n\ndata: dataframe containing variables\naes : aesthetic mappings (position, color, symbol, …)\ngeom : geometric element (point, line, bar, box, …)\nstat : statistical variable transformation (identity, count, linear model, quantile, …)\nscale : scale transformation (log scale, color mapping, axes tick breaks, …)\ncoord : Cartesian, polar, map projection, …\nfacet : divide into subplots using a categorical variable"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#how-to-build-a-graphic",
    "href": "slides/week-2/w2-import-ggplot.html#how-to-build-a-graphic",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "How to Build a Graphic",
    "text": "How to Build a Graphic\nComplete this template to build a basic graphic:\n\n\n\nWe use + to add layers to a graphic."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#section",
    "href": "slides/week-2/w2-import-ggplot.html#section",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "",
    "text": "Add dataAdd aestheticsAdd one geom per layer\n\n\nThis begins a plot that you can add layers to:\n\nggplot(data = mpg)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg, \n       aes(x = class, y = hwy))\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg, \n       aes(x = class, y = hwy)) +\n  geom_jitter()\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg, \n       aes(x = class, y = hwy)) +\n  geom_jitter() +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nHow would you make the points be on top of the boxplots?"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#aesthetics",
    "href": "slides/week-2/w2-import-ggplot.html#aesthetics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Aesthetics",
    "text": "Aesthetics\nWe map variables (columns) from the data to aesthetics on the graphic useing the aes() function.\n\nWhat aesthetics can we set (see ggplot2 cheat sheet for more)?\n\n\n\n\nx, y\ncolor, fill\nlinetype\nlineend\nsize\nshape"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#aesthetics-1",
    "href": "slides/week-2/w2-import-ggplot.html#aesthetics-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Aesthetics",
    "text": "Aesthetics\nWe map variables (columns) from the data to aesthetics on the graphic useing the aes() function.\nWhat aesthetics can we set (see ggplot2 cheat sheet for more)?\n\n\n\n\nx, y\ncolor, fill\nlinetype\nlineend\nsize\nshape"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#global-v.-local-aesthetics",
    "href": "slides/week-2/w2-import-ggplot.html#global-v.-local-aesthetics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Global v. Local Aesthetics",
    "text": "Global v. Local Aesthetics\nGlobal Aesthetics\n\nggplot(data = mpg, \n       mapping = aes(x = class, \n                     y = hwy)) +\n  geom_boxplot()\n\n\nLocal Aesthetics\n\nggplot(data = mpg) +\n  geom_boxplot(mapping = aes(x = class, \n                             y = hwy))"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#mapping-v.-setting-aesthetics",
    "href": "slides/week-2/w2-import-ggplot.html#mapping-v.-setting-aesthetics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Mapping v. Setting Aesthetics",
    "text": "Mapping v. Setting Aesthetics\nMapping Aesthetics\n\nggplot(data = mpg) +\n  geom_jitter(mapping = aes(x = class, \n                             y = hwy,\n                             color = class))\n\n\nSetting Aesthetics\n\nggplot(data = mpg) +\n  geom_jitter(mapping = aes(x = class, \n                             y = hwy),\n               color = \"steelblue\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#geometric-objects",
    "href": "slides/week-2/w2-import-ggplot.html#geometric-objects",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Geometric Objects",
    "text": "Geometric Objects\nWe use a geom_xxx() function to represent data points.\n\n\n\none variable\n\ngeom_density()\ngeom_dotplot()\ngeom_histogram()\ngeom_boxplot()\n\n\ntwo variable\n\ngeom_point()\ngeom_line()\ngeom_density_2d()\n\n\nthree variable\n\ngeom_contour()\ngeom_raster()\n\n\n\n\nNot an exhaustive list – see ggplot2 cheat sheet."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#section-1",
    "href": "slides/week-2/w2-import-ggplot.html#section-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "",
    "text": "geom_point()geom_text()geom_line()\n\n\n\n\nCode\nggplot(data = mpg,\n       aes(x = cty,\n           y = hwy,\n           color = class)) +\n  geom_point() +\n  labs(x = \"City (mpg)\", y = \"Highway (mpg)\") +\n  theme(axis.title = element_text(size = 14),\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg,\n       aes(x = cty,\n           y = hwy,\n           color = class)) +\n  geom_text(aes(label = class)) +\n  labs(x = \"City (mpg)\", y = \"Highway (mpg)\") +\n  theme(axis.title = element_text(size = 14),\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg,\n       aes(x = cty,\n           y = hwy,\n           color = class)) +\n  geom_line() +\n  labs(x = \"City (mpg)\", y = \"Highway (mpg)\") +\n  theme(axis.title = element_text(size = 14),\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#creating-a-graphic",
    "href": "slides/week-2/w2-import-ggplot.html#creating-a-graphic",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Creating a Graphic",
    "text": "Creating a Graphic\nTo create a specific type of graphic, we will combine aesthetics and geometric objects.\n\n\nLet’s try it!"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#game-planning",
    "href": "slides/week-2/w2-import-ggplot.html#game-planning",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Game Planning",
    "text": "Game Planning\nWhat: Game Plans! are strategic guides that prompt you to map your coding strategies before implementation.\nHow: Your favorite sketch app, paper + pencil, online whiteboard (Excalidraw!).\nWhy: Tool to connect data and desired graphic before you start coding"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#section-2",
    "href": "slides/week-2/w2-import-ggplot.html#section-2",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "",
    "text": "The GoalGame Planggplot\n\n\nStart with the TX housing data.\n\nMake a plot of median house price over time (including both individual data points and a smoothed trend line), distinguishing between different cities.\n\n\n\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median, color = city)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#faceting",
    "href": "slides/week-2/w2-import-ggplot.html#faceting",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Faceting",
    "text": "Faceting\nExtracts subsets of data and places them in side-by-side plots.\n\nfacet_grid()facet_wrap()\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  facet_grid(cols = vars(city)) +\n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  facet_wrap(vars(city)) +\n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#faceting-1",
    "href": "slides/week-2/w2-import-ggplot.html#faceting-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Faceting",
    "text": "Faceting\nExtracts subsets of data and places them in side-by-side plots.\n\nOptionsScalesLabels\n\n\n\n\nfacet_grid(cols = vars(b)): facet into columns based on b\nfacet_grid(rows = vars(a)): facet into rows based on a\nfacet_grid(rows = vars(a), cols = vars(b)): facet into both rows and columns\nfacet_wrap(vars(b)): wrap facets into a rectangular layout\n\n\n\n\nYou can set scales to let axis limits vary across facets:\n\nfacet_grid(rows = vars(a),\n           cols = vars(b),\n           scales = ______)\n\n\n\n\"fixed\" – default, x- and y-axis limits are the same for each facet\n\"free\" – both x- and y-axis limits adjust to individual facets\n\"free_x\" – only x-axis limits adjust\n\"free_y\" – only y-axis limits adjust\n\n\n\n\nYou can set a labeller to adjust facet labels.\n\nInclude both the variable name and factor name in the labels:\n\nfacet_grid(cols = vars(b), labeller = label_both)\n\nDisplay math symbols in the labels:\n\nfacet_grid(cols = vars(b), labeller = label_bquote(cols = alpha ^ .(b)))\nfacet_grid(cols = vars(b), labeller = label_parsed)"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#example-facet-labels",
    "href": "slides/week-2/w2-import-ggplot.html#example-facet-labels",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Example Facet Labels",
    "text": "Example Facet Labels\n\nExample 1Example 2\n\n\nIncluding the variable and facet names using label_both:\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  facet_grid(cols = vars(city),\n             labeller = label_both) +\n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")\n\n\n\n\n\n\n\n\n\n\n\nIncluding math labels in facet names using label_bquote:\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  facet_grid(cols = vars(city),\n             labeller = label_bquote(cols = .(city)^2)) +\n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#statistical-transformation-stat",
    "href": "slides/week-2/w2-import-ggplot.html#statistical-transformation-stat",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Statistical Transformation: stat",
    "text": "Statistical Transformation: stat\nA stat transforms an existing variable into a new variable to plot.\n\nidentity leaves the data as is.\ncount counts the number of observations.\nsummary allows you to specify a desired transformation function.\n\n\nSometimes these statistical transformations happen under the hood when we call a geom."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#statistical-transformation-stat-1",
    "href": "slides/week-2/w2-import-ggplot.html#statistical-transformation-stat-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Statistical Transformation: stat",
    "text": "Statistical Transformation: stat\n\nstat_count()stat_summary()\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = class)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = class)) +\n  stat_count(geom = \"bar\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = class,\n                     y = hwy)) +\n  stat_summary(geom = \"bar\",\n               fun = \"mean\") +\n  scale_y_continuous(limits = c(0,45))\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = class,\n                     y = hwy)) +\n  stat_summary(geom = \"bar\",\n               fun = \"max\") +\n  scale_y_continuous(limits = c(0,45))"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#position-adjustements",
    "href": "slides/week-2/w2-import-ggplot.html#position-adjustements",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Position Adjustements",
    "text": "Position Adjustements\nPosition adjustments determine how to arrange geom’s that would otherwise occupy the same space.\n\n\nposition = 'dodge': Arrange elements side by side.\nposition = 'fill': Stack elements on top of one another + normalize height.\nposition = 'stack': Stack elements on top of one another.\nposition = 'jitter\": Add random noise to X & Y position of each element to avoid overplotting (see geom_jitter())."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#position-adjustements-1",
    "href": "slides/week-2/w2-import-ggplot.html#position-adjustements-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Position Adjustements",
    "text": "Position Adjustements\n\nggplot(mpg, aes(x = fl, fill = drv)) + \n  geom_bar(position = \"_____\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#plot-customizations",
    "href": "slides/week-2/w2-import-ggplot.html#plot-customizations",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Plot Customizations",
    "text": "Plot Customizations\n\nLabelsThemesScales: Axes TicksScales: Color\n\n\n\n\nCode\nggplot(data = mpg) + \n  geom_jitter(mapping = aes(x = displ, y = hwy, color = cyl)) + \n  labs(x = \"Engine Displacement (liters)\", \n       y = \"Highway MPG\", \n       color = \"Number of \\nCylinders\",\n       title = \"Car Efficiency\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg) + \n  geom_jitter(mapping = aes(x = displ, y = hwy, color = cyl)) + \n  labs(xlab = \"Engine Displacement (liters)\", \n       ylab = \"Highway MPG\", \n       color = \"Number of \\nCylinders\",\n       title = \"Car Efficiency\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg) + \n  geom_jitter(mapping = aes(x = displ, y = hwy, color = cyl)) + \n  labs(x     = \"Engine Displacement (liters)\",\n       color = \"Number of \\nCylinders\",\n       title = \"Car Efficiency\") +\n  scale_y_continuous(\"Highway MPG\", \n                     limits = c(0,50),\n                     breaks = seq(0,50,5))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg) + \n  geom_jitter(mapping = aes(x = displ, y = hwy, color = cyl)) + \n  labs(x    = \"Engine Displacement (liters)\",\n       y    = \"Highway MPG\",\n       color = \"Number of \\nCylinders\",\n       title = \"Car Efficiency\") +\n  scale_color_gradient(low = \"white\", high = \"green4\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#formatting-your-plot-code",
    "href": "slides/week-2/w2-import-ggplot.html#formatting-your-plot-code",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Formatting your Plot Code",
    "text": "Formatting your Plot Code\nIt is good practice to put each geom and aes on a new line.\n\nThis makes code easier to read!\nGenerally: no line of code should be over 80 characters long.\n\n\nBad PracticeGood PracticeSomewhere In Between\n\n\n\nggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = class)) + geom_point() + theme_bw() + labs(x = \"City (mpg)\", y = \"Highway (mpg)\")\n\n\n\n\nggplot(data = mpg, \n       mapping = aes(x = cty, \n                     y = hwy, \n                     color = class)) + \n  geom_point() + \n  theme_bw() + \n  labs(x = \"City (mpg)\", \n       y = \"Highway (mpg)\")\n\n\n\n\nggplot(data = mpg, \n       mapping = aes(x = cty, y = hwy, color = class)) + \n  geom_point() + \n  theme_bw() + \n  labs(x = \"City (mpg)\", y = \"Highway (mpg)\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#lets-practice",
    "href": "slides/week-2/w2-import-ggplot.html#lets-practice",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Let’s Practice!",
    "text": "Let’s Practice!\nHow would you make this plot from the diamonds dataset in ggplot2?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata\naes\ngeom\nfacet"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#creating-a-game-plan",
    "href": "slides/week-2/w2-import-ggplot.html#creating-a-game-plan",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Creating a Game Plan",
    "text": "Creating a Game Plan\nThere are a lot of pieces to put together when creating a good graphic.\n\nSo, when sitting down to create a plot, you should first create a game plan!\n\n\nThis game plan should include:\n\nWhat data are you starting from?\nWhat are your x- and y-axes?\nWhat type(s) of geom do you need?\nWhat other aes’s do you need?"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#section-3",
    "href": "slides/week-2/w2-import-ggplot.html#section-3",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "",
    "text": "Make a Game Plan!ExampleR Code - Baseline PlotR Code - Formatted Plot\n\n\nUse the mpg dataset to create two side-by-side scatterplots of city MPG vs. highway MPG where the points are colored by the drive type (drv). The two plots should be separated by year.\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg,\n       mapping = aes(x = cty,\n                     y = hwy,\n                     color = drv)) +\n  geom_point() +\n  facet_grid(cols = vars(year))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg,\n       mapping = aes(x = cty,\n                     y = hwy,\n                     color = drv)) +\n  geom_point() +\n  facet_grid(cols = vars(year)) +\n  labs(x = \"city MPG\",\n       y = \"highway MPG\") +\n  scale_color_discrete(name = \"drive type\",\n                      labels = c(\"4-wheel\",\"front\",\"rear\"))"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#pa-2-using-data-visualization-to-find-the-penguins",
    "href": "slides/week-2/w2-import-ggplot.html#pa-2-using-data-visualization-to-find-the-penguins",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "PA 2: Using Data Visualization to Find the Penguins",
    "text": "PA 2: Using Data Visualization to Find the Penguins\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#to-do",
    "href": "slides/week-2/w2-import-ggplot.html#to-do",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "To do…",
    "text": "To do…\n\nPA 2: Using Data Visualization to Find the Penguins\n\nDue Thursday (4/10) before class\n\nLab 2: Exploring Rodents with ggplot2\n\nDue Monday (4/14) at 11:59 pm"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#thursday-april-3",
    "href": "slides/week-1/w1-notebooks.html#thursday-april-3",
    "title": "Quarto & Reproducibility",
    "section": "Thursday, April 3",
    "text": "Thursday, April 3\nToday we will…\n\nAnswer Clarifying Questions:\n\nSyllabus?\nChapter 1 Reading?\nPA 1: Find the Mistakes?\n\nNew Material\n\nReproducibility\nScripts + Notebooks\n\nLab 1: Introduction to Quarto"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#reproducibility",
    "href": "slides/week-1/w1-notebooks.html#reproducibility",
    "title": "Quarto & Reproducibility",
    "section": "Reproducibility",
    "text": "Reproducibility\n\n\nIn computing: analyses can be executed again with identical results (either by you or by someone else!)\nDiscussion: Why does it matter?\n\n\n\nAbstruse Goose"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#principles-of-reproducibility",
    "href": "slides/week-1/w1-notebooks.html#principles-of-reproducibility",
    "title": "Quarto & Reproducibility",
    "section": "Principles of Reproducibility",
    "text": "Principles of Reproducibility\nYou can to send your code to someone else, and they can jump in and start working right away.\nThis means:\n\n\nFiles are organized and well-named.\nReferences to data and code work for everyone.\nPackage dependency is clear.\nCode will run the same every time, even if data values change.\nAnalysis process is well-explained and easy to read."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#principles-of-reproducibility-1",
    "href": "slides/week-1/w1-notebooks.html#principles-of-reproducibility-1",
    "title": "Quarto & Reproducibility",
    "section": "Principles of Reproducibility",
    "text": "Principles of Reproducibility\nYou can to send your code to someone else, and they can jump in and start working right away.\nThis means:\n\nFiles are organized and well-named.\nReferences to data and code work for everyone.\nPackage dependency is clear.\nCode will run the same every time, even if data values change.\nAnalysis process is well-explained and easy to read."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#paths",
    "href": "slides/week-1/w1-notebooks.html#paths",
    "title": "Quarto & Reproducibility",
    "section": "Paths",
    "text": "Paths\n\nA path describes where a certain file or directory lives.\n\n\n\n[1] \"/Users/czmann/Documents/teaching/stat331/stat331-calpoly-s25/slides/week-1\"\n\n\nThis file lives in my user files Users/…\n…on my account czmann/ …\n…in my Documents folder …\n…in a series of organized folders."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#absolute-vs.-relative-file-paths",
    "href": "slides/week-1/w1-notebooks.html#absolute-vs.-relative-file-paths",
    "title": "Quarto & Reproducibility",
    "section": "Absolute vs. Relative File Paths",
    "text": "Absolute vs. Relative File Paths\n\nabsolute file path: full path from the root directory on your computer\nrelative file path: path based on the relationship with a current working directory in terms of a hierarchichy of directories\n\n../ is the relative path to a parent directory\nexamples to folow!\n\n\n\n\n\n\n\n\n\nWarning\n\n\nAn absolute file path will only work on your computer!!\n\n\n[1] \"/Users/czmann/Documents/teaching/stat331/stat331-calpoly-s25/slides/week-1\""
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#absolute-vs.-relative-file-paths-1",
    "href": "slides/week-1/w1-notebooks.html#absolute-vs.-relative-file-paths-1",
    "title": "Quarto & Reproducibility",
    "section": "Absolute vs. Relative File Paths",
    "text": "Absolute vs. Relative File Paths"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#working-directories-in-r",
    "href": "slides/week-1/w1-notebooks.html#working-directories-in-r",
    "title": "Quarto & Reproducibility",
    "section": "Working Directories in R",
    "text": "Working Directories in R\n\nYour working directory is the folder that R “thinks it lives” in at the moment.\n\nIf you import or reference files, R will look in the working directory by default\nIf you save things you have created, they save to your working directory by default.\n\n\n\n\ngetwd()\n\n[1] \"/Users/czmann/Documents/teaching/stat331/stat331-calpoly-s25/slides/week-1\"\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nIf you are in practice of using setwd() to set a working directory in R FORGET THIS. We will be using other, better practice methods to set a working directory."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#reproducibility-pulling-it-all-together",
    "href": "slides/week-1/w1-notebooks.html#reproducibility-pulling-it-all-together",
    "title": "Quarto & Reproducibility",
    "section": "Reproducibility: Pulling it all together",
    "text": "Reproducibility: Pulling it all together\nRelative file paths allow someone else to run your code exactly (reproducibly!), as long as they\n\nhave everything organized the exact way that you do and\nthe same working directory\n\n\nEnter R Projects!"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#the-beauty-of-r-projects",
    "href": "slides/week-1/w1-notebooks.html#the-beauty-of-r-projects",
    "title": "Quarto & Reproducibility",
    "section": "The Beauty of R Projects",
    "text": "The Beauty of R Projects\n\nAn R Project is basically a “flag” planted in a certain directory.\n\n\n\nWhen you double click an .Rproj file, it:\n\n\n\n\nOpens RStudio\nSets the working directory to be wherever the .Rproj file lives.\nHas any files open or elements in your environment that you last saved.\nLinks to GitHub, if set up (more on that later!)"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#the-beauty-of-r-projects-1",
    "href": "slides/week-1/w1-notebooks.html#the-beauty-of-r-projects-1",
    "title": "Quarto & Reproducibility",
    "section": "The Beauty of R Projects",
    "text": "The Beauty of R Projects\n\n\nR Projects are great for reproducibility!\n\nYou can send anyone your folder with your .Rproj file and they will be able to run your code on their computer.\n\nR Projects are great for organization\n\nHaving a separate R project for every ..well.. project will keep your analyses separate and organized!\nWhenever you want to work on this class, double click the R Project you created to open everything up"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#scripts",
    "href": "slides/week-1/w1-notebooks.html#scripts",
    "title": "Quarto & Reproducibility",
    "section": "Scripts",
    "text": "Scripts\n\nScripts (File &gt; New File &gt; R Script) are files of code that are meant to be run on their own.\n\n\n\nScripts can be run in RStudio by clicking the Run button at the top of the editor window when the script is open.\nYou can also run code interactively in a script by:\n\nhighlighting lines of code and hitting run.\nplacing your cursor on a line of code and hitting run.\nplacing your cursor on a line of code and hitting ctrl + enter or command + enter."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#notebooks",
    "href": "slides/week-1/w1-notebooks.html#notebooks",
    "title": "Quarto & Reproducibility",
    "section": "Notebooks",
    "text": "Notebooks\nNotebooks are an implementation of literate programming.\n\nThey allow you to integrate code, output, text, images, etc. into a single document.\nE.g.,\n\nR Markdown notebook\nQuarto notebook\nJupyter notebook\n\n\nReproducibility!"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#what-is-markdown",
    "href": "slides/week-1/w1-notebooks.html#what-is-markdown",
    "title": "Quarto & Reproducibility",
    "section": "What is Markdown?",
    "text": "What is Markdown?\nMarkdown is a markup language.\n\nIt uses special symbols and formatting to make pretty documents.\nMarkdown files have the .md extension."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#what-is-quarto",
    "href": "slides/week-1/w1-notebooks.html#what-is-quarto",
    "title": "Quarto & Reproducibility",
    "section": "What is Quarto?",
    "text": "What is Quarto?\nQuarto uses regular Markdown, AND it can run and display R code.\n\n(Other languages, too!)\nQuarto files have the .qmd extension.\n\n\n\nQuarto is the next generation R Markdown"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto---rendering",
    "href": "slides/week-1/w1-notebooks.html#quarto---rendering",
    "title": "Quarto & Reproducibility",
    "section": "Quarto - Rendering",
    "text": "Quarto - Rendering\nTo take your .qmd file and make it look pretty, you have to render it."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#rendering-your-quarto-document",
    "href": "slides/week-1/w1-notebooks.html#rendering-your-quarto-document",
    "title": "Quarto & Reproducibility",
    "section": "Rendering your Quarto Document",
    "text": "Rendering your Quarto Document"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#rendering---what-happens",
    "href": "slides/week-1/w1-notebooks.html#rendering---what-happens",
    "title": "Quarto & Reproducibility",
    "section": "Rendering - What happens?",
    "text": "Rendering - What happens?\nWhen you render:\n\nYour file is saved.\nThe R code written in your .qmd file gets run in order.\n\nIt starts from scratch, even if you previously ran some of the code.\n\nA new file is created.\n\nIf your Quarto file is called “lab1.qmd”, then a file called “lab1.html” will be created.\nThis will be saved in the same folder as “lab1.qmd”."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#rendering---under-the-hood",
    "href": "slides/week-1/w1-notebooks.html#rendering---under-the-hood",
    "title": "Quarto & Reproducibility",
    "section": "Rendering - Under the hood",
    "text": "Rendering - Under the hood\nQuarto CLI (command line interface) orchestrates each step of rendering:\n\nProcess the executable code chunks with either knitr or jupyter.\nConvert the resulting Markdown file to the desired output."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto-components",
    "href": "slides/week-1/w1-notebooks.html#quarto-components",
    "title": "Quarto & Reproducibility",
    "section": "Quarto Components",
    "text": "Quarto Components"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto---front-matter",
    "href": "slides/week-1/w1-notebooks.html#quarto---front-matter",
    "title": "Quarto & Reproducibility",
    "section": "Quarto - Front Matter",
    "text": "Quarto - Front Matter\n\nConfiguration instructions: YAML\nBasic specifications like:\n\nDocument type\nTitle\nAuthor\nDate\n\nFancier specifications (you will explore this in Lab 1!)"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto---code",
    "href": "slides/week-1/w1-notebooks.html#quarto---code",
    "title": "Quarto & Reproducibility",
    "section": "Quarto - Code",
    "text": "Quarto - Code\n\n“code chunks”\noutput of code appears below the chunk\ngood practice: divide your code throughout a document into steps in different chunks\nyou specify how you want Quarto to handle code in each chunk in the final “rendered” document"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#r-code-options-in-quarto",
    "href": "slides/week-1/w1-notebooks.html#r-code-options-in-quarto",
    "title": "Quarto & Reproducibility",
    "section": "R Code Options in Quarto",
    "text": "R Code Options in Quarto\nR code chunk options are included at the top of each code chunk, prefaced with a #| (hashpipe).\n\nThese options control how the following code is run and reported in the final Quarto document.\nR code options can also be included in the front matter (YAML) and are applied globally to the document."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto---markdown",
    "href": "slides/week-1/w1-notebooks.html#quarto---markdown",
    "title": "Quarto & Reproducibility",
    "section": "Quarto - Markdown",
    "text": "Quarto - Markdown\n\nAnything other that code and output should be included as Markdown in a Quarto notebook\nSome Markdown text basics:\n\n*text* – makes italics\n**text** – makes bold text\n# – makes headers\n![ ]( ) – includes images or HTML links\n&lt; &gt; – embeds URLs\n\nFind more Markdown basics here."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#so-many-hashtags",
    "href": "slides/week-1/w1-notebooks.html#so-many-hashtags",
    "title": "Quarto & Reproducibility",
    "section": "#so many hashtags??",
    "text": "#so many hashtags??\n#’s are used in three different ways in Quarto documents…\n\n\nIn MARKDOWN, they define HEADERS\nIn YAML, they are preceded by a pipe | to define R CODE CHUNK OPTIONS\nIn R CODE, they define a COMMENT"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto-working-directory",
    "href": "slides/week-1/w1-notebooks.html#quarto-working-directory",
    "title": "Quarto & Reproducibility",
    "section": "Quarto Working Directory",
    "text": "Quarto Working Directory\n\nQuarto automatically sets the working directory to be where the notebook you are working in is located\nTHIS OVERRIDES R PROJECTS"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto-relative-file-paths",
    "href": "slides/week-1/w1-notebooks.html#quarto-relative-file-paths",
    "title": "Quarto & Reproducibility",
    "section": "Quarto & Relative File Paths",
    "text": "Quarto & Relative File Paths\n\nALWAYSNEVER 💥\n\n\n\nUse relative file paths!\nRemember that when you run code within a .qmd file or render it, the working directory is the directory where the .qmd file is saved.\n\n\n\n\nput something like this at the top of your .qmd file:\n\n\nsetwd(\"/User/chappelroan/Desktop/R_Class/Lab_1/\")\n\n\nSetting working directory by hand = ☠️\nAbsolute file paths = ☠️\nsome one else’s computer will have no idea “where” this working directory is"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto-formats",
    "href": "slides/week-1/w1-notebooks.html#quarto-formats",
    "title": "Quarto & Reproducibility",
    "section": "Quarto Formats",
    "text": "Quarto Formats\nQuarto makes moving between outputs straightforward.\n\nAll that needs to change between these formats is a few lines in the front matter (YAML)!\n\n\n\nDocument\ntitle: \"Lesson 1\"\nformat: html\nPresentation\ntitle: \"Lesson 1\"\nformat: revealjs\n\nWebsite\nproject:\n  type: website\n\nwebsite: \n  navbar: \n    left:\n      - lesson-1.qmd"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#summary---highlights-of-quarto",
    "href": "slides/week-1/w1-notebooks.html#summary---highlights-of-quarto",
    "title": "Quarto & Reproducibility",
    "section": "Summary - Highlights of Quarto",
    "text": "Summary - Highlights of Quarto\n\n\nSupports reproducibility!\n\nCode, output, figures, and text all in one place\n\nConsistent implementation of pretty and handy features across different formats\n\ndocuments, presentations, websites, books, & more\n\nGuardrails that are helpful when learning:\n\nE.g., YAML completion, informative syntax errors, etc.\n\nSupport for other languages like Python, Julia, Observable, and more."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#lab-1-introduction-to-quarto",
    "href": "slides/week-1/w1-notebooks.html#lab-1-introduction-to-quarto",
    "title": "Quarto & Reproducibility",
    "section": "Lab 1: Introduction to Quarto",
    "text": "Lab 1: Introduction to Quarto\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#to-do",
    "href": "slides/week-1/w1-notebooks.html#to-do",
    "title": "Quarto & Reproducibility",
    "section": "To do…",
    "text": "To do…\n\nLab 1: Introduction to Quarto\n\nDue Monday 4/7 at 11:59pm\n\nRead Chapter 2: Importing Data + Basics of Graphics\n\nCheck-in 2.1 + 2.2 due Tuesday (4/8) before class"
  },
  {
    "objectID": "practice-activities/pa3.html",
    "href": "practice-activities/pa3.html",
    "title": "PA 3: Identify the Mystery College 🏫",
    "section": "",
    "text": "Today you will use the dplyr package to clean some data. We will then use that cleaned data to figure out what college Margaret has been accepted to.\nDownload starter .qmd file"
  },
  {
    "objectID": "practice-activities/pa3.html#data-download-package-loading",
    "href": "practice-activities/pa3.html#data-download-package-loading",
    "title": "PA 3: Identify the Mystery College 🏫",
    "section": "Data Download & Package Loading",
    "text": "Data Download & Package Loading\nFirst, we declare our package dependencies and load the data.\n\n\n\n\n\n\nWarning\n\n\n\nThe data loading function read_csv() will give you an outpouring of helpful information about the dataset. If you do not see the word “error”, there is nothing to be concerned about.\n\n\n\nlibrary(tidyverse)\ncolleges &lt;- read_csv(\"https://www.dropbox.com/s/bt5hvctdevhbq6j/colleges.csv?dl=1\")\n\nTake a look at the variables in your downloaded data by running the following code. This code with the str (structure) function reports the data type for each column in the dataset.\n\nstr(colleges, give.attr = FALSE)\n\nspc_tbl_ [7,058 × 27] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ...1                         : num [1:7058] 1 2 3 4 5 6 7 8 9 10 ...\n $ INSTNM                       : chr [1:7058] \"Alabama A & M University\" \"University of Alabama at Birmingham\" \"Amridge University\" \"University of Alabama in Huntsville\" ...\n $ CITY                         : chr [1:7058] \"Normal\" \"Birmingham\" \"Montgomery\" \"Huntsville\" ...\n $ STABBR                       : chr [1:7058] \"AL\" \"AL\" \"AL\" \"AL\" ...\n $ ZIP                          : chr [1:7058] \"35762\" \"35294-0110\" \"36117-3553\" \"35899\" ...\n $ CONTROL                      : num [1:7058] 1 1 2 1 1 1 1 1 1 1 ...\n $ ADM_RATE                     : chr [1:7058] \"0.9027\" \"0.9181\" \"NULL\" \"0.8123\" ...\n $ SAT_AVG                      : chr [1:7058] \"929\" \"1195\" \"NULL\" \"1322\" ...\n $ TUITIONFEE_IN                : chr [1:7058] \"9857\" \"8328\" \"6900\" \"10280\" ...\n $ TUITIONFEE_OUT               : chr [1:7058] \"18236\" \"19032\" \"6900\" \"21480\" ...\n $ UGDS                         : chr [1:7058] \"4824\" \"12866\" \"322\" \"6917\" ...\n $ REGION                       : num [1:7058] 5 5 5 5 5 5 5 5 5 5 ...\n $ DEP_INC_PCT_H2               : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ MD_INC_WDRAW_2YR_TRANS_YR4_RT: chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ IND_COMP_4YR_TRANS_YR4_RT    : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ SD_EARN_WNE_P10              : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ FEMALE_WDRAW_4YR_TRANS_YR6_RT: chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ LO_INC_COMP_2YR_TRANS_YR3_RT : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ NOLOAN_COMP_ORIG_YR4_RT      : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ OPENADMP                     : chr [1:7058] \"2\" \"2\" \"1\" \"2\" ...\n $ PELL_COMP_4YR_TRANS_YR3_RT   : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ DEATH_YR2_RT                 : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ NOLOAN_UNKN_ORIG_YR2_RT      : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ NOT1STGEN_WDRAW_ORIG_YR6_RT  : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ HI_INC_YR8_N                 : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ CUML_DEBT_P90                : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ C100_L4                      : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ..."
  },
  {
    "objectID": "practice-activities/pa3.html#data-cleaning",
    "href": "practice-activities/pa3.html#data-cleaning",
    "title": "PA 3: Identify the Mystery College 🏫",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nNow we will clean the data. Alas, each of the R chunks in this section will cause an error and / or do the desired task incorrectly. Even the chunks that run without error are not correct! You will need to find the mistake and correct it to complete the intended action.\nStep 1: There are too many variables in this data set. We don’t need all of them. Narrow your data set down to only:\n\nINSTNM name of the institution\nCITY city, STABBR state, and ZIP ZIP code of the institution\nADM_RATE admissions rate\nSAT_AVG average SAT score\nUGDS number of undergraduate students\nTUITIONFEE_IN in- and TUITIONFEE_OUT out-of-state tuition\nCONTROL Whether the school is public or private\nREGION region of the school.\n\n\ncolleges_clean &lt;- colleges | &gt;  \n  select(INSTNM, CITY, STABBR, ZIP,\n         ADM_RATE, SAT_AVG, UGDS,\n         TUITIONFEE_IN, TUITIONFEE_OUT\n         CONTROL, REGION) \n\nError in parse(text = input): &lt;text&gt;:1:30: unexpected '&gt;'\n1: colleges_clean &lt;- colleges | &gt;\n                                 ^\n\n\nStep 2: Remove the schools that are for-profit (category 3), keeping public (category 1) and private schools (category 2).\n\ncolleges_clean &lt;- colleges_clean |&gt; \n  filter(CONTROL == 1, CONTROL == 2)\n\nError: object 'colleges_clean' not found\n\n\nStep 3: Adjust the appropriate variables to be numeric, using as.numeric().\n\ncolleges_clean &lt;- colleges_clean |&gt; \n  mutate(TUITIONFEE_IN  = numeric(TUITIONFEE_IN),\n         TUITIONFEE_OUT = numeric(TUITIONFEE_OUT),\n         SAT_AVG        = numeric(SAT_AVG),\n         UGDS           = numeric(UGDS),\n         ADM_RATE       = numeric(ADM_RATE)) \n\nError: object 'colleges_clean' not found\n\n\nStep 4: Adjust the appropriate variables to be factors, using as.factor().\n\n\n\n\n\n\nNote\n\n\n\nWe will talk more about special data types (including factors) in a few weeks.\n\n\n\ncolleges_clean &lt;- colleges_clean |&gt;\n  mutate(CONTROL = as.character(CONTROL),\n         REGION  = as.character(REGION))\n\nError: object 'colleges_clean' not found\n\n\nStep 5: Create a new variable called TUITION_DIFF which contains the difference between out-of-state and in-state costs.\n\ncolleges_clean |&gt; \n    TUITION_DIFF = TUITIONFEE_OUT - TUITIONFEE_IN\n\nError in TUITION_DIFF: The pipe operator requires a function call as RHS (&lt;input&gt;:2:5)\n\n\nStep 6: Create a new variable called TOTAL_IN which contains the total amount of money made from tuition per year. (Note, this is just an approximation by mutliplying the number of undergrads by the in-state tuition)\n\ncolleges_clean &lt;- colleges_clean |&gt; \n    select(TOTAL_IN = UGDS x TUITIONFEE_IN)\n\nError in parse(text = input): &lt;text&gt;:2:28: unexpected symbol\n1: colleges_clean &lt;- colleges_clean |&gt; \n2:     select(TOTAL_IN = UGDS x\n                              ^\n\n\nStep 7: Remove every row with missing data.\n\n\n\n\n\n\nWarning\n\n\n\nThis is not always a great idea! Usually, even if some of the information is missing, we don’t want to throw out the entire row. This time, however, we’ll be lazy.\n\n\n\ncolleges_clean &lt;- colleges_clean |&gt; \n  drop.na()\n\nError in drop.na(colleges_clean): could not find function \"drop.na\"\n\n\nLastly, notice that each of these steps started with\n\ncolleges_clean &lt;- colleges_clean |&gt; ...\n\nThat is pretty redundant! Instead, we could perform all these tasks as one long “pipeline.”\nStep 8: Combine your (fixed) code chunks into a single code chunk that carries out all of the steps necessary to clean the data and save it as colleges_clean.\n\n\n\n\n\n\nTip\n\n\n\nThink about coding efficiency – you should not have multiple calls to the same function!\n\n\n\n# Code combining ALL of your previous steps into ONE pipeline"
  },
  {
    "objectID": "practice-activities/pa1.html",
    "href": "practice-activities/pa1.html",
    "title": "PA 1: Find the Mistakes",
    "section": "",
    "text": "Today you will be creating and manipulating vectors, lists, and data frames to uncover a top secret message.\nSome advice:"
  },
  {
    "objectID": "practice-activities/pa1.html#access",
    "href": "practice-activities/pa1.html#access",
    "title": "PA 1: Find the Mistakes",
    "section": "Access",
    "text": "Access\nYou can access PA1: Find the Mistakes in RStudio in one of two ways:\n\nClick here to access a Posit Cloud project.\n\n\nNote: if you do not have a Posit Cloud account, you will be asked to create one.\nNote: make sure you save a permanent version!\n\n\nIf you have already installed R, RStudio, and Quarto, you can download the practice activity template here.\n\n\nMake sure to move this from your Downloads folder into your stat-331/practice-activities folder (or equivalent)!"
  },
  {
    "objectID": "practice-activities/pa1.html#part-one-setup",
    "href": "practice-activities/pa1.html#part-one-setup",
    "title": "PA 1: Find the Mistakes",
    "section": "Part One: Setup",
    "text": "Part One: Setup\nEach of the following R chunks will cause one or more errors and / or do the desired task incorrectly. Find the mistake, and correct it to complete the intended action.\n\nCreate vectors containing the upper case letters, lower case letters, and some punctuation marks.\n\n\nlower_case &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\",\n                \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\")\nupper_case &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\" \"I\", \"J\", \"K\", \"L\", \"M\",\n                \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\")\npunctuation &lt;- c(\".\", \",\", \"!\", \"?\", \"'\", '\"', \"(\", \")\", \" \", \"-\", \";\", \":\")\n\nError in parse(text = input): &lt;text&gt;:3:56: unexpected string constant\n2:                 \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\")\n3: upper_case &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\" \"I\"\n                                                          ^\n\n\n\nMake one long vector containing all the symbols.\n\n\nmy_symbols &lt;- cbind(lower_case, upper_case, punctuation)\n\nError: object 'lower_case' not found\n\n\n\nTurn the my_symbols vector into a data frame, with one column named “Symbol”.\n\n\nmy_symbols &lt;- dataframe(Symbol = my_symbols)\n\nError in dataframe(Symbol = my_symbols): could not find function \"dataframe\"\n\n\n\nFind the total number of symbols we have in our data frame.\n\n\nlen &lt;- length(my_symbols)\n\nError: object 'my_symbols' not found\n\n\n\nCreate a new variable in your dataframe that assigns a number to each symbol.\n\n\nmy_symbols%Num &lt;- 1:len\n\nError in parse(text = input): &lt;text&gt;:1:11: unexpected input\n1: my_symbols%Num &lt;- 1:len\n              ^"
  },
  {
    "objectID": "practice-activities/pa1.html#part-two-decoding-the-secret-message.",
    "href": "practice-activities/pa1.html#part-two-decoding-the-secret-message.",
    "title": "PA 1: Find the Mistakes",
    "section": "Part Two: Decoding the secret message.",
    "text": "Part Two: Decoding the secret message.\nThis chunk will load up the encoded secret message as a vector.\n\nlibrary(readr)\ntop_secret &lt;- read_csv(\"https://www.dropbox.com/s/k72h1zewk4gtqep/PA_Secret_Code?dl=1\", \n                       col_names = FALSE)$X1\n\nBy altering this top secret set of numbers, you will be able to create a message. Write your own code to complete the steps, in the order given below.\nHint: To update a vector after performing an operation, you overwrite the existing object with the updated version. This looks something like this:\nx &lt;- x + 12,\nwhere the original value(s) in x have had 12 added to them, and the resulting values are put back in to the object named x.\nBe careful not to overwrite more than you intend. If this happens, go back and re-read in the raw data and run and any subsequent code chunks to start fresh with the top_secret vector.\n\nAdd 14 to every number (completed for you!)\n\n\n## Code completed for you\ntop_secret &lt;- top_secret + 14\n\n\nMultiply every number by 18, then subtract 257 (watch your order of operations!)\n\n\n## Code to carry out step 1\n\n\nUse the exp() function to exponentiate every number.\n\n\n## Code to carry out step 2\n\n\nSquare every number.\n\n\n## Code to carry out step 3\n\nCheckpoint: Headquarters has informed you that at this stage of decoding, there should be 352 numbers in the secret message that are below 17. The code below verifies that this is true for your top_secret object!\nHint: This is what is called a “relational” comparison, where you compare an object to a number and R will give you a vector of TRUEs and FALSEs based on whether the comparison is / is not met. You can then use these TRUEs and FALSEs as numbers, since TRUE = 1 and FALSE = 0 in R land.\n\n# Write code to verify that there are 352 numbers with values **below** 17\n\nNext, carry out the following steps:\n\nTurn your vector of numbers into a matrix with 5 columns. (I would recommend naming this something different than top_secret and informative such as secret_mat.)\n\n\n## Write code to carry out step 4.\n\n\nSeparately from your top secret numbers, create a vector of all the even numbers between 1 and 382. Name it evens. That is, evens should contain 2, 4, 6, 8 …, 382.\n\n\n## Write code to carry out step 5.\n\n\nSubtract the “evens” vector from the first column of your secret message matrix.\n\n\n## Write code to carry out step 6.\n\n\nSubtract 100 from all numbers in the 18-24th rows of the 3rd column of your secret message matrix.\n\n\n## Complete the code to carry out step 7.\n\n\nMultiply all numbers in the 4th and 5th column of your secret message matrix by 2.\n\n\n## Code to carry out step 8.\n\n\nTurn your secret message matrix back into a vector.\n\n\n## Write code to carry out step 9.\n\nCheckpoint: Headquarters has informed you that at this stage of decoding, all numbers in indices 500 and beyond are below 100. The code below verifies that this is true for your top_secret object!\n\n# Write code to verify that indices 500 and beyond have values **below** 100\n\n\nTake the square root of all numbers in indices 38 to 465.\nUse the round() function to round all numbers to the nearest whole number.\nReplace all instances of the number 39 with 20.\n\n\nThis step requires another relational comparison, but this time it is equality. Equality in R is checked with a double equal sign rather than a single equal sign!\n\nCheckpoint: Headquarters has informed you that your final message should have 344 even numbers.\nHint: Checking for divisibility is an interesting operation that isn’t done much in R. Modulus is the operation you are interested in, where you are checking for whether the numbers are divisible by 2, with no remainder. See what you can find about modulus in R!\n\n# Code to verify how many even numbers are in your top_secret vector\n# Should be 344!"
  },
  {
    "objectID": "practice-activities/pa1.html#part-three-the-secret-message",
    "href": "practice-activities/pa1.html#part-three-the-secret-message",
    "title": "PA 1: Find the Mistakes",
    "section": "Part Three: The secret message!",
    "text": "Part Three: The secret message!\nUse your final vector of numbers as indices for my_symbols to discover the final message, by running the following code. Note: if your vector of numbers is not named top_secret at this point, change the code below appropriately to use your correct vector!\n\nstringr::str_c(my_symbols$Symbol[top_secret], collapse = \"\")\n\nError: object 'my_symbols' not found\n\n\nGoogle the first line of this message, if you do not recognize it, to see what poem it is.\nYou will enter your answer in the PA1 Canvas assignment."
  },
  {
    "objectID": "labs/lab2/lab2-ggplot.html",
    "href": "labs/lab2/lab2-ggplot.html",
    "title": "Lab 2: Exploring Rodents with ggplot2",
    "section": "",
    "text": "Seeking Help\n\n\n\nPart of learning to program is learning from a variety of resources. Thus, I expect you will use resources that you find on the internet. There is, however, an important balance between copying someone else’s code and using their code to learn. Therefore, if you use external resources, I want to know about it. You can “inform” me of any resources you used by pasting the link to the resource in a code comment next to where you used that resource.\nAdditionally, you are permitted and encouraged to work with your peers as you complete lab assignments, but you are expected to do your own work. Copying from each other is cheating, and letting people copy from you is also cheating. Please don’t do either of those things.\nDownload starter .qmd file here.\nDownload the data - surveys.csv - file here."
  },
  {
    "objectID": "labs/lab2/lab2-ggplot.html#scatterplot",
    "href": "labs/lab2/lab2-ggplot.html#scatterplot",
    "title": "Lab 2: Exploring Rodents with ggplot2",
    "section": "Scatterplot",
    "text": "Scatterplot\n\n# Scatterplot code for question s 4-8! \n\n4. First, let’s create a scatterplot of the relationship between weight (on the \\(x\\)-axis) and hindfoot_length (on the \\(y\\)-axis).\nWe can see there are a lot of points plotted on top of each other. Let’s try and modify this plot to extract more information from it.\n5. Let’s add transparency (alpha) to the points, to make the points more transparent and (possibly) easier to see.\nDespite our best efforts there is still a substantial amount of overplotting occurring in our scatterplot. Let’s try splitting the dataset into smaller subsets and see if that allows for us to see the trends a bit better.\n6. Facet your scatterplot by species.\n7. No plot is complete without axis labels and a title. Include reader friendly labels and a title to your plot.\nIt takes a larger cognitive load to read text that is rotated. It is common practice in many journals and media outlets to move the \\(y\\)-axis label to the top of the graph under the title.\n8. Specify your \\(y\\)-axis label to be empty and move the \\(y\\)-axis label into the subtitle. You may overwrite your code from Q7."
  },
  {
    "objectID": "labs/lab2/lab2-ggplot.html#boxplots",
    "href": "labs/lab2/lab2-ggplot.html#boxplots",
    "title": "Lab 2: Exploring Rodents with ggplot2",
    "section": "Boxplots",
    "text": "Boxplots\n9. Sketch out (by hand or using Excalidraw) a game plan for creating side-by-side boxplots to visualize the distribution of weight within each species. Include an image of your game plan. This can take on your own flavor! The ideas is that you are thinking before coding. I recommend saving this in the same folder as your .qmd file.\n \n\n# Boxplot code for question 10 - 15!\n\n10. Implement your game plan to create side-by-side boxplots to visualize the distribution of weight within each species.\nA fundamental complaint of boxplots is that they do not plot the raw data. However, with ggplot we can add the raw points on top of the boxplots!\n11. Add another layer to your previous plot that plots each observation.\nAlright, this should look less than optimal. Your points should appear rather stacked on top of each other. To make them less stacked, we need to jitter them a bit, using geom_jitter().\n12. Remove the previous layer and include a geom_jitter() layer instead. (You can overwrite your code for Q11)\nThat should look a bit better! But its really hard to see the points when everything is black.\n13. Set the color aesthetic in geom_jitter() to change the color of the points and add set the alpha aesthetic to add transparency.\n\n\n\n\n\n\nNote\n\n\n\nYou are welcome to use whatever color you wish! Some of my favorites are “orange3” and “steelblue”.\n\n\nGreat! Now that you can see the points, you should notice something odd: there are two colors of points still being plotted. Some of the observations are being plotted twice, once from geom_boxplot() as outliers and again from geom_jitter()!\n14. Inspect the help file for geom_boxplot() and see how you can remove the outliers from being plotted by geom_boxplot(). Make this change in your code!\nSome small changes can make big differences to plots. One of these changes are better labels for a plot’s axes and legend.\n15. Modify the \\(x\\)-axis and \\(y\\)-axis labels to describe what is being plotted. Be sure to include any necessary units! You might also be getting overlap in the species names – use theme(axis.text.x = ____) or theme(axis.text.y = ____) to turn the species axis labels 45 degrees. (You will need to look at the documentation or Google to find the syntax for this!)\nSome people (and journals) prefer for boxplots to be stacked with a specific orientation! Let’s practice changing the orientation of our boxplots.\n16. Copy-paste your boxplot code from above. Flip the orientation of your boxplots. If you created horizontally stacked boxplots, your boxplots should now be stacked vertically. If you had vertically stacked boxplots, you should now stack your boxplots horizontally!\n\n# Copy-paste boxplot code. Then modify for question 16!\n\nNotice how vertically stacked boxplots make the species labels more readable than horizontally stacked boxplots. This is good practice!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Computing in R",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the quarter. Note that this schedule will be updated as the quarter progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDay\nTopic / Reading\nSlides\nStarter Notes\nPractice Activity\nLab\n\n\n\n\n1\nTue, 4/1\n1: Introduction\nSyllabus & Intro to R\nWeek 1\nPA 1\n\n\n\n\nThu, 4/3\n\nIntro to Quarto\n\n\nLab 1\n\n\n2\nTue, 4/8\n2: Basics of Graphics\nImporting Data + Graphics with ggplot2\nWeek 2\nPA 2\n\n\n\n\nThu, 4/10\n\nMore Graphics!\n\n\nLab 2\n\n\n3\nTue, 4/15\n3: Data Cleaning + Manipulation\nData Cleaning with dplyr\nWeek 3\nPA 3\n\n\n\n\nThu, 4/17\nData Feminism: The Numbers Don’t Speak for Themselves\nExtending dplyr + Data Ethics\n\n\nLab 3\n\n\n4\nTue, 4/22\n4: Data Joins + Transformations\nData Joins + Pivots\nWeek 4\nPA 4\n\n\n\n\nThu, 4/24\n\nFactor Variables\n\n\nLab 4\n\n\n5\nTue, 4/29\n5: Special Data Types\nStrings\nWeek 5\nPA 5.1\n\n\n\n\nThu, 5/1\n\nDates\n\nPA 5.2\nLab 5\n\n\n6\nTue, 5/6\n6: Version Control\nVersion Control\n\nPA 6\n\n\n\n\nThu, 5/8\n\nMidterm Exam\n\n\n\n\n\n7\nTue, 5/13\n7: Writing Functions\nFunctions\nWeek 7\nPA 7\n\n\n\n\nThu, 5/15\n\nMore Functions\n\n\nLab 7\n\n\n8\nTue, 5/20\n8: Iteration and Simulation\nIteration\nWeek 8\nPA 8.1\n\n\n\n\nThu, 5/22\n\nSimulation + Tables\n\nPA 8.2\nLab 8\n\n\n9\nTue, 5/27\nNO\nCLASS\nENJOY\nTHE\nBREAK!\n\n\n\nThu, 5/29\n9: Linear Regression\nLinear Regression\nWeek 9\nPA 9\nLab 9\n\n\n10\nTue, 6/3\n10: Model Validation + More Graphics\nModel Validation + Maps\n\nPA 10\n\n\n\n\nThu, 6/5\n\nWrap-Up",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "course-info/discord-instructions.html",
    "href": "course-info/discord-instructions.html",
    "title": "Course Discord Instructions",
    "section": "",
    "text": "We’ll be using Discord to interact with our peers and group members.\nDiscord is a platform for text chatting, voice chatting, and screen sharing."
  },
  {
    "objectID": "course-info/discord-instructions.html#join-the-server",
    "href": "course-info/discord-instructions.html#join-the-server",
    "title": "Course Discord Instructions",
    "section": "1 Join the server",
    "text": "1 Join the server\nJoin the Stat 331/531 Server to start experimenting with the interface.\nWhen you join the server, you will be given some suggestions to get started.\n\nI recommend you click through these - and in particular, it is probably a good idea to download the desktop version of Discord, and perhaps to install it on your phone if you wish."
  },
  {
    "objectID": "course-info/discord-instructions.html#set-up-your-account",
    "href": "course-info/discord-instructions.html#set-up-your-account",
    "title": "Course Discord Instructions",
    "section": "2 Set up your account",
    "text": "2 Set up your account\n\nVerify your email\nTo use this Discord server, you must have a verified email.\nNobody (including your professors) will be able to see this email, and it does not have to be your Cal Poly email. This is simply to keep the server from being overrun by temporary accounts.\n\n\nCreate your identity\nThe first thing you should do is decide what name and picture you would like to use.\n\nI would like to strongly encourage you to use your real name and picture, so that everyone can get to know you. This also helps me know who I am talking to! However, if you prefer to remain anonymous, you are free to do so.\n\n(Please do not be like Regina and use the name of another student, however!\nThis kind of impersonation will result in a permanent ban from the server.)\n\n\nDecide about privacy and notifications\nThe default settings on the channel are probably just fine for you.\nFeel free to make any changes that work for you, though.\nYou can change your message notifications:\n\nYou can edit your privacy settings, although most things are already private:"
  },
  {
    "objectID": "course-info/discord-instructions.html#using-the-channels",
    "href": "course-info/discord-instructions.html#using-the-channels",
    "title": "Course Discord Instructions",
    "section": "3 Using the Channels",
    "text": "3 Using the Channels\nThe server is made up of many channels. Some are text chatrooms, while some are “Voice Channels” that connect you via audio to everyone else in the channel.\n\nText Channels\nUse the #general channel for anything and everything:\n\nIf your question is about course logistics, rather than the material itself, consider using the #class-logistics channel:\n\nYou can use the specific weekly channels to ask questions about the material…\n\n… or the specific lab assignment.\n\nNotice that you can use tick marks (```), like in Markdown, to make your code appear in a formatted code box.\n\n\nPrivate messages\nIt is also easy to send private messages, to your professor or to each other. These private messages can also easily be used to launch a private video chat and / or screen sharing."
  },
  {
    "objectID": "course-info/discord-instructions.html#creating-your-own-server",
    "href": "course-info/discord-instructions.html#creating-your-own-server",
    "title": "Course Discord Instructions",
    "section": "4 Creating your own server",
    "text": "4 Creating your own server\nLast but not least - for the teams you are a part of, you may want to use Discord to communicate with each other about the weekly assignments. You can do this by creating your own server! You can easily hop between servers during work parties, to ask each other questions or just to take a break and chat about life."
  },
  {
    "objectID": "course-info/course-resources.html",
    "href": "course-info/course-resources.html",
    "title": "R Resources",
    "section": "",
    "text": "Tip\n\n\n\nClick on the link to access the R Cheatsheet related to a specific topic / package!\n\n\n\nWeekly R Cheatsheets\nWeek 1\n\nRStudion IDE\nQuarto\nBase R\nGit & GitHub\n\nWeek 2\n\nData Visualization with ggplot2\nData Import with readr\n\nWeek 3\n\nData Wrangling with dplyr\n\nWeek 4\n\nData Tidying with tidyr\nFactors with forcats\n\nWeek 5\n\nDates with lubridate\nStrings with stringr\nRegular Expressions\n\nWeek 7\n\nTidy Evaluation\n\nWeek 8\n\nIteration with purrr",
    "crumbs": [
      "Course information",
      "R Resources"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html",
    "href": "course-info/syllabus-w25.html",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "",
    "text": "Dr. Charlotte Zilber Mann\nYou can call me Professor, Professor/Prof. C. or Dr. C.\n Email: czmann@calpoly.edu\n Office: Building 25 Office 201\nEmail:\n\nOnly email me with your @calpoly.edu email – I cannot respond to other email addresses\nStart your email subject line with “[STAT 331]”\nI will do my best to respond within 24 hours during the week\nIf you send me an email past 7pm or on the weekend, I will likely not respond until the morning of the next working day\nYou should only email me about things that relate to you as an individual. Any other questions should be posted on the course Discord (more details below).\n\nCourse Discord Page:\nFor questions of general interest, such as course clarifications or conceptual questions, please use the course Discord page (you will join this Week 1). If you have a question – someone else in class does too! I encourage you all to respond to each other. I will do my best to check Discord at least twice each weekday during working hours (8-6) to ensure that questions are being answered accurately.\nI encourage you to give your post a concise and informative initial sentence, so that other people can find it. For example, “How do I color bars in a barplot with ggplot?” is a better opening sentence than “help with plotting”.\nYou may post snippets of your code and errors on Discord, but please do not post full solutions to lab assignments.\n While your posts are not anonymous, in this case there is no such thing as a bad question!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#communication",
    "href": "course-info/syllabus-w25.html#communication",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "",
    "text": "Dr. Charlotte Zilber Mann\nYou can call me Professor, Professor/Prof. C. or Dr. C.\n Email: czmann@calpoly.edu\n Office: Building 25 Office 201\nEmail:\n\nOnly email me with your @calpoly.edu email – I cannot respond to other email addresses\nStart your email subject line with “[STAT 331]”\nI will do my best to respond within 24 hours during the week\nIf you send me an email past 7pm or on the weekend, I will likely not respond until the morning of the next working day\nYou should only email me about things that relate to you as an individual. Any other questions should be posted on the course Discord (more details below).\n\nCourse Discord Page:\nFor questions of general interest, such as course clarifications or conceptual questions, please use the course Discord page (you will join this Week 1). If you have a question – someone else in class does too! I encourage you all to respond to each other. I will do my best to check Discord at least twice each weekday during working hours (8-6) to ensure that questions are being answered accurately.\nI encourage you to give your post a concise and informative initial sentence, so that other people can find it. For example, “How do I color bars in a barplot with ggplot?” is a better opening sentence than “help with plotting”.\nYou may post snippets of your code and errors on Discord, but please do not post full solutions to lab assignments.\n While your posts are not anonymous, in this case there is no such thing as a bad question!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-logistics",
    "href": "course-info/syllabus-w25.html#course-logistics",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Logistics",
    "text": "Course Logistics\nClass Meeting Times: Tuesdays / Thursdays\n\nSection 70: 9:10am - 11:00am\nSection 71: 12:10pm - 2:00pm\n\nRoom: - Section 70: 38-122 (Math & Science) - Section 71: 180-272 (Baker Center - Math & Science)\nOffice Hours are held in my office (25-201) during the following times:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOffice hours are for you! During this time, I am available to talk about anything related to the course.\nOffice hours are also helpful for me… This is my chance to get to know you all better and also get a good idea of what is most challenging and most interesting to you.\nFriday office hours will be remote by default, but can be in-person on request.\nSee this resource for ways that students use office hours.\nOne thing I will not do during office hours is tell you whether an answer to a problem is “correct” or not. We can talk through your thinking that led to your solution, but will leave the final assessment to once you have submitted an assignment.\nNote that office hours are not just for when you have content questions. Stop by to introduce yourself, ask questions about the broader field of statistics, or share what you are working on!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-description",
    "href": "course-info/syllabus-w25.html#course-description",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Description",
    "text": "Course Description\nStat 335/531 provides you with an introduction to programming for data and statistical analysis. The course covers basic programming concepts necessary for statistics, good computing practice, and use of built-in functions to complete basic statistical analyses.\nPrerequisites\nEntrance to STAT 331/531 requires successful completion of:\n\na Stat II qualifying course, and\nan introductory programming course.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#learning-objectives",
    "href": "course-info/syllabus-w25.html#learning-objectives",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThis course will teach you the foundations of statistical computing principles in the language of R.\nAfter taking this course, you will be able to:\n\nWork with the RStudio Integrated development environment (IDE) and quarto documents.\nImport, manage, and clean data from a wide variety of data sources.\nVisualize and summarize data for informative exploratory data analysis and presentations.\nWrite efficient, well-documented, and tidy R code.\nProgram random experiments and simulations from probability models.\n\nAdditionally, it is my hope that you will learn to:\n\nExtend your R skills independently through documentation and online resources.\nBe thoughtful, deliberate, and ethical in your use of R and similar tools.\nUse R to be playful, creative, and fun!\nContribute to and participate in the R Open Source Community.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-materials",
    "href": "course-info/syllabus-w25.html#course-materials",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Materials",
    "text": "Course Materials\nCourse Webpage (Canvas)\nAll course material will be made available on our Canvas page, including check-ins, practice activities, lab assignments, challenges, review questions, and selected solutions. Canvas will also contain detailed weekly schedules throughout the term. You are responsible for checking the Canvas page on a regular basis.\nI will also be posting material on this website for easy access to materials. Please note that this website does not include deadlines and all material will additionally be posted to Canvas. Canvas will always contain the most updated information about course deadlines and details, so always defer to these.\nTextbook\n https://manncz.github.io/stat331-calpoly-text/.\nThere is an abundance of free online resources for learning programming and R. Therefore, the primary text for this course is a compilation of various resources - it is available online for free. It is a work in progress, so expect changes and updates throughout the course.\nThis text was constructed by Dr. Emily Robinson and was modified from material by Dr. Susan VanderPlas. See Statistical Computing using R and Python for her course book with integration of content and videos from Dr. Allison Theobold and Dr. Kelly Bodwin.\nIn addition, you may find it useful to reference some of the following resources that Dr. Robinson consulted while assembling the text. Most are available online for free.\n\nR for Data Science (2nd edition)\nModern Dive\nIntroduction to Modern Statistics\nAdvanced R\n\nComputing\n Although you may always work on the computers in the classroom, I strongly recommend that you use your own personal laptop for this course if you have one.\nWe will (obviously) be using the R statistical software throughout this course. In addition, you are required to use RStudio, a companion integrated developer environment (IDE). Both R and RStudio are freely available. Download instructions are available on Canvas.\n\n\n\n\n\n\nWarning\n\n\n\nChromebooks and iPads will not be sufficient to use R. If this requirement is limiting for you, please contact me ASAP.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#class-schedule-topic-outline",
    "href": "course-info/syllabus-w25.html#class-schedule-topic-outline",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Class Schedule & Topic Outline",
    "text": "Class Schedule & Topic Outline\nThis schedule is tentative and subject to change.\n\n\n\n\n\nNote: Tuesday, May 27th will follow a Monday class schedule.\n\n\n\n\n\n\n\nTentative schedule of class topics and important due dates\n\n\nDate\nTopic\n\n\n\n\nApr 1, Apr 3\nIntroduction to R\n\n\nApr 8, Apr 10\nBasics of Graphics\n\n\nApr 15, Apr 17\nData Cleaning and Manipulation\n\n\nApr 22, Apr 24\nData Transformations + Factors\n\n\nApr 29, May 1\nSpecial Data Types\n\n\nMay 6\nVersion Control\n\n\nMay 8\nMidterm Exam\n\n\nMay 13, May 15\nFunctions\n\n\nMay 20, May 22\nFunctional Programming\n\n\nMay 29\nSimulation\n\n\nJun 3, Jun 5\nTBA\n\n\nJun 6\nProject Final Report Due\n\n\nJun 10\nFinal Exam (70) 10:10am - 1:00 pm\n\n\nJun 12\nFinal Exam (71) 10:10am - 1:00 pm",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#assessments",
    "href": "course-info/syllabus-w25.html#assessments",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Assessments",
    "text": "Assessments\n\nGeneral Evaluation Criteria\nIn every assignment, discussion, and written component of this class, you are expected to demonstrate that you are intellectually engaging with the material. I will evaluate you based on this engagement, which means that technically correct but low effort answers which do not demonstrate engagement or understanding will receive no credit.\nWhen you answer questions in this class, your goal is to show that you either understand the material or are actively engaging with it. If you did not achieve this goal, then your answer is incomplete, regardless of whether or not it is technically correct. This is not to encourage you to add unnecessary complexity to your answer - simple, elegant solutions are always preferable to unwieldly, complex solutions that accomplish the same task.\nWhile this is not an English class, grammar and spelling are important, as is your ability to communicate technical information in writing; both of these criteria will be used in addition to assignment-specific rubrics to evaluate your work.\n\n\nFormative Assessments\n\nCheck-ins\nEach week, you will find short Check-In questions or tasks throughout the text to make sure you are prepared for class that week. Check-Ins are based on the material in each week’s reading from the textbook. Note that the Canvas Check-in quizzes can be submitted two two times and your highest score will be kept, so you should get close to 100% on this part of the course!\n\nCheck-ins are (typically) due Tuesdays before class.\n\nSection 70: 9:00am\nSection 71: 12:00pm\n\n\n\n\nPractice Activities\nMost Tuesdays’s, you will be given a Practice Activity to complete, to get the hang of the week’s necessary R skills. These activities will always result in a single, straightforward correct answer, that you will submit via Canvas (two attempts, the average score being kept).\nSince these activities are intended to be your first attempt at new skills, they are meant to be done with help from me and your peers. Therefore, you will always be given some time in class to work on them.\n\nPractice Activities are (typically) due Thursdays before class.\n\nSection 70: 9:00am\nSection 71: 12:00pm\n\n\n\n\nLab Assignments\nYour typical homework assignments will be weekly labs. You will follow each lab’s instructions to complete tasks in R and submit a rendered .html Quarto document to Canvas.\nMost weeks, there will be class time on Wednesdays dedicated to working on completing lab assignments. While you will work with peers during class time on Thursdays, you will be expected to submit your own individual work for the final submission.\n\nLabs are (typically) due on Mondays (of the following week) at 11:59pm.\n\n\n\n\nEvaluative Assessments\n\nFinal Project\nThere will be a data analysis project to be completed throughout the second half of the term. You will work in a group of 3-4 people. Each group will produce a written project report covering linear regression and model simulation. More information will follow on Canvas.\n\n\nExams\nThere will be a midterm exam and a final exam. The midterm will have both in-class and take-home portions. The final will be entirely in-class during our scheduled final exam slot. More information will follow.\n\n\n\n\n\nCourse Grade\nYour grade in STAT 331/531 will contain the following components:\n\n\n\nAssignments\nWeight\n\n\n\n\nCheck-ins\n5%\n\n\nPractice Activities\n10%\n\n\nLab Assignments\n30%\n\n\nMidterm Exam\n15%\n\n\nFinal Project\n15%\n\n\nFinal Exam\n25%\n\n\n\nLower bounds for grade cutoffs are shown in the following table. It is possible that I could lower any of the grade cutoffs. You will only have the opportunity for grade rounding if you completed all assignments in the course. \n\n\n\n\n\n\n\nLetter grade\nX +\nX\nX -\n\n\n\n\nA\n.\n93\n90\n\n\nB\n87\n83\n80\n\n\nC\n77\n73\n70\n\n\nD\n67\n63\n60\n\n\nF\n&lt;60\n\n\n\n\n\nInterpretation of this table:\n\nA grade of 85 will receive a B.\nA grade of 77 will receive a C+.\nA grade of 70 will receive a C-.\nAnything below a 60 will receive an F.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-policies",
    "href": "course-info/syllabus-w25.html#course-policies",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Policies",
    "text": "Course Policies\n\nAttendance & Participation\nI do not take formal attendance in this class. However, it is my expectation that you remain in class and on task until you have finished all your activities and assignments.\nIf you are feeling ill, please do not come to class.\nHere’s what you should do if you do miss a class:\n\nTalk to a classmate to figure out what information you missed\nCheck Canvas for any necessary handouts or changes to assignments\nPost on Discord with any questions you have after reviewing notes and handouts\n\nIf you miss a bunch of classes, please come talk to me. I’m working from the assumption that you care and are trying, but something is getting in your way (health issues? college stress? work?); let’s figure out what that is and how I can help.\n\n\nAccessibility and Accomodations\nI have taken numerous steps to ensure that all of the materials presented in this course are accessible to all participants, regardless of physical or learning disabilities. I know that everyone is unique and I may have unintentionally overlooked something that limits access to some materials or activities. Please let me know if you cannot access any content. If you find you need additional accommodations to complete the required course work, please contact me as soon as possible! I want to support your success.\nIf you wish to request disability-related accommodations such as extra exam time for this or any other course, please contact the Disability Resource Center. It’s important to do this with as much advanced notice as possible, so you have full access to your course materials and activities in a timely manner. Please also email me to let me know that I should expect an email from the DRC to get you the accommodations that you need.\n\n\nInclusive Classroom\nBecause data are collected by and about humans, data necessarily encode aspects of our proclivities and biases. As a result, this course may touch upon difficult topics related to race, gender, inequality, class, and oppression. We each come into this class with different perspectives that can be shared to enhance our understanding of these issues. I ask that you enter these conversations with respect, curiosity, and cultural humility. You should be open to alternative perspectives and be willing to revise beliefs that are based on misinformation. As a general rule, your ideas and experiences can always be shared during these conversations, but please refrain from dismissing the experiences of others. Personal attacks of any kind will not be tolerated.\n\n\nGroup Work\nThis course will rely heavily on in-class group work. You will be expected to work with classmates on in-class material. If you have concerns about random group assignment, please talk to me at the start of the term.\nYou are also encouraged to discuss your ideas for lab assignments; however, I expect that these collaborations are about ideas and no R code is shared. Each person’s lab assignment submissions are expected to reflect their own thinking, and thus copying the work of others does not provide me with any information about your learning.\nThe community standards for student-to-student and student-to-instructor interactions include the following:\n\nListen actively and attentively.\nAsk for clarification if you are confused.\nChallenge one another respectfully.\nGracefully accept constructive criticism.\nTake responsibility for the quality of the discussion and the work.\nDo not monopolize discussion.\nAcknowledge that everyone has something to offer.\nSpeak from your own experience, without generalizing.\n\n\n\nLate Policy\nEveryone will be given a “bank” of 4 deadline extensions which can be used on Check-ins, Practice Activities, and Lab Assignments at any point in the quarter. One deadline extension will get you a 24 hour extension on a given assignment. You can use all of your deadline extensions on one assignment or split them up in any way.\n\nLike how the “real world” works, you must request a deadline extension before the deadline. To use your deadline extensions, you need to email me before the assignment deadline. You don’t need to get a response from me, you just need to email me at least a minute before the deadline.\nIf you do not email me before the assignment deadline (or you run out of late days), you will be docked 20% for each day that the assignment is late. (e.g. you can get a maximum of 80% on the assignment if it is submitted within 24 hours after the original due date and time.)\n\nA note on this policy: my priority is for all of you to engage with and understand the course materials. The best way to achieve this is to complete all assignments and receive feedback on your work. At the same time, I understand that things happen outside of our control and that you are balancing many responsibilities.\n\n\n\n\n\n\nAutomatic Canvas Settings\n\n\n\nCanvas is set up to automatically input 0% for missing assignments (as an incentive to go complete the assignment) and apply the 20% grade deduction policy. I will need to manually adjust your grade when you use your “deadline extensions.” You are responsible for double checking your grade to make sure I didn’t miss anything.\n\n\nIf you find yourself with extenuating circumstances beyond the defined late policy, please email me before the due date.\n\n\nExam Conflicts\nIf you have a known conflict with an exam, please discuss it with me at least three weeks prior to the exam date. If an illness or a family emergency arises, please let me know as soon as possible, and we will work out a solution. This may involve taking the exam at a later date or replacing the missed exam score with the final exam score. If you are unable to take the final exam, you will likely receive an Incomplete in the course.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-expectations",
    "href": "course-info/syllabus-w25.html#course-expectations",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Expectations",
    "text": "Course Expectations\nFor Students, I expect:\n\nYou will ask lots of questions.\nYou will do reading and other assignments outside of class and be prepared for each class meeting.\nIf you find yourself struggling or feel that you are falling behind, please reach out to me as soon as possible so that we can develop a plan for your success together.\nYou will take advantage of the resources that I provide and to seek out additional resources if you find that you are struggling with the material. You do not need to seek out additional resources all on your own – we can figure out what additional resources you may need.\n\nYou will be doing your best to engage with what we are all doing together during class. This means that you are using technology (i.e. laptops/tablets/phones) for class activities and not in ways that distract you.\nYou will approach the course with academic integrity.\nYou will come to class on time and work on class material with your peers.\nEveryone can learn the material in this course.\n\nFor Me:\n\nI am responsible for ensuring that all students feel welcome and valued in the classroom.\nI am responsible for providing the resources necessary so that all students in the course can achieve the learning objectives.\nI am responsible for providing prompt and clear feedback on your coursework.\nI welcome and appreciate any actionable feedback regarding how the class is meeting your learning needs. We can discuss ways to adjust the course to ensure it is supporting your learning and do more of anything that is working well!\n\n\nMake Mistakes!\nProgramming is the process of making a series of silly or stupid mistakes, and then slowly fixing each mistake (while adding a few more). The only way to know how to fix these mistakes (and avoid them in the future) is to make them. (Sometimes, you have to make the same mistake a few dozen times before you can avoid it in the future). At some point during the class, you will find that you’ve spent 30 minutes staring at an error caused by a typo, a space, a parenthesis in the wrong place. You may ask for help debugging this weird error, only to have someone immediately point out the problem… it is always easier to see these things in someone else’s code. This is part of programming, it is normal, and you shouldn’t feel embarrassed or sorry (unless you put no effort into troubleshooting the problem before you asked for help)\nIf you manage to produce an error I haven’t seen before, then congratulations. You have achieved something special, and that achievement should be celebrated. Each new and bizarre error is an opportunity to learn a bit more about the programming language, the operating system, or the interaction between the two.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#academic-integrity-and-class-conduct",
    "href": "course-info/syllabus-w25.html#academic-integrity-and-class-conduct",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Academic Integrity and Class Conduct",
    "text": "Academic Integrity and Class Conduct\nOur academic community is at its best when we treat each other with fairness, honesty, respect, and trust. Unfortunately, sometimes students slip up and do something that gives themselves (or someone else) an unfair advantage over other students. Such actions will not be tolerated in this class.\nIt is most likely that a student will slip up if they are feeling overwhelmed or unsure of how to approach a problem that they are stuck on. So let’s be proactive to prevent those situations!! If you are helpless in an assignment or in studying, post on discord, come to office hours, or email me or one of your classmates! I am working hard to provide all of the resources you need to succeed\nHowever, the college doesn’t really care if you break the rules on purpose or by accident. If I suspect you have done something that violates academic integrity on any graded elements of the course (included those graded for completion), you will receive an email to tell you about my suspicion and how the situation will be handled. Typically, students earn a 0 for the assignment on which academic misconduct is found. University policy dictates that we must report every instance of suspected academic dishonesty to the Office of Student Rights and Responsibilities, no matter how small. For more information on academic misconduct and what constitutes cheating and plagiarism, please see academicprograms.calpoly.edu/content/academicpolicies/Cheating.\nIt is important to note that paraphrasing or quoting another’s work without proper citation is a form of academic misconduct. This includes the R code produced by someone else! Writing code is like writing a paper, it is obvious if you copied-and-pasted a sentence from someone else into your paper because the way each person writes is different.\nEven inadvertent or unintentional misuse or appropriation of another’s work (such as relying heavily on source material that is not expressly acknowledged) is considered plagiarism. This includes using Chat GPT, which should only be used to help you problem solve just as a tutor or peer would, and not as a substitute for your own work. If you are struggling with writing the R code for an assignment, please reach out to me. I would prefer that I get to help you rather than you spending hours Googling things and get nowhere!\n\n\n\n\n\n\nAlways Cite Outside Resources!\n\n\n\nIn this class the assumed knowledge is the course materials, including the course textbook, coursework pages, and course slides. If you use outside resources on assignments I expect that you will cite those resources. This means that\n\nIf you use any R functions or code that are not in the course materials, you must cite where you found it. e.g., if you look up the help file for mutate() and you learn about a function not covered in the course materials, you are required to cite the documentation when using that function.\nIf you use Google you are expected to “inform” me of any resources you used by pasting the link to the resource in a code comment next to where you used that resource.\nIf you use ChatGPT you are expected to “inform” me by stating that you used it in a code comment next to where you used it including the full prompt that you gave ChatGPT.\nIf you work with classmates on an assignment, you are expected to “inform” me by including a note with their names.\n\n\n\nIf you have any questions about using and citing sources, you are expected to ask for clarification.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#learning-environment-and-support",
    "href": "course-info/syllabus-w25.html#learning-environment-and-support",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Learning Environment and Support",
    "text": "Learning Environment and Support\nMy priority is your success in this course. I understand that things happen unexpectedly and obtaining official accommodations can be slow.\nIf you feel that any circumstances or factors beyond your control may affect your presence and work in this class, please reach out to me and we will work to accommodate your needs. You do not need to share personal information with me when you reach out, unless you would like to.\n\nMental Health\nNational surveys of college students have consistently found that stress, sleep problems, anxiety, depression, interpersonal concerns, death of a significant other and alcohol use are among the top ten health impediments to academic performance. If you are experiencing any mental health issues, I and Cal Poly are here to help you. Cal Poly’s Counseling Services (805-756-2511) is a free and confidential resource for assistance, support and advocacy https://chw.calpoly.edu/counseling.\n\n\nSupport Services\nIf you are experiencing food insecurity, housing instability, or other challenges that may impact your ability to succeed in this course, please refer to the resources listed on Canvas under “Student Support Services at Cal Poly.” These resources provide a range of essential support services, including emergency financial assistance, counseling, and academic support.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html",
    "href": "labs/lab1/lab1-quarto.html",
    "title": "Lab 1: Introduction to Quarto",
    "section": "",
    "text": "Read and follow all lab instructions carefully!"
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#setup",
    "href": "labs/lab1/lab1-quarto.html#setup",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Setup",
    "text": "Setup\n\nMake a Lab Directory\nIf you have completed Check-in 1.3, you have already completed steps 1 & 2 below.\n\nIf you have not already, create a folder on your computer called “stat-331” or similar.\nCreate an RStudio Project inside of this folder.\nInside your stat-331 folder, create another folder called either “week-1” or “labs”. Remember, we are trying to be organized and not work out of our Downloads folder!\nInside of this folder, create another folder called “lab1” or similar.\n\n\n\nCreate your Lab 1 File\nTo create a Quarto document, you first need to ensure Quarto is installed on your computer. To do this, go here. You may have already installed Quarto during Check-in 1.3.\n\nOnce you have Quarto installed, open RStudio on your computer.\nIn RStudio, go to File &gt; New File &gt; Quarto Document... and click on Create in the dialog box without changing anything.\n\n\n\n\n\n\n\nWarning\n\n\n\nFor the instructions in this lab, I am expecting that the .qmd document you just created will look exactly like the one shown in the Quarto-Rendering course slide. If your document is instead entirely blank other than a YAML header, some of these instructions will be confusing and you should talk to me!\n\n\n\nChange the title of your document to be “Lab 1: Introduction to Quarto”\nAdd additional lines to your YAML header:\n\n\nadd a line with author: and your name.\nadd a line with embed-resources: true.\nadd a line with code-tools: true.\n(optional) add a line to specify the editor as your preference for either source or visual.\n\n\nSave the Quarto file as “lab1.qmd” in your “week-1” or “labs” folder. You can change up the name of your document, but the name cannot have spaces and it should describe what the document is."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#changing-the-execution-options",
    "href": "labs/lab1/lab1-quarto.html#changing-the-execution-options",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Changing the Execution Options",
    "text": "Changing the Execution Options\nExecution options specify how the R code in your Quarto document should be displayed. This guide provides descriptions on the options you can specify in a document’s execution.\nTo start, your YAML should look something like this:\n\n---\ntitle: \"Lab 1: Introduction to Quarto\"\nauthor: \"Dr. C\"\nformat: html\nembed-resources: true\ncode-tools: true\neditor: source (or visual)\n---\n\nSimilar to how you added an author, embed-resources, (and editor) line, you will first need to add an execute line to your YAML.\nUse the guide to specify execution options so that:\n\nyour source code is always output on the page.\nyour document will render even if there are errors."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#running-the-provided-code",
    "href": "labs/lab1/lab1-quarto.html#running-the-provided-code",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Running the Provided Code",
    "text": "Running the Provided Code\nNext, click on the “Play” button on the right of the first auto-populated code chunk. Alternatively, you can highlight (or simply put your cursor on the line of) the code you want to run and hit ctrl + Enter or ⌘ + Enter.\nYou should see the code appear in the console, as well as the result of the code (2). Keep in mind the [1] before the 2 is vector notation. This means the result is a vector of length 1, whose first element is 2.\nLet’s spice this code up a bit. Delete 1 + 1 from the code chunk and write the following code:\n\n# Load a dataset into the R Environment.\ndata(ToothGrowth)\n\n# Look at the summary of the variables in the dataset.\nsummary(ToothGrowth)\n\n# Look at a frequency table of a categorical variable.\ntable(ToothGrowth$supp)\n\nNow run this code. You should see a six-number summary of the variables len and dose included in the ToothGrowth dataset, as well as the frequency of the levels contained in the supp variable. Second, there is just the frequency table for the supp variable. Further, if you inspect the Environment tab, the ToothGrowth dataset should appear. You can click on the dataset name (not the blue play button!) to look at the data."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#check-the-data-documentation",
    "href": "labs/lab1/lab1-quarto.html#check-the-data-documentation",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Check the Data Documentation",
    "text": "Check the Data Documentation\nIn your console (not in the Quarto document), type ?ToothGrowth (or alternatively help(ToothGrowth).\n\nUse the information that pops up in the Help pane in RStudio to fill in the blanks below.\nAdd the questions and your responses after the R code chunk.\nBefore the code chunk, create a section header (using #s) that describes the contents of the section (e.g., Tooth Growth Dataset).\n\nThis dataset investigates the effect of ______ ____ on tooth growth in _________ ________.\nThe two supplement delivery methods include OJ (_______ _______) and VC (_________ ______).\nIt is a data frame with ____ observations and ____ variables.\nYour Tooth Growth Dataset section should look something like this (although it will also include the table of supp):"
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#sec-creating-a-plot",
    "href": "labs/lab1/lab1-quarto.html#sec-creating-a-plot",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Creating a Plot",
    "text": "Creating a Plot\nYour second code chunk is just as boring as your first, so let’s spice it up! Replace the 2 * 2 code with the following (we will talk about graphics next week!):\n\n# make sure to load the package ggplot2\nlibrary(ggplot2)\nggplot(data = ToothGrowth, \n       aes(x = supp,\n           y = len)) +\n  geom_boxplot() +\n  labs()\n\nNow, run this code chunk! You should see side-by-side boxplots comparing tooth length between the two supplement delivery methods contained in the ToothGrowth data set.\nLook back at the help documentation for the ToothGrowth dataset to determine what len represents (i.e., “Length of xxx”).\nNext, look up the help file on the labs() ggplot2 function to find the arguments you can use to specify the \\(x\\)- and \\(y\\)-axis labels. Particularly, looking at the examples at the bottom of the help file and this site may also be helpful. Change the \\(x\\)-axis and \\(y\\)-axis labels to display reader-friendly axis labels as found in the ToothGrowth help file. For example, “Supplement Type” is better than “supp”.\nNote that #| echo: false is an output option applied only to this specific code chunk. Remove this line so the code appears in your final rendered document.\nCreate another section header (like you did before) stating what is included in this section."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#inserting-a-new-code-chunk",
    "href": "labs/lab1/lab1-quarto.html#inserting-a-new-code-chunk",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Inserting a New Code Chunk",
    "text": "Inserting a New Code Chunk\nNavigate to the last sentence of the Quarto document. We’re now going to insert a new R code chunk at the bottom of the document.\nThere are four different ways to do this:\n\ntype ctrl + alt + i on Windows, or ⌘ + ⌥ + i on macOS,\nClick on the  symbol. This should automatically default to R code, but if you have a Python compiler on your computer, you might need to select “R” from the options.\nIf you are using the Visual editor, click on the “Insert” button, then select “Code Chunk”, and finally select “R”.\nManually add the code chunk by typing ```{r}. Make sure to close your code chunk with ```."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#conducting-statistical-analyses",
    "href": "labs/lab1/lab1-quarto.html#conducting-statistical-analyses",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Conducting Statistical Analyses",
    "text": "Conducting Statistical Analyses\n\n\n\n\n\n\nRefresher on a two-sample independent t-test\n\n\n\nWhile a second course in statistics is a pre-requisite for this class, you may want to go here for a refresher on conducting two-sample independent t-tests.\n\n\nIn this section, we are going to conduct a two-sample independent t-test to compare tooth length between the two supplement methods in the ToothGrowth dataset. I have outlined the null and alternative hypotheses we will be testing:\n\n\n\n\n\n\nNull\n\n\n\nThe treatment mean tooth length for the OJ supplement delivery method is the same as the treatment mean tooth length for the VC supplement delivery method.\n\n\n\n\n\n\n\n\nAlternative\n\n\n\nThe treatment mean tooth length for the OJ supplement delivery method is different from the treatment mean tooth length for the VC supplement delivery method.\n\n\nCarry out the following steps:\n\nLook up the help documentation for t.test().\n\n\n\n\n\n\n\nHint\n\n\n\nLook at the example for a two-sample t-test comparing mpg in morning and afternoon with the mtcars data.\n\n\n\nUsing the function t.test(), write code to carry out the analysis. You can assume unequal variances and a two-sided alternative.\nRun your code chunk to obtain the output for your statistical test.\nWrite a numbered list (in Markdown) below the code chunk containing:\n\nYour conclusion (in the context of these data) based on the p-value.\nAn interpretation of the confidence interval (make sure to read what confidence level is used by default).\n\nCreate another section header, describing the contents of this section."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#render-your-document",
    "href": "labs/lab1/lab1-quarto.html#render-your-document",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Render your Document",
    "text": "Render your Document\nRender your document as an html file. Use the “Render” button (the blue arrow!) at the top of your screen.\nIf you run into trouble rendering your document, try restarting R and running your code chunks in order, and see if you can find the problem.\nAnother common issue is deleting the tick marks (```) that surround your code chunks. If you notice that the code chunks are not showing a “Play” button, or that they are not highlighted in gray, double check your tick marks!\nRecall we included error: true in our YAML execution options. This means that your document will still render even if there are errors. Make sure you are double checking your work!\nYou will notice that there is auto-generated text that is unrelated to the work that you completed. It is always a good idea to delete this extra text!"
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#include-an-image",
    "href": "labs/lab1/lab1-quarto.html#include-an-image",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Include an Image",
    "text": "Include an Image\n\nSave an image of an activity, place, book, or movie that you enjoy. Save the image somewhere that makes sense to you in your course directory.\nCheck out this documentation for how to include an image/figure in Markdown.\nInclude your image at the end of your lab, along with a brief description.\n\n\nThe Markdown code will look something like: ![Brief description](relativepath/image.png)\nYou must use a relative file path to your image!\nYou may want to adjust the image size.\n\n\nAdd a new section header before your image.\nRender your document again to make sure it worked.\n\n\n\n\nI am obsessed with this book of short stories by Ken Liu."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#styling-your-quarto-document",
    "href": "labs/lab1/lab1-quarto.html#styling-your-quarto-document",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Styling your Quarto Document",
    "text": "Styling your Quarto Document\nYou can find a list of every option you can use to format an HTML document here and here. Further, here are lists of different themes you can specify in your YAML to produce differently styled outputs.\nMake the following changes to your document:\n\nSpecify “Code Folding” in your YAML document options.\nSpecify in the code chunk options that your boxplots of tooth length by supplement delivery method should be center aligned.\nWrite and include a figure caption for the boxplots using a code-chunk option.\nClean it up - delete the any automatically included headers or text in the file that are still there.\n\nYou might have fun playing around with other themes or options!"
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#render-again",
    "href": "labs/lab1/lab1-quarto.html#render-again",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Render again!",
    "text": "Render again!\nNotice that when you render the document, all of the code reruns again, producing the same output as before, but with your changes – this is called reproducibility!\nYou should render often while completing your practice activities and lab assignments. Make small changes, then make sure the file still renders rather than making a bunch of big changes and then realizing something is wrong."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#turn-it-in",
    "href": "labs/lab1/lab1-quarto.html#turn-it-in",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Turn it in!",
    "text": "Turn it in!\nOpen the .html file on your computer to make sure it looks as you expected. Then upload the rendered (.html extension) document to Canvas!\n\n\n\n\n\n\nCaution\n\n\n\nDouble check that you have embed-resources: true in your YAML. Without this, your html will not be formatted correctly on Canvas. You may want to look at what you turn in through your Canvas portal!\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou’ll be doing this same process for all your future Lab Assignments. Each of these will involve a Quarto file. Some weeks, I may have a template for you to copy into the Quarto file just as with the first practice activity."
  },
  {
    "objectID": "labs/lab3/lab3-dplyr.html",
    "href": "labs/lab3/lab3-dplyr.html",
    "title": "Lab 3: Student Evaluations of Teaching",
    "section": "",
    "text": "In this lab, we will be using the dplyr package to explore student evaluations of teaching data. You are expected to use functions from dplyr to do your data manipulation!\nDownload starter .qmd file\nDownload teacher_evals.csv"
  },
  {
    "objectID": "labs/lab3/lab3-dplyr.html#rate-my-professor",
    "href": "labs/lab3/lab3-dplyr.html#rate-my-professor",
    "title": "Lab 3: Student Evaluations of Teaching",
    "section": "Rate my Professor",
    "text": "Rate my Professor\nFor the questions in this section (9 - 11), you don’t need to write up any answers – you only need to show the output of your code (nicely formatted with kable()) to respond to each. Your code output should clearly show the answer.\n\n\n\n\n\n\nTip\n\n\n\nHelpful functions: slice_max(), slice_min()\n\n\n9. Which instructor(s) had the lowest average rating for Question 1 (“I learnt a lot during the course.”) across all their courses (i.e. you should be looking at the mean of the SET_score_avg variable across courses for each instructor)? Include the number of courses the instructor(s) taught in your output\na. Sketch a game plan and include the image below.\n\nb. Implement/code your game plan\n\n# code chunk for Q9\n\n10. Which instructor(s), who had at least five courses reviewed in the data, had the highest average rating for Question 1 (I learnt a lot during the course.) across all their courses?\n\n# code chunk for Q10\n\n11. Which instructor(s) with either a doctorate or professor degree had the highest and lowest average percent of students responding to the evaluation across all their courses? Include how many years the instructor had worked (seniority) and their sex in your output. You can use two pipelines to answer these questions.\n\n\n\n\n\n\nTip\n\n\n\nThinking about how to include the seniority and sex of the instructor in your output may be tricky!! There are a couple of ways to approach this. One hint is to think about how many distinct seniority levels / sexes there are for each instructor.\n\n\n\n# code chunk for Q11"
  },
  {
    "objectID": "labs/lab3/lab3-dplyr.html#chi-square-test-of-independence",
    "href": "labs/lab3/lab3-dplyr.html#chi-square-test-of-independence",
    "title": "Lab 3: Student Evaluations of Teaching",
    "section": "Chi-Square Test of Independence",
    "text": "Chi-Square Test of Independence\n\n\n\n\n\n\nRefresher on Chi-square test of independence\n\n\n\nWhile a second course in statistics is a pre-requisite for this class, here is a refresher on Chi-square tests of independence.\n\n\nLet’s compare the level of SET ratings for Question 3 (The professor used activities to make the class more engaging.) between senior instructors and junior instructors.\n12. Create a new dataset teacher_evals_compare that accomplishes the following with one dplyr pipeline:\n\nincludes responses for Question 3 only,\ncreates a new variable called set_level that is “excellent” if the SET_score_avg is 4 or higher (inclusive) and “standard” otherwise,\ncreates a new variable called sen_level that is “junior” if the instructor has been teaching for 4 years or less (inclusive), “senior” if between 5-8 years (inclusive), and “very senior” if more than 8 years\ncontains only the variables we are interested in – course_id, set_level, and sen_level.\n\n\n\n\n\n\n\nTip\n\n\n\nHelpful functions: if_else(), case_when()\n\n\n\n# code chunk for Q12\n\n13. Using the new dataset and your ggplot2 skills, recreate the filled bar plot shown below.\n\n\n\n\n\n\n\nTip\n\n\n\nNote that getting the general structure and reader friendly labels is good enough. I used Cal Poly’s branded colors for fun, which use HEX codes #BD8B13 and #154734.\n\n\n\n# code chunk for Q13\n\n14. Use chisq.test() to carry out a chi-square test of independence between the SET level and instructor seniority level in your new dataset. You will want to look at the documentation and maybe Google a bit!\n\n\n\n\n\n\nTip\n\n\n\nNote that the chisq.test() function does not take a formula / data specification as we have seen before. You will either have to use with() or indicate the variables of interest using $ syntax.\n\n\n\n# code chunk for Q14\n\n15. Draw a conclusion about the independence of student evaluation of instructor’s use of activities and seniority level based on your chi-square test.\n\nStudy Critique\nPart of the impetus behind this study was to investigate characteristics of a course or an instructor that might affect student evaluations of teaching that are not explicitly related to teaching effectiveness. For instance, it has been shown that gender identity and presentation affect student evaluations of teaching (an example).\n16. If you were to conduct this study at Cal Poly, what are two other variables you would like to collect that you think might be related to student evaluations? These should be course or instructor characteristics that were not collected in this study. Explain what effects you would expect to see for each."
  },
  {
    "objectID": "practice-activities/pa2.html",
    "href": "practice-activities/pa2.html",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "",
    "text": "Download the .qmd template and save it in a reasonable location.\nToday you will be exploring different types of visualizations to uncover which species of penguins reside on different islands.\nSome advice:"
  },
  {
    "objectID": "practice-activities/pa2.html#getting-started",
    "href": "practice-activities/pa2.html#getting-started",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Getting Started",
    "text": "Getting Started\nWe will be creating visualizations using the ggplot2 package.\nFor this activity, we will be exploring the penguins data from the palmerpenguins package, which has fantastic documentation with really awesome artwork. So, you will need to install the palmerpenguins package.\ninstall.packages(\"palmerpenguins\")\n\n\n\n\n\n\ninstall.packages() in the console NOT in your .qmd file!\n\n\n\nYou should type this into your console and NOT include it in a code chunk in your .qmd file. Recall that we only have to install a package once, but load it each time we open R. Each time you render your .qmd file, ALLthe code chunks are run. Therefore, installing a package in a code chunk would cause R to unnecessarily install the package over and over again. Not good."
  },
  {
    "objectID": "practice-activities/pa2.html#creating-a-setup-code-chunk",
    "href": "practice-activities/pa2.html#creating-a-setup-code-chunk",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Creating a Setup Code Chunk",
    "text": "Creating a Setup Code Chunk\n\nInsert a code chunk at the beginning of your document (directly under the YAML).\nName the code chunk setup.\nUse the hashpipe #| to specify a code chunk option that prevents any messages (e.g., from loading in packages) from appearing.\nLoad in the tidyverse or ggplot2 package.\nLoad in the palmerpenguins package.\n\n\n\n\n\n\n\nCode chunk name: setup\n\n\n\nNaming your code chunk “setup” has special properties in a .qmd - specifically, this code chunk will run automatically when you try to run a subsequent code chunk. This ensures all packages and any other specifications for your document are loaded and will not cause you errors or messages."
  },
  {
    "objectID": "practice-activities/pa2.html#dataset-penguins",
    "href": "practice-activities/pa2.html#dataset-penguins",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Dataset: penguins",
    "text": "Dataset: penguins\nI like to start by seeing the dataset I will be working with, so I am going to pull the penguins data into my R environment. Do you see it in the top right Environment tab?\n\ndata(penguins)\n\nWarning in data(penguins): data set 'penguins' not found\n\n\nYou may notice that a dataset called penquins_raw also loaded. We will ignore this and focus on the penguins dataset.\n\nGet to know your data. What are the variables and what units are they measured in? What does each row represent?"
  },
  {
    "objectID": "practice-activities/pa2.html#graphics",
    "href": "practice-activities/pa2.html#graphics",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Graphics",
    "text": "Graphics\n\n\n\n\n\n\nNote\n\n\n\nMake sure to give your plots reader friendly axes labels!\n\n\n\n\n\n\n\n\nNote\n\n\n\nMake sure your final report does not display any warnings or messages from RStudio!\n\n\n\nUse https://excalidraw.com/ (or pen and paper, a tablet, etc.) to create a game plan for a barchart of species, where species is mapped to the fill color of the barchart. Save or take a screenshot of your game plan – you will be uploading this to Canvas with your practice activity submission.\nUse ggplot2 to create the barchart you outlined above.\n\n\nUse ggplot2 to create a scatterplot of the relationship between the bill length (bill_length_mm) and bill depth (bill_depth_mm).\n\n\nBuilding on your code from (9), add an aesthetic to differentiate the species by color.\n\n\nBuilding on your code from (10), add the location of the penguins (island) to your visualization. There us more than one way you could to address this, however, one method will make it easier to answer the questions below, so you might want to read those questions first!"
  },
  {
    "objectID": "practice-activities/pa2.html#canvas-quiz",
    "href": "practice-activities/pa2.html#canvas-quiz",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Canvas Quiz",
    "text": "Canvas Quiz\n\n\n\n\n\n\nUse the plots you created to answer the following questions on Canvas.\n\n\n\n\nWhich species of penguins is represented least in the Palmer Penguins data set?\nWhich species of penguins are found on every island?\nWhich species of penguins are found only on Dream Island?\nWhich species of penguins are found only on Biscoe Island?"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#tuesday-april-1",
    "href": "slides/week-1/w1-intro-r.html#tuesday-april-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Tuesday, April 1",
    "text": "Tuesday, April 1\nToday we will…\n\nWelcome to Stat 331/531: Statistical Computing in R\nIntro to Me + You + the course\n“Unplugged” Warm-up\nIntro to R + RStudio\nOrganization\nR Basics & Troubleshooting\nPA 1: Find the Mistakes"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#me",
    "href": "slides/week-1/w1-intro-r.html#me",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Me!",
    "text": "Me!\n\n\nHi, I’m Dr. C!\n\n\nI am a transplant to the west coast.\nMy favorite things right now are cooking, knitting, and biking around SLO county.\nI genuinely love R."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#you",
    "href": "slides/week-1/w1-intro-r.html#you",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "You!",
    "text": "You!\nI am looking forward to reading your introductions on Discord!\n\nPlease read the intros of your classmates so you can discover who you will be learning with this quarter."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#communication",
    "href": "slides/week-1/w1-intro-r.html#communication",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Communication",
    "text": "Communication\n\n\n✉️ email\n\nwith your @calpoly.edu email address\nwith questions that relate to you as an individual\n\n💬 Discord\n\nany and all questions!!\nyou will join and introduce yourself before Thursday\n\n🏢 office hours\n\ncome and discuss anything during my scheduled hours!\nreach out to schedule other times"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#course-materials",
    "href": "slides/week-1/w1-intro-r.html#course-materials",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Course Materials",
    "text": "Course Materials\n\n\n🏫 Canvas\n\neverything will be linked or posted on Canvas!\nrefer to Canvas for current deadilnes & announcements\n\n📕 “textbook”\n\nonline course notes\nincludes videos & tutorials\n\n🖥️ materials website\n\nslides, labs, and practice activities are organized\nthis is for convenience, but everything will also be linked in Canvas"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#assessments---formative",
    "href": "slides/week-1/w1-intro-r.html#assessments---formative",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Assessments - Formative",
    "text": "Assessments - Formative\n\n\nCheck-In’s (5%)\n\n“check” that you are prepared for the week\nbased on reading from the textbook\n\nPractice Activities (10%)\n\nfirst attempt at new skills\nget the hang of the week’s R skills\n\nLab Activities (30%)\n\n“homework”\n\n\n\n\n\n\n\n\n\n\nWork with other’s!\n\n\nYou should work with other’s on all assignments! The final work you submit for a Lab should be your own."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#assessments---evaluative",
    "href": "slides/week-1/w1-intro-r.html#assessments---evaluative",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Assessments - Evaluative",
    "text": "Assessments - Evaluative\n\nExams\n\nMidterm Exam (15%)\nFinal Exam (25%)\n\nFinal project (15%)\n\ngroup project\ndue end of week 10\n\n\n\n\n\n\n\n\nExam Conflicts\n\n\nIf you have a known conflict with an exam, please discuss it with me at least three weeks prior to the exam date"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#assessments---general-criteria",
    "href": "slides/week-1/w1-intro-r.html#assessments---general-criteria",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Assessments - General Criteria",
    "text": "Assessments - General Criteria\n\n\ncorrect outputs are great, but you will also need to demonstrate that you are intellectually engaging with the material in assignments\nin addition to getting a correct output from your code, you will be assessed for efficiency and formatting\ntechnical communication will also be an important element of assessments\nI hope you will be proud of your work in this class!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#weekly-overview",
    "href": "slides/week-1/w1-intro-r.html#weekly-overview",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Weekly Overview",
    "text": "Weekly Overview"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#course-policies",
    "href": "slides/week-1/w1-intro-r.html#course-policies",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Course Policies",
    "text": "Course Policies\n\nLate Policy\n\n4 “deadline extensions”\nemail me before the deadline for a 24 hour extention\n\nAttendance\nAccessibility and Accomodations\n\nlet me know what I can do better\nemail me if you use the DRC"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#academic-integrity",
    "href": "slides/week-1/w1-intro-r.html#academic-integrity",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Academic Integrity",
    "text": "Academic Integrity\n\n\nlet’s be proactive to prevent situations where you are overwhelmed!\nuse Chat GPT as a tutor, not a substitute for your own work\ncite outside resources!\nplease review the syllabus carefully"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#my-expectations-for-you",
    "href": "slides/week-1/w1-intro-r.html#my-expectations-for-you",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "My expectations for you",
    "text": "My expectations for you\n\n\nask lots of questions\ntake advantage of resources to help you learn\n\nthis includes working with others!\n\nengage with what we are all doing together during class\nwork towards independent learning"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#my-expectations-for-me",
    "href": "slides/week-1/w1-intro-r.html#my-expectations-for-me",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "My expectations for me",
    "text": "My expectations for me\n\n\ncreating an inclusive and accessible classroom\nproviding resources needed to learn the material\nproviding prompt and clear feedback\ndoing my best to make class worth your time\nclearly communicating"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-to-expect-from-this-course",
    "href": "slides/week-1/w1-intro-r.html#what-to-expect-from-this-course",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What to expect from this course",
    "text": "What to expect from this course\n\n\neveryone comes with different knowledge and skills – figure out what helps you learn the best in this course\nindependent learning and learning from documentation is part of the course\ncoding involves unique challenges, frustrations, and satisfaction!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#statistical-computing-involves",
    "href": "slides/week-1/w1-intro-r.html#statistical-computing-involves",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Statistical computing involves…",
    "text": "Statistical computing involves…\n\n\nunderstanding data structures\n\ni.e. “what you have to work with”\n\ndeveloping an algorithm\n\ni.e. “what you want the computer to do”\n\nknowing the syntax of a specific language\n\ni.e. “how to tell the computer what to do so it will understand”\n\nimproving efficiency of your code\n\n\n\n\n\n\n\n\n\nNot just syntax\n\n\nAll of these skills improve as the others improve and we will work on all of them in this course!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#paper-planes",
    "href": "slides/week-1/w1-intro-r.html#paper-planes",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Paper Planes",
    "text": "Paper Planes\n\n\nWork with the person next to you & introduce yourself!\nWrite a set of instructions to fold a paper airplane\n\n\nvideo / picture instructions if you don’t know/remember how\n\n\nSwap the instructions with the pair next to you\nFollow their instructions as literally as possible to fold a plane"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-is-r",
    "href": "slides/week-1/w1-intro-r.html#what-is-r",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What is R?",
    "text": "What is R?\n\nR is a programming language designed originally for statistical analyses.\nR is open source"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-going-on-with-r",
    "href": "slides/week-1/w1-intro-r.html#what-going-on-with-r",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What’ going on with R?",
    "text": "What’ going on with R?\n\nStrengthsWeaknesses\n\n\nR’s strengths are…\n\n\nhandling data with lots of different types of variables.\nmaking nice and complex data visualizations.\nhaving cutting-edge statistical methods available to users.\n\n\n\n\nR’s weaknesses are…\n\n\nperforming non-analysis programming tasks, like website creation (python, ruby, …).\nhyper-efficient numerical computation (matlab, C, …).\nbeing a simple tool for all audiences (SPSS, STATA, JMP, minitab, …)."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#but-wait",
    "href": "slides/week-1/w1-intro-r.html#but-wait",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "But wait!",
    "text": "But wait!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#packages",
    "href": "slides/week-1/w1-intro-r.html#packages",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Packages",
    "text": "Packages\nThe heart and soul of R are packages.\n\n\nThese are “extra” sets of code that add new functionality to R when installed.\n“base” R refers to functions that are in the R software, and do not require a package."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#open-source",
    "href": "slides/week-1/w1-intro-r.html#open-source",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Open-Source",
    "text": "Open-Source\nImportantly, R is open-source.\n\n\nThere is no company that owns R, like there is for SAS or Matlab.\nThis means packages are created by users like you and me!\n“Official” R packages live on the Comprehensive R Archive Network, or CRAN.\nBut anyone can write and share new code in “package form”"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#open-source-1",
    "href": "slides/week-1/w1-intro-r.html#open-source-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Open-Source",
    "text": "Open-Source\nBeing a good open-source citizen means…\n\n\nsharing your code publicly when possible (later in this course, we’ll learn about GitHub!).\ncontributing to public projects and packages, as you are able.\ncreating your own packages, if you can.\nusing R for ethical and respectful projects."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-is-rstudio",
    "href": "slides/week-1/w1-intro-r.html#what-is-rstudio",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nRStudio is an IDE (Integrated Developer Environment).\n\nThis means it is an application that makes it easier for you to interact with R."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#rstudio-is-your-friend",
    "href": "slides/week-1/w1-intro-r.html#rstudio-is-your-friend",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "RStudio is Your Friend!",
    "text": "RStudio is Your Friend!\n\nYou will always interact with R through RStudio\nHelps with organization and some “point-and-click” options if desired"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#a-lot-of-pieces-go-into-a-data-analysis",
    "href": "slides/week-1/w1-intro-r.html#a-lot-of-pieces-go-into-a-data-analysis",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "A lot of pieces go into a data analysis!",
    "text": "A lot of pieces go into a data analysis!\n\n\n\nfiles with code\ndata files\ndocumentation\nimages\nreports\netc.\n\n\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#organization-is-key",
    "href": "slides/week-1/w1-intro-r.html#organization-is-key",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Organization is key!",
    "text": "Organization is key!\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-is-a-directory",
    "href": "slides/week-1/w1-intro-r.html#what-is-a-directory",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What is a directory?",
    "text": "What is a directory?\n\n\nA directory is just a fancy name for a folder.\nDirectories are your friends!\nBest practice:\n\neverything should have a place in a well-named directory\ndo not include spaces in directory names"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#project-directory-examples",
    "href": "slides/week-1/w1-intro-r.html#project-directory-examples",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Project Directory Examples",
    "text": "Project Directory Examples\n\nGOOD 😃BAD ☠️"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#class-directory-examples",
    "href": "slides/week-1/w1-intro-r.html#class-directory-examples",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Class Directory Examples",
    "text": "Class Directory Examples\n\nGOOD 😃BAD ☠️"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#manage-your-class-directory",
    "href": "slides/week-1/w1-intro-r.html#manage-your-class-directory",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Manage your Class Directory",
    "text": "Manage your Class Directory\nCreate a directory for this class!\n\n\nIs it in a place you can easily find it?\n\nNOT IN YOUR DOWNLOADS FOLDER ☠️\n\nDoes it have an informative name?\n\nlike “stat-331” or similar\n\nAre the files inside it well-organized?\n\n\n\n\n\n\n\n\n\nWarning\n\n\nI cannot stress how important this is!!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#how-do-i-run-code-in-r",
    "href": "slides/week-1/w1-intro-r.html#how-do-i-run-code-in-r",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "How do I run code in R?",
    "text": "How do I run code in R?\n\n\nYou can run any lines of code directly in the Console\n\nBut then your code isn’t saved!\nThis is best for exporatory and one-off tasks\n\nWe primarily write and run code in R scripts or notebooks in Source\n\nThese are documents where you can organize and save code!\nMore on scripts vs. notebooks tomorrow"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#packages-1",
    "href": "slides/week-1/w1-intro-r.html#packages-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Packages",
    "text": "Packages\nTo install a package use:\n\ninstall.packages(\"tibble\")\n\n\nYou should have to install a package only once.\n\n\nTo load a package use:\n\nlibrary(tibble)\n\n\nYou have to load a package each time you restart R.\nYou also should load packages at the beginning of any script.\n\n\n\n\n\n\n\n\n\nWarning\n\n\nNote that when you install packages you need to include quotation marks around the package name, but you don’t need to when loading a package!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#data-types",
    "href": "slides/week-1/w1-intro-r.html#data-types",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Data Types",
    "text": "Data Types\n\nA value is a basic unit of stuff that a program works with.\nValues have types:\n\n\n\nlogical / boolean: FALSE/TRUE or 0/1 values.\n\n\n\n\ninteger: whole numbers.\n\n\n\n\ndouble / float / numeric: decimal numbers.\n\n\n\n\ncharacter / string - holds text, usually enclosed in quotes."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#variables",
    "href": "slides/week-1/w1-intro-r.html#variables",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Variables",
    "text": "Variables\nVariables are names that refer to values.\n\nA variable is like a container that holds something - when you refer to the container, you get whatever is stored inside.\nWe assign values to variables using the syntax object_name &lt;- value.\n\nYou can read this as “object name gets value” in your head.\n\n\n\n\nmessage &lt;- \"So long and thanks for all the fish\"\nyear &lt;- 2025\nthe_answer &lt;- 42\nearth_demolished &lt;- FALSE"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#naming-conventions",
    "href": "slides/week-1/w1-intro-r.html#naming-conventions",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Naming Conventions",
    "text": "Naming Conventions\n\nsome_people_use_snake_case\nsomePeopleUseCamelCase\nsome.people.use.periods\nA few people mix conventions with variables_thatLookLike.this and they are almost universally hated.\n\n\n\n\n\n\n\nTip\n\n\nJust pick one and stick with it!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#data-structures",
    "href": "slides/week-1/w1-intro-r.html#data-structures",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Data Structures",
    "text": "Data Structures\nHomogeneous: every element has the same data type.\n\nVector: a one-dimensional column of homogeneous data.\nMatrix: the next step after a vector - it’s a set of homogenous data arranged in a two-dimensional, rectangular format.\n\n\nHeterogeneous: the elements can be of different types.\n\nList: a one-dimensional column of heterogeneous data.\nDataframe: a two-dimensional set of heterogeneous data arranged in a rectangular format."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#indexing",
    "href": "slides/week-1/w1-intro-r.html#indexing",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Indexing",
    "text": "Indexing\nWe use square brackets ([]) to access elements within data structures.\n\nIn R, we start indexing from 1.\n\n\n\n\nVector:\n\n\nvec[4]    # 4th element\nvec[1:3]  # first 3 elements\n\n\n\n\nMatrix:\n\n\nmat[2,6]  # element in row 2, col 6\nmat[,3]   # all elements in col 3\n\n\n\n\nList:\n\n\nli[[5]]    # 5th element\n\n\n\n\nDataframe:\n\n\ndf[1,2]     # element in row 1, col 2\ndf[17,]     # all elements in row 17\ndf$calName  # all elements in the col named \"colName\"\ndf[[\"calName\"]] # all elements in the col named \"colName\""
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#logic",
    "href": "slides/week-1/w1-intro-r.html#logic",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Logic",
    "text": "Logic\nWe can combine logical statements using and, or, and not.\n\n(X AND Y) requires that both X and Y are true.\n(X OR Y) requires that one of X or Y is true.\n(NOT X) is true if X is false, and false if X is true.\n\n\n\nx &lt;- c(TRUE, FALSE, TRUE, FALSE)\ny &lt;- c(TRUE, TRUE, FALSE, FALSE)\n\nx & y   # AND\n\n[1]  TRUE FALSE FALSE FALSE\n\nx | y   # OR\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n!x & y  # NOT X AND Y\n\n[1] FALSE  TRUE FALSE FALSE"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#vectorization",
    "href": "slides/week-1/w1-intro-r.html#vectorization",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Vectorization",
    "text": "Vectorization\n\n\nR is designed to do vector and matrix math nicely\nMany operations in R are vectorized.\n\nThese functions operate on vectors of values rather than a single value.\ni.e. the function applies to every element of a vector individually.\n\n\n\n\ne.g.:\n\nx &lt;- seq(from = -2, to = 2)\nx\n\n[1] -2 -1  0  1  2\n\n\nSay we want to add 1 to every element of x…"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#vectorization-1",
    "href": "slides/week-1/w1-intro-r.html#vectorization-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Vectorization",
    "text": "Vectorization\n\n\nLoop:\n\nfor(i in 1:length(x)){\n  x[i] &lt;- x[i] + 1\n}\nx\n\n[1] -1  0  1  2  3\n\n\n\nVectorized:\n\nx &lt;- x + 1\nx\n\n[1] -1  0  1  2  3\n\n\n\n\n\nSee how leveraging vectorization in R is great?\n\n\n\n\n\n\n\nLoops be gone!\n\n\nNow forget about loops after this slide! We rarely need them in R and will avoid using them in this class"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#did-you-leave-off-a-parenthesis",
    "href": "slides/week-1/w1-intro-r.html#did-you-leave-off-a-parenthesis",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Did you leave off a parenthesis?",
    "text": "Did you leave off a parenthesis?\nseq(from = 1, to = 10, by = 1\n\nseq(from = 1, to = 10, by = 1\n\nError in parse(text = input): &lt;text&gt;:2:0: unexpected end of input\n1: seq(from = 1, to = 10, by = 1\n   ^\n\n\n\n\nseq(from = 1, to = 10, by = 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#did-you-leave-off-a-comma",
    "href": "slides/week-1/w1-intro-r.html#did-you-leave-off-a-comma",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Did you leave off a comma?",
    "text": "Did you leave off a comma?\nseq(from = 1, to = 10 by = 1)\n\nseq(from = 1, to = 10 by = 1)\n\nError in parse(text = input): &lt;text&gt;:1:23: unexpected symbol\n1: seq(from = 1, to = 10 by\n                          ^\n\n\n\n\nseq(from = 1, to = 10, by = 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#did-you-make-a-typo-are-you-using-the-right-names",
    "href": "slides/week-1/w1-intro-r.html#did-you-make-a-typo-are-you-using-the-right-names",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Did you make a typo? Are you using the right names?",
    "text": "Did you make a typo? Are you using the right names?\nsequence(from = 1, to = 10, by = 1)\n\nsequence(from = 1, to = 10, by = 1)\n\nError in sequence.default(from = 1, to = 10, by = 1): argument \"nvec\" is missing, with no default\n\n\n\n\nseq(from = 1, to = 10, by = 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#are-you-using-the-right-input-that-the-function-expects",
    "href": "slides/week-1/w1-intro-r.html#are-you-using-the-right-input-that-the-function-expects",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Are you using the right input that the function expects?",
    "text": "Are you using the right input that the function expects?\nsqrt(‘1’)\n\nsqrt('1')\n\nError in sqrt(\"1\"): non-numeric argument to mathematical function\n\n\n\n\nsqrt(1)\n\n[1] 1"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#are-you-expecting-the-right-output-of-the-function",
    "href": "slides/week-1/w1-intro-r.html#are-you-expecting-the-right-output-of-the-function",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Are you expecting the right output of the function?",
    "text": "Are you expecting the right output of the function?\n\nmy_obj &lt;- seq(from = 1, to = 10, by = 1)\n\nmy_obj(5)\n\nError in my_obj(5): could not find function \"my_obj\"\n\n\n\n\nmy_obj[5]\n\n[1] 5"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#messages",
    "href": "slides/week-1/w1-intro-r.html#messages",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Messages",
    "text": "Messages\nJust because you see scary red text, this does not mean something went wrong! This is just R communicating with you.\n\n\nFor example, you will often see:\n\n\nlibrary(lme4)\n\nLoading required package: Matrix"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#warnings",
    "href": "slides/week-1/w1-intro-r.html#warnings",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Warnings",
    "text": "Warnings\nOften, R will give you a warning.\n\nThis means that your code did run…\n…but you probably want to make sure it succeeded.\n\n\nDoes this look right?\n\nmy_vec &lt;- c(\"a\", \"b\", \"c\")\n\nmy_new_vec &lt;- as.numeric(my_vec)\n\nWarning: NAs introduced by coercion\n\n\n\n\n\nmy_new_vec\n\n[1] NA NA NA"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#errors",
    "href": "slides/week-1/w1-intro-r.html#errors",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Errors",
    "text": "Errors\nIf the word Error appears in your message from R, then you have a problem.\n\nThis means your code could not run!\n\n\n\nmy_vec &lt;- c(\"a\", \"b\", \"c\")\n\nmy_new_vec &lt;- my_vec + 1\n\nError in my_vec + 1: non-numeric argument to binary operator"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#r-says",
    "href": "slides/week-1/w1-intro-r.html#r-says",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "R says…",
    "text": "R says…\n\nError in ggplot() : could not find function “ggplot”\n\n\nIt probably means…\n\nYou haven’t installed/loaded the package that includes the ggplot() function OR you mispelled the function name\n\nYou should:\n\ncheck if the package is installed\nload the package (library())"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#r-says-1",
    "href": "slides/week-1/w1-intro-r.html#r-says-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "R says…",
    "text": "R says…\n\nError: Object some_obj not found.\n\n\nIt probably means…\n\nYou haven’t run the code to create some_obj OR you have a typo in the name!\n\n\nsome_ojb &lt;- 1:10\n\nmean(some_obj)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'mean': object 'some_obj' not found"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#r-says-2",
    "href": "slides/week-1/w1-intro-r.html#r-says-2",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "R says…",
    "text": "R says…\n\nError: Object of type ‘closure’ is not subsettable.\n\n\nIt probably means…\n\nOops, you tried to use square brackets on a function\n\n\nmean[1, 2]\n\nError in mean[1, 2]: object of type 'closure' is not subsettable"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#r-says-3",
    "href": "slides/week-1/w1-intro-r.html#r-says-3",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "R says…",
    "text": "R says…\n\nError: Non-numeric argument to binary operator.\n\n\nIt probably means…\n\nYou tried to do math on data that isn’t numeric.\n\n\n\"a\" + 2\n\nError in \"a\" + 2: non-numeric argument to binary operator"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-if-none-of-these-solved-my-error",
    "href": "slides/week-1/w1-intro-r.html#what-if-none-of-these-solved-my-error",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What if none of these solved my error?",
    "text": "What if none of these solved my error?\n\nLook at the help file for the function!\nBreak what you are doing down into smaller pieces and look at whether or not each step gives you what you expect\nWhen all else fails, Google your error message.\n\nInclude the function you are using."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#try-it",
    "href": "slides/week-1/w1-intro-r.html#try-it",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Try it…",
    "text": "Try it…\nWhat’s wrong here?\n\nmatrix(c(\"a\", \"b\", \"c\", \"d\"), num_row = 2)\n\nError in matrix(c(\"a\", \"b\", \"c\", \"d\"), num_row = 2): unused argument (num_row = 2)\n\n\n\n\n\n\n\n\n\nTip\n\n\nLook up the help file for the function matrix by running ?matrix in the Console."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#pa-1-find-the-mistakes",
    "href": "slides/week-1/w1-intro-r.html#pa-1-find-the-mistakes",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "PA 1: Find the Mistakes",
    "text": "PA 1: Find the Mistakes\nPart One:\nThis file has many mistakes in the code. Some are errors that will prevent the file from knitting; some are mistakes that do NOT result in an error.\nFix all the problems in the code chunks.\nPart Two:\nFollow the instructions in the file to uncover a secret message.\nSubmit the name of the poem as the answer to the Canvas Quiz question."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#to-do",
    "href": "slides/week-1/w1-intro-r.html#to-do",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "To do…",
    "text": "To do…\n\nRead Chapter 1: Introduction\nCheck-ins 1.1 - 1.4\n\nDue Thursday (4/3) before class\n\nPA 1: Find the Mistakes\n\nDue Friday (4/4) at 11:59 pm"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#thursday-april-10",
    "href": "slides/week-2/w2-graphics.html#thursday-april-10",
    "title": "Basics of Graphics",
    "section": "Thursday, April 10",
    "text": "Thursday, April 10\nToday we will…\n\nNew Material\n\nWhat makes a good graphic?\nColor\n\nLab 2: Exploring Rodents with ggplot2"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#lab-1-notes",
    "href": "slides/week-2/w2-graphics.html#lab-1-notes",
    "title": "Basics of Graphics",
    "section": "Lab 1 Notes",
    "text": "Lab 1 Notes\n\nOverall looking nice!\nmake sure your code is visible: echo: true\nsee what your rendered document looks like before you submit it\nif you have questions about statistical interpretations, just ask!"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#graphics",
    "href": "slides/week-2/w2-graphics.html#graphics",
    "title": "Basics of Graphics",
    "section": "Graphics",
    "text": "Graphics\nGraphics consist of:\n\nStructure: boxplot, scatterplot, etc.\nAesthetics: features such as color, shape, and size that map other variables to structural features.\n\nBoth the structure and aesthetics should help viewers interpret the information."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#what-makes-bad-graphics-bad",
    "href": "slides/week-2/w2-graphics.html#what-makes-bad-graphics-bad",
    "title": "Basics of Graphics",
    "section": "What makes bad graphics bad?",
    "text": "What makes bad graphics bad?\n\nBAD DATA.\nToo much “chartjunk” – superfluous details (Tufte).\nDesign choices that are difficult for the human brain to process, including:\n\n\n\n\n\n\nColors\nOrientation\nOrganization"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#what-makes-good-graphics-good",
    "href": "slides/week-2/w2-graphics.html#what-makes-good-graphics-good",
    "title": "Basics of Graphics",
    "section": "What makes good graphics good?",
    "text": "What makes good graphics good?\nEdward R. Tufte is a well-known critic of visualizations, and his definition of graphical excellence consists of:\n\n\ncommunicating complex ideas with clarity, precision, and efficiency.\nmaximizing the data-to-ink ratio.\nusing multivariate displays.\ntelling the truth about the data."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#graphics-1",
    "href": "slides/week-2/w2-graphics.html#graphics-1",
    "title": "Basics of Graphics",
    "section": "Graphics",
    "text": "Graphics\n\nWhen creating graphics, we need to think carefully about how we make structural and aesthetic decisions.\nThis takes iteration and practice!"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#gestalt-principles",
    "href": "slides/week-2/w2-graphics.html#gestalt-principles",
    "title": "Basics of Graphics",
    "section": "Gestalt Principles",
    "text": "Gestalt Principles\nOur brains have an amazing ability to create and perceive structure among visual objects.\n\n“Gestalt principles of visual perception”\nThis framework can help us think about how to create the most expressive and effective data visualizations"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#gestalt-principles-1",
    "href": "slides/week-2/w2-graphics.html#gestalt-principles-1",
    "title": "Basics of Graphics",
    "section": "Gestalt Principles",
    "text": "Gestalt Principles\n\n\n\nGestalt Hierarchy\nGraphical Feature\n\n\n\n\n1. Enclosure\nFacets\n\n\n2. Connection\nLines\n\n\n3. Proximitiy\nWhite Space\n\n\n4. Similarity\nColor/Shape\n\n\n\n\nImplications for practice:\n\nKnow that we perceive some groups before others.\nDesign to facilitate and emphasize the most important comparisons."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pre-attentive-features",
    "href": "slides/week-2/w2-graphics.html#pre-attentive-features",
    "title": "Basics of Graphics",
    "section": "Pre-attentive Features",
    "text": "Pre-attentive Features\n\nThe next slide will have one point that is not like the others.\n\nRaise your hand when you notice it."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pre-attentive-features-1",
    "href": "slides/week-2/w2-graphics.html#pre-attentive-features-1",
    "title": "Basics of Graphics",
    "section": "Pre-attentive Features",
    "text": "Pre-attentive Features"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pre-attentive-features-2",
    "href": "slides/week-2/w2-graphics.html#pre-attentive-features-2",
    "title": "Basics of Graphics",
    "section": "Pre-attentive Features",
    "text": "Pre-attentive Features"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pre-attentive-features-3",
    "href": "slides/week-2/w2-graphics.html#pre-attentive-features-3",
    "title": "Basics of Graphics",
    "section": "Pre-attentive Features",
    "text": "Pre-attentive Features\nPre-attentive features are features that we see and perceive before we even think about it.\n\nThey will jump out at us in less than 250 ms.\nE.g., color, form, movement, spatial location.\n\n\nThere is a hierarchy of features:\n\nColor is stronger than shape.\nCombinations of pre-attentive features may not be pre-attentive due to interference."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#double-encoding",
    "href": "slides/week-2/w2-graphics.html#double-encoding",
    "title": "Basics of Graphics",
    "section": "Double Encoding",
    "text": "Double Encoding"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#no-double-encoding",
    "href": "slides/week-2/w2-graphics.html#no-double-encoding",
    "title": "Basics of Graphics",
    "section": "No Double Encoding",
    "text": "No Double Encoding"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-1",
    "href": "slides/week-2/w2-graphics.html#color-1",
    "title": "Basics of Graphics",
    "section": "Color",
    "text": "Color\n\nColor, hue, and intensity are pre-attentive features, and bigger contrasts lead to faster detection.\n\nHue: main color family (red, orange, yellow…)\nIntensity: amount of color"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines",
    "href": "slides/week-2/w2-graphics.html#color-guidelines",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\n\nDo not use rainbow color gradients!\nBe conscious of what certain colors “mean”.\n\nGood idea to use red for “good” and green for “bad”?"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-1",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-1",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\n\nFor categorical data, try not to use more than 7 colors:\n\n\n\n\n\n\n\n\n\n\nCan use colorRampPalette() from the RColorBrewer package to produce larger palettes:"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-2",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-2",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\n\nFor quantitative data, use mappings from data to color that are numerically and perceptually uniform.\n\nRelative discriminability of two colors should be proportional to the difference between the corresponding data values."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-3",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-3",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\nTo colorblind-proof a graphic…\n\nuse double encoding - when you use color, also use another aesthetic (line type, shape, etc.)."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-4",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-4",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\nTo colorblind-proof a graphic…\n\nwith a unidirectional scale (e.g., all + values), use a monochromatic color gradient.\n\n\n\n\n\n\n\n\n\n\n\nwith a bidirectional scale (e.g., + and - values), use a purple-white-orange color gradient. Transition through white!"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-5",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-5",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\nTo colorblind-proof a graphic…\n\nprint your chart out in black and white – if you can still read it, it will be safe for all users."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-in-ggplot2",
    "href": "slides/week-2/w2-graphics.html#color-in-ggplot2",
    "title": "Basics of Graphics",
    "section": "Color in ggplot2",
    "text": "Color in ggplot2\nThere are several packages with color scheme options:\n\nRcolorbrewer\nggsci\nviridis\nwesanderson\n\nThese packages have color palettes that are aesthetically pleasing and, in many cases, colorblind friendly.\nYou can also take a look at other ways to find nice color palettes. ColorBrewer is my personal favorite."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#penguins---flipper-length-by-species",
    "href": "slides/week-2/w2-graphics.html#penguins---flipper-length-by-species",
    "title": "Basics of Graphics",
    "section": "Penguins - Flipper Length by Species",
    "text": "Penguins - Flipper Length by Species\n\nSpecies X-AxisSpecies Facets\n\n\n\n\nCode\nggplot(data = penguins,\n       mapping = aes(y = flipper_length_mm, \n                              x = species)) +\n    geom_boxplot() + \n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         x = \"Species\" , \n         y = \"Flipper Length (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = penguins,\n       mapping = aes(y = flipper_length_mm)) +\n    geom_boxplot() + \n    facet_grid(cols = vars(species)) +\n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         y = \"Flipper Length (mm)\")"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#penguins---flipper-length-by-species-sex",
    "href": "slides/week-2/w2-graphics.html#penguins---flipper-length-by-species-sex",
    "title": "Basics of Graphics",
    "section": "Penguins - Flipper Length by Species & Sex",
    "text": "Penguins - Flipper Length by Species & Sex\n\nOption 1Option 2Option 3\n\n\n\n\nCode\nggplot(data = penguins) +\n    geom_boxplot(mapping = aes(y = flipper_length_mm, \n                             x = species,\n                             color = sex)) + \n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         x = \"Species\" , \n         y = \"Flipper Length (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = penguins) +\n    geom_boxplot(mapping = aes(y = flipper_length_mm,\n                               x = sex)) + \n    facet_grid(cols = vars(species)) +\n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         y = \"Flipper Length (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = penguins) +\n    geom_boxplot(mapping = aes(y = flipper_length_mm,\n                               x = species)) + \n    facet_grid(cols = vars(sex)) +\n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         y = \"Flipper Length (mm)\")"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pa-2-example---two-categorical-variables",
    "href": "slides/week-2/w2-graphics.html#pa-2-example---two-categorical-variables",
    "title": "Basics of Graphics",
    "section": "PA 2 Example - Two Categorical Variables",
    "text": "PA 2 Example - Two Categorical Variables\n\nColors & ShapesColors & Facets\n\n\n\n\nCode\nggplot(data = penguins) +\n    geom_point(mapping = aes(x = bill_length_mm, \n                             y = bill_depth_mm, \n                             color = species, \n                             shape = island )) + \n    labs(title = \"Relationship Between Bill Length and Bill Depth\", \n         x = \"Bill Length (mm)\" , \n         y = \"Bill Depth (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = penguins,\n       mapping = aes(x = bill_length_mm, \n                     y = bill_depth_mm, \n                     color = species)) +\n  geom_point() + \n  facet_wrap(~island) +\n  labs(x = \"Bill Length (mm)\",\n       y = \"Bill Depth (mm)\", \n       title = \"Relationship Between Bill Length and Bill Depth\")"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#lecture-example---texas-housing-data",
    "href": "slides/week-2/w2-graphics.html#lecture-example---texas-housing-data",
    "title": "Basics of Graphics",
    "section": "Lecture Example - Texas Housing Data",
    "text": "Lecture Example - Texas Housing Data\n\nColorFacet\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median, color = city)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices over Time for Select Cities\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") + \n  facet_wrap(vars(city)) +\n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices over Time for Select Cities\")"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#example-1",
    "href": "slides/week-2/w2-graphics.html#example-1",
    "title": "Basics of Graphics",
    "section": "Example 1",
    "text": "Example 1"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#example-2",
    "href": "slides/week-2/w2-graphics.html#example-2",
    "title": "Basics of Graphics",
    "section": "Example 2",
    "text": "Example 2\n\nhttps://www.data-to-viz.com/graph/area.html"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#example-3",
    "href": "slides/week-2/w2-graphics.html#example-3",
    "title": "Basics of Graphics",
    "section": "Example 3",
    "text": "Example 3\n\nhttps://r-graph-gallery.com/web-vertical-line-chart-with-ggplot2.html"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#example-4",
    "href": "slides/week-2/w2-graphics.html#example-4",
    "title": "Basics of Graphics",
    "section": "Example 4",
    "text": "Example 4\n\nhttps://r-graph-gallery.com/web-line-chart-with-labels-at-end-of-line.html"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#lab-2-exploring-rodents-with-ggplot2",
    "href": "slides/week-2/w2-graphics.html#lab-2-exploring-rodents-with-ggplot2",
    "title": "Basics of Graphics",
    "section": "Lab 2: Exploring Rodents with ggplot2",
    "text": "Lab 2: Exploring Rodents with ggplot2"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#lab-formatting",
    "href": "slides/week-2/w2-graphics.html#lab-formatting",
    "title": "Basics of Graphics",
    "section": "Lab Formatting",
    "text": "Lab Formatting\n\nStarting with Lab 2, your labs will be graded more strictly on appearance and code format.\nReview the lab formatting guidelines on Canvas before you submit your lab!\nBig points:\n\nuse relative file paths\nmake sure all markdown renders as expected\nNEVER PRINT OUT FULL DATASETS\nno long code lines - use line breaks liberally\n“clean up” the lab before submitting"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#ggplot2-cheatsheet",
    "href": "slides/week-2/w2-graphics.html#ggplot2-cheatsheet",
    "title": "Basics of Graphics",
    "section": "ggplot2 cheatsheet",
    "text": "ggplot2 cheatsheet\n\nggplot2 cheatsheet"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#to-do",
    "href": "slides/week-2/w2-graphics.html#to-do",
    "title": "Basics of Graphics",
    "section": "To do…",
    "text": "To do…\n\nLab 2: Exploring Rodents with ggplot2\n\ndue Monday 4/14 at 11:59pm\n\nRead Chapter 3: Data Cleaning and Manipulation\n\nCheck-in 3.1 due Tuesday 4/15 before class"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#tuesday-april-15",
    "href": "slides/week-3/w3-dplyr.html#tuesday-april-15",
    "title": "Data Cleaning & Manipulation",
    "section": "Tuesday, April 15",
    "text": "Tuesday, April 15\nToday we will…\n\nComments from Week 2\nNew Material\n\nData wrangling\nIntroduce the dplyr package.\nUse dplyr verbs to manipulate data.\n\nPA 3: Identify the Mystery College\n\n\n\n\n\n\n\nFollow along\n\n\nRemember to download, save, and open up the starter notes for this week!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#syle-note-of-the-day---spacing",
    "href": "slides/week-3/w3-dplyr.html#syle-note-of-the-day---spacing",
    "title": "Data Cleaning & Manipulation",
    "section": "Syle Note of the Day - Spacing",
    "text": "Syle Note of the Day - Spacing\n\n\nAlways put a space after a comma, but never before\nSurround = with spaces when naming arguments\nSurround many mathematical operators (+, -, *) with spaces (but not all!)\nDon’t include spaces around parentheses for function calls (although you may include a new-line)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#syle-note-of-the-day---spacing-1",
    "href": "slides/week-3/w3-dplyr.html#syle-note-of-the-day---spacing-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Syle Note of the Day - Spacing",
    "text": "Syle Note of the Day - Spacing\nNice:\n\nmean(x, na.rm = TRUE)\n\nheight &lt;- (feet * 12) + inches\n\n2^2\n\nNo thank you:\n\nmean(x,na.rm=TRUE)\nmean( x , na.rm = TRUE )\nmean (x, na.rm = TRUE)\n\nheight&lt;-(feet*12)+inches\n\n2 ^ 2"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#demonstration-data-cereal",
    "href": "slides/week-3/w3-dplyr.html#demonstration-data-cereal",
    "title": "Data Cleaning & Manipulation",
    "section": "Demonstration Data – Cereal",
    "text": "Demonstration Data – Cereal\n\nlibrary(liver)\ndata(cereal)\n\n\n\nData StructureHead of the DataData Summary\n\n\n\nstr(cereal, give.attr = FALSE)\n\n'data.frame':   77 obs. of  16 variables:\n $ name    : Factor w/ 77 levels \"100% Bran\",\"100% Natural Bran\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ manuf   : Factor w/ 7 levels \"A\",\"G\",\"K\",\"N\",..: 4 6 3 3 7 2 3 2 7 5 ...\n $ type    : Factor w/ 2 levels \"cold\",\"hot\": 1 1 1 1 1 1 1 1 1 1 ...\n $ calories: int  70 120 70 50 110 110 110 130 90 90 ...\n $ protein : int  4 3 4 4 2 2 2 3 2 3 ...\n $ fat     : int  1 5 1 0 2 2 0 2 1 0 ...\n $ sodium  : int  130 15 260 140 200 180 125 210 200 210 ...\n $ fiber   : num  10 2 9 14 1 1.5 1 2 4 5 ...\n $ carbo   : num  5 8 7 8 14 10.5 11 18 15 13 ...\n $ sugars  : int  6 8 5 0 8 10 14 8 6 5 ...\n $ potass  : int  280 135 320 330 -1 70 30 100 125 190 ...\n $ vitamins: int  25 0 25 25 25 25 25 25 25 25 ...\n $ shelf   : int  3 3 3 3 3 1 2 3 1 3 ...\n $ weight  : num  1 1 1 1 1 1 1 1.33 1 1 ...\n $ cups    : num  0.33 1 0.33 0.5 0.75 0.75 1 0.75 0.67 0.67 ...\n $ rating  : num  68.4 34 59.4 93.7 34.4 ...\n\n\n\n\n\nhead(cereal) \n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1\n0.75\n29.50954\n\n\n\n\n\n\n\n\n\n\nsummary(cereal)\n\n                        name    manuf    type       calories    \n 100% Bran                : 1   A: 1   cold:74   Min.   : 50.0  \n 100% Natural Bran        : 1   G:22   hot : 3   1st Qu.:100.0  \n All-Bran                 : 1   K:23             Median :110.0  \n All-Bran with Extra Fiber: 1   N: 6             Mean   :106.9  \n Almond Delight           : 1   P: 9             3rd Qu.:110.0  \n Apple Cinnamon Cheerios  : 1   Q: 8             Max.   :160.0  \n (Other)                  :71   R: 8                            \n    protein           fat            sodium          fiber       \n Min.   :1.000   Min.   :0.000   Min.   :  0.0   Min.   : 0.000  \n 1st Qu.:2.000   1st Qu.:0.000   1st Qu.:130.0   1st Qu.: 1.000  \n Median :3.000   Median :1.000   Median :180.0   Median : 2.000  \n Mean   :2.545   Mean   :1.013   Mean   :159.7   Mean   : 2.152  \n 3rd Qu.:3.000   3rd Qu.:2.000   3rd Qu.:210.0   3rd Qu.: 3.000  \n Max.   :6.000   Max.   :5.000   Max.   :320.0   Max.   :14.000  \n                                                                 \n     carbo          sugars           potass          vitamins     \n Min.   :-1.0   Min.   :-1.000   Min.   : -1.00   Min.   :  0.00  \n 1st Qu.:12.0   1st Qu.: 3.000   1st Qu.: 40.00   1st Qu.: 25.00  \n Median :14.0   Median : 7.000   Median : 90.00   Median : 25.00  \n Mean   :14.6   Mean   : 6.922   Mean   : 96.08   Mean   : 28.25  \n 3rd Qu.:17.0   3rd Qu.:11.000   3rd Qu.:120.00   3rd Qu.: 25.00  \n Max.   :23.0   Max.   :15.000   Max.   :330.00   Max.   :100.00  \n                                                                  \n     shelf           weight          cups           rating     \n Min.   :1.000   Min.   :0.50   Min.   :0.250   Min.   :18.04  \n 1st Qu.:1.000   1st Qu.:1.00   1st Qu.:0.670   1st Qu.:33.17  \n Median :2.000   Median :1.00   Median :0.750   Median :40.40  \n Mean   :2.208   Mean   :1.03   Mean   :0.821   Mean   :42.67  \n 3rd Qu.:3.000   3rd Qu.:1.00   3rd Qu.:1.000   3rd Qu.:50.83  \n Max.   :3.000   Max.   :1.50   Max.   :1.500   Max.   :93.70"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#before-jumping-in-to-code",
    "href": "slides/week-3/w3-dplyr.html#before-jumping-in-to-code",
    "title": "Data Cleaning & Manipulation",
    "section": "Before jumping in to code…",
    "text": "Before jumping in to code…\nIn groups, write a game plan or describe in words steps you would take from cereal data to get the output for each of the following:\n\nWhat is the ratio of fiber to sugars in each cereal?\nCreate a new dataset that only has Nabisco cereals and displays the protein, fat, and sodium in each.\nCreate a table that shows, for each manufacturer the average and standard deviation of the grams of sugar in their cereals, along with how many cereals are in the data for each manufacturer. Order the table from most sugar (on average) to least."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#dplyr",
    "href": "slides/week-3/w3-dplyr.html#dplyr",
    "title": "Data Cleaning & Manipulation",
    "section": "dplyr",
    "text": "dplyr\ndplyr is part of the tidyverse that provides us with the Grammar of Data Manipulation.\n\nThis package gives us the tools to wrangle, manipulate, and tidy our data with ease.\nCheck out the dplyr cheatsheet."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#dplyr-verbs",
    "href": "slides/week-3/w3-dplyr.html#dplyr-verbs",
    "title": "Data Cleaning & Manipulation",
    "section": "dplyr verbs",
    "text": "dplyr verbs\n\nfilter() – select rows based on their values\narrange() – sort rows based on their values\nselect() – select columns\nmutate() – add new columns by transforming other columns\nsummarize() – perform summary operations on columns\ngroup_by() – facilitate group-wise operations\n\n\nUse the pipe operator (|&gt; or %&gt;%) to chain together data wrangling operations."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#match-the-dplyr-verb",
    "href": "slides/week-3/w3-dplyr.html#match-the-dplyr-verb",
    "title": "Data Cleaning & Manipulation",
    "section": "Match the dplyr verb",
    "text": "Match the dplyr verb\nIn groups match the dplyr verbs to your suggested steps:\n\nWhat is the ratio of fiber to sugars in each cereal?\nCreate a new dataset that only has Nabisco cereals and displays the protein, fat, and sodium in each.\nCreate a table that shows, for each manufacturer the average and standard deviation of the grams of sugar in their cereals, along with how many cereals are in the data for each manufacturer. Order the table from most sugar (on average) to least."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#the-pipe-operator-1",
    "href": "slides/week-3/w3-dplyr.html#the-pipe-operator-1",
    "title": "Data Cleaning & Manipulation",
    "section": "The Pipe Operator",
    "text": "The Pipe Operator\n\nThe pipe specifies a sequence of operations.\nThe output from one operation is passed (piped) into the first argument of the next operation.\n\n\nThese are equivalent:\n\n\n\nsummary(cereal)\n\n\n\ncereal |&gt; \n  summary()"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#the-pipe-operator-2",
    "href": "slides/week-3/w3-dplyr.html#the-pipe-operator-2",
    "title": "Data Cleaning & Manipulation",
    "section": "The Pipe Operator",
    "text": "The Pipe Operator\n\n\nThe “original” pipe: %&gt;%\n\nLoaded with tidyverse package (part of magrittr).\n\nThe “native” pipe: |&gt;\n\nCreated in R version 4.1.0.\nTools &gt; Global Options... &gt; Code &gt; check Use native pipe operator box to use keyboard shortcut:\n\nctrl/cmd + shift + m"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#the-pipe-operator-3",
    "href": "slides/week-3/w3-dplyr.html#the-pipe-operator-3",
    "title": "Data Cleaning & Manipulation",
    "section": "The Pipe Operator",
    "text": "The Pipe Operator\n\nWith dplyr, your code should read like a sentence.\nThe data is the primary object in your sentence, so it should come first in your code.\nThe pipe operator is an important part of that readability.\n\n\n\ndr_c |&gt;\n  bake_a_dessert()\n\n\n\n\ndr_c |&gt;\n  put_on(\"apron\") |&gt;\n  bake_a_dessert(type = \"cake\")\n\n\n\nSO MUCH better than:\n\n  bake_a_dessert(put_on(dr_c, \"apron\"), type = \"cake\")"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#data-comes-first",
    "href": "slides/week-3/w3-dplyr.html#data-comes-first",
    "title": "Data Cleaning & Manipulation",
    "section": "Data Comes First!",
    "text": "Data Comes First!\ndplyr verbs are designed for piping!\n\nfilter(.data = cereal, ...)\nselect(.data = cereal, ...)\nmutate(.data = cereal, ...)\n\n\n\nThe pipe operator is your friend!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-1",
    "href": "slides/week-3/w3-dplyr.html#filter-1",
    "title": "Data Cleaning & Manipulation",
    "section": "filter()",
    "text": "filter()\nWe filter to the rows (observations) we would like to keep in the data.\n\n\ncereal |&gt; \n  filter(sugars &lt; 5)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17\n3\n110\n25\n1\n1.00\n1.00\n51.59219"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-2",
    "href": "slides/week-3/w3-dplyr.html#filter-2",
    "title": "Data Cleaning & Manipulation",
    "section": "filter()",
    "text": "filter()\nWe can add multiple filters to our data, to get a more specific subset.\n\ncereal |&gt; \n  filter(sugars &lt; 5,\n         type == \"hot\")\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21\n0\n-1\n0\n2\n1\n1.00\n64.53382\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1\n1.00\n54.85092\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1\n0.67\n50.82839"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-handy-helpers",
    "href": "slides/week-3/w3-dplyr.html#filter-handy-helpers",
    "title": "Data Cleaning & Manipulation",
    "section": "filter(): Handy Helpers!",
    "text": "filter(): Handy Helpers!\n\n&gt; – greater than\n&lt; – less than\n== – equal to\n! – not\n%in% – checks if an element belongs to a vector\nis.na() – binary evaluation of missing values\n\n\n\n& and , – and\n| – or"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-3",
    "href": "slides/week-3/w3-dplyr.html#filter-3",
    "title": "Data Cleaning & Manipulation",
    "section": "filter(): |",
    "text": "filter(): |\n\ncereal |&gt; \n  filter(sugars &lt; 5,\n         type == \"hot\")\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21\n0\n-1\n0\n2\n1\n1.00\n64.53382\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1\n1.00\n54.85092\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1\n0.67\n50.82839\n\n\n\n\n\n\n\n\nWhat if I wanted either non-sugary cereals or hot cereals…\n\n\nCode\ncereal |&gt; \n  filter(sugars &lt; 5 |\n           type == \"hot\")"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-in",
    "href": "slides/week-3/w3-dplyr.html#filter-in",
    "title": "Data Cleaning & Manipulation",
    "section": "filter(): %in%",
    "text": "filter(): %in%\nAre you interested in observations with values in multiple levels?\n\n\ncereal |&gt; \n  filter(name %in% c(\"Cheerios\", \"Cinnamon Toast Crunch\", \"Raisin Bran\", \"Cracklin' Oat Bran\"))\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2\n17\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0\n13\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4\n10\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5\n14\n12\n240\n25\n2\n1.33\n0.75\n39.25920"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-related-functions",
    "href": "slides/week-3/w3-dplyr.html#filter-related-functions",
    "title": "Data Cleaning & Manipulation",
    "section": "filter(): Related Functions",
    "text": "filter(): Related Functions\nThese functions select rows by row number.\n\nslice() – select rows with the specified indicies\nslice_head() – select the first n rows\nslice_tail() – select the last n rows\nslice_sample() – randomly select n rows"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#arrange-1",
    "href": "slides/week-3/w3-dplyr.html#arrange-1",
    "title": "Data Cleaning & Manipulation",
    "section": "arrange()",
    "text": "arrange()\nWe arrange the rows of the data in order of a particular variable.\n\n\n\ncereal |&gt; \n  arrange(sodium)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#arrange-2",
    "href": "slides/week-3/w3-dplyr.html#arrange-2",
    "title": "Data Cleaning & Manipulation",
    "section": "arrange()",
    "text": "arrange()\nWe can arrange by multiple variables.\n\n\n\ncereal |&gt; \n  arrange(sodium, sugars) |&gt;\n  select(name:type, sodium, sugars)\n\n\n\n\n\n\n\nname\nmanuf\ntype\nsodium\nsugars\n\n\n\n\nQuaker Oatmeal\nQ\nhot\n0\n-1\n\n\nPuffed Rice\nQ\ncold\n0\n0\n\n\nPuffed Wheat\nQ\ncold\n0\n0\n\n\nShredded Wheat\nN\ncold\n0\n0\n\n\nShredded Wheat 'n'Bran\nN\ncold\n0\n0\n\n\nShredded Wheat spoon size\nN\ncold\n0\n0\n\n\nMaypo\nA\nhot\n0\n3\n\n\nRaisin Squares\nK\ncold\n0\n6\n\n\nFrosted Mini-Wheats\nK\ncold\n0\n7\n\n\nStrawberry Fruit Wheats\nN\ncold\n15\n5\n\n\n100% Natural Bran\nQ\ncold\n15\n8\n\n\nGolden Crisp\nP\ncold\n45\n15\n\n\nSmacks\nK\ncold\n70\n15\n\n\nGreat Grains Pecan\nP\ncold\n75\n4\n\n\nCream of Wheat (Quick)\nN\nhot\n80\n0\n\n\nCorn Pops\nK\ncold\n90\n12\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n95\n11\n\n\nFroot Loops\nK\ncold\n125\n13\n\n\nApple Jacks\nK\ncold\n125\n14\n\n\n100% Bran\nN\ncold\n130\n6\n\n\nQuaker Oat Squares\nQ\ncold\n135\n6\n\n\nFruity Pebbles\nP\ncold\n135\n12\n\n\nAll-Bran with Extra Fiber\nK\ncold\n140\n0\n\n\nGrape Nuts Flakes\nP\ncold\n140\n5\n\n\nClusters\nG\ncold\n140\n7\n\n\nCracklin' Oat Bran\nK\ncold\n140\n7\n\n\nRaisin Nut Bran\nG\ncold\n140\n8\n\n\nCrispy Wheat & Raisins\nG\ncold\n140\n10\n\n\nTrix\nG\ncold\n140\n12\n\n\nLife\nQ\ncold\n150\n6\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n11\n\n\nMueslix Crispy Blend\nK\ncold\n150\n13\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n160\n10\n\n\nNutri-grain Wheat\nK\ncold\n170\n2\n\n\nGrape-Nuts\nP\ncold\n170\n3\n\n\nJust Right Crunchy Nuggets\nK\ncold\n170\n6\n\n\nJust Right Fruit & Nut\nK\ncold\n170\n9\n\n\nOatmeal Raisin Crisp\nG\ncold\n170\n10\n\n\nApple Cinnamon Cheerios\nG\ncold\n180\n10\n\n\nHoney-comb\nP\ncold\n180\n11\n\n\nLucky Charms\nG\ncold\n180\n12\n\n\nCocoa Puffs\nG\ncold\n180\n13\n\n\nCount Chocula\nG\ncold\n180\n13\n\n\nDouble Chex\nR\ncold\n190\n5\n\n\nNut&Honey Crunch\nK\ncold\n190\n9\n\n\nTotal Raisin Bran\nG\ncold\n190\n14\n\n\nTotal Corn Flakes\nG\ncold\n200\n3\n\n\nTotal Whole Grain\nG\ncold\n200\n3\n\n\nWheaties\nG\ncold\n200\n3\n\n\nBran Chex\nR\ncold\n200\n6\n\n\nAlmond Delight\nR\ncold\n200\n8\n\n\nWheaties Honey Gold\nG\ncold\n200\n8\n\n\nFrosted Flakes\nK\ncold\n200\n11\n\n\nPost Nat. Raisin Bran\nP\ncold\n200\n14\n\n\nBran Flakes\nP\ncold\n210\n5\n\n\nBasic 4\nG\ncold\n210\n8\n\n\nCinnamon Toast Crunch\nG\ncold\n210\n9\n\n\nRaisin Bran\nK\ncold\n210\n12\n\n\nCrispix\nK\ncold\n220\n3\n\n\nMulti-Grain Cheerios\nG\ncold\n220\n6\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n220\n7\n\n\nHoney Graham Ohs\nQ\ncold\n220\n11\n\n\nCap'n'Crunch\nQ\ncold\n220\n12\n\n\nSpecial K\nK\ncold\n230\n3\n\n\nWheat Chex\nR\ncold\n230\n3\n\n\nRice Chex\nR\ncold\n240\n2\n\n\nFruitful Bran\nK\ncold\n240\n12\n\n\nTriples\nG\ncold\n250\n3\n\n\nHoney Nut Cheerios\nG\ncold\n250\n10\n\n\nKix\nG\ncold\n260\n3\n\n\nAll-Bran\nK\ncold\n260\n5\n\n\nCorn Chex\nR\ncold\n280\n3\n\n\nGolden Grahams\nG\ncold\n280\n9\n\n\nCheerios\nG\ncold\n290\n1\n\n\nCorn Flakes\nK\ncold\n290\n2\n\n\nRice Krispies\nK\ncold\n290\n3\n\n\nProduct 19\nK\ncold\n320\n3"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#arrange-descending-order",
    "href": "slides/week-3/w3-dplyr.html#arrange-descending-order",
    "title": "Data Cleaning & Manipulation",
    "section": "arrange(): Descending Order",
    "text": "arrange(): Descending Order\nDefault is ascending order…\n\ncereal |&gt; \n  arrange(sodium)\n\n\n…but can add desc() to get descending order!\n\ncereal |&gt; \n  arrange(desc(sodium))"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#arrange-related-functions",
    "href": "slides/week-3/w3-dplyr.html#arrange-related-functions",
    "title": "Data Cleaning & Manipulation",
    "section": "arrange(): Related Functions",
    "text": "arrange(): Related Functions\nThese functions implicitly arrange the data before slicing it (selecting rows).\n\nslice_min() – select rows with the lowest value(s) of a variable\nslice_max() – select rows with the highest value(s) of a variable"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#slice_max",
    "href": "slides/week-3/w3-dplyr.html#slice_max",
    "title": "Data Cleaning & Manipulation",
    "section": "slice_max()",
    "text": "slice_max()\nSelects the n rows with the maximum values of the specified variable.\n\ncereal |&gt; \n  slice_max(order_by = sugars, n = 3)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0\n11\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1\n9\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1\n11\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6\n11\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4\n15\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\n\n\n\n\n\n\n\ncereal |&gt; \n  slice_max(order_by = sugars, n = 3, with_ties = FALSE)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#efficiency-note",
    "href": "slides/week-3/w3-dplyr.html#efficiency-note",
    "title": "Data Cleaning & Manipulation",
    "section": "Efficiency note",
    "text": "Efficiency note\nUse slice_max()/slice_min():\n\ncereal |&gt; \n  slice_max(order_by = sugars, n = 3)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0\n11\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1\n9\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1\n11\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6\n11\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4\n15\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\n\n\n\n\n\nNot arrange() and slice_head():\n\ncereal |&gt; \n  arrange(desc(sugars)) |&gt; \n  slice_head(n = 3)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0\n11\n15\n40\n25\n1\n1\n0.88\n35.25244\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1\n9\n15\n40\n25\n2\n1\n0.75\n31.23005\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1\n11\n14\n30\n25\n2\n1\n1.00\n33.17409"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#select-1",
    "href": "slides/week-3/w3-dplyr.html#select-1",
    "title": "Data Cleaning & Manipulation",
    "section": "select()",
    "text": "select()\nWe select which variables we would like to remain in the data.\n\n\ncereal |&gt; \n  select(name, manuf, calories, cups)\n\n\n\n\n\n\n\nname\nmanuf\ncalories\ncups\n\n\n\n\n100% Bran\nN\n70\n0.33\n\n\n100% Natural Bran\nQ\n120\n1.00\n\n\nAll-Bran\nK\n70\n0.33\n\n\nAll-Bran with Extra Fiber\nK\n50\n0.50\n\n\nAlmond Delight\nR\n110\n0.75\n\n\nApple Cinnamon Cheerios\nG\n110\n0.75\n\n\nApple Jacks\nK\n110\n1.00\n\n\nBasic 4\nG\n130\n0.75\n\n\nBran Chex\nR\n90\n0.67\n\n\nBran Flakes\nP\n90\n0.67\n\n\nCap'n'Crunch\nQ\n120\n0.75\n\n\nCheerios\nG\n110\n1.25\n\n\nCinnamon Toast Crunch\nG\n120\n0.75\n\n\nClusters\nG\n110\n0.50\n\n\nCocoa Puffs\nG\n110\n1.00\n\n\nCorn Chex\nR\n110\n1.00\n\n\nCorn Flakes\nK\n100\n1.00\n\n\nCorn Pops\nK\n110\n1.00\n\n\nCount Chocula\nG\n110\n1.00\n\n\nCracklin' Oat Bran\nK\n110\n0.50\n\n\nCream of Wheat (Quick)\nN\n100\n1.00\n\n\nCrispix\nK\n110\n1.00\n\n\nCrispy Wheat & Raisins\nG\n100\n0.75\n\n\nDouble Chex\nR\n100\n0.75\n\n\nFroot Loops\nK\n110\n1.00\n\n\nFrosted Flakes\nK\n110\n0.75\n\n\nFrosted Mini-Wheats\nK\n100\n0.80\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\n120\n0.67\n\n\nFruitful Bran\nK\n120\n0.67\n\n\nFruity Pebbles\nP\n110\n0.75\n\n\nGolden Crisp\nP\n100\n0.88\n\n\nGolden Grahams\nG\n110\n0.75\n\n\nGrape Nuts Flakes\nP\n100\n0.88\n\n\nGrape-Nuts\nP\n110\n0.25\n\n\nGreat Grains Pecan\nP\n120\n0.33\n\n\nHoney Graham Ohs\nQ\n120\n1.00\n\n\nHoney Nut Cheerios\nG\n110\n0.75\n\n\nHoney-comb\nP\n110\n1.33\n\n\nJust Right Crunchy Nuggets\nK\n110\n1.00\n\n\nJust Right Fruit & Nut\nK\n140\n0.75\n\n\nKix\nG\n110\n1.50\n\n\nLife\nQ\n100\n0.67\n\n\nLucky Charms\nG\n110\n1.00\n\n\nMaypo\nA\n100\n1.00\n\n\nMuesli Raisins; Dates; & Almonds\nR\n150\n1.00\n\n\nMuesli Raisins; Peaches; & Pecans\nR\n150\n1.00\n\n\nMueslix Crispy Blend\nK\n160\n0.67\n\n\nMulti-Grain Cheerios\nG\n100\n1.00\n\n\nNut&Honey Crunch\nK\n120\n0.67\n\n\nNutri-Grain Almond-Raisin\nK\n140\n0.67\n\n\nNutri-grain Wheat\nK\n90\n1.00\n\n\nOatmeal Raisin Crisp\nG\n130\n0.50\n\n\nPost Nat. Raisin Bran\nP\n120\n0.67\n\n\nProduct 19\nK\n100\n1.00\n\n\nPuffed Rice\nQ\n50\n1.00\n\n\nPuffed Wheat\nQ\n50\n1.00\n\n\nQuaker Oat Squares\nQ\n100\n0.50\n\n\nQuaker Oatmeal\nQ\n100\n0.67\n\n\nRaisin Bran\nK\n120\n0.75\n\n\nRaisin Nut Bran\nG\n100\n0.50\n\n\nRaisin Squares\nK\n90\n0.50\n\n\nRice Chex\nR\n110\n1.13\n\n\nRice Krispies\nK\n110\n1.00\n\n\nShredded Wheat\nN\n80\n1.00\n\n\nShredded Wheat 'n'Bran\nN\n90\n0.67\n\n\nShredded Wheat spoon size\nN\n90\n0.67\n\n\nSmacks\nK\n110\n0.75\n\n\nSpecial K\nK\n110\n1.00\n\n\nStrawberry Fruit Wheats\nN\n90\n1.00\n\n\nTotal Corn Flakes\nG\n110\n1.00\n\n\nTotal Raisin Bran\nG\n140\n1.00\n\n\nTotal Whole Grain\nG\n100\n1.00\n\n\nTriples\nG\n110\n0.75\n\n\nTrix\nG\n110\n1.00\n\n\nWheat Chex\nR\n100\n0.67\n\n\nWheaties\nG\n100\n1.00\n\n\nWheaties Honey Gold\nG\n110\n0.75"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#select-2",
    "href": "slides/week-3/w3-dplyr.html#select-2",
    "title": "Data Cleaning & Manipulation",
    "section": "select()",
    "text": "select()\nYou can use : to select a sequence of columns.\n\ncereal |&gt; \n  select(name:calories)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\n\n\n\n\n100% Bran\nN\ncold\n70\n\n\n100% Natural Bran\nQ\ncold\n120\n\n\nAll-Bran\nK\ncold\n70\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n\n\nAlmond Delight\nR\ncold\n110\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n\n\nApple Jacks\nK\ncold\n110\n\n\nBasic 4\nG\ncold\n130\n\n\nBran Chex\nR\ncold\n90\n\n\nBran Flakes\nP\ncold\n90\n\n\nCap'n'Crunch\nQ\ncold\n120\n\n\nCheerios\nG\ncold\n110\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n\n\nClusters\nG\ncold\n110\n\n\nCocoa Puffs\nG\ncold\n110\n\n\nCorn Chex\nR\ncold\n110\n\n\nCorn Flakes\nK\ncold\n100\n\n\nCorn Pops\nK\ncold\n110\n\n\nCount Chocula\nG\ncold\n110\n\n\nCracklin' Oat Bran\nK\ncold\n110\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n\n\nCrispix\nK\ncold\n110\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n\n\nDouble Chex\nR\ncold\n100\n\n\nFroot Loops\nK\ncold\n110\n\n\nFrosted Flakes\nK\ncold\n110\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n\n\nFruitful Bran\nK\ncold\n120\n\n\nFruity Pebbles\nP\ncold\n110\n\n\nGolden Crisp\nP\ncold\n100\n\n\nGolden Grahams\nG\ncold\n110\n\n\nGrape Nuts Flakes\nP\ncold\n100\n\n\nGrape-Nuts\nP\ncold\n110\n\n\nGreat Grains Pecan\nP\ncold\n120\n\n\nHoney Graham Ohs\nQ\ncold\n120\n\n\nHoney Nut Cheerios\nG\ncold\n110\n\n\nHoney-comb\nP\ncold\n110\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n\n\nKix\nG\ncold\n110\n\n\nLife\nQ\ncold\n100\n\n\nLucky Charms\nG\ncold\n110\n\n\nMaypo\nA\nhot\n100\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n\n\nMueslix Crispy Blend\nK\ncold\n160\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n\n\nNut&Honey Crunch\nK\ncold\n120\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n\n\nNutri-grain Wheat\nK\ncold\n90\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n\n\nProduct 19\nK\ncold\n100\n\n\nPuffed Rice\nQ\ncold\n50\n\n\nPuffed Wheat\nQ\ncold\n50\n\n\nQuaker Oat Squares\nQ\ncold\n100\n\n\nQuaker Oatmeal\nQ\nhot\n100\n\n\nRaisin Bran\nK\ncold\n120\n\n\nRaisin Nut Bran\nG\ncold\n100\n\n\nRaisin Squares\nK\ncold\n90\n\n\nRice Chex\nR\ncold\n110\n\n\nRice Krispies\nK\ncold\n110\n\n\nShredded Wheat\nN\ncold\n80\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n\n\nShredded Wheat spoon size\nN\ncold\n90\n\n\nSmacks\nK\ncold\n110\n\n\nSpecial K\nK\ncold\n110\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n\n\nTotal Corn Flakes\nG\ncold\n110\n\n\nTotal Raisin Bran\nG\ncold\n140\n\n\nTotal Whole Grain\nG\ncold\n100\n\n\nTriples\nG\ncold\n110\n\n\nTrix\nG\ncold\n110\n\n\nWheat Chex\nR\ncold\n100\n\n\nWheaties\nG\ncold\n100\n\n\nWheaties Honey Gold\nG\ncold\n110\n\n\n\n\n\n\n\n\nYou can remove columns from the dataset using a -.\n\ncereal |&gt; \n  select(-rating)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#select-reordering",
    "href": "slides/week-3/w3-dplyr.html#select-reordering",
    "title": "Data Cleaning & Manipulation",
    "section": "select(): Reordering",
    "text": "select(): Reordering\nYou can reorder columns inside of select().\n\ncereal |&gt; \n  select(name, rating, manuf, type, calories, cups, weight,\n         everything())\n\n\n\n\n\n\n\nname\nrating\nmanuf\ntype\ncalories\ncups\nweight\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\n\n\n\n\n100% Bran\n68.40297\nN\ncold\n70\n0.33\n1.00\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n\n\n100% Natural Bran\n33.98368\nQ\ncold\n120\n1.00\n1.00\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n\n\nAll-Bran\n59.42551\nK\ncold\n70\n0.33\n1.00\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n\n\nAll-Bran with Extra Fiber\n93.70491\nK\ncold\n50\n0.50\n1.00\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n\n\nAlmond Delight\n34.38484\nR\ncold\n110\n0.75\n1.00\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n\n\nApple Cinnamon Cheerios\n29.50954\nG\ncold\n110\n0.75\n1.00\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n\n\nApple Jacks\n33.17409\nK\ncold\n110\n1.00\n1.00\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n\n\nBasic 4\n37.03856\nG\ncold\n130\n0.75\n1.33\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n\n\nBran Chex\n49.12025\nR\ncold\n90\n0.67\n1.00\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n\n\nBran Flakes\n53.31381\nP\ncold\n90\n0.67\n1.00\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n\n\nCap'n'Crunch\n18.04285\nQ\ncold\n120\n0.75\n1.00\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n\n\nCheerios\n50.76500\nG\ncold\n110\n1.25\n1.00\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n\n\nCinnamon Toast Crunch\n19.82357\nG\ncold\n120\n0.75\n1.00\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n\n\nClusters\n40.40021\nG\ncold\n110\n0.50\n1.00\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n\n\nCocoa Puffs\n22.73645\nG\ncold\n110\n1.00\n1.00\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n\n\nCorn Chex\n41.44502\nR\ncold\n110\n1.00\n1.00\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n\n\nCorn Flakes\n45.86332\nK\ncold\n100\n1.00\n1.00\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n\n\nCorn Pops\n35.78279\nK\ncold\n110\n1.00\n1.00\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n\n\nCount Chocula\n22.39651\nG\ncold\n110\n1.00\n1.00\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n\n\nCracklin' Oat Bran\n40.44877\nK\ncold\n110\n0.50\n1.00\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n\n\nCream of Wheat (Quick)\n64.53382\nN\nhot\n100\n1.00\n1.00\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n\n\nCrispix\n46.89564\nK\ncold\n110\n1.00\n1.00\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n\n\nCrispy Wheat & Raisins\n36.17620\nG\ncold\n100\n0.75\n1.00\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n\n\nDouble Chex\n44.33086\nR\ncold\n100\n0.75\n1.00\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n\n\nFroot Loops\n32.20758\nK\ncold\n110\n1.00\n1.00\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n\n\nFrosted Flakes\n31.43597\nK\ncold\n110\n0.75\n1.00\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n\n\nFrosted Mini-Wheats\n58.34514\nK\ncold\n100\n0.80\n1.00\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n\n\nFruit & Fibre Dates; Walnuts; and Oats\n40.91705\nP\ncold\n120\n0.67\n1.25\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n\n\nFruitful Bran\n41.01549\nK\ncold\n120\n0.67\n1.33\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n\n\nFruity Pebbles\n28.02576\nP\ncold\n110\n0.75\n1.00\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n\n\nGolden Crisp\n35.25244\nP\ncold\n100\n0.88\n1.00\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n\n\nGolden Grahams\n23.80404\nG\ncold\n110\n0.75\n1.00\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n\n\nGrape Nuts Flakes\n52.07690\nP\ncold\n100\n0.88\n1.00\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n\n\nGrape-Nuts\n53.37101\nP\ncold\n110\n0.25\n1.00\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n\n\nGreat Grains Pecan\n45.81172\nP\ncold\n120\n0.33\n1.00\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n\n\nHoney Graham Ohs\n21.87129\nQ\ncold\n120\n1.00\n1.00\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n\n\nHoney Nut Cheerios\n31.07222\nG\ncold\n110\n0.75\n1.00\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n\n\nHoney-comb\n28.74241\nP\ncold\n110\n1.33\n1.00\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n\n\nJust Right Crunchy Nuggets\n36.52368\nK\ncold\n110\n1.00\n1.00\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n\n\nJust Right Fruit & Nut\n36.47151\nK\ncold\n140\n0.75\n1.30\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n\n\nKix\n39.24111\nG\ncold\n110\n1.50\n1.00\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n\n\nLife\n45.32807\nQ\ncold\n100\n0.67\n1.00\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n\n\nLucky Charms\n26.73451\nG\ncold\n110\n1.00\n1.00\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n\n\nMaypo\n54.85092\nA\nhot\n100\n1.00\n1.00\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n\n\nMuesli Raisins; Dates; & Almonds\n37.13686\nR\ncold\n150\n1.00\n1.00\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n\n\nMuesli Raisins; Peaches; & Pecans\n34.13976\nR\ncold\n150\n1.00\n1.00\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n\n\nMueslix Crispy Blend\n30.31335\nK\ncold\n160\n0.67\n1.50\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n\n\nMulti-Grain Cheerios\n40.10596\nG\ncold\n100\n1.00\n1.00\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n\n\nNut&Honey Crunch\n29.92429\nK\ncold\n120\n0.67\n1.00\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n\n\nNutri-Grain Almond-Raisin\n40.69232\nK\ncold\n140\n0.67\n1.33\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n\n\nNutri-grain Wheat\n59.64284\nK\ncold\n90\n1.00\n1.00\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n\n\nOatmeal Raisin Crisp\n30.45084\nG\ncold\n130\n0.50\n1.25\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n\n\nPost Nat. Raisin Bran\n37.84059\nP\ncold\n120\n0.67\n1.33\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n\n\nProduct 19\n41.50354\nK\ncold\n100\n1.00\n1.00\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n\n\nPuffed Rice\n60.75611\nQ\ncold\n50\n1.00\n0.50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n\n\nPuffed Wheat\n63.00565\nQ\ncold\n50\n1.00\n0.50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n\n\nQuaker Oat Squares\n49.51187\nQ\ncold\n100\n0.50\n1.00\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n\n\nQuaker Oatmeal\n50.82839\nQ\nhot\n100\n0.67\n1.00\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n\n\nRaisin Bran\n39.25920\nK\ncold\n120\n0.75\n1.33\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n\n\nRaisin Nut Bran\n39.70340\nG\ncold\n100\n0.50\n1.00\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n\n\nRaisin Squares\n55.33314\nK\ncold\n90\n0.50\n1.00\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n\n\nRice Chex\n41.99893\nR\ncold\n110\n1.13\n1.00\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n\n\nRice Krispies\n40.56016\nK\ncold\n110\n1.00\n1.00\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n\n\nShredded Wheat\n68.23588\nN\ncold\n80\n1.00\n0.83\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n\n\nShredded Wheat 'n'Bran\n74.47295\nN\ncold\n90\n0.67\n1.00\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n\n\nShredded Wheat spoon size\n72.80179\nN\ncold\n90\n0.67\n1.00\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n\n\nSmacks\n31.23005\nK\ncold\n110\n0.75\n1.00\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n\n\nSpecial K\n53.13132\nK\ncold\n110\n1.00\n1.00\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n\n\nStrawberry Fruit Wheats\n59.36399\nN\ncold\n90\n1.00\n1.00\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n\n\nTotal Corn Flakes\n38.83975\nG\ncold\n110\n1.00\n1.00\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n\n\nTotal Raisin Bran\n28.59278\nG\ncold\n140\n1.00\n1.50\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n\n\nTotal Whole Grain\n46.65884\nG\ncold\n100\n1.00\n1.00\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n\n\nTriples\n39.10617\nG\ncold\n110\n0.75\n1.00\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n\n\nTrix\n27.75330\nG\ncold\n110\n1.00\n1.00\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n\n\nWheat Chex\n49.78744\nR\ncold\n100\n0.67\n1.00\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n\n\nWheaties\n51.59219\nG\ncold\n100\n1.00\n1.00\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n\n\nWheaties Honey Gold\n36.18756\nG\ncold\n110\n0.75\n1.00\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#select-handy-helpers",
    "href": "slides/week-3/w3-dplyr.html#select-handy-helpers",
    "title": "Data Cleaning & Manipulation",
    "section": "select(): Handy Helpers!",
    "text": "select(): Handy Helpers!\n\neverything() – selects all columns that you have not already specified\nstarts_with() – selects columns with names that start with the specified string\nends_with() – selects columns with names that end with the specified string\ncontains() – selects columns with names that contain the specified string\nwhere() – applies a function to all variables and selects those for which the function returns TRUE\n\nSee the help file for select()!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#rename",
    "href": "slides/week-3/w3-dplyr.html#rename",
    "title": "Data Cleaning & Manipulation",
    "section": "rename()",
    "text": "rename()\n\nYou can rename columns with select(), but all columns not specified will be dropped.\n\nUsing the rename() function is easier!\n\n\n\ncereal |&gt; \n  rename(temp = type)\n\n\n\n\n\n\n\nname\nmanuf\ntemp\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#mutate-1",
    "href": "slides/week-3/w3-dplyr.html#mutate-1",
    "title": "Data Cleaning & Manipulation",
    "section": "mutate()",
    "text": "mutate()\nThe dataset gets mutated to either include a new variable…\n\ncereal |&gt; \n  mutate(potass_per_cup = potass / cups)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\npotass_per_cup\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n848.484848\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n135.000000\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n969.696970\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n660.000000\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n-1.333333\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n93.333333\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n30.000000\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n133.333333\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n186.567164\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n283.582090\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n46.666667\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n84.000000\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n60.000000\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n210.000000\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n55.000000\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n25.000000\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n35.000000\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n20.000000\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n65.000000\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n320.000000\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n-1.000000\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n30.000000\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n160.000000\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n106.666667\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n30.000000\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n33.333333\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n125.000000\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n298.507463\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n283.582090\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n33.333333\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n45.454546\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n60.000000\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n96.590909\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n360.000000\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n303.030303\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n45.000000\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n120.000000\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n26.315790\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n60.000000\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n126.666667\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n26.666667\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n141.791045\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n55.000000\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n95.000000\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n170.000000\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n170.000000\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n238.805970\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n90.000000\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n59.701493\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n194.029851\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n90.000000\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n240.000000\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n388.059702\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n45.000000\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n15.000000\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n50.000000\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n220.000000\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n164.179104\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n320.000000\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n280.000000\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n220.000000\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n26.548673\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n35.000000\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n95.000000\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n208.955224\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n179.104478\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n53.333333\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n55.000000\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n90.000000\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n35.000000\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n230.000000\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n110.000000\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n80.000000\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n25.000000\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n171.641791\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n110.000000\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n80.000000\n\n\n\n\n\n\n\n\n…OR revise an existing variable.\n\ncereal |&gt; \n  mutate(shelf = as.factor(shelf))"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#mutate-handy-helpers",
    "href": "slides/week-3/w3-dplyr.html#mutate-handy-helpers",
    "title": "Data Cleaning & Manipulation",
    "section": "mutate(): Handy Helpers!",
    "text": "mutate(): Handy Helpers!\n\nif_else() or case_when() – shortcut for if-else loop\nas.factor(), as.numeric(), etc. – change variable type\n+, -, *, / – basic mathematical operations\n%% – modulo (returns the remainder when doing division)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#summarize-1",
    "href": "slides/week-3/w3-dplyr.html#summarize-1",
    "title": "Data Cleaning & Manipulation",
    "section": "summarize()",
    "text": "summarize()\nWe can calculate summaries of variables in the data.\n\n\ncereal |&gt; \n  summarise(mean_fiber = mean(fiber))\n\n  mean_fiber\n1   2.151948\n\n\n\n\nOr multiple summaries at the same time.\n\ncereal |&gt; \nsummarise(mean_fiber = mean(fiber),\n          num_cereals = n(),\n          mean_sugar = mean(sugars))\n\n  mean_fiber num_cereals mean_sugar\n1   2.151948          77   6.922078\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nsummarize() and summarise() are synonyms!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#summarize-handy-helpers",
    "href": "slides/week-3/w3-dplyr.html#summarize-handy-helpers",
    "title": "Data Cleaning & Manipulation",
    "section": "summarize(): Handy Helpers!",
    "text": "summarize(): Handy Helpers!\n\nmean(), median(), sd(), sum()\nmin(), max()\nn(), n_distinct() – counts the number of (distinct) elements\nfirst(), last(), nth() – extract the first, last, or nth element\nacross() – apply a function across columns"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#group_by-1",
    "href": "slides/week-3/w3-dplyr.html#group_by-1",
    "title": "Data Cleaning & Manipulation",
    "section": "group_by()",
    "text": "group_by()\nSeparate the data into different groups based on a categorical variable.\n\n\nThe data gets grouped, but nothing happens externally if used on its own.\n\n\ncereal |&gt; \n  group_by(type)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#group_by-summarize",
    "href": "slides/week-3/w3-dplyr.html#group_by-summarize",
    "title": "Data Cleaning & Manipulation",
    "section": "group_by() + summarize()!",
    "text": "group_by() + summarize()!\n\ngroup_by a variable (or multiple variables)\nsummarize a variable (or multiple variables) within the groups\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_sugar = mean(sugars))\n\n\n\n\n\n\n\nmanuf\nmean_sugar\n\n\n\n\nA\n3.000000\n\n\nG\n7.954546\n\n\nK\n7.565217\n\n\nN\n1.833333\n\n\nP\n8.777778\n\n\nQ\n5.250000\n\n\nR\n6.125000"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#group_by-mutate",
    "href": "slides/week-3/w3-dplyr.html#group_by-mutate",
    "title": "Data Cleaning & Manipulation",
    "section": "group_by() + mutate()!",
    "text": "group_by() + mutate()!\n\ngroup_by a variable (or multiple variables)\nmutate a variable (or multiple variables) within the groups\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  mutate(mean_sugar = mean(sugars))\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\nmean_sugar\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n1.833333\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n5.250000\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n7.565217\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n7.565217\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n6.125000\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n7.954546\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n7.565217\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n7.954546\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n6.125000\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n8.777778\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n5.250000\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n7.954546\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n7.954546\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n7.954546\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n7.954546\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n6.125000\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n7.565217\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n7.565217\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n7.954546\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n7.565217\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n1.833333\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n7.565217\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n7.954546\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n6.125000\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n7.565217\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n7.565217\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n7.565217\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n8.777778\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n7.565217\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n8.777778\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n8.777778\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n7.954546\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n8.777778\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n8.777778\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n8.777778\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n5.250000\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n7.954546\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n8.777778\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n7.565217\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n7.565217\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n7.954546\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n5.250000\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n7.954546\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n3.000000\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n6.125000\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n6.125000\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n7.565217\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n7.954546\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n7.565217\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n7.565217\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n7.565217\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n7.954546\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n8.777778\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n7.565217\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n5.250000\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n5.250000\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n5.250000\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n5.250000\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n7.565217\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n7.954546\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n7.565217\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n6.125000\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n7.565217\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n1.833333\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n1.833333\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n1.833333\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n7.565217\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n7.565217\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n1.833333\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n7.954546\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n7.954546\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n7.954546\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n7.954546\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n7.954546\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n6.125000\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n7.954546\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n7.954546"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#mutate-vs-summarise",
    "href": "slides/week-3/w3-dplyr.html#mutate-vs-summarise",
    "title": "Data Cleaning & Manipulation",
    "section": "mutate() vs summarise()",
    "text": "mutate() vs summarise()\n\ngroup_by() + summarize() collapses the data.\n\nYou will only have one row per group remaining.\nYou will only have one column for each grouping variable, plus each variable that you specified in summarize.\n\n\ngroup_by() + mutate() does not.\n\nYou will have the full number of rows remaining.\nYou will have the full number of columns remaining, plus additional columns you created."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#mutate-vs-summarise-1",
    "href": "slides/week-3/w3-dplyr.html#mutate-vs-summarise-1",
    "title": "Data Cleaning & Manipulation",
    "section": "mutate() vs summarise()",
    "text": "mutate() vs summarise()\n\nsummarise()mutate()"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#quick-check",
    "href": "slides/week-3/w3-dplyr.html#quick-check",
    "title": "Data Cleaning & Manipulation",
    "section": "Quick check",
    "text": "Quick check\nHow many rows and columns will each of these data frames have?\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  mutate(fiber_carb_rat = mean(fiber / carbo))\n\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  summarize(fiber_carb_rat = mean(fiber / carbo))\n\n\n\n\n\n\n\n\nTip\n\n\nThe cereal data starts with 77 rows and 16 columns. There are 7 manufacturers in the data."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#ungroup",
    "href": "slides/week-3/w3-dplyr.html#ungroup",
    "title": "Data Cleaning & Manipulation",
    "section": "ungroup()",
    "text": "ungroup()\nThe ungroup() function will remove the internal grouping in your data.\n\n\nUseful if you want to create a different grouping\nThis is not something that you always need to do.\nTip: if you are getting unexpected output downstream from a group_by() statement, try ungrouping your data!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#glue-it-all-together",
    "href": "slides/week-3/w3-dplyr.html#glue-it-all-together",
    "title": "Data Cleaning & Manipulation",
    "section": "Glue it all together!",
    "text": "Glue it all together!\n\ncereal |&gt; \n  filter(type == \"cold\") |&gt; \n  mutate(potass_per_cup = potass / cups) |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_potass_per_cup = mean(potass_per_cup))\n\n\n\n\n\n\n\nmanuf\nmean_potass_per_cup\n\n\n\n\nG\n109.1970\n\n\nK\n175.3978\n\n\nN\n284.3089\n\n\nP\n203.8749\n\n\nQ\n93.3511\n\n\nR\n106.8864"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#save-your-changes",
    "href": "slides/week-3/w3-dplyr.html#save-your-changes",
    "title": "Data Cleaning & Manipulation",
    "section": "Save your changes!",
    "text": "Save your changes!\nWhen you manipulate your data, make sure you assign your new dataset to a variable.\n\ncereal_summary &lt;- cereal |&gt; \n  filter(type == \"cold\") |&gt; \n  mutate(potass_per_cup = potas / cups) |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_potass_per_cup = mean(potass_per_cup))"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#code-formatting",
    "href": "slides/week-3/w3-dplyr.html#code-formatting",
    "title": "Data Cleaning & Manipulation",
    "section": "Code Formatting",
    "text": "Code Formatting\nSimilar to the + formatting in ggplot, do not continue a line after writing a |&gt;!\n\nBad PracticeGood Practice\n\n\n\ncereal |&gt; group_by(type) |&gt; summarise(mean_fiber = mean(fiber), num_cereals = n(), mean_sugar = mean(sugars))\n\n\n\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarise(mean_fiber = mean(fiber), \n            num_cereals = n(),\n            mean_sugar = mean(sugars))"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#now-you",
    "href": "slides/week-3/w3-dplyr.html#now-you",
    "title": "Data Cleaning & Manipulation",
    "section": "Now you!",
    "text": "Now you!\nIn your group implement the dplyr pipelines to address the three questions from the beginning of class:\n\nWhat is the ratio of fiber to sugars in each cereal?\nCreate a new dataset that only has Nabisco cereals and displays the protein, fat, and sodium in each.\nCreate a table that shows, for each manufacturer the average and standard deviation of the grams of sugar in their cereals, along with how many cereals are in the data for each manufacturer. Order the table from most sugar (on average) to least."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#pa-3-identify-the-mystery-college",
    "href": "slides/week-3/w3-dplyr.html#pa-3-identify-the-mystery-college",
    "title": "Data Cleaning & Manipulation",
    "section": "PA 3: Identify the Mystery College",
    "text": "PA 3: Identify the Mystery College\nToday you will use the dplyr package to clean some data and then use that cleaned data to figure out what college Margaret has been accepted to.\n\nSubmit the full name of the college Margaret will attend to the Canvas Quiz."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#to-do",
    "href": "slides/week-3/w3-dplyr.html#to-do",
    "title": "Data Cleaning & Manipulation",
    "section": "To do…",
    "text": "To do…\n\nPA 3: Identify the Mystery College\n\nDue Thursday 4/17 before class\n\nExtra Data Ethics Reading\n\nData Feminism: The Numbers Don’t Speak for Themselves\nRead before class on Thursday\n\nLab 3: Teacher Evaluations\n\nDue Monday 4/21 at 11:59 pm"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-filter-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-filter-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “filter” in base R?",
    "text": "How do we “filter” in base R?\nYou can use the subset() function!\n\ncereal |&gt; \n  subset(name %in% c(\"Cheerios\", \"Cinnamon Toast Crunch\", \"Raisin Bran\", \"Cracklin' Oat Bran\"))\n\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n12\nCheerios\nG\ncold\n110\n6\n2\n290\n2\n17\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\n13\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0\n13\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\n20\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4\n10\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\n59\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5\n14\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\n\n\n\n\n\n\n\ncereal |&gt; \n  subset(sugars &lt; 5 & type == \"hot\")\n\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n21\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21\n0\n-1\n0\n2\n1\n1.00\n64.53382\n\n\n44\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1\n1.00\n54.85092\n\n\n58\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1\n0.67\n50.82839"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-arrange-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-arrange-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “arrange” in base R?",
    "text": "How do we “arrange” in base R?\nYou can use the order() function!\n\ncereal[order(cereal$sodium),]\n\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n27\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\n44\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\n55\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\n56\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\n58\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\n61\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\n64\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\n65\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\n66\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\n2\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\n69\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\n31\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\n67\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\n35\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\n21\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\n18\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\n45\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\n7\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\n25\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\n1\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n30\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\n57\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\n4\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\n14\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\n20\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\n23\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\n33\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\n60\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\n74\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\n42\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\n46\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\n47\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\n28\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\n34\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\n39\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\n40\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\n51\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\n52\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\n6\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\n15\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\n19\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\n38\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\n43\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\n24\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\n49\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\n71\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\n5\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\n9\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\n26\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\n53\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\n70\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\n72\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\n76\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\n77\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n\n\n8\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\n10\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\n13\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\n59\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\n11\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\n22\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\n36\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\n48\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\n50\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\n68\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\n75\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\n29\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\n62\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\n37\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\n73\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\n3\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\n41\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\n16\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\n32\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\n12\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\n17\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\n63\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\n54\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\n\n\n\n\n\n\n\ncereal[order(cereal$sodium, cereal$sugars),]\n\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n58\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\n55\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\n56\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\n64\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\n65\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\n66\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\n44\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\n61\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\n27\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\n69\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\n2\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\n31\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\n67\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\n35\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\n21\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\n18\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\n45\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\n25\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\n7\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\n1\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n57\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\n30\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\n4\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\n33\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\n14\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\n20\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\n60\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\n23\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\n74\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\n42\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\n46\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\n47\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\n28\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\n51\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\n34\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\n39\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\n40\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\n52\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\n6\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\n38\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\n43\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\n15\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\n19\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\n24\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\n49\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\n71\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\n70\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\n72\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\n76\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\n9\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\n5\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\n77\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n\n\n26\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\n53\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\n10\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\n8\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\n13\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\n59\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\n22\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\n48\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\n50\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\n36\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\n11\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\n68\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\n75\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\n62\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\n29\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\n73\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\n37\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\n41\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\n3\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\n16\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\n32\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\n12\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\n17\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\n63\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\n54\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-select-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-select-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “select” in base R?",
    "text": "How do we “select” in base R?\nYou don’t really use a specific function!\n\ncereal[,c(\"name\", \"manuf\", \"calories\", \"cups\")]\n\n\n\n\n\n\n\nname\nmanuf\ncalories\ncups\n\n\n\n\n100% Bran\nN\n70\n0.33\n\n\n100% Natural Bran\nQ\n120\n1.00\n\n\nAll-Bran\nK\n70\n0.33\n\n\nAll-Bran with Extra Fiber\nK\n50\n0.50\n\n\nAlmond Delight\nR\n110\n0.75\n\n\nApple Cinnamon Cheerios\nG\n110\n0.75\n\n\nApple Jacks\nK\n110\n1.00\n\n\nBasic 4\nG\n130\n0.75\n\n\nBran Chex\nR\n90\n0.67\n\n\nBran Flakes\nP\n90\n0.67\n\n\nCap'n'Crunch\nQ\n120\n0.75\n\n\nCheerios\nG\n110\n1.25\n\n\nCinnamon Toast Crunch\nG\n120\n0.75\n\n\nClusters\nG\n110\n0.50\n\n\nCocoa Puffs\nG\n110\n1.00\n\n\nCorn Chex\nR\n110\n1.00\n\n\nCorn Flakes\nK\n100\n1.00\n\n\nCorn Pops\nK\n110\n1.00\n\n\nCount Chocula\nG\n110\n1.00\n\n\nCracklin' Oat Bran\nK\n110\n0.50\n\n\nCream of Wheat (Quick)\nN\n100\n1.00\n\n\nCrispix\nK\n110\n1.00\n\n\nCrispy Wheat & Raisins\nG\n100\n0.75\n\n\nDouble Chex\nR\n100\n0.75\n\n\nFroot Loops\nK\n110\n1.00\n\n\nFrosted Flakes\nK\n110\n0.75\n\n\nFrosted Mini-Wheats\nK\n100\n0.80\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\n120\n0.67\n\n\nFruitful Bran\nK\n120\n0.67\n\n\nFruity Pebbles\nP\n110\n0.75\n\n\nGolden Crisp\nP\n100\n0.88\n\n\nGolden Grahams\nG\n110\n0.75\n\n\nGrape Nuts Flakes\nP\n100\n0.88\n\n\nGrape-Nuts\nP\n110\n0.25\n\n\nGreat Grains Pecan\nP\n120\n0.33\n\n\nHoney Graham Ohs\nQ\n120\n1.00\n\n\nHoney Nut Cheerios\nG\n110\n0.75\n\n\nHoney-comb\nP\n110\n1.33\n\n\nJust Right Crunchy Nuggets\nK\n110\n1.00\n\n\nJust Right Fruit & Nut\nK\n140\n0.75\n\n\nKix\nG\n110\n1.50\n\n\nLife\nQ\n100\n0.67\n\n\nLucky Charms\nG\n110\n1.00\n\n\nMaypo\nA\n100\n1.00\n\n\nMuesli Raisins; Dates; & Almonds\nR\n150\n1.00\n\n\nMuesli Raisins; Peaches; & Pecans\nR\n150\n1.00\n\n\nMueslix Crispy Blend\nK\n160\n0.67\n\n\nMulti-Grain Cheerios\nG\n100\n1.00\n\n\nNut&Honey Crunch\nK\n120\n0.67\n\n\nNutri-Grain Almond-Raisin\nK\n140\n0.67\n\n\nNutri-grain Wheat\nK\n90\n1.00\n\n\nOatmeal Raisin Crisp\nG\n130\n0.50\n\n\nPost Nat. Raisin Bran\nP\n120\n0.67\n\n\nProduct 19\nK\n100\n1.00\n\n\nPuffed Rice\nQ\n50\n1.00\n\n\nPuffed Wheat\nQ\n50\n1.00\n\n\nQuaker Oat Squares\nQ\n100\n0.50\n\n\nQuaker Oatmeal\nQ\n100\n0.67\n\n\nRaisin Bran\nK\n120\n0.75\n\n\nRaisin Nut Bran\nG\n100\n0.50\n\n\nRaisin Squares\nK\n90\n0.50\n\n\nRice Chex\nR\n110\n1.13\n\n\nRice Krispies\nK\n110\n1.00\n\n\nShredded Wheat\nN\n80\n1.00\n\n\nShredded Wheat 'n'Bran\nN\n90\n0.67\n\n\nShredded Wheat spoon size\nN\n90\n0.67\n\n\nSmacks\nK\n110\n0.75\n\n\nSpecial K\nK\n110\n1.00\n\n\nStrawberry Fruit Wheats\nN\n90\n1.00\n\n\nTotal Corn Flakes\nG\n110\n1.00\n\n\nTotal Raisin Bran\nG\n140\n1.00\n\n\nTotal Whole Grain\nG\n100\n1.00\n\n\nTriples\nG\n110\n0.75\n\n\nTrix\nG\n110\n1.00\n\n\nWheat Chex\nR\n100\n0.67\n\n\nWheaties\nG\n100\n1.00\n\n\nWheaties Honey Gold\nG\n110\n0.75\n\n\n\n\n\n\n\n\n\ncereal |&gt; \n  subset(select = -c(rating))\n\n\n\n\n\ncolnames(cereal)[2:4] &lt;- c(\"maker\",\"temp\",\"cals\")"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-mutate-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-mutate-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “mutate” in base R?",
    "text": "How do we “mutate” in base R?\nYou can define new columns…\n\ncereal$potass_per_cup &lt;- cereal$potass / cereal$cups\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\npotass_per_cup\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n848.484848\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n135.000000\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n969.696970\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n660.000000\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n-1.333333\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n93.333333\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n30.000000\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n133.333333\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n186.567164\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n283.582090\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n46.666667\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n84.000000\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n60.000000\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n210.000000\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n55.000000\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n25.000000\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n35.000000\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n20.000000\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n65.000000\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n320.000000\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n-1.000000\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n30.000000\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n160.000000\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n106.666667\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n30.000000\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n33.333333\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n125.000000\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n298.507463\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n283.582090\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n33.333333\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n45.454546\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n60.000000\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n96.590909\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n360.000000\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n303.030303\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n45.000000\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n120.000000\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n26.315790\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n60.000000\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n126.666667\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n26.666667\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n141.791045\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n55.000000\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n95.000000\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n170.000000\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n170.000000\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n238.805970\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n90.000000\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n59.701493\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n194.029851\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n90.000000\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n240.000000\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n388.059702\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n45.000000\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n15.000000\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n50.000000\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n220.000000\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n164.179104\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n320.000000\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n280.000000\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n220.000000\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n26.548673\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n35.000000\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n95.000000\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n208.955224\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n179.104478\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n53.333333\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n55.000000\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n90.000000\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n35.000000\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n230.000000\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n110.000000\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n80.000000\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n25.000000\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n171.641791\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n110.000000\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n80.000000\n\n\n\n\n\n\n\n\n…OR overwrite old ones!\n\ncereal$shelf &lt;- as.factor(cereal$shelf)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-group-and-summarize-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-group-and-summarize-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “group” and “summarize” in base R?",
    "text": "How do we “group” and “summarize” in base R?\nYou can use the aggregate() function.\n\ncereal |&gt; \n  aggregate(sugars ~ manuf, FUN = mean)\n\n\n\n\n\n\n\nmanuf\nsugars\n\n\n\n\nA\n3.000000\n\n\nG\n7.954546\n\n\nK\n7.565217\n\n\nN\n1.833333\n\n\nP\n8.777778\n\n\nQ\n5.250000\n\n\nR\n6.125000"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#questions-from-week-2",
    "href": "slides/week-3/w3-dplyr.html#questions-from-week-2",
    "title": "Data Cleaning & Manipulation",
    "section": "Questions from Week 2?",
    "text": "Questions from Week 2?\n\nStat departmnet joke of the week by Syliva Du. Image created with AI."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#check-in-3.1-question-8",
    "href": "slides/week-3/w3-dplyr.html#check-in-3.1-question-8",
    "title": "Data Cleaning & Manipulation",
    "section": "Check-in 3.1 Question 8",
    "text": "Check-in 3.1 Question 8\n\nWhile the following code runs it does not do what we want:\n\n\npenguins |&gt; \n  filter(species == \"Adelie\") |&gt; \n  select(body_mass_g) |&gt; \n  mean(na.rm = T)\n\nWarning in mean.default(select(filter(penguins, species == \"Adelie\"),\nbody_mass_g), : argument is not numeric or logical: returning NA\n\n\n[1] NA\n\n\n\nWe will learn how to fix this code on Thursday\nI will go back and fix grades. Either choosing “Line 4” or “No error” will be considered correct."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#style-note-of-the-day---spacing",
    "href": "slides/week-3/w3-dplyr.html#style-note-of-the-day---spacing",
    "title": "Data Cleaning & Manipulation",
    "section": "Style Note of the Day - Spacing",
    "text": "Style Note of the Day - Spacing\n\n\nAlways put a space after a comma, but never before\nSurround = with spaces when naming arguments\nSurround many mathematical operators (+, -, *) with spaces (but not all!)\nDon’t include spaces around parentheses for function calls (although you may include a new-line)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#style-note-of-the-day---spacing-1",
    "href": "slides/week-3/w3-dplyr.html#style-note-of-the-day---spacing-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Style Note of the Day - Spacing",
    "text": "Style Note of the Day - Spacing\nNice:\n\nmean(x, na.rm = TRUE)\n\nheight &lt;- (feet * 12) + inches\n\n2^2\n\nNo thank you:\n\nmean(x,na.rm=TRUE)\nmean( x , na.rm = TRUE )\nmean (x, na.rm = TRUE)\n\nheight&lt;-(feet*12)+inches\n\n2 ^ 2"
  },
  {
    "objectID": "project/proj-citations.html",
    "href": "project/proj-citations.html",
    "title": "Project Citations",
    "section": "",
    "text": "If you are just letting me know how you found any functions that we have not discussed in class - please include this as a comment in your code chunk. Remember, the text of your report should be discussing your analysis and findings, NOT your code.\nFor example:\n\n# basenames() function found in stackoverflow discussion\n# https://stackoverflow.com/questions/29113973/get-filename-without-extension-in-r\n\ncsv_files &lt;- list.files(path = \"../\", pattern = \".csv\", \n                          full.names = TRUE)\n\nnames &lt;- basename(csv_files)"
  },
  {
    "objectID": "project/proj-citations.html#citing-small-coding-sources",
    "href": "project/proj-citations.html#citing-small-coding-sources",
    "title": "Project Citations",
    "section": "",
    "text": "If you are just letting me know how you found any functions that we have not discussed in class - please include this as a comment in your code chunk. Remember, the text of your report should be discussing your analysis and findings, NOT your code.\nFor example:\n\n# basenames() function found in stackoverflow discussion\n# https://stackoverflow.com/questions/29113973/get-filename-without-extension-in-r\n\ncsv_files &lt;- list.files(path = \"../\", pattern = \".csv\", \n                          full.names = TRUE)\n\nnames &lt;- basename(csv_files)"
  },
  {
    "objectID": "project/proj-citations.html#citing-data-and-other-sources",
    "href": "project/proj-citations.html#citing-data-and-other-sources",
    "title": "Project Citations",
    "section": "Citing Data and Other Sources",
    "text": "Citing Data and Other Sources\nAll other sources should be cited both in-text and in a “References” section at the end of your report.\nIn-text citations should include the author name and year of publication (if relevant) like:\n\n(Wilkinson 2005)\n\n\n(Wilkinson, 2005)\n\n\nWilkinson (2005)\n\nIf there is no author or year of publication (like for many websites) a hyperlink to the website is acceptable in-text and do your best to create a full citation in the References section citation.\nYou may use any citation style for References as long as it is consistent.\nYou can do all of this manually, but you may also want to use citation tools in Quarto, which I explain in the next section."
  },
  {
    "objectID": "project/proj-citations.html#citing-automatically-in-quarto",
    "href": "project/proj-citations.html#citing-automatically-in-quarto",
    "title": "Project Citations",
    "section": "Citing Automatically in Quarto",
    "text": "Citing Automatically in Quarto\n\n\n\n\n\n\nOptional but NICE!\n\n\n\nYou are not required to do this for the project, but using automatic citations is VERY nice and a good practice to start.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nYou will want to download the .qmd for this document to see exactly how everything works.\n\n\n\n\n\n\n\n\nMake sure bibtex is installed on your computer\n\n\n\nJust once, you will need to install the bibtex package if you don’t already have bibtex installed on your computer.\n\n\nQuarto supports automatic citations using BibTex. You can find detailed information at (Posit 2025), but I will also summarize some of the big points and give some tips.\nStep 1: Create a .bib document and save it in the same directory as your report .qmd. You can download the references.bib file that I created for this example as a starting point.\nStep 2: Tell Quarto to that you have a references document. Include the following in your YAML (changin the name of the .bib document appropriately:\nbibliography: references.bib\nStep 3: Add citations to your .bib! BibTex has a special way that you need to include the citations.\n\nYou can find some examples in the references.bib file.\nThere are many websites that you can find that help you generate a BibTex citation such as this one.\nOften journals also provide a way to download a BibTex citation for a given paper.\n\nCitations look something like this:\n@book{wickham2016r,\n    title = {R for data science: {Import}, tidy, transform, visualize, and model data},\n    url = {https://books.google.com/books?id=vfi3DQAAQBAJ},\n    publisher = {O'Reilly Media},\n    author = {Wickham, H. and Grolemund, G.},\n    year = {2016},\n    note = {tex.lccn: 2017300238},\n}\nThe first entry wickham2016r gives a “nickname” for the citation that you can then use to reference it in your main document.\nStep 4: Cite!\nIn Quarto you can include in text citations by refrencing that nickname with an @ in front (e.g. @wickham2016r). You can chose one of two formats for in-text citation depending on the context:\n\n(Wickham and Grolemund 2016) or\nWickham and Grolemund (2016)\n\nThis will make a nicely formatted in-text citation as well as automatically creating a “References” section at the end of your document with the full citations like you can see here!"
  },
  {
    "objectID": "practice-activities/pa4.html",
    "href": "practice-activities/pa4.html",
    "title": "PA 4: Military Spending",
    "section": "",
    "text": "# load packages\nlibrary(readxl) \nlibrary(tidyverse)\nToday you will be tidying messy data to explore the relationship between countries of the world and military spending.\nDownload starter .qmd file\nDownload data – SPIRI-Milex-data-1949-2024.xlsx"
  },
  {
    "objectID": "practice-activities/pa4.html#data-description",
    "href": "practice-activities/pa4.html#data-description",
    "title": "PA 4: Military Spending",
    "section": "Data Description",
    "text": "Data Description\nWe will be using data from the Stockholm International Peace Research Institute (SIPRI). The SIPRI Military Expenditure Database is an open source data set containing time series on the military spending of countries from 1949–2023. The database is updated annually, which may include updates to data from previous years.\nMilitary expenditure is presented in many ways:\n\nin local currency and in US $ (both from 2022 and current);\nin terms of financial years and calendar years;\nas a share of GDP and per capita.\n\nThe availability of data varies considerably by country, but we note that data is available from at least the late 1950s for a majority of countries that were independent at the time. Estimates for regional military expenditure have been extended backwards depending on availability of data, but no estimates for total world military expenditure are available before 1988 due to the lack of data from the Soviet Union.\nSIPRI military expenditure data is based on open sources only."
  },
  {
    "objectID": "practice-activities/pa4.html#data-import",
    "href": "practice-activities/pa4.html#data-import",
    "title": "PA 4: Military Spending",
    "section": "Data Import",
    "text": "Data Import\nFirst, you should notice that there are ten different sheets included in the dataset. We are interested in the sheet labeled “Share of Govt. spending”, which contains information about the share of all government spending that is allocated to the military.\nNext, you’ll notice that there are notes about the data in the first six rows. Ugh!\nRather than copying this one sheet into a new Excel file and deleting the first few rows, let’s learn something new about the read_xlsx() function!\n\n\n\n\n\n\nWarning\n\n\n\nAs much as you can, always try to keep your raw data raw! Rather than changing anything about the raw data file by hand - figure out different ways to import the data to fit your needs.\n\n\n\n\n\n\n\n\nData Import with read_xlsx()\n\n\n\nThe read_xlsx() function has several useful arguments:\n\nsheet: specify the name of the sheet that you want to use. The name must be passed in as a string (in quotations)!\nskip: specify the number of rows you want to skip before reading in the data.\n\n\n\n1. Modify the code below (potentially including the file path) to read the military expenditures data into your workspace.\n\nmilitary &lt;- read_xlsx(\"SIPRI-Milex-data-1949-2024.xlsx\", \n                      sheet = , \n                      skip  = )\n\nError: `path` does not exist: 'SIPRI-Milex-data-1949-2024.xlsx'\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you have the Excel file open on your computer while trying to import the data, you may get an error. If you do, close the Excel file and try running your code again."
  },
  {
    "objectID": "practice-activities/pa4.html#data-cleaning",
    "href": "practice-activities/pa4.html#data-cleaning",
    "title": "PA 4: Military Spending",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nYou will notice that there are a couple of columns that don’t include spending data or are all missing (Notes and Reporting year). There is also an extra row that doesn’t include information on a country.\n2. In one pipeline, drop those columns and that row. Save this dataset as a new object named military_clean.\n\n# code for Q2\n\nIn addition to NAs, missing values were coded in two other ways.\n3. Find these two methods and write code to replace these values with NAs. Save these changes into an updated version of military_clean.\n\n\n\n\n\n\nTip\n\n\n\nThe information in the top 6 rows of the excel sheet will help you answer this question.\nHelpful functions: mutate(), across() – you will need two of these, na_if()\nNote: When referring to one of the year variable names that start with a number must put tick marks (above the tab key) around the name. Starting the name of a variable with a number is not commonly read as a variable name. E.g., to read the 1988 column through the 2019 column, use `1988.0`:`2019.0`. However, you don’t have to refer to the variable names to complete this task - it might be most efficient to specify columns you don’t want to mutate.\n\n\n\n# code for Q3\n\nBecause characters were used to indicate missing values, all of the columns 1988 through 2023 were read in as characters.\n4. Change these columns to a numeric data type. Save these changes into an updated version of military_clean.\n\n# code for Q4\n\nIf you give the Country column a look, you’ll see there are names of continents and regions included. These names are only included to make it simpler to find countries, as they contain no data.\nLuckily for us, these region names were also stored in the “Regional totals” sheet. We can use the Region column of this dataset to filter out the names we don’t want.\nRun the code below to read in the “Regional totals” dat, making any necessary modifications to the file path.\n\ncont_region &lt;- read_xlsx(\"SIPRI-Milex-data-1949-2024.xlsx\", \n                      sheet = \"Regional totals\", \n                      skip = 13) |&gt; \n  filter(Region != \"World total (including Iraq)\", \n         Region != \"World total (excluding Iraq)\") |&gt; \n  select(Region)\n\nError: `path` does not exist: 'SIPRI-Milex-data-1949-2024.xlsx'\n\n\nA clever way to filter out observations you don’t want is with a join. A tool tailored just for this scenario is the anti_join() function. This function will return all of the rows of one dataset without a match in another dataset.\n5. Use the anti_join() function to filter out the Country values we don’t want in the military_clean data. The by argument needs to be filled with the name(s) of the variables that the two datasets should be joined with.\n\n\n\n\n\n\nTip\n\n\n\nJoin by different variables in dataX and dataY: join_by(a == b) will match dataX$a to dataY$b.\n\n\n\n# code for Q5\n\n\n\n\n\n\n\nCanvas Q1 & Q2\n\n\n\n6. How many countries have no spending information in this dataset? What are some of these countries (a list to choose from will be given in Canvas)?\n\n\n\n\n\n\n\n\nTip\n\n\n\nUseful functions: filter(), if_all(), is.na(). You will also want to double check that any observations that are missing information aren’t just a region that we missed excluding!\n\n\n\n# code for Q6"
  },
  {
    "objectID": "practice-activities/pa4.html#data-organization",
    "href": "practice-activities/pa4.html#data-organization",
    "title": "PA 4: Military Spending",
    "section": "Data Organization",
    "text": "Data Organization\nWe are interested in comparing the military expenditures of countries in Eastern Europe. We want to look at trends over time and to visualize variability in expenditures within and between countries, like the following two plots:\n\n\n\n\n\nDesired boxplot: Countries from Central Asia used for demonstration – your plot will have different countries and spending values.\n\n\n\n\n\n\n\n\n\nDesired line plot: Countries from North Africa used for demonstration – your plot will have different countries and spending values.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nUnfortunately, if we want a point in the graph representing the spending for every country and year (without some SERIOUS headache), we need every year to be a single column!\n\n\nTo tidy a dataset like this, we need to pivot the columns of years from wide format to long format. To do this process we need three arguments:\n\ncols: The set of columns that represent values, not variables. In these data, those are all the columns from 1988.0 to 2023.0.\nnames_to: The name of the variable that should be created to move these columns into. In these data, this could be \"year\".\nvalues_to: The name of the variable that should be created to move these column’s values into. In these data, this could be labeled \"spending\".\n\nThese form the three required arguments for the pivot_longer() function.\n7. Pivot the cleaned up military data set to a “longer” orientation. Save this new “long” version as a new variable called military_long.\n\n\n\n\n\n\nCaution\n\n\n\nDo not overwrite your cleaned up dataset!\n\n\n\n# code for Q7\n\n8. Notice that when you pivoted the data, the year variable is a character data type. Convert this to numeric.\n\nsummary(military_long)\n\nError: object 'military_long' not found\n\n\n\n# code for Q8"
  },
  {
    "objectID": "practice-activities/pa4.html#data-visualization",
    "href": "practice-activities/pa4.html#data-visualization",
    "title": "PA 4: Military Spending",
    "section": "Data Visualization",
    "text": "Data Visualization\nNow that we’ve transformed the data, let’s create a plot to explore military spending across Eastern European countries.\n9. Create side-by-side boxplots to explore the military spending between Eastern European countries.\n\n\n\n\n\n\nTip\n\n\n\nMake sure you change the plot title and axis labels to accurately represent the plot.\nYou might also want to change the x-axis limits and the color of your plots.\nPlace the Country variable on an axis that makes it easier to read the labels!\n\n\n\n# I have provided a list of Eastern European countries (in these data) for you to use.\neastern_europe &lt;- c(\"Armenia\", \"Azerbaijan\", \"Belarus\", \n                    \"Georgia\", \"Moldova\", \"Russia\", \"Ukraine\")\n\n# code for Q9\n\n10. Create a line plot to explore the military spending of Eastern European countries over time.\n\n# code for Q10\n\n\n\n\n\n\n\nCanvas Q3 + Q4\n\n\n\n11. Looking at the plots you created above, which Eastern European country had the smallest variability in military expenditures over time? Consider a measure of variability that is robust to outliers (like IQR).\n12. Looking at the plots you created above, you can see that for one Eastern European country, their miliary spending (%) over doubled and then returned to previous levels by around 2015. What is the name of the war that would explain this trend?."
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html",
    "href": "labs/lab4/lab4-childcare.html",
    "title": "Lab 4: Childcare Costs in California",
    "section": "",
    "text": "Tip\n\n\n\n\n\nI advise you to focus particularly on:\n\nSetting chunk options carefully.\nMaking sure you don’t print out more output than you need.\nMaking sure you don’t assign more objects than necessary. Avoid “object junk” in your environment.\nMaking your code readable and nicely formatted.\nThinking through your desired result before writing any code.\nDownload starter .qmd file"
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html#the-data",
    "href": "labs/lab4/lab4-childcare.html#the-data",
    "title": "Lab 4: Childcare Costs in California",
    "section": "The Data",
    "text": "The Data\nIn this lab we’re going look at the median weekly cost of childcare in California. The data come to us from TidyTuesday. A detailed description of the data can be found here. You will need to use this data dictionary to complete the lab!\nWe also have information from the California State Controller on tax revenue for california counties from 2005 - 2018. I compiled the data from this website for you. Note that there is no data for San Franscisco County. The variables included in the ca_tax_revenue.csv data file (loaded below) include:\n\nentity_name: County name\nyear: fiscal year\ntotal_property_taxes: total revenue in $ from property taxes\nsales_and_use_taxes: total revenue in $ from sales and use taxes\n\n0. Load the appropriate libraries and the data.\n\n# load libraries\n\n\n# load data\nchildcare_costs &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/childcare_costs.csv')\n\nError in read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/childcare_costs.csv\"): could not find function \"read_csv\"\n\ncounties &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/counties.csv')\n\nError in read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/counties.csv\"): could not find function \"read_csv\"\n\ntax_rev &lt;- read_csv('https://raw.githubusercontent.com/manncz/stat-331-s25/main/labs/lab4/data/ca_tax_revenue.csv')\n\nError in read_csv(\"https://raw.githubusercontent.com/manncz/stat-331-s25/main/labs/lab4/data/ca_tax_revenue.csv\"): could not find function \"read_csv\"\n\n\n1. Briefly describe the data (~ 4 sentences). What information does it contain?"
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html#california-childcare-costs",
    "href": "labs/lab4/lab4-childcare.html#california-childcare-costs",
    "title": "Lab 4: Childcare Costs in California",
    "section": "California Childcare Costs",
    "text": "California Childcare Costs\n2. Let’s focus only on California. Create a ca_childcare dataset containing (1) county information and (2) all information from the childcare_costs dataset.\na. Sketch a game plan for completing this task. You should do all of this within one pipeline\n\nb. Implement/code your game plan to create the dataset of childcare costs in California. Checkpoint: There are 58 counties in CA and 11 years in the dataset. Therefore, your new dataset should have 638 observations.\n\n# code for Q2\n\n3. Now, lets add the tax revenue information to the ca_childcare dataset. Add the data from tax_rev for the counties and years that are already in the ca_childcare data. Overwrite the old ca_childcare data with this dataset. Checkpoint: you are just adding columns here, so your new dataset should still have 638 observations\n\n# code for Q3\n\n4. Using a function from the forcats package, complete the code below to create a new variable where each county is categorized into one of the 10 Census regions in California. Use the Region description (from the plot), not the Region number. The code below will help you get started.\n\n\nCode\n# defining 10 census regions\n\nsuperior_counties &lt;- c(\"Butte\",\"Colusa\",\"El Dorado\",\n                       \"Glenn\",\"Lassen\",\"Modoc\",\n                       \"Nevada\",\"Placer\",\"Plumas\",\n                       \"Sacramento\",\"Shasta\",\"Sierra\",\"Siskiyou\",\n                       \"Sutter\",\"Tehama\",\"Yolo\",\"Yuba\")\n\nnorth_coast_counties &lt;- c(\"Del Norte\",\"Humboldt\",\"Lake\",\n                          \"Mendocino\",\"Napa\",\"Sonoma\",\"Trinity\")\n\nsan_fran_counties &lt;- c(\"Alameda\",\"Contra Costa\",\"Marin\",\n                       \"San Francisco\",\"San Mateo\",\"Santa Clara\",\n                       \"Solano\")\n\nn_san_joaquin_counties &lt;- c(\"Alpine\",\"Amador\",\"Calaveras\",\"Madera\",\n                            \"Mariposa\",\"Merced\",\"Mono\",\"San Joaquin\",\n                            \"Stanislaus\",\"Tuolumne\")\n\ncentral_coast_counties &lt;- c(\"Monterey\",\"San Benito\",\"San Luis Obispo\",\n                            \"Santa Barbara\",\"Santa Cruz\",\"Ventura\")\n\ns_san_joaquin_counties &lt;- c(\"Fresno\",\"Inyo\",\"Kern\",\"Kings\",\"Tulare\")\n\ninland_counties &lt;- c(\"Riverside\",\"San Bernardino\")\n\nla_county &lt;- \"Los Angeles\"\n\norange_county  &lt;- \"Orange\"\n\nsan_diego_imperial_counties &lt;- c(\"Imperial\",\"San Diego\")\n\n\n\n# finish this code for Q4\n\nca_childcare &lt;- ca_childcare |&gt; \n  mutate(county_name = str_remove(county_name, \" County\"))\n\nError in mutate(ca_childcare, county_name = str_remove(county_name, \" County\")): could not find function \"mutate\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nI have provided you with code that eliminates the word “County” from each of the county names in your ca_childcare dataset. You should keep this line of code and pipe into the rest of your data manipulations.\nYou will learn about the str_remove() function from the stringr package next week!\n\n\n5. Let’s consider the median household income of each region, and how that income has changed over time. Create a table with ten rows, one for each region, and two columns, one for 2008 and one for 2018 (plus a column for region). The cells should contain the median() of the median household income (expressed in 2018 dollars) of the region and the study_year. Order the rows by 2018 values from highest income to lowest income.\n\n\n\n\n\n\nTip\n\n\n\nThis will require transforming your data! Sketch out what you want the data to look like before you begin to code. You should be starting with your California dataset that contains the regions.\n\n\n\n# code for Q5\n\n6. Which California region had the lowest median full-time median weekly price for center-based childcare for infants in 2018? Does this region correspond to the region with the lowest median income in 2018 that you found in Q4?\n\n\n\n\n\n\nWarning\n\n\n\nThe code for the first question should give me the EXACT answer. This means having the code output the exact row(s) and variable(s) necessary for providing the solution. To answer the second question, compare this output with the output from Q4.\n\n\n\n# code for Q6\n\n7. The following plot shows, for all ten regions, the change over time of the full-time median price for center-based childcare for infants, toddlers, and preschoolers. Recreate the plot. You do not have to replicate the exact colors or theme, but your plot should have the same content, including the order of the facets and legend, reader-friendly labels, axes breaks, and a loess smoother.\n\n\n\n\n\n\nHints\n\n\n\nThis will require transforming your data! Sketch out what you want the data to look like before you begin to code. You should be starting with your California dataset that contains the regions.\nA point on the plot represents one county and year.\nYou should use a forcats function to reorder the legend automatically\nTry setting aspect.ratio = 1 in theme() if your plot is squished\nAgain, your plot does not need to look exactly like this one!!\nRemember to avoid “object junk” in your environment!\n\n\n\n\n\nPlot to recreate\n\n\n\n# code for Q7"
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html#median-household-income-vs.-childcare-costs-for-infants",
    "href": "labs/lab4/lab4-childcare.html#median-household-income-vs.-childcare-costs-for-infants",
    "title": "Lab 4: Childcare Costs in California",
    "section": "Median Household Income vs. Childcare Costs for Infants",
    "text": "Median Household Income vs. Childcare Costs for Infants\n\n\n\n\n\n\nRefresher on Linear Regression\n\n\n\nWhile a second course in statistics is a pre-requisite for this class, here is a refresher on simple linear regression with a single predictor.\n\n\n8. Create a scatterplot showing the relationship between median household income (expressed in 2018 dollars) and the full-time median weekly price charged for center-based childcare for an infant in California. Overlay a linear regression line (lm) to show the trend.\n\n# plot for scatterplot\n\n9. Look up the documentation for lm() and fit a linear regression model to the relationship shown in your plot above (recall: \\(y = mx+b\\)). Identify the coefficient estimates from the model.\n\n# complete the code provided\nreg_mod1 &lt;- lm()\n\nError in terms.formula(formula, data = data): argument is not a valid model\n\nsummary(reg_mod1)\n\nError: object 'reg_mod1' not found\n\n\n10. Do you have evidence to conclude there is a relationship between the median household income and the median weekly cost of center-based childcare for infants in California? Cite values from your output for support."
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html#open-ended-analysis",
    "href": "labs/lab4/lab4-childcare.html#open-ended-analysis",
    "title": "Lab 4: Childcare Costs in California",
    "section": "Open-Ended Analysis",
    "text": "Open-Ended Analysis\nLet’s give you a taste of what to expect for the take-home portion of the midterm exam.\n11. Investigate the full-time median price for childcare in a center-based setting versus the full-time median price for childcare in a family (in-home) setting in California. Posit a research question. This could include any other variables in the dataset as well. Present one table of summary statistics and one plot that helps to address your research question.\nThis write-up should include:\n\nA description of the data you are using\nYour research question\nOne well-designed table of summary statistics\n\nNote, this should not be inference (results from a statistical test)\nThis should be a summary table of the data itself, like Q5\n\nOne well-designed plot\nDescriptions of the table and plot that both:\n\nExplain what the table/plot is literally showing (e.g. the median cost by year)\nAnalyze what you learn from the table/plot about your research question\n\n\nThe table and plot should not show reduntant information, they should be used to gain more insight on your question.\nDr. C will be reading through these and providing some feedback!"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#across-related-functions",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#across-related-functions",
    "title": "Data Cleaning & Manipulation",
    "section": "across(): Related Functions",
    "text": "across(): Related Functions\nThese functions are used with filter() to select rows based on a logical statement applied to multiple columns\n\nif_any() – returns a logical vector (one element for each row) that is TRUE if the logical statement is true for any column in the supplied columns\nif_all() – returns a logical vector (one element for each row) that is TRUE if the logical statement is true for all columns in the supplied columns"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#if_any-example",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#if_any-example",
    "title": "Data Cleaning & Manipulation",
    "section": "if_any() Example",
    "text": "if_any() Example\nRemember, you got warnings in PA3 when converting some columns to numeric? If you look at the original data, you can see this is because missing values were indicated with the string \"NULL\".\n\n\n\n\n\n\nINSTNM\nCITY\nSTABBR\nZIP\nADM_RATE\nSAT_AVG\nUGDS\nTUITIONFEE_IN\nTUITIONFEE_OUT\nCONTROL\nREGION\n\n\n\n\nAlabama A & M University\nNormal\nAL\n35762\n0.9027\n929\n4824\n9857\n18236\n1\n5\n\n\nUniversity of Alabama at Birmingham\nBirmingham\nAL\n35294-0110\n0.9181\n1195\n12866\n8328\n19032\n1\n5\n\n\nAmridge University\nMontgomery\nAL\n36117-3553\nNULL\nNULL\n322\n6900\n6900\n2\n5\n\n\n\n\n\n\n\n\nWe could drop these rows before converting the columns to numeric if desired, using if_any():\n\ncolleges_clean &lt;- colleges_clean |&gt; \n  filter(!if_any(.cols = ADM_RATE:TUITIONFEE_OUT, \n                 .fns = ~ .x == \"NULL\"))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#the-numbers-dont-speak-for-themselves",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#the-numbers-dont-speak-for-themselves",
    "title": "Data Cleaning & Manipulation",
    "section": "The Numbers Don’t Speak for Themselves",
    "text": "The Numbers Don’t Speak for Themselves\nWith the people next to you discuss:\n\nWhat was the main take-away for you?\nWhat points stood out to you?\nWhat was something that suprised you?\nIs there anything you didn’t agree with?\nWhat questions do you have after reading?\n\n\nSource: Data Feminism by by Catherine D’Ignazio and Lauren Klein (2020)"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#tuesday-april-22",
    "href": "slides/week-4/w4-joins-pivots.html#tuesday-april-22",
    "title": "Data Joins + Pivots",
    "section": "Tuesday, April 22",
    "text": "Tuesday, April 22\nToday we will…\n\nBig Picture\nNew Material\n\nJoining data with dplyr\nPivoting data with tidyr\n\nPA 4: Military Spending\n\n\n\n\n\n\n\nFollow along\n\n\nRemember to download, save, and open up the starter notes for this week! This week you need to download and save some data as well."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#comments-from-week-3",
    "href": "slides/week-4/w4-joins-pivots.html#comments-from-week-3",
    "title": "Data Joins + Pivots",
    "section": "Comments from Week 3",
    "text": "Comments from Week 3\n\nVery nice work overall!!\nWork on the lab early!\n\nGet an idea of how long it may take and what any big challenges are\n\nBe thoughtful about use of color in plots\nOnly save variables / intermediate objects when needed\nAvoid long lines of code"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#data-science-process",
    "href": "slides/week-4/w4-joins-pivots.html#data-science-process",
    "title": "Data Joins + Pivots",
    "section": "Data Science Process",
    "text": "Data Science Process\n\nAdapted from r4ds"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#we-have-covered",
    "href": "slides/week-4/w4-joins-pivots.html#we-have-covered",
    "title": "Data Joins + Pivots",
    "section": "We have covered…",
    "text": "We have covered…"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#today",
    "href": "slides/week-4/w4-joins-pivots.html#today",
    "title": "Data Joins + Pivots",
    "section": "Today",
    "text": "Today"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#getting-data",
    "href": "slides/week-4/w4-joins-pivots.html#getting-data",
    "title": "Data Joins + Pivots",
    "section": "Getting Data",
    "text": "Getting Data\n\nSo far, we have simply needed to import one nice rectangular data set in a typical file type\nReal life often gets a bit more complicated!!"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#motivating-real-example1",
    "href": "slides/week-4/w4-joins-pivots.html#motivating-real-example1",
    "title": "Data Joins + Pivots",
    "section": "Motivating (Real) Example1",
    "text": "Motivating (Real) Example1\n\n\nTexas Education Data (AEIS): K-12 student performance data provided by the Texas Education Agency\nProvides A LOT of information … in many separate files:\n\nby year\nfor State, Regions, Districts, or Schools\nfor different sets of variables\n\n\n\n\n🧐 need to get this #%$ together before we can analyze it\n\nI worked with this data for a project. See the paper and Github repo if you are interested!"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#relational-data",
    "href": "slides/week-4/w4-joins-pivots.html#relational-data",
    "title": "Data Joins + Pivots",
    "section": "Relational Data",
    "text": "Relational Data\n\n\nMultiple, interconnected tables of data are called relational.\nIndividual datsets may not provide exactly what we need - but we can use the relation between datasets to get the information we want.\n\n\n\n\n\n\nIMDb movie relational data"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#example---imdb-movie-data",
    "href": "slides/week-4/w4-joins-pivots.html#example---imdb-movie-data",
    "title": "Data Joins + Pivots",
    "section": "Example - IMDb Movie Data",
    "text": "Example - IMDb Movie Data\n\n\n\n\n\n\nDiscussion\n\n\nWhat if we want to know which actor has worked with the most directors in the dataset?\nWhat analytical dataset would we need to answer this question? What are the rows, and variables needed?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#example---imdb-movie-data-1",
    "href": "slides/week-4/w4-joins-pivots.html#example---imdb-movie-data-1",
    "title": "Data Joins + Pivots",
    "section": "Example - IMDb Movie Data",
    "text": "Example - IMDb Movie Data\n\n\n\n\n\n\nDiscussion\n\n\nWhat if we want to know which actor has worked with the most directors in the dataset?\nWhat analytical dataset would we need to answer this question? What are the rows, and variables needed?\n\n\n\n\n\n💡 In order to answer our question, we need to combine some of the individual datasets into one big dataset\nJoins!"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#data-joins-1",
    "href": "slides/week-4/w4-joins-pivots.html#data-joins-1",
    "title": "Data Joins + Pivots",
    "section": "Data Joins",
    "text": "Data Joins\nWe can combine (join) data tables based on their relations.\n\n\nMutating joins\nAdd variables from a new dataframe to observations in an existing dataframe.\nfull_join(), left_join(), right_join(), inner_join()\n\nFiltering Joins\nFilter observations based on values in new dataframe.\nsemi_join(), anti_join()"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#keys",
    "href": "slides/week-4/w4-joins-pivots.html#keys",
    "title": "Data Joins + Pivots",
    "section": "Keys",
    "text": "Keys\nSome combination of variables (should) uniquely identify an observation in a data set.\n\nTo combine (join) two datasets, a key needs to be present in both."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#general-structure-of-a-join",
    "href": "slides/week-4/w4-joins-pivots.html#general-structure-of-a-join",
    "title": "Data Joins + Pivots",
    "section": "General Structure of a Join",
    "text": "General Structure of a Join\n\n\n\n\nChoose a left and a right dataset\nAdd or remove rows based on the type of join and the structure of the left vs. right data\nAdd columns (or not) based on the type of join and the and the structure of the left vs. right data"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#inner_join",
    "href": "slides/week-4/w4-joins-pivots.html#inner_join",
    "title": "Data Joins + Pivots",
    "section": "inner_join()",
    "text": "inner_join()\nKeeps observations when their keys are present in both datasets.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\n\nWhen would you want to use inner_join()?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#inner_join-imdb-example",
    "href": "slides/week-4/w4-joins-pivots.html#inner_join-imdb-example",
    "title": "Data Joins + Pivots",
    "section": "inner_join(): IMDb Example",
    "text": "inner_join(): IMDb Example\n\n\n\ndirectors_genres\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n429\nAdventure\n0.750000\n\n\n429\nFantasy\n0.750000\n\n\n2931\nDrama\n0.714286\n\n\n2931\nAction\n0.428571\n\n\n11652\nSci-Fi\n0.500000\n\n\n11652\nAction\n0.500000\n\n\n14927\nAnimation\n1.000000\n\n\n14927\nFamily\n1.000000\n\n\n15092\nComedy\n0.545455\n\n\n15092\nCrime\n0.545455\n\n\n\n\n\n\n\n\n\nmovies_directors\n\n\n\n\n\n\n\ndirector_id\nmovie_id\n\n\n\n\n429\n300229\n\n\n9247\n124110\n\n\n11652\n10920\n\n\n11652\n333856\n\n\n14927\n192017\n\n\n15092\n109093\n\n\n15092\n237431\n\n\n\n\n\n\n\n\n\nID: 429, 2931, 11652, 14927, 15092       ID: 429, 9247, 11652, 14927, 15092\n\n\n\ninner_join(directors_genres, movies_directors, \n           by = \"director_id\")\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\nmovie_id\n\n\n\n\n429\nAdventure\n0.750000\n300229\n\n\n429\nFantasy\n0.750000\n300229\n\n\n11652\nSci-Fi\n0.500000\n10920\n\n\n11652\nSci-Fi\n0.500000\n333856\n\n\n11652\nAction\n0.500000\n10920\n\n\n11652\nAction\n0.500000\n333856\n\n\n14927\nAnimation\n1.000000\n192017\n\n\n14927\nFamily\n1.000000\n192017\n\n\n15092\nComedy\n0.545455\n109093\n\n\n15092\nComedy\n0.545455\n237431\n\n\n15092\nCrime\n0.545455\n109093\n\n\n15092\nCrime\n0.545455\n237431\n\n\n\n\n\n\n\n\nID: 429, 2931, 9247, 11652, 14927, 15092"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#inner_join-imdb-example-1",
    "href": "slides/week-4/w4-joins-pivots.html#inner_join-imdb-example-1",
    "title": "Data Joins + Pivots",
    "section": "inner_join(): IMDb Example",
    "text": "inner_join(): IMDb Example\nWhat if our key does not have the same name?\n\n\n\ndirectors_genres\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n429\nAdventure\n0.750000\n\n\n429\nFantasy\n0.750000\n\n\n2931\nDrama\n0.714286\n\n\n2931\nAction\n0.428571\n\n\n11652\nSci-Fi\n0.500000\n\n\n11652\nAction\n0.500000\n\n\n14927\nAnimation\n1.000000\n\n\n14927\nFamily\n1.000000\n\n\n15092\nComedy\n0.545455\n\n\n15092\nCrime\n0.545455\n\n\n\n\n\n\n\n\n\ndirectors\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\n\n\n\n\n429\nAndrew\nAdamson\n\n\n9247\nZach\nBraff\n\n\n11652\nJames (I)\nCameron\n\n\n14927\nRon\nClements\n\n\n15092\nEthan\nCoen\n\n\n\n\n\n\n\n\n\n\ninner_join(directors_genres, \n           directors, \n           by = join_by(director_id == id))\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\ngenre\nprob\n\n\n\n\n429\nAndrew\nAdamson\nAdventure\n0.750000\n\n\n429\nAndrew\nAdamson\nFantasy\n0.750000\n\n\n11652\nJames (I)\nCameron\nSci-Fi\n0.500000\n\n\n11652\nJames (I)\nCameron\nAction\n0.500000\n\n\n14927\nRon\nClements\nAnimation\n1.000000\n\n\n14927\nRon\nClements\nFamily\n1.000000\n\n\n15092\nEthan\nCoen\nComedy\n0.545455\n\n\n15092\nEthan\nCoen\nCrime\n0.545455\n\n\n\n\n\n\n\n Join by different variables on dataX and dataY: join_by(a == b) will match dataX$a to dataY$b."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#piping-joins",
    "href": "slides/week-4/w4-joins-pivots.html#piping-joins",
    "title": "Data Joins + Pivots",
    "section": "Piping Joins",
    "text": "Piping Joins\nRemember: the dataset you pipe in becomes the first argument of the function you are piping into!\n\nIf you are using a pipe,\n\nthe piped in data is the left dataset\nspecify the right dataset inside the join function.\n\n\n\n\ninner_join(directors_genres, movies_directors)\n\n…is equivalent to…\n\ndirectors_genres |&gt; \n  inner_join(movies_directors, by = \"director_id\")"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#more-mutating-joins",
    "href": "slides/week-4/w4-joins-pivots.html#more-mutating-joins",
    "title": "Data Joins + Pivots",
    "section": "More Mutating Joins",
    "text": "More Mutating Joins\n\nleft_join() – keep only (and all) observations present in the left data set\nright_join() – keep only (and all) observations present in the right data set\nfull_join() – keep only (and all) observations present in both data sets"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#why-use-a-certain-mutating-join",
    "href": "slides/week-4/w4-joins-pivots.html#why-use-a-certain-mutating-join",
    "title": "Data Joins + Pivots",
    "section": "Why Use a Certain Mutating Join?",
    "text": "Why Use a Certain Mutating Join?\n\n\n\ninner_join()\n\nYou want all of the columns from both left and right data and only to include the observations that have information in both\n\nleft_join()\n\nThe left dataset is your “main” data and you just want to add information (columns) from the right dataset\n\nright_join()\n\nThe right data is your “main data” and you just want to add columns from the left dataset\n\nfull_join()\n\nYou want all of the columns from both left and right data for all of the observations possible"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#which-join",
    "href": "slides/week-4/w4-joins-pivots.html#which-join",
    "title": "Data Joins + Pivots",
    "section": "Which Join?",
    "text": "Which Join?\n\n\n\n\n\n\nDiscussion\n\n\nHow many movies are there in the data for each director (by name), including if any directors don’t have any movies in the data? Which join should I use??\n\n\n\ndirectors |&gt; \n  ??_join(movies_directors, \n          by = join_by(\"id\" == \"director_id\"))\n\n\n\n\ndirectors |&gt; \n  slice_head(n = 5)\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\n\n\n\n\n429\nAndrew\nAdamson\n\n\n2931\nDarren\nAronofsky\n\n\n9247\nZach\nBraff\n\n\n11652\nJames (I)\nCameron\n\n\n14927\nRon\nClements\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  slice_head(n = 5)\n\n\n\n\n\n\n\ndirector_id\nmovie_id\n\n\n\n\n429\n300229\n\n\n2931\n254943\n\n\n9247\n124110\n\n\n11652\n10920\n\n\n11652\n333856"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#which-join-1",
    "href": "slides/week-4/w4-joins-pivots.html#which-join-1",
    "title": "Data Joins + Pivots",
    "section": "Which Join?",
    "text": "Which Join?\n\n\n\n\n\n\nDiscussion\n\n\nWhat is the complete set movies and actors included in the data? Which join should I use??\n\n\n\nroles |&gt; \n  ??_join(actors, \n          by = join_by(\"actor_id\" == \"id\"))\n\n\n\n\nroles |&gt; \n  slice_head(n = 5)\n\n\n\n\n\n\n\nactor_id\nmovie_id\nrole\n\n\n\n\n933\n333856\nLewis Bodine\n\n\n2547\n300229\nDuloc Mascot\n\n\n2700\n306032\nTyrone\n\n\n2898\n333856\nSlovakian three-year-old boy\n\n\n2925\n192017\nAdditional Voices\n\n\n\n\n\n\n\n\n\nactors |&gt; \n  slice_head(n = 5)\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\ngender\nfilm_count\n\n\n\n\n933\nLewis\nAbernathy\nM\n1\n\n\n2547\nAndrew\nAdamson\nM\n1\n\n\n2700\nWilliam\nAddy\nM\n1\n\n\n2898\nSeth (I)\nAdkins\nM\n1\n\n\n2925\nCharles (I)\nAdler\nM\n1"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#filtering-joins-semi_join",
    "href": "slides/week-4/w4-joins-pivots.html#filtering-joins-semi_join",
    "title": "Data Joins + Pivots",
    "section": "Filtering Joins: semi_join()",
    "text": "Filtering Joins: semi_join()\nKeeps observations when their keys are present in both datasets, but only keeps variables from the left dataset.\n\n\n\n\n\n\n→"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#imdb-data-example",
    "href": "slides/week-4/w4-joins-pivots.html#imdb-data-example",
    "title": "Data Joins + Pivots",
    "section": "IMDb Data Example",
    "text": "IMDb Data Example\n\n\n\ndirectors_genres |&gt; \n  distinct(director_id)\n\n\n\n\n\n\n\ndirector_id\n\n\n\n\n429\n\n\n2931\n\n\n11652\n\n\n14927\n\n\n15092\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  distinct(director_id)\n\n\n\n\n\n\n\ndirector_id\n\n\n\n\n429\n\n\n9247\n\n\n11652\n\n\n14927\n\n\n15092"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#filtering-joins-semi_join-1",
    "href": "slides/week-4/w4-joins-pivots.html#filtering-joins-semi_join-1",
    "title": "Data Joins + Pivots",
    "section": "Filtering Joins: semi_join()",
    "text": "Filtering Joins: semi_join()\n\nsemi_join()Connection to filter()\n\n\n\ndirectors_genres |&gt; \n  semi_join(movies_directors)\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n429\nAdventure\n0.750000\n\n\n429\nFantasy\n0.750000\n\n\n11652\nSci-Fi\n0.500000\n\n\n11652\nAction\n0.500000\n\n\n14927\nAnimation\n1.000000\n\n\n14927\nFamily\n1.000000\n\n\n15092\nComedy\n0.545455\n\n\n15092\nCrime\n0.545455\n\n\n\n\n\n\n\nMovie Directors: 429, 2931, 11652, 14927, 15092\n\n\n\ndirectors_genres |&gt;\n  filter(director_id %in% movies_directors$director_id)\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n429\nAdventure\n0.750000\n\n\n429\nFantasy\n0.750000\n\n\n11652\nSci-Fi\n0.500000\n\n\n11652\nAction\n0.500000\n\n\n14927\nAnimation\n1.000000\n\n\n14927\nFamily\n1.000000\n\n\n15092\nComedy\n0.545455\n\n\n15092\nCrime\n0.545455"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#filtering-joins-anti_join",
    "href": "slides/week-4/w4-joins-pivots.html#filtering-joins-anti_join",
    "title": "Data Joins + Pivots",
    "section": "Filtering Joins: anti_join()",
    "text": "Filtering Joins: anti_join()\nRemoves observations when their keys are present in both datasets, and only keeps variables from the left dataset.\n\n\n\n\n\n\n→"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#filtering-joins-anti_join-1",
    "href": "slides/week-4/w4-joins-pivots.html#filtering-joins-anti_join-1",
    "title": "Data Joins + Pivots",
    "section": "Filtering Joins: anti_join()",
    "text": "Filtering Joins: anti_join()\n\nanti_join()Connection to filter()\n\n\n\ndirectors_genres |&gt; \n  anti_join(movies_directors)\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n2931\nDrama\n0.714286\n\n\n2931\nAction\n0.428571\n\n\n\n\n\n\n\nMovie Directors: 429, 2931, 11652, 14927, 15092\n\n\n\ndirectors_genres |&gt;\n  filter(!director_id %in% movies_directors$director_id)\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n2931\nDrama\n0.714286\n\n\n2931\nAction\n0.428571"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#building-an-analytical-dataset-1",
    "href": "slides/week-4/w4-joins-pivots.html#building-an-analytical-dataset-1",
    "title": "Data Joins + Pivots",
    "section": "Building an Analytical Dataset",
    "text": "Building an Analytical Dataset\nNow we have tools to:\n\nCombine multiple data sets (xx_join())\nSubset to certain observations (filter() and xx_join())\nCreate new variables (mutate())\nSelect columns of interest (select())\n\n\nWe are well on our way to building and cleaning up a nice dataset! 🥳"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#transform-and-tidy",
    "href": "slides/week-4/w4-joins-pivots.html#transform-and-tidy",
    "title": "Data Joins + Pivots",
    "section": "Transform and Tidy",
    "text": "Transform and Tidy\nWhat’s next?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#transform-and-tidy-1",
    "href": "slides/week-4/w4-joins-pivots.html#transform-and-tidy-1",
    "title": "Data Joins + Pivots",
    "section": "Transform and Tidy",
    "text": "Transform and Tidy\nWhat’s next?\nWe may need to transform our data to turn it into the version of tidy that is best for a task at hand.\n\nAllison Horst"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#creating-tidy-data",
    "href": "slides/week-4/w4-joins-pivots.html#creating-tidy-data",
    "title": "Data Joins + Pivots",
    "section": "Creating Tidy Data",
    "text": "Creating Tidy Data\nLet’s say we want to look at mean cereal nutrients based on shelf.\n\n\nThe data are in a wide format – a separate column for each nutrient.\n\n\nlibrary(liver)\ndata(cereal)\nhead(cereal)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1\n0.75\n29.50954"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#creating-tidy-data-1",
    "href": "slides/week-4/w4-joins-pivots.html#creating-tidy-data-1",
    "title": "Data Joins + Pivots",
    "section": "Creating Tidy Data",
    "text": "Creating Tidy Data\n\n\n\n\n\n\nDiscussion\n\n\nHow would we plot the mean cereal nutrients by shelf (as shown below) with the wide data using ggplot2?\n\n\n\n\n\nTransforming the data will make plotting much easier"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#creating-tidy-data-2",
    "href": "slides/week-4/w4-joins-pivots.html#creating-tidy-data-2",
    "title": "Data Joins + Pivots",
    "section": "Creating Tidy Data",
    "text": "Creating Tidy Data\n\nWideWide PlotLongLong Plot\n\n\n\n\nCode\ncereal_wide &lt;- cereal |&gt; \n  group_by(shelf) |&gt; \n  summarise(across(calories:vitamins, mean))\n\n\n\n\n\n\n\n\nshelf\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\n\n\n\n\n1\n102.5000\n2.650000\n0.60\n176.2500\n1.6850000\n15.80000\n4.800000\n75.50000\n20.00000\n\n\n2\n109.5238\n1.904762\n1.00\n145.7143\n0.9047619\n13.61905\n9.619048\n57.80952\n23.80952\n\n\n3\n107.7778\n2.861111\n1.25\n158.6111\n3.1388889\n14.50000\n6.527778\n129.83333\n35.41667\n\n\n\n\n\n\n\n\n\n\n\nCode\nmy_colors &lt;- c(\"calories_col\" = \"steelblue\", \"sugars_col\" = \"orange3\")\n\ncereal_wide |&gt; \n  ggplot() +\n  geom_point(aes(x = shelf, y = calories, color = \"calories_col\")) +\n  geom_line(aes(x = shelf, y = calories, color = \"calories_col\")) + \n  geom_point(aes(x = shelf, y = sugars, color = \"sugars_col\")) +\n  geom_line(aes(x = shelf, y = sugars, color = \"sugars_col\")) +\n  scale_color_manual(values = my_colors, labels = names(my_colors)) +\n  labs(x = \"Shelf\", y = \"\", subtitle = \"Mean Amount\", color = \"Nutrient\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncereal_long&lt;- cereal |&gt; \n  pivot_longer(cols = calories:vitamins,\n               names_to = \"Nutrient\",\n               values_to = \"Amount\") |&gt; \n  group_by(shelf, Nutrient) |&gt; \n  summarise(mean_amount = mean(Amount))\n\n\n\n\n\n\n\n\nshelf\nNutrient\nmean_amount\n\n\n\n\n1\ncalories\n102.5000000\n\n\n1\ncarbo\n15.8000000\n\n\n1\nfat\n0.6000000\n\n\n1\nfiber\n1.6850000\n\n\n1\npotass\n75.5000000\n\n\n1\nprotein\n2.6500000\n\n\n1\nsodium\n176.2500000\n\n\n1\nsugars\n4.8000000\n\n\n1\nvitamins\n20.0000000\n\n\n2\ncalories\n109.5238095\n\n\n2\ncarbo\n13.6190476\n\n\n2\nfat\n1.0000000\n\n\n2\nfiber\n0.9047619\n\n\n2\npotass\n57.8095238\n\n\n2\nprotein\n1.9047619\n\n\n2\nsodium\n145.7142857\n\n\n2\nsugars\n9.6190476\n\n\n2\nvitamins\n23.8095238\n\n\n3\ncalories\n107.7777778\n\n\n3\ncarbo\n14.5000000\n\n\n3\nfat\n1.2500000\n\n\n3\nfiber\n3.1388889\n\n\n3\npotass\n129.8333333\n\n\n3\nprotein\n2.8611111\n\n\n3\nsodium\n158.6111111\n\n\n3\nsugars\n6.5277778\n\n\n3\nvitamins\n35.4166667\n\n\n\n\n\n\n\n\n\n\n\nCode\ncereal_long |&gt; \n  ggplot(aes(x = shelf, \n             y = mean_amount, \n             color = Nutrient)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Shelf\", y = \"\", subtitle = \"Mean Amount\")"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#data-layouts",
    "href": "slides/week-4/w4-joins-pivots.html#data-layouts",
    "title": "Data Joins + Pivots",
    "section": "Data Layouts",
    "text": "Data Layouts\n\nKelsey Gonzalez"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#manual-method",
    "href": "slides/week-4/w4-joins-pivots.html#manual-method",
    "title": "Data Joins + Pivots",
    "section": "Manual Method",
    "text": "Manual Method\nConsider daily rainfall observed in SLO in January 2023.\n\nThe data is in a human-friendly form (like a calendar).\nEach week has a row, and each day has a column.\n\n\nData source\n\n\n\n\n\nDiscussion\n\n\nHow would you manually convert this to long format?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#manual-method-steps",
    "href": "slides/week-4/w4-joins-pivots.html#manual-method-steps",
    "title": "Data Joins + Pivots",
    "section": "Manual Method: Steps",
    "text": "Manual Method: Steps\n\nKeep the column Week.\nCreate a new column Day_of_Week.\nCreate a new column Rainfall (hold daily rainfall values).\nNow we have three columns – move Sunday values over.\nDuplicate Week 1-5 and copy Monday values over.\n\n\n\n\n\nRepeat …"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#computational-approach",
    "href": "slides/week-4/w4-joins-pivots.html#computational-approach",
    "title": "Data Joins + Pivots",
    "section": "Computational Approach",
    "text": "Computational Approach\n\nWe can use pivot_longer() to turn a wide dataset into a long(er) dataset."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pivot_longer",
    "href": "slides/week-4/w4-joins-pivots.html#pivot_longer",
    "title": "Data Joins + Pivots",
    "section": "pivot_longer()",
    "text": "pivot_longer()\nTake a wide dataset and turn it into a long dataset.\n\ncols – specify the columns that should be pivoted.\n\nDo not include the names of ID columns (columns to not be pivoted).\n\nnames_to – the name of the new column containing the old column names.\nvalues_to – the name of the new column containing the old column values."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pivot_longer-1",
    "href": "slides/week-4/w4-joins-pivots.html#pivot_longer-1",
    "title": "Data Joins + Pivots",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nslo_rainfall |&gt; \n  pivot_longer(cols      = Sunday:Saturday,\n               names_to  = \"Day_of_Week\",\n               values_to = \"Daily_Rainfall\")\n\n\n\n\n\n\n\nWeek\nDay_of_Week\nDaily_Rainfall\n\n\n\n\n1\nSunday\n0.00\n\n\n1\nMonday\n0.12\n\n\n1\nTuesday\n0.00\n\n\n1\nWednesday\n1.58\n\n\n1\nThursday\n0.91\n\n\n1\nFriday\n0.00\n\n\n1\nSaturday\n0.05\n\n\n2\nSunday\n0.27\n\n\n2\nMonday\n4.26\n\n\n2\nTuesday\n0.43\n\n\n2\nWednesday\n0.00\n\n\n2\nThursday\n0.00\n\n\n2\nFriday\n0.16\n\n\n2\nSaturday\n1.41\n\n\n3\nSunday\n0.34\n\n\n3\nMonday\n0.33\n\n\n3\nTuesday\n0.00\n\n\n3\nWednesday\n0.00\n\n\n3\nThursday\n0.13\n\n\n3\nFriday\n0.00\n\n\n3\nSaturday\n0.00\n\n\n4\nSunday\n0.00\n\n\n4\nMonday\n0.00\n\n\n4\nTuesday\n0.00\n\n\n4\nWednesday\n0.00\n\n\n4\nThursday\n0.00\n\n\n4\nFriday\n0.00\n\n\n4\nSaturday\nNA\n\n\n5\nSunday\nNA\n\n\n5\nMonday\nNA\n\n\n5\nTuesday\nNA\n\n\n5\nWednesday\nNA\n\n\n5\nThursday\nNA\n\n\n5\nFriday\nNA\n\n\n5\nSaturday\nNA"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#long-to-wide",
    "href": "slides/week-4/w4-joins-pivots.html#long-to-wide",
    "title": "Data Joins + Pivots",
    "section": "Long to Wide",
    "text": "Long to Wide\nWhat are the mean amount of protein for cereals on each shelf and for each manuf?\n\nmean_protein &lt;- cereal |&gt; \n  group_by(manuf, shelf) |&gt; \n  summarize(mean_protein = mean(protein))\n\n\n\n\n\n\n\nmanuf\nshelf\nmean_protein\n\n\n\n\nA\n2\n4.000000\n\n\nG\n1\n3.000000\n\n\nG\n2\n1.285714\n\n\nG\n3\n2.666667\n\n\nK\n1\n2.750000\n\n\nK\n2\n2.142857\n\n\nK\n3\n2.916667\n\n\nN\n1\n2.666667\n\n\nN\n2\n2.500000\n\n\nN\n3\n4.000000\n\n\nP\n1\n1.500000\n\n\nP\n2\n1.000000\n\n\nP\n3\n3.000000\n\n\nQ\n1\n5.000000\n\n\nQ\n2\n2.000000\n\n\nQ\n3\n2.500000\n\n\nR\n1\n2.000000\n\n\nR\n3\n3.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\n\nWhat could we do to make this table easier to understand?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pivot_wider",
    "href": "slides/week-4/w4-joins-pivots.html#pivot_wider",
    "title": "Data Joins + Pivots",
    "section": "pivot_wider()",
    "text": "pivot_wider()\nTake a long dataset and turn it into a wide dataset.\n\nid_cols – specify the column(s) that contain the ID for unique rows in the wide dataset.\nnames_from – the name of the column containing the new column names.\nvalues_from – the name of the column containing the new column values."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pivot_wider-1",
    "href": "slides/week-4/w4-joins-pivots.html#pivot_wider-1",
    "title": "Data Joins + Pivots",
    "section": "pivot_wider()",
    "text": "pivot_wider()\nMuch easier to read!\n\nmean_protein |&gt; \n  arrange(shelf) |&gt; \n  pivot_wider(id_cols = manuf,\n              names_from = shelf,\n              values_from = mean_protein)\n\n\n\n\n\n\n\nmanuf\n1\n2\n3\n\n\n\n\nG\n3.000000\n1.285714\n2.666667\n\n\nK\n2.750000\n2.142857\n2.916667\n\n\nN\n2.666667\n2.500000\n4.000000\n\n\nP\n1.500000\n1.000000\n3.000000\n\n\nQ\n5.000000\n2.000000\n2.500000\n\n\nR\n2.000000\nNA\n3.000000\n\n\nA\nNA\n4.000000\nNA"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#better-names-in-pivot_wider",
    "href": "slides/week-4/w4-joins-pivots.html#better-names-in-pivot_wider",
    "title": "Data Joins + Pivots",
    "section": "Better names in pivot_wider()",
    "text": "Better names in pivot_wider()\nEven better!\n\nmean_protein |&gt; \n  arrange(shelf) |&gt; \n  pivot_wider(id_cols = manuf,\n              names_from = shelf,\n              values_from = mean_protein,\n              names_prefix = \"Shelf_\")\n\n\n\n\n\n\n\nmanuf\nShelf_1\nShelf_2\nShelf_3\n\n\n\n\nG\n3.000000\n1.285714\n2.666667\n\n\nK\n2.750000\n2.142857\n2.916667\n\n\nN\n2.666667\n2.500000\n4.000000\n\n\nP\n1.500000\n1.000000\n3.000000\n\n\nQ\n5.000000\n2.000000\n2.500000\n\n\nR\n2.000000\nNA\n3.000000\n\n\nA\nNA\n4.000000\nNA"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pa-4-military-spending",
    "href": "slides/week-4/w4-joins-pivots.html#pa-4-military-spending",
    "title": "Data Joins + Pivots",
    "section": "PA 4: Military Spending",
    "text": "PA 4: Military Spending\nToday you will be tidying messy data to explore the relationship between countries of the world and military spending."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#resources---use-them-all",
    "href": "slides/week-4/w4-joins-pivots.html#resources---use-them-all",
    "title": "Data Joins + Pivots",
    "section": "Resources - use them all!",
    "text": "Resources - use them all!\n\n\n\ndplyr and tidyr cheatsheets\nslides and textbook\nhelp files\n\n\n\n⭐️️ each other⭐️\nand me 😎\n\n\n\nDon’t struggle individually for too long!"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#to-do",
    "href": "slides/week-4/w4-joins-pivots.html#to-do",
    "title": "Data Joins + Pivots",
    "section": "To do…",
    "text": "To do…\n\nPA 4: Military Spending\n\nDue Thursday, 4/24 before class"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html",
    "href": "labs/lab5/lab5-murder.html",
    "title": "Lab 5: Murder in SQL City",
    "section": "",
    "text": "Download starter .qmd file\nFor this lab, you will be joining and filtering related datasets to solve a murder mystery!"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#instructions",
    "href": "labs/lab5/lab5-murder.html#instructions",
    "title": "Lab 5: Murder in SQL City",
    "section": "Instructions",
    "text": "Instructions\nNorthwestern University’s Knight Lab wanted to help sharpen users’ database skills, so they created a murder mystery. Can you solve this crime in SQL City??\nThe relational data you will be working with contains tables with different pieces of information pertinent to the crime - people, social media check-ins, driver’s licenses, crime scene reports, police interviews, and more!\n\n\n\nDatabase schema"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#access-the-data",
    "href": "labs/lab5/lab5-murder.html#access-the-data",
    "title": "Lab 5: Murder in SQL City",
    "section": "Access the Data",
    "text": "Access the Data\nThis code chunk will read in all of the tables of data for you. Don’t modify or remove this!\n\nlibrary(tidyverse)\n\nurl(\"https://raw.githubusercontent.com/manncz/stat-331-s25/main/labs/lab5/data/bCH_murder_data.Rdata\") |&gt; \n  load()\n\n\n\n\n\n\n\nTip\n\n\n\nIf the code above does not work for you for some reason, you can download the special data file here and use the load() function to read it in."
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#solve-the-crime",
    "href": "labs/lab5/lab5-murder.html#solve-the-crime",
    "title": "Lab 5: Murder in SQL City",
    "section": "Solve the Crime",
    "text": "Solve the Crime\n\nCrime Scene Report\nDetective Wickham reaches out to you…\n\nA crime has taken place and I need your help! There was a murder in SQL City sometime on Jan.15, 2018. Could you retrieve the crime scene report from the police department’s database and follow the clues to find the person responsible for the murder?!\n\nSolve the murder mystery, showing all of your work in this document. Your document and code must be well organized, easy to follow, and reproducible.\n\nUse headers and written descriptions to indicate what you are doing.\nYou must use dplyr verbs and join functions rather than just looking through the tables manually.\nYou should never filter on a specific person id – rather use join functions\nYou should have a final output that just includes the murder’s name as well as their interview transcript (which is missing!).\nUse the data frames you just created when helpful!\nUse good code formatting practices.\nComment your code.\nCite any external sources you use to solve the mystery.\n\n\n\n\n\n\n\nTip\n\n\n\nUse kable() to nicely output clues!\n\n\nFollow the evidence to the person responsible for the murder, building a report as you go.\n\n# code for looking at the relevant crime scene report.\n\n# you will want to use multiple chunks!\n\n\n\n\n\n\n\nCaution\n\n\n\nMake sure you check for interviews with any suspects and anyone mentioned!\nThe murderer will have no interview - don’t stop until you find them!\n\n\n\n\n\n\n\n\nAnd the final suspect is…\n\n\n\nput the name of the person responsible for the murder here."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#thursday-april-24",
    "href": "slides/week-4/w4-factors.html#thursday-april-24",
    "title": "Extending Data Joins + Factors",
    "section": "Thursday, April 24",
    "text": "Thursday, April 24\nToday we will…\n\nNotes on Lab 3\nProject Info\nNew Material\n\nExtensions to Data Joins\nFactors with forcats\nClean Variable Names\nLifecycle Stages\n\nLab 4: Childcare Costs in California"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#notes-on-lab-3",
    "href": "slides/week-4/w4-factors.html#notes-on-lab-3",
    "title": "Data Joins + Pivots + Factors",
    "section": "Notes on Lab 3",
    "text": "Notes on Lab 3\n\n\nOnly include output that (exactly) answers a specific question\n\nIf you find yourself outputting a datatable with more than 20 rows, think again!\n\nBe mindful of “environment junk”\nIf we have cleaned up a dataset, you can assume that will be used for the remainder of the lab, unless otherwise specified\nPlease look at the solutions for efficient code and statistical interpretations"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#where-is-my-file",
    "href": "slides/week-4/w4-factors.html#where-is-my-file",
    "title": "Data Joins + Pivots + Factors",
    "section": "Where is my file?",
    "text": "Where is my file?\n\nRemember: I will smash 💥 your computer if you:\n\nSet a working directory in a Quarto file setwd() OR\nUse an aboslute file path that would only work on your computer\n\n\n\n\nUSE RELATIVE FILE PATHS I BEG OF YOU"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#lab-3-question-11",
    "href": "slides/week-4/w4-factors.html#lab-3-question-11",
    "title": "Data Joins + Pivots + Factors",
    "section": "Lab 3 Question 11",
    "text": "Lab 3 Question 11\n Which instructor(s) with either a doctorate or professor degree had the highest and lowest average percent of students responding to the evaluation across all their courses? Include how many years the professor had worked (seniority) and their sex in your output \n\nThe trick: group_by() instructor_id, seniority, and sex\n\nteacher_evals_clean |&gt; \n  filter(academic_degree %in% c(\"dr\", \"prof\")) |&gt; \n  group_by(teacher_id, seniority, sex) |&gt; \n  summarize(avg_response = mean(resp_share)) |&gt; \n  ungroup() |&gt; \n  slice_max(order_by = avg_response) |&gt; \n  kable()\n\n\nIf you find yourself using mutate() and then distinct(), you should probably be using summarize()"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#relational-data-reminder---keys",
    "href": "slides/week-4/w4-factors.html#relational-data-reminder---keys",
    "title": "Extending Data Joins + Factors",
    "section": "Relational Data Reminder - Keys",
    "text": "Relational Data Reminder - Keys\nWhen we work with relational data, we rely on keys.\n\nA key uniquely identifies an observation in a dataset.\nA key allows us to relate datasets to each other"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#imdb-movies-data",
    "href": "slides/week-4/w4-factors.html#imdb-movies-data",
    "title": "Extending Data Joins + Factors",
    "section": "IMDb Movies Data",
    "text": "IMDb Movies Data\n\nWhat were the active years of each director?\n\n\n\n\n\n\nDiscussion\n\n\nWhich datasets do we need to use to answer this question?"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#joining-multiple-data-sets",
    "href": "slides/week-4/w4-factors.html#joining-multiple-data-sets",
    "title": "Extending Data Joins + Factors",
    "section": "Joining Multiple Data Sets",
    "text": "Joining Multiple Data Sets\n\nDataSketch1st + 2nd+ 3rdAnalysis\n\n\n\n\n\nmovies_directors |&gt; \n  slice_head(n = 4)\n\n\n\n\n\n\n\ndirector_id\nmovie_id\n\n\n\n\n429\n300229\n\n\n2931\n254943\n\n\n9247\n124110\n\n\n11652\n10920\n\n\n\n\n\n\n\n\n\ndirectors |&gt; \n  slice_head(n = 4)\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\n\n\n\n\n429\nAndrew\nAdamson\n\n\n2931\nDarren\nAronofsky\n\n\n9247\nZach\nBraff\n\n\n11652\nJames (I)\nCameron\n\n\n\n\n\n\n\n\n\n\n\n\n\nmovies |&gt; \n  slice_head(n = 4)\n\n\n\n\n\n\n\nid\nname\nyear\nrank\n\n\n\n\n10920\nAliens\n1986\n8.2\n\n\n17173\nAnimal House\n1978\n7.5\n\n\n18979\nApollo 13\n1995\n7.5\n\n\n30959\nBatman Begins\n2005\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  inner_join(directors, \n             join_by(director_id == id))\n\n\n\n\n\n\n\ndirector_id\nmovie_id\nfirst_name\nlast_name\n\n\n\n\n429\n300229\nAndrew\nAdamson\n\n\n2931\n254943\nDarren\nAronofsky\n\n\n9247\n124110\nZach\nBraff\n\n\n11652\n10920\nJames (I)\nCameron\n\n\n11652\n333856\nJames (I)\nCameron\n\n\n14927\n192017\nRon\nClements\n\n\n15092\n109093\nEthan\nCoen\n\n\n15092\n237431\nEthan\nCoen\n\n\n15093\n109093\nJoel\nCoen\n\n\n15093\n237431\nJoel\nCoen\n\n\n15901\n130128\nFrancis Ford\nCoppola\n\n\n15906\n194874\nSofia\nCoppola\n\n\n16816\n350424\nCameron\nCrowe\n\n\n17810\n297838\nFrank\nDarabont\n\n\n22104\n224842\nClint\nEastwood\n\n\n24758\n112290\nDavid\nFincher\n\n\n28395\n46169\nMel (I)\nGibson\n\n\n35573\n18979\nRon\nHoward\n\n\n35838\n257264\nJohn (I)\nHughes\n\n\n37872\n300229\nVicky\nJenson\n\n\n38746\n238695\nMike (I)\nJudge\n\n\n41975\n314965\nDavid\nKoepp\n\n\n44291\n17173\nJohn (I)\nLandis\n\n\n46315\n344203\nJay\nLevey\n\n\n48115\n313459\nGeorge\nLucas\n\n\n56332\n192017\nJohn\nMusker\n\n\n58201\n30959\nChristopher\nNolan\n\n\n58201\n210511\nChristopher\nNolan\n\n\n65940\n111813\nRob\nReiner\n\n\n66849\n306032\nGuy\nRitchie\n\n\n68161\n116907\nHerbert (I)\nRoss\n\n\n74758\n238072\nSteven\nSoderbergh\n\n\n76524\n167324\nOliver (I)\nStone\n\n\n78273\n176711\nQuentin\nTarantino\n\n\n78273\n176712\nQuentin\nTarantino\n\n\n78273\n267038\nQuentin\nTarantino\n\n\n78273\n276217\nQuentin\nTarantino\n\n\n82525\n147603\nPaul (I)\nVerhoeven\n\n\n83616\n207992\nAndy\nWachowski\n\n\n83617\n207992\nLarry\nWachowski\n\n\n88802\n256630\nUnknown\nDirector\n\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  inner_join(directors, \n             join_by(director_id == id)) |&gt; \n  inner_join(movies,\n             join_by(movie_id == id))\n\n\n\n\n\n\n\ndirector_id\nmovie_id\nfirst_name\nlast_name\nname\nyear\nrank\n\n\n\n\n429\n300229\nAndrew\nAdamson\nShrek\n2001\n8.1\n\n\n2931\n254943\nDarren\nAronofsky\nPi\n1998\n7.5\n\n\n9247\n124110\nZach\nBraff\nGarden State\n2004\n8.3\n\n\n11652\n10920\nJames (I)\nCameron\nAliens\n1986\n8.2\n\n\n11652\n333856\nJames (I)\nCameron\nTitanic\n1997\n6.9\n\n\n14927\n192017\nRon\nClements\nLittle Mermaid, The\n1989\n7.3\n\n\n15092\n109093\nEthan\nCoen\nFargo\n1996\n8.2\n\n\n15092\n237431\nEthan\nCoen\nO Brother, Where Art Thou?\n2000\n7.8\n\n\n15093\n109093\nJoel\nCoen\nFargo\n1996\n8.2\n\n\n15093\n237431\nJoel\nCoen\nO Brother, Where Art Thou?\n2000\n7.8\n\n\n15901\n130128\nFrancis Ford\nCoppola\nGodfather, The\n1972\n9.0\n\n\n15906\n194874\nSofia\nCoppola\nLost in Translation\n2003\n8.0\n\n\n16816\n350424\nCameron\nCrowe\nVanilla Sky\n2001\n6.9\n\n\n17810\n297838\nFrank\nDarabont\nShawshank Redemption, The\n1994\n9.0\n\n\n22104\n224842\nClint\nEastwood\nMystic River\n2003\n8.1\n\n\n24758\n112290\nDavid\nFincher\nFight Club\n1999\n8.5\n\n\n28395\n46169\nMel (I)\nGibson\nBraveheart\n1995\n8.3\n\n\n35573\n18979\nRon\nHoward\nApollo 13\n1995\n7.5\n\n\n35838\n257264\nJohn (I)\nHughes\nPlanes, Trains & Automobiles\n1987\n7.2\n\n\n37872\n300229\nVicky\nJenson\nShrek\n2001\n8.1\n\n\n38746\n238695\nMike (I)\nJudge\nOffice Space\n1999\n7.6\n\n\n41975\n314965\nDavid\nKoepp\nStir of Echoes\n1999\n7.0\n\n\n44291\n17173\nJohn (I)\nLandis\nAnimal House\n1978\n7.5\n\n\n46315\n344203\nJay\nLevey\nUHF\n1989\n6.6\n\n\n48115\n313459\nGeorge\nLucas\nStar Wars\n1977\n8.8\n\n\n56332\n192017\nJohn\nMusker\nLittle Mermaid, The\n1989\n7.3\n\n\n58201\n30959\nChristopher\nNolan\nBatman Begins\n2005\nNA\n\n\n58201\n210511\nChristopher\nNolan\nMemento\n2000\n8.7\n\n\n65940\n111813\nRob\nReiner\nFew Good Men, A\n1992\n7.5\n\n\n66849\n306032\nGuy\nRitchie\nSnatch.\n2000\n7.9\n\n\n68161\n116907\nHerbert (I)\nRoss\nFootloose\n1984\n5.8\n\n\n74758\n238072\nSteven\nSoderbergh\nOcean's Eleven\n2001\n7.5\n\n\n76524\n167324\nOliver (I)\nStone\nJFK\n1991\n7.8\n\n\n78273\n176711\nQuentin\nTarantino\nKill Bill: Vol. 1\n2003\n8.4\n\n\n78273\n176712\nQuentin\nTarantino\nKill Bill: Vol. 2\n2004\n8.2\n\n\n78273\n267038\nQuentin\nTarantino\nPulp Fiction\n1994\n8.7\n\n\n78273\n276217\nQuentin\nTarantino\nReservoir Dogs\n1992\n8.3\n\n\n82525\n147603\nPaul (I)\nVerhoeven\nHollow Man\n2000\n5.3\n\n\n83616\n207992\nAndy\nWachowski\nMatrix, The\n1999\n8.5\n\n\n83617\n207992\nLarry\nWachowski\nMatrix, The\n1999\n8.5\n\n\n88802\n256630\nUnknown\nDirector\nPirates of the Caribbean\n2003\nNA\n\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  inner_join(directors, \n             join_by(director_id == id)) |&gt; \n  inner_join(movies,\n             join_by(movie_id == id)) |&gt; \n  group_by(first_name, last_name) |&gt;\n  summarize(start_year = min(year),\n            end_year = max(year)) |&gt; \n  mutate(n_years_active = end_year - start_year) |&gt; \n  arrange(desc(n_years_active))\n\n\n\n\n\n\n\nfirst_name\nlast_name\nstart_year\nend_year\nn_years_active\n\n\n\n\nQuentin\nTarantino\n1992\n2004\n12\n\n\nJames (I)\nCameron\n1986\n1997\n11\n\n\nChristopher\nNolan\n2000\n2005\n5\n\n\nEthan\nCoen\n1996\n2000\n4\n\n\nJoel\nCoen\n1996\n2000\n4\n\n\nAndrew\nAdamson\n2001\n2001\n0\n\n\nAndy\nWachowski\n1999\n1999\n0\n\n\nCameron\nCrowe\n2001\n2001\n0\n\n\nClint\nEastwood\n2003\n2003\n0\n\n\nDarren\nAronofsky\n1998\n1998\n0\n\n\nDavid\nFincher\n1999\n1999\n0\n\n\nDavid\nKoepp\n1999\n1999\n0\n\n\nFrancis Ford\nCoppola\n1972\n1972\n0\n\n\nFrank\nDarabont\n1994\n1994\n0\n\n\nGeorge\nLucas\n1977\n1977\n0\n\n\nGuy\nRitchie\n2000\n2000\n0\n\n\nHerbert (I)\nRoss\n1984\n1984\n0\n\n\nJay\nLevey\n1989\n1989\n0\n\n\nJohn\nMusker\n1989\n1989\n0\n\n\nJohn (I)\nHughes\n1987\n1987\n0\n\n\nJohn (I)\nLandis\n1978\n1978\n0\n\n\nLarry\nWachowski\n1999\n1999\n0\n\n\nMel (I)\nGibson\n1995\n1995\n0\n\n\nMike (I)\nJudge\n1999\n1999\n0\n\n\nOliver (I)\nStone\n1991\n1991\n0\n\n\nPaul (I)\nVerhoeven\n2000\n2000\n0\n\n\nRob\nReiner\n1992\n1992\n0\n\n\nRon\nClements\n1989\n1989\n0\n\n\nRon\nHoward\n1995\n1995\n0\n\n\nSofia\nCoppola\n2003\n2003\n0\n\n\nSteven\nSoderbergh\n2001\n2001\n0\n\n\nUnknown\nDirector\n2003\n2003\n0\n\n\nVicky\nJenson\n2001\n2001\n0\n\n\nZach\nBraff\n2004\n2004\n0"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#know-your-unique-observations",
    "href": "slides/week-4/w4-factors.html#know-your-unique-observations",
    "title": "Extending Data Joins + Factors",
    "section": "Know Your Unique Observations!",
    "text": "Know Your Unique Observations!\n\n\n\n\n\n\nDiscussion\n\n\nWhat is the observational unit after joining the directors and movies_directors by the director_id key? What happens for directors that have multiple movies in the movies_directors data?\n\n\n\n\n\ndirectors |&gt; \n  inner_join(movies_directors, \n             join_by(id == director_id))\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\nmovie_id\n\n\n\n\n429\nAndrew\nAdamson\n300229\n\n\n2931\nDarren\nAronofsky\n254943\n\n\n9247\nZach\nBraff\n124110\n\n\n11652\nJames (I)\nCameron\n10920\n\n\n11652\nJames (I)\nCameron\n333856\n\n\n14927\nRon\nClements\n192017\n\n\n15092\nEthan\nCoen\n109093\n\n\n15092\nEthan\nCoen\n237431\n\n\n15093\nJoel\nCoen\n109093\n\n\n15093\nJoel\nCoen\n237431\n\n\n15901\nFrancis Ford\nCoppola\n130128\n\n\n15906\nSofia\nCoppola\n194874\n\n\n16816\nCameron\nCrowe\n350424\n\n\n17810\nFrank\nDarabont\n297838\n\n\n22104\nClint\nEastwood\n224842\n\n\n24758\nDavid\nFincher\n112290\n\n\n28395\nMel (I)\nGibson\n46169\n\n\n35573\nRon\nHoward\n18979\n\n\n35838\nJohn (I)\nHughes\n257264\n\n\n37872\nVicky\nJenson\n300229\n\n\n38746\nMike (I)\nJudge\n238695\n\n\n41975\nDavid\nKoepp\n314965\n\n\n44291\nJohn (I)\nLandis\n17173\n\n\n46315\nJay\nLevey\n344203\n\n\n48115\nGeorge\nLucas\n313459\n\n\n56332\nJohn\nMusker\n192017\n\n\n58201\nChristopher\nNolan\n30959\n\n\n58201\nChristopher\nNolan\n210511\n\n\n65940\nRob\nReiner\n111813\n\n\n66849\nGuy\nRitchie\n306032\n\n\n68161\nHerbert (I)\nRoss\n116907\n\n\n74758\nSteven\nSoderbergh\n238072\n\n\n76524\nOliver (I)\nStone\n167324\n\n\n78273\nQuentin\nTarantino\n176711\n\n\n78273\nQuentin\nTarantino\n176712\n\n\n78273\nQuentin\nTarantino\n267038\n\n\n78273\nQuentin\nTarantino\n276217\n\n\n82525\nPaul (I)\nVerhoeven\n147603\n\n\n83616\nAndy\nWachowski\n207992\n\n\n83617\nLarry\nWachowski\n207992\n\n\n88802\nUnknown\nDirector\n256630"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#know-your-unique-observations-1",
    "href": "slides/week-4/w4-factors.html#know-your-unique-observations-1",
    "title": "Extending Data Joins + Factors",
    "section": "Know Your Unique Observations!",
    "text": "Know Your Unique Observations!\nRemember the rodent data from Lab 2. Say we had separate datsets for measurements and species information:\n\nSpeciesMeasurements\n\n\n\nspecies\n\n\n\n\n\n\n\ngenus\nspecies\ntaxa\nspecies_id\n\n\n\n\nDipodomys\nmerriami\nRodent\nDM\n\n\nDipodomys\nordii\nRodent\nDO\n\n\nPerognathus\nflavus\nRodent\nPF\n\n\nChaetodipus\npenicillatus\nRodent\nPP\n\n\nPeromyscus\neremicus\nRodent\nPE\n\n\nOnychomys\nleucogaster\nRodent\nOL\n\n\nReithrodontomys\nmegalotis\nRodent\nRM\n\n\nDipodomys\nspectabilis\nRodent\nDS\n\n\nOnychomys\ntorridus\nRodent\nOT\n\n\nNeotoma\nalbigula\nRodent\nNL\n\n\nPeromyscus\nmaniculatus\nRodent\nPM\n\n\nSigmodon\nhispidus\nRodent\nSH\n\n\nReithrodontomys\nfulvescens\nRodent\nRF\n\n\nChaetodipus\nbaileyi\nRodent\nPB\n\n\n\n\n\n\n\n\n\n\nmeasurements\n\n\n\n\n\n\n\ngenus_name\nspecies\nsex\nhindfoot_length\nweight\n\n\n\n\nDipodomys\nmerriami\nM\n35\n40\n\n\nDipodomys\nmerriami\nM\n37\n48\n\n\nDipodomys\nmerriami\nF\n34\n29\n\n\nDipodomys\nmerriami\nF\n35\n46\n\n\nDipodomys\nmerriami\nM\n35\n36\n\n\nDipodomys\nordii\nF\n32\n52\n\n\nPerognathus\nflavus\nM\n15\n8\n\n\nDipodomys\nmerriami\nF\n36\n35\n\n\nPerognathus\nflavus\nM\n12\n7\n\n\nDipodomys\nmerriami\nF\n32\n22\n\n\nPerognathus\nflavus\nM\n16\n9\n\n\nDipodomys\nmerriami\nF\n34\n42\n\n\nPerognathus\nflavus\nF\n14\n8\n\n\nDipodomys\nmerriami\nF\n35\n41\n\n\nDipodomys\nmerriami\nF\n37\n37\n\n\nDipodomys\nmerriami\nF\n35\n43\n\n\nDipodomys\nmerriami\nF\n35\n41\n\n\nDipodomys\nmerriami\nF\n33\n40\n\n\nPerognathus\nflavus\nF\n11\n9\n\n\nDipodomys\nmerriami\nF\n35\n45\n\n\nChaetodipus\npenicillatus\nF\n20\n15\n\n\nDipodomys\nmerriami\nM\n35\n29\n\n\nDipodomys\nmerriami\nM\n35\n39\n\n\nDipodomys\nmerriami\nF\n36\n43\n\n\nDipodomys\nmerriami\nM\n38\n46\n\n\nDipodomys\nmerriami\nM\n36\n41\n\n\nDipodomys\nmerriami\nM\n36\n41\n\n\nDipodomys\nmerriami\nM\n38\n40\n\n\nDipodomys\nmerriami\nM\n37\n45\n\n\nDipodomys\nmerriami\nF\n35\n46\n\n\nDipodomys\nmerriami\nF\n35\n40\n\n\nDipodomys\nmerriami\nF\n35\n30\n\n\nDipodomys\nmerriami\nM\n35\n39\n\n\nDipodomys\nmerriami\nM\n35\n34\n\n\nDipodomys\nmerriami\nF\n37\n42\n\n\nDipodomys\nmerriami\nM\n37\n42\n\n\nPerognathus\nflavus\nF\n13\n8\n\n\nDipodomys\nmerriami\nF\n37\n31\n\n\nDipodomys\nmerriami\nF\n36\n40\n\n\nDipodomys\nmerriami\nM\n36\n37\n\n\nDipodomys\nmerriami\nM\n36\n48\n\n\nDipodomys\nmerriami\nM\n37\n42\n\n\nDipodomys\nmerriami\nF\n39\n45\n\n\nChaetodipus\npenicillatus\nF\n21\n16\n\n\nDipodomys\nmerriami\nF\n36\n36\n\n\nDipodomys\nmerriami\nM\n36\n42\n\n\nDipodomys\nmerriami\nM\n36\n44\n\n\nDipodomys\nmerriami\nF\n36\n41\n\n\nDipodomys\nmerriami\nF\n36\n40\n\n\nDipodomys\nmerriami\nM\n37\n34\n\n\nDipodomys\nmerriami\nM\n33\n40\n\n\nDipodomys\nmerriami\nM\n33\n44\n\n\nDipodomys\nmerriami\nM\n37\n44\n\n\nDipodomys\nmerriami\nM\n34\n36\n\n\nDipodomys\nmerriami\nM\n35\n33\n\n\nDipodomys\nmerriami\nF\n37\n46\n\n\nDipodomys\nmerriami\nF\n34\n35\n\n\nDipodomys\nmerriami\nM\n36\n46\n\n\nDipodomys\nmerriami\nF\n33\n37\n\n\nDipodomys\nmerriami\nM\n36\n34\n\n\nDipodomys\nmerriami\nF\n36\n45\n\n\nPerognathus\nflavus\nF\n15\n7\n\n\nDipodomys\nmerriami\nM\n37\n51\n\n\nDipodomys\nmerriami\nM\n35\n39\n\n\nDipodomys\nmerriami\nM\n36\n29\n\n\nDipodomys\nmerriami\nF\n32\n48\n\n\nDipodomys\nmerriami\nM\n38\n46\n\n\nDipodomys\nmerriami\nF\n37\n41\n\n\nDipodomys\nmerriami\nM\n37\n45\n\n\nDipodomys\nmerriami\nF\n35\n42\n\n\nDipodomys\nmerriami\nF\n36\n53\n\n\nDipodomys\nmerriami\nF\n35\n49\n\n\nDipodomys\nmerriami\nF\n36\n46\n\n\nPerognathus\nflavus\nF\n13\n9\n\n\nChaetodipus\npenicillatus\nF\n19\n15\n\n\nPerognathus\nflavus\nM\n13\n4\n\n\nDipodomys\nmerriami\nM\n36\n48\n\n\nDipodomys\nmerriami\nM\n37\n51\n\n\nDipodomys\nmerriami\nM\n38\n50\n\n\nDipodomys\nmerriami\nM\n35\n44\n\n\nDipodomys\nmerriami\nM\n25\n44\n\n\nDipodomys\nmerriami\nM\n35\n45\n\n\nDipodomys\nmerriami\nF\n37\n45\n\n\nPeromyscus\neremicus\nM\n20\n19\n\n\nDipodomys\nmerriami\nF\n38\n44\n\n\nDipodomys\nmerriami\nF\n36\n42\n\n\nDipodomys\nmerriami\nM\n37\n39\n\n\nDipodomys\nmerriami\nM\n37\n47\n\n\nDipodomys\nmerriami\nM\n36\n42\n\n\nDipodomys\nmerriami\nM\n36\n49\n\n\nDipodomys\nmerriami\nM\n38\n39\n\n\nDipodomys\nmerriami\nF\n36\n43\n\n\nDipodomys\nmerriami\nM\n35\n50\n\n\nDipodomys\nmerriami\nM\n36\n41\n\n\nDipodomys\nmerriami\nM\n37\n47\n\n\nDipodomys\nmerriami\nF\n36\n37\n\n\nDipodomys\nmerriami\nM\n36\n41\n\n\nDipodomys\nmerriami\nF\n36\n36\n\n\nDipodomys\nmerriami\nM\n36\n45\n\n\nPeromyscus\neremicus\nM\n19\n20"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#know-your-unique-observations-2",
    "href": "slides/week-4/w4-factors.html#know-your-unique-observations-2",
    "title": "Extending Data Joins + Factors",
    "section": "Know Your Unique Observations!",
    "text": "Know Your Unique Observations!\n\n\n\n\n\n\nDiscussion\n\n\nWhat happens if we join species and measurements by the genus only?\n\n\n\n\nmeasurements |&gt; \n  inner_join(species, \n             by = join_by(genus_name == genus))\n\n\n\n\n\n\n\ngenus_name\nspecies.x\nsex\nhindfoot_length\nweight\nspecies.y\ntaxa\nspecies_id\n\n\n\n\nDipodomys\nmerriami\nM\n35\n40\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n40\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n40\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n37\n48\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n37\n48\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n37\n48\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n34\n29\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n34\n29\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n34\n29\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n46\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n46\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n46\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n35\n36\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n36\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n36\nspectabilis\nRodent\nDS\n\n\nDipodomys\nordii\nF\n32\n52\nmerriami\nRodent\nDM\n\n\nDipodomys\nordii\nF\n32\n52\nordii\nRodent\nDO\n\n\nDipodomys\nordii\nF\n32\n52\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nM\n15\n8\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n36\n35\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n36\n35\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n36\n35\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nM\n12\n7\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n32\n22\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n32\n22\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n32\n22\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nM\n16\n9\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n34\n42\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n34\n42\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n34\n42\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nF\n14\n8\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n35\n41\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n41\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n41\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n37\n37\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n37\n37\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n37\n37\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n43\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n43\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n43\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n41\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n41\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n41\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n33\n40\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n33\n40\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n33\n40\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nF\n11\n9\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n35\n45\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n45\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n45\nspectabilis\nRodent\nDS\n\n\nChaetodipus\npenicillatus\nF\n20\n15\npenicillatus\nRodent\nPP\n\n\nChaetodipus\npenicillatus\nF\n20\n15\nbaileyi\nRodent\nPB\n\n\nDipodomys\nmerriami\nM\n35\n29\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n29\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n29\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n35\n39\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n39\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n39\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n36\n43\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n36\n43\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n36\n43\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n38\n46\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n38\n46\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n38\n46\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n36\n41\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n36\n41\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n36\n41\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n36\n41\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n36\n41\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n36\n41\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n38\n40\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n38\n40\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n38\n40\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n37\n45\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n37\n45\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n37\n45\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n46\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n46\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n46\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n40\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n40\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n40\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n30\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n30\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n30\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n35\n39\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n39\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n39\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n35\n34\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n34\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n34\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n37\n42\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n37\n42\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n37\n42\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n37\n42\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n37\n42\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n37\n42\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nF\n13\n8\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n37\n31\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n37\n31\nordii\nRodent\nDO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDANGER : MANY-TO-MANY JOIN!\n\n\nOur observations exploded and the species_id isn’t even right for some observations! We also now have a species.x and species.y variable since the variable was present in both the left and right data."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#joining-on-multiple-variables",
    "href": "slides/week-4/w4-factors.html#joining-on-multiple-variables",
    "title": "Extending Data Joins + Factors",
    "section": "Joining on Multiple Variables",
    "text": "Joining on Multiple Variables\nTo fix this, we need to join on multiple variables (a compound key):\n\nspecies |&gt; \n  full_join(measurements,\n            join_by(species == species, \n                    genus == genus_name))\n\n\n\n\n\n\n\ngenus\nspecies\ntaxa\nspecies_id\nsex\nhindfoot_length\nweight\n\n\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n34\n29\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n35\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n32\n22\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n34\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n37\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n43\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n33\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n29\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n43\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n30\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n34\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n31\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n37\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n39\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n34\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n33\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n33\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n34\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n33\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n34\n35\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n33\n37\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n34\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n51\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n29\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n32\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n53\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n49\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n51\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n50\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n25\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n38\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n47\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n49\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n43\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n50\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n47\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n37\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n49\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n55\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n38\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n34\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n53\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n47\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n42"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#what-is-a-factor-variable",
    "href": "slides/week-4/w4-factors.html#what-is-a-factor-variable",
    "title": "Extending Data Joins + Factors",
    "section": "What is a factor variable?",
    "text": "What is a factor variable?\nFactors are used for\n\ncategorical variables with a fixed and known set of possible values.\n\n\nE.g., day_born = Sunday, Monday, Tuesday, …, Saturday\n\n\ndisplaying character vectors in non-alphabetical order.\n\n\nuseful for nice tables and plots!"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#eras-tour",
    "href": "slides/week-4/w4-factors.html#eras-tour",
    "title": "Extending Data Joins + Factors",
    "section": "Eras Tour",
    "text": "Eras Tour\nLet’s consider songs that Taylor Swift played on her Eras Tour.\nI have randomly selected 25 songs (and their albums) to demonstrate.\n\neras_data |&gt; \n  slice_head(n = 10)\n\n\n\n\n\n\n\nSong\nAlbum\n\n\n\n\n22\nRed\n\n\n...Ready for It?\nReputation\n\n\nThe Archer\nLover\n\n\nBejeweled\nMidnights\n\n\nStyle\n1989\n\n\nYou Belong With Me\nFearless\n\n\nDon't Blame Me\nReputation\n\n\nillicit affairs\nFolklore\n\n\nLavender Haze\nMidnights\n\n\nmarjorie\nEvermore"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-base-r",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-base-r",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – Base R",
    "text": "Creating a Factor – Base R\nA character vector:\n\neras_data |&gt; \n  pull(Album)\n\n [1] \"Red\"        \"Reputation\" \"Lover\"      \"Midnights\"  \"1989\"      \n [6] \"Fearless\"   \"Reputation\" \"Folklore\"   \"Midnights\"  \"Evermore\"  \n[11] \"Evermore\"   \"Lover\"      \"Lover\"      \"Red\"        \"Reputation\"\n[16] \"Reputation\" \"Speak Now\"  \"Red\"        \"Midnights\"  \"Fearless\"  \n[21] \"1989\"       \"Midnights\"  \"Fearless\"   \"Folklore\"   \"Lover\"     \n\n\n\nA factor vector:\n\neras_data |&gt; \n  pull(Album) |&gt; \n  factor()\n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: 1989 Evermore Fearless Folklore Lover Midnights Red ... Speak Now"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-base-r-1",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-base-r-1",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – Base R",
    "text": "Creating a Factor – Base R\nWhen you create a factor variable from a vector…\n\nEvery unique element in the vector becomes a level.\nThe levels are ordered alphabetically.\nThe elements are no longer displayed in quotes."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-base-r-2",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-base-r-2",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – Base R",
    "text": "Creating a Factor – Base R\nYou can specify the order of the levels with the level argument.\n\neras_data |&gt; \n  pull(Album) |&gt; \n  factor(levels = c(\"Fearless\",\"Speak Now\",\"Red\",\"1989\",\n                    \"Reputation\",\"Lover\",\"Folklore\",\n                    \"Evermore\",\"Midnights\"))\n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Fearless Speak Now Red 1989 Reputation Lover Folklore ... Midnights"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#forcats",
    "href": "slides/week-4/w4-factors.html#forcats",
    "title": "Extending Data Joins + Factors",
    "section": "forcats",
    "text": "forcats\n\n\nWe use this package to…\n\nturn character variables into factors.\nmake factors by discretizing numeric variables.\nrename or reorder the levels of an existing factor.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe packages forcats (“for categoricals”) helps wrangle categorical variables.\n\nforcats loads with tidyverse!"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-fct",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-fct",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – fct",
    "text": "Creating a Factor – fct\nWith fct(), the levels are automatically ordered in the order of first appearance.\n\neras_data |&gt; \n  mutate(Album = fct(Album)) |&gt; \n  pull(Album)\n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Red Reputation Lover Midnights 1989 Fearless Folklore ... Speak Now"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-fct-1",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-fct-1",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – fct",
    "text": "Creating a Factor – fct\nYou can still specify the order of the levels with level.\n\neras_data |&gt; \n  mutate(Album = fct(Album,\n                     levels = c(\"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\", \"Reputation\",\"Lover\",\n                                \"Folklore\", \"Evermore\",\"Midnights\"))) |&gt; \n  pull(Album) \n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Fearless Speak Now Red 1989 Reputation Lover Folklore ... Midnights"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-fct-2",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-fct-2",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – fct",
    "text": "Creating a Factor – fct\nYou can also specify non-present levels.\n\neras_data |&gt; \n  mutate(Album = fct(Album, \n                     levels = c(\"Taylor Swift\",\n                                \"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\", \"Reputation\",\"Lover\",\n                                \"Folklore\", \"Evermore\",\"Midnights\",\n                                \"The Tortured Poets Department\"))) |&gt; \n  pull(Album) \n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n11 Levels: Taylor Swift Fearless Speak Now Red 1989 Reputation ... The Tortured Poets Department"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-coding-a-factor-fct_recode",
    "href": "slides/week-4/w4-factors.html#re-coding-a-factor-fct_recode",
    "title": "Extending Data Joins + Factors",
    "section": "Re-coding a Factor – fct_recode",
    "text": "Re-coding a Factor – fct_recode\nOops, we have a typo in some of our levels! We change existing levels with the syntax &lt;new level&gt; = &lt;old level&gt;.\n\n\neras_data |&gt;\n  mutate(Album = fct_recode(.f = Album,\n                            \"folklore\" = \"Folklore\",\n                            \"evermore\" = \"Evermore\",\n                            \"reputation\" = \"Reputation\")) |&gt;\n  pull(Album) \n\n [1] Red        reputation Lover      Midnights  1989       Fearless  \n [7] reputation folklore   Midnights  evermore   evermore   Lover     \n[13] Lover      Red        reputation reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   folklore  \n[25] Lover     \n11 Levels: Taylor Swift Fearless Speak Now Red 1989 reputation ... The Tortured Poets Department\n\n\n\n\nNon-specified levels are not re-coded."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-coding-a-factor-case_when",
    "href": "slides/week-4/w4-factors.html#re-coding-a-factor-case_when",
    "title": "Extending Data Joins + Factors",
    "section": "Re-coding a Factor – case_when",
    "text": "Re-coding a Factor – case_when\nWe have similar functionality with the case_when() function…\n\n\neras_data |&gt;\n  mutate(Album = case_when(Album == \"Folklore\" ~ \"folklore\",\n                           Album == \"Evermore\" ~ \"evermore\",\n                           Album == \"Reputation\" ~ \"reputation\",\n                           .default = Album),\n         Album = fct(Album)) |&gt; \n  pull(Album)\n\n [1] Red        reputation Lover      Midnights  1989       Fearless  \n [7] reputation folklore   Midnights  evermore   evermore   Lover     \n[13] Lover      Red        reputation reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   folklore  \n[25] Lover     \n9 Levels: Red reputation Lover Midnights 1989 Fearless folklore ... Speak Now"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#collapsing-a-factor-fct_collapse",
    "href": "slides/week-4/w4-factors.html#collapsing-a-factor-fct_collapse",
    "title": "Extending Data Joins + Factors",
    "section": "Collapsing a Factor –fct_collapse",
    "text": "Collapsing a Factor –fct_collapse\nCollapse multiple existing levels of a factor with the syntax &lt;new level&gt; = c(&lt;old levels&gt;).\n\n\neras_data |&gt; \n  mutate(Genre = fct_collapse(.f= Album,\n                       \"country pop\" = c(\"Taylor Swift\", \"Fearless\"),\n                       \"pop rock\" = c(\"Speak Now\",\"Red\"),\n                       \"electropop\" = c(\"1989\",\"reputation\",\"Lover\"),\n                       \"folk pop\" = c(\"folklore\",\"evermore\"),\n                       \"alt-pop\" = \"Midnights\")) |&gt; \n  slice_sample(n = 6)\n\n\n\n\n\n\n\nSong\nAlbum\nGenre\n\n\n\n\nwillow\nevermore\nfolk pop\n\n\nYou Belong With Me\nFearless\ncountry pop\n\n\nLavender Haze\nMidnights\nalt-pop\n\n\nWe Are Never Ever Getting Back Together\nRed\npop rock\n\n\nillicit affairs\nfolklore\nfolk pop\n\n\nLook What You Made Me Do\nreputation\nelectropop"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-leveling-a-factor-fct_relevel",
    "href": "slides/week-4/w4-factors.html#re-leveling-a-factor-fct_relevel",
    "title": "Extending Data Joins + Factors",
    "section": "Re-leveling a Factor –fct_relevel",
    "text": "Re-leveling a Factor –fct_relevel\nChange the order of the levels of an existing factor.\n\nOriginalOrdered by Copies Sold\n\n\n\neras_data |&gt;\n  pull(Album) |&gt; \n  levels()\n\n [1] \"Taylor Swift\"                  \"Fearless\"                     \n [3] \"Speak Now\"                     \"Red\"                          \n [5] \"1989\"                          \"reputation\"                   \n [7] \"Lover\"                         \"folklore\"                     \n [9] \"evermore\"                      \"Midnights\"                    \n[11] \"The Tortured Poets Department\"\n\n\n\n\n\neras_data |&gt; \n  mutate(Album = fct_relevel(.f = Album, \n                             c(\"Fearless\",\"1989\",\"Taylor Swift\",\n                               \"Speak Now\",\"Red\",\"Midnights\",\"reputation\",\n                               \"folklore\",\"Lover\",\"evermore\"))) |&gt;\n  pull(Album) |&gt;\n  levels()\n\n [1] \"Fearless\"                      \"1989\"                         \n [3] \"Taylor Swift\"                  \"Speak Now\"                    \n [5] \"Red\"                           \"Midnights\"                    \n [7] \"reputation\"                    \"folklore\"                     \n [9] \"Lover\"                         \"evermore\"                     \n[11] \"The Tortured Poets Department\"\n\n\nUnspecified levels remain in the same order at the end."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2",
    "href": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2",
    "title": "Extending Data Joins + Factors",
    "section": "Re-ordering Factors in ggplot2",
    "text": "Re-ordering Factors in ggplot2\n\nOriginalPlotSpecify LevelsPlot\n\n\nThe bars follow the default factor levels.\n\nfull_eras |&gt; \n  mutate(Album = fct(Album)) |&gt; \n  ggplot() +\n  geom_bar(aes(y = Album), fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can order factor levels to order the bar plot.\n\nfull_eras |&gt; \n  mutate(Album = fct(Album,\n                     levels = c(\"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\",\"Reputation\",\"Lover\",\n                                \"Folklore\",\"Evermore\",\n                                \"Midnights\"))) |&gt; \n  ggplot() +\n  geom_bar(aes(y = Album), fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-1",
    "href": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-1",
    "title": "Extending Data Joins + Factors",
    "section": "Re-ordering Factors in ggplot2",
    "text": "Re-ordering Factors in ggplot2\n\nOriginalPlotReorder by ValuePlot\n\n\nThe bars follow the default factor levels.\n\nfull_eras |&gt; \n  mutate(Album = fct(Album)) |&gt; \n  ggplot() +\n  geom_bar(aes(y = Album), fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can order factor levels to order the bar plot by the count using fct_infreq()\n\nfull_eras |&gt; \n  ggplot() +\n  geom_bar(aes(y = fct_infreq(Album)), \n           fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-2",
    "href": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-2",
    "title": "Extending Data Joins + Factors",
    "section": "Re-ordering Factors in ggplot2",
    "text": "Re-ordering Factors in ggplot2\n\nOriginalPlotfct_reorder()Plot\n\n\nThe ridge plots follow the order of the factor levels.\n\nfull_eras |&gt; \n  ggplot(aes(x = Length, \n             y = Album, \n             fill = Album)) +\n  geom_density_ridges() +\n  theme_minimal() +\n  theme(legend.position = \"none\")+\n  labs(x = \"Song Length (mins)\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInside ggplot(), we can order factor levels by a summary value.\n\nfull_eras |&gt; \n  ggplot(aes(x = Length, \n             y = fct_reorder(.f = Album,\n                             .x = Length,\n                             .fun = mean), \n             fill = Album)) +\n  geom_density_ridges() +\n  theme_minimal() +\n  theme(legend.position = \"none\")+\n  labs(x = \"Song Length (mins)\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-3",
    "href": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-3",
    "title": "Extending Data Joins + Factors",
    "section": "Re-ordering Factors in ggplot2",
    "text": "Re-ordering Factors in ggplot2\n\nOriginalPlotfct_reorder2()Plot\n\n\nRemember the miliary data from the practice activity?\nThe legend follows the order of the factor levels.\n\nmilitary_long |&gt; \n  filter(Country %in% central.asia,\n         !is.na(spending)) |&gt; \n  ggplot(aes(x = year,\n             y = spending,\n             color = Country)) +\n  geom_line() +\n  labs(x = \"Year\",\n       y = \"\",\n       subtitle = \"Spending (as % of Government Spending)\",\n       title = \"Military Expenditures in Central Asia\") +\n  scale_color_manual(values = brewer.pal(3, \"Dark2\")) +\n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = seq(1990, 2023, 5)) +\n  theme_bw() +\n  theme(panel.grid.minor.x = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInside ggplot(), we can order factor levels by the \\(y\\) values associated with the largest \\(x\\) values.\n\nmilitary_long |&gt; \n  filter(Country %in% central.asia,\n         !is.na(spending)) |&gt; \n  ggplot(aes(x = year,\n             y = spending,\n             color = fct_reorder2(.x = year,\n                                  .y = spending,\n                                  .f = Country))) +\n  geom_line() +\n  labs(x = \"Year\",\n       y = \"\",\n       color = \"Country\",\n       subtitle = \"Spending (as % of Government Spending)\",\n       title = \"Military Expenditures in Central Asia\") +\n  scale_color_manual(values = brewer.pal(3, \"Dark2\")) +\n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = seq(1990, 2023, 5)) +\n  theme_bw() +\n  theme(panel.grid.minor.x = element_blank())"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#why-mess-with-factors",
    "href": "slides/week-4/w4-factors.html#why-mess-with-factors",
    "title": "Extending Data Joins + Factors",
    "section": "Why Mess with Factors?",
    "text": "Why Mess with Factors?\n\n\n\n\n\n\nDiscussion\n\n\nWhat are some of the benefits to re-ordering or re-leveling factors variables?"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#variable-names-in-r",
    "href": "slides/week-4/w4-factors.html#variable-names-in-r",
    "title": "Extending Data Joins + Factors",
    "section": "Variable Names in R",
    "text": "Variable Names in R\nData from external sources likely has variable names not ideally formatted for R.\nNames may…\n\ncontain spaces.\nstart with numbers.\nstart with a mix of capital and lower case letters.\n\n\n\nnames(military)[1:12]\n\n [1] \"Country\"        \"Notes\"          \"Reporting year\" \"1988.0\"        \n [5] \"1989.0\"         \"1990.0\"         \"1991.0\"         \"1992.0\"        \n [9] \"1993.0\"         \"1994.0\"         \"1995.0\"         \"1996.0\""
  },
  {
    "objectID": "slides/week-4/w4-factors.html#messy-variable-names-are-a-pain",
    "href": "slides/week-4/w4-factors.html#messy-variable-names-are-a-pain",
    "title": "Extending Data Joins + Factors",
    "section": "Messy Variable Names are a Pain",
    "text": "Messy Variable Names are a Pain\n\nYou should have noticed this in Practice Activity 4 working with the SIPRI data\nYou have to use back tick marks around variables that start with numbers or have spaces:\n\n\nmilitary |&gt; \n  select(`Reporting year`,\n          `1988.0`)\n\n\nI personally find capitilization in variable names is very annoying and slows me down"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#janitor-to-the-rescue",
    "href": "slides/week-4/w4-factors.html#janitor-to-the-rescue",
    "title": "Extending Data Joins + Factors",
    "section": "janitor to the rescue!",
    "text": "janitor to the rescue!\n\nMr. Johnson from Abbot Elementary (https://giphy.com/abcnetwork)"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#clean-variable-names-with-janitor",
    "href": "slides/week-4/w4-factors.html#clean-variable-names-with-janitor",
    "title": "Extending Data Joins + Factors",
    "section": "Clean Variable Names with janitor",
    "text": "Clean Variable Names with janitor\nThe janitor package converts all variable names in a dataset to snake_case.\n\nNames will…\n\nstart with a lower case letter.\nhave spaces and special characters filled in with _.\n\n\nlibrary(janitor)\nmilitary_clean_names &lt;- military |&gt; \n  clean_names()\n\nnames(military_clean_names)[1:12]\n\n [1] \"country\"        \"notes\"          \"reporting_year\" \"x1988_0\"       \n [5] \"x1989_0\"        \"x1990_0\"        \"x1991_0\"        \"x1992_0\"       \n [9] \"x1993_0\"        \"x1994_0\"        \"x1995_0\"        \"x1996_0\""
  },
  {
    "objectID": "slides/week-4/w4-factors.html#r-is-always-evolving",
    "href": "slides/week-4/w4-factors.html#r-is-always-evolving",
    "title": "Extending Data Joins + Factors",
    "section": "R Is Always Evolving",
    "text": "R Is Always Evolving\n\nRemember: R is open source so folks are always adding and updating packages and functions\n\n\n\n\n\n\n\nDiscussion\n\n\nWhat benefits and drawbacks of R’s ever-evolving nature have you noticed?\n\n\n\n\n\nthe good 🥳the annoying\n\n\n\nalways (aiming) to get better!\nresponsive to user input\nnew functionality for new statistical methods\n\n\n\n\ncode may no longer run after an update 😭\nneed to learn new syntax\nhave to keep track of it all 🫠"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#lifceycle-stages",
    "href": "slides/week-4/w4-factors.html#lifceycle-stages",
    "title": "Extending Data Joins + Factors",
    "section": "Lifceycle Stages",
    "text": "Lifceycle Stages\nAs packages get updated, the functions and function arguments included in those packages will change.\n\nThe accepted syntax for a function may change.\nA function/functionality may disappear.\n\n\nLearn more about lifecycle stages of packages, functions, function arguments in R."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#lifceycle-stages-1",
    "href": "slides/week-4/w4-factors.html#lifceycle-stages-1",
    "title": "Extending Data Joins + Factors",
    "section": "Lifceycle Stages",
    "text": "Lifceycle Stages"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#deprecated-functions",
    "href": "slides/week-4/w4-factors.html#deprecated-functions",
    "title": "Extending Data Joins + Factors",
    "section": "Deprecated Functions",
    "text": "Deprecated Functions\nA deprecated functionality has a better alternative available and is scheduled for removal.\n\nYou get a warning telling you what to use instead.\n\n\n\nmilitary_clean |&gt; \n  filter(across(!Country, is.na)) |&gt; \n  slice_head(n = 3) |&gt; \n  select(1:8)\n\nWarning: Using `across()` in `filter()` was deprecated in dplyr 1.0.8.\nℹ Please use `if_any()` or `if_all()` instead.\n\n\n# A tibble: 3 × 8\n  Country         `1988.0` `1989.0` `1990.0` `1991.0` `1992.0` `1993.0` `1994.0`\n  &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 Africa          &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n2 North Africa    &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n3 sub-Saharan Af… &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#deprecated-functions-1",
    "href": "slides/week-4/w4-factors.html#deprecated-functions-1",
    "title": "Extending Data Joins + Factors",
    "section": "Deprecated Functions",
    "text": "Deprecated Functions\nYou should not use deprecated functions!\nInstead, we use…\n\nmilitary_clean |&gt;\n  filter(if_all(!Country, ~ is.na(.x))) |&gt; \n  slice_head(n = 3) |&gt; \n  select(1:8)\n\n# A tibble: 3 × 8\n  Country         `1988.0` `1989.0` `1990.0` `1991.0` `1992.0` `1993.0` `1994.0`\n  &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 Africa          &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n2 North Africa    &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n3 sub-Saharan Af… &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#superceded-functions",
    "href": "slides/week-4/w4-factors.html#superceded-functions",
    "title": "Extending Data Joins + Factors",
    "section": "Superceded Functions",
    "text": "Superceded Functions\nA superseded functionality has a better alternative, but is not going away.\n\nThis is a softer alternative to deprecation.\nA superseded function will not give a warning (since there’s no risk if you keep using it), but the documentation will give you a recommendation."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#lab-4-childcare-costs-in-california",
    "href": "slides/week-4/w4-factors.html#lab-4-childcare-costs-in-california",
    "title": "Extending Data Joins + Factors",
    "section": "Lab 4: Childcare Costs in California",
    "text": "Lab 4: Childcare Costs in California"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#to-do",
    "href": "slides/week-4/w4-factors.html#to-do",
    "title": "Extending Data Joins + Factors",
    "section": "To do…",
    "text": "To do…\n\nLab 4: Childcare Costs in California\n\nDue Monday 4/28 at 11:59pm\n\nRead Chapter 5: Strings + Dates\n\nCheck-in 5.1 - 5.2 due Tuesday (4/29) before class"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#combine-the-data",
    "href": "labs/lab5/lab5-murder.html#combine-the-data",
    "title": "Lab 5: Murder in SQL City",
    "section": "Combine the Data",
    "text": "Combine the Data\nLet’s set ourselves up to solve this crime lickity-split!\nCreate two new datasets:\n\nget_fit_now_full\n\nevery row represents one visit to the “Get Fit” gym.\nall member information is included (e.g. check in times, names, and membership information)\nshould have 2,703 rows and 8 columns\n\nsuspects_all\n\neach row represents one person\nincludes their address, driver’s licence information, income, and interview with the police, if they have one\nshould have 10,011 rows and 16 columns\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t worry about missing values! We are just gathering all of the information that we have about everyone.\n\n\n\n# code to create get_fit_now_full\n\n\n# code to create suspects_all"
  },
  {
    "objectID": "labs/lab4/data/prepare-data.html",
    "href": "labs/lab4/data/prepare-data.html",
    "title": "Prepare County Data Lab 4",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(janitor)"
  },
  {
    "objectID": "labs/lab4/data/prepare-data.html#county-revenue-data",
    "href": "labs/lab4/data/prepare-data.html#county-revenue-data",
    "title": "Prepare County Data Lab 4",
    "section": "County Revenue Data",
    "text": "County Revenue Data\nData collected from the California State Controller. San Franscisco County is excluded.\n\n2003 - 2016 data\n\ndat_03_16 &lt;- read_excel(\"CountiesRawData_20180613.xlsx\",\n                        sheet = \"CO_REV_PROP_OTHR_TAXES\") |&gt; \n  clean_names() |&gt; \n  select(entity_name, year = fiscal_year,\n         total_property_taxes, sales_and_use_taxes)\n\n\n\n2017 data\n\ndat_17 &lt;- read_excel(\"CountiesRawData_20181228.xlsx\",\n                        sheet = \"CO_REV_PROP_OTHR_TAX\",\n                     na = c(\"\", \"NULL\")) |&gt; \n  clean_names() |&gt; \n  select(entity_name, year = fiscal_year,\n         sales_and_use_taxes = sales_and_use_taxes_total_governmental_funds_taxes_other,\n         total_property_taxes = total_property_taxes_total_governmental_funds_property_taxes) \n\n\n\n2018 data\n\ndat_18 &lt;- read_excel(\"CountiesRawData_FY2018-2020_20210926_V4.xlsx\",\n                        sheet = \"CO_REV_PROP_OTHR_TAXES\") |&gt; \n  clean_names() |&gt; \n  select(entity_name, year = fiscal_year,\n         sales_and_use_taxes = sales_and_use_taxes_total_governmental_funds_taxes_other,\n         total_property_taxes = total_property_taxes_total_governmental_funds)\n\n\n\nAppend and clean\n\ntax_dat &lt;- dat_03_16 |&gt; \n  rows_append(dat_17) |&gt; \n  rows_append(dat_18) |&gt; \n  arrange(entity_name, year) |&gt; \n  filter(year %in% 2005:2018) |&gt; \n  mutate(entity_name = str_c(entity_name, \" County\"))"
  },
  {
    "objectID": "labs/lab4/data/prepare-data.html#check-that-county-names-align-with-other-lab-data",
    "href": "labs/lab4/data/prepare-data.html#check-that-county-names-align-with-other-lab-data",
    "title": "Prepare County Data Lab 4",
    "section": "Check that county names align with other lab data",
    "text": "Check that county names align with other lab data\n\ncounties &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/counties.csv')\n\n\ntax_counties &lt;- tax_dat |&gt; \n  group_by(entity_name) |&gt; \n  summarize(mean_tax = mean(total_property_taxes))\n\n\nca_counties &lt;- counties |&gt; \n  filter(state_abbreviation == \"CA\") |&gt; \n  left_join(tax_counties, by = join_by(county_name == entity_name))"
  },
  {
    "objectID": "labs/lab4/data/prepare-data.html#save-data",
    "href": "labs/lab4/data/prepare-data.html#save-data",
    "title": "Prepare County Data Lab 4",
    "section": "Save data",
    "text": "Save data\n\nwrite_csv(tax_dat, \n          file = \"ca_tax_revenue.csv\")"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#data-biography",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#data-biography",
    "title": "Data Cleaning & Manipulation",
    "section": "Data Biography",
    "text": "Data Biography\nHeather Kraus suggests asking 5 questions of your data:\n\nWhere did it come from?\nWho collected it?\nWhen?\nHow was it collected?\nWhy was it collected?"
  },
  {
    "objectID": "labs/lab5/data/bCH_murder_setup.html",
    "href": "labs/lab5/data/bCH_murder_setup.html",
    "title": "Setup Up Murder Data for Lab 5",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n# clear global environment\n\nrm(list = ls())\n\n\ntable_names &lt;- c(\"crime_scene_report\",\"drivers_license\",\n                 \"facebook_event_checkin\",\n                 \"get_fit_now_check_in\",\"get_fit_now_member\",\n                 \"income\", \"interview\",\"person\")\n\n# For each name, read in the table and store it as the name.\npurrr::walk(table_names, function(x) {\n  assign(x, readr::read_csv(paste0(\"../bCH_murder_data/\", x, \".csv\")), envir = .GlobalEnv)\n})\n\nRows: 1228 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): type, description, city\ndbl (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 10007 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): eye_color, hair_color, gender, plate_number, car_make, car_model\ndbl (3): id, age, height\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 20011 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): event_name\ndbl (3): person_id, event_id, date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 2703 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): membership_id\ndbl (3): check_in_date, check_in_time, check_out_time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 184 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, name, membership_status\ndbl (2): person_id, membership_start_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 7514 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): ssn, annual_income\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 4991 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): transcript\ndbl (1): person_id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 10011 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): name, address_street_name\ndbl (4): id, license_id, address_number, ssn\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# remove vector from global environment\n\nrm(table_names)\n\nTo add some extra practice with regular expressions, I am going to edit the person data.\n\nperson &lt;- person |&gt; \n  mutate(address = str_c(address_number, \n                         address_street_name,\n                         sep = \" \"),\n         .before = address_number) |&gt; \n  select(-address_number,\n         -address_street_name)\n\n\n# save all data frames in global environment to an .Rdata file\n# when loaded, will open up all data frames\n\nsave.image(file = \"bCH_murder_data.Rdata\")"
  },
  {
    "objectID": "slides/week-4/w4-notes.html",
    "href": "slides/week-4/w4-notes.html",
    "title": "Week 4 Starter Notes",
    "section": "",
    "text": "Download .qmd\n\n\n\n\n\n\nWarning\n\n\n\nDownload the data that we will be using this week at the followings links and add them to a data/ directory\nIMDb data\nRainfall data\nEras Tour data\n\n\n\nData\n\n\n\n\n\n\n.Rdata Files\n\n\n\n\n\nOnce in R, data frames can be saves as .Rdata files using the syntax:\nsave(data_frame1, data_frame2, ..., file = \"path/file-name.Rdata\")\nand then loaded into R using the syntax:\nload(\"path/file-name.Rdata\")\nThis can be preferable when saving intermediate datasets in an analysis because .Rdata files are much smaller and more memory efficient than .csv files. Additionally, you can save and load multiple data frames at once!\nYou can see that this is useful here, where we have 7 related data frames saved in imdb_data.Rdata, which are then loaded in one line below.\n\n\n\nWe will use 7 datasets that describe movies from IMDb.\n\n\n\n\n\nRelationship between data sets in IMDb movie data.\n\n\n\n\n\nload(file = \"data/imdb_data.Rdata\")\n\nOn Thursday will also look at joining datasets created from the Lab 2 Rodent data. Note that you will need to change the file path to be appropriate for your directory strucure!\n\nrodent &lt;- read_csv(\"../../labs/lab2/surveys.csv\")\n\nspecies &lt;- rodent |&gt; \n  select(genus:taxa, species_id) |&gt; \n  distinct()\n\nmeasurements &lt;- rodent |&gt; \n  select(genus, species, sex:weight) |&gt; \n  rename(genus_name = genus)\n\n… and daily rainfall observed in SLO in January 2023. Data source\n\nslo_rainfall &lt;- read_excel(\"data/2023-rainfall-slo.xlsx\")\n\nslo_rainfall &lt;- slo_rainfall |&gt; \n  mutate(across(Sunday:Saturday, as.numeric))"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#data-joins",
    "href": "slides/week-4/w4-notes.html#data-joins",
    "title": "Week 4 Starter Notes",
    "section": "Data Joins",
    "text": "Data Joins\n\ninner_join(directors_genres, \n           movies_directors, \n           by = \"director_id\")\n\n# A tibble: 344 × 4\n   director_id genre      prob movie_id\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1         429 Adventure 0.75    300229\n 2         429 Music     0.25    300229\n 3         429 Fantasy   0.75    300229\n 4         429 Romance   0.5     300229\n 5         429 Family    0.75    300229\n 6         429 Comedy    0.75    300229\n 7         429 Short     0.25    300229\n 8         429 Animation 0.75    300229\n 9        2931 Action    0.429   254943\n10        2931 Horror    0.143   254943\n# ℹ 334 more rows\n\n\n\ninner_join(directors_genres, \n           directors, \n           by = join_by(director_id == id))\n\n# A tibble: 285 × 5\n   director_id genre      prob first_name last_name\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;    \n 1         429 Adventure 0.75  Andrew     Adamson  \n 2         429 Music     0.25  Andrew     Adamson  \n 3         429 Fantasy   0.75  Andrew     Adamson  \n 4         429 Romance   0.5   Andrew     Adamson  \n 5         429 Family    0.75  Andrew     Adamson  \n 6         429 Comedy    0.75  Andrew     Adamson  \n 7         429 Short     0.25  Andrew     Adamson  \n 8         429 Animation 0.75  Andrew     Adamson  \n 9        2931 Action    0.429 Darren     Aronofsky\n10        2931 Horror    0.143 Darren     Aronofsky\n# ℹ 275 more rows\n\n\n\ndirectors_genres |&gt; \n  inner_join(movies_directors, \n             by = \"director_id\")\n\n# A tibble: 344 × 4\n   director_id genre      prob movie_id\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1         429 Adventure 0.75    300229\n 2         429 Music     0.25    300229\n 3         429 Fantasy   0.75    300229\n 4         429 Romance   0.5     300229\n 5         429 Family    0.75    300229\n 6         429 Comedy    0.75    300229\n 7         429 Short     0.25    300229\n 8         429 Animation 0.75    300229\n 9        2931 Action    0.429   254943\n10        2931 Horror    0.143   254943\n# ℹ 334 more rows"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#which-join",
    "href": "slides/week-4/w4-notes.html#which-join",
    "title": "Week 4 Starter Notes",
    "section": "Which Join?",
    "text": "Which Join?\nHow many movies are there in the data for each director (by name), including if any directors don’t have any movies in the data?\n\ndirectors |&gt; \n  ??_join(movies_directors, \n          by = join_by(id == director_id))\n\nWhat is the complete set of movies and actors included in the data?\n\nroles |&gt; \n  ??_join(actors, \n          by = join_by(actor_id == id))"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#filtering-joins",
    "href": "slides/week-4/w4-notes.html#filtering-joins",
    "title": "Week 4 Starter Notes",
    "section": "Filtering Joins",
    "text": "Filtering Joins\n\ndirectors_genres |&gt; \n  semi_join(movies_directors)\n\n# A tibble: 285 × 3\n   director_id genre      prob\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1         429 Adventure 0.75 \n 2         429 Music     0.25 \n 3         429 Fantasy   0.75 \n 4         429 Romance   0.5  \n 5         429 Family    0.75 \n 6         429 Comedy    0.75 \n 7         429 Short     0.25 \n 8         429 Animation 0.75 \n 9        2931 Action    0.429\n10        2931 Horror    0.143\n# ℹ 275 more rows\n\n\n\ndirectors_genres |&gt;\n  filter(director_id %in% movies_directors$director_id)\n\n# A tibble: 285 × 3\n   director_id genre      prob\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1         429 Adventure 0.75 \n 2         429 Music     0.25 \n 3         429 Fantasy   0.75 \n 4         429 Romance   0.5  \n 5         429 Family    0.75 \n 6         429 Comedy    0.75 \n 7         429 Short     0.25 \n 8         429 Animation 0.75 \n 9        2931 Action    0.429\n10        2931 Horror    0.143\n# ℹ 275 more rows\n\n\n\ndirectors_genres |&gt; \n  anti_join(movies_directors)\n\n# A tibble: 0 × 3\n# ℹ 3 variables: director_id &lt;dbl&gt;, genre &lt;chr&gt;, prob &lt;dbl&gt;\n\n\n\ndirectors_genres |&gt;\n  filter(!director_id %in% movies_directors$director_id)\n\n# A tibble: 0 × 3\n# ℹ 3 variables: director_id &lt;dbl&gt;, genre &lt;chr&gt;, prob &lt;dbl&gt;"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#data-pivots",
    "href": "slides/week-4/w4-notes.html#data-pivots",
    "title": "Week 4 Starter Notes",
    "section": "Data Pivots",
    "text": "Data Pivots\nExample data includes the cereal dataset from the liver package (which we saw last week)…\n\ndata(cereal)\n\nHow would we plot the mean cereal nutrients by shelf (as shown below) with the wide data?\n\nmy_colors &lt;- c(\"calories_col\" = \"steelblue\", \"sugars_col\" = \"orange3\")\n\ncereal |&gt; \n  group_by(shelf) |&gt; \n  summarise(across(calories:vitamins, mean)) |&gt; \n  ggplot() +\n  geom_point(aes(x = shelf, y = calories, color = \"calories_col\")) +\n  geom_line(aes(x = shelf, y = calories, color = \"calories_col\")) + \n  geom_point(aes(x = shelf, y = sugars, color = \"sugars_col\")) +\n  geom_line(aes(x = shelf, y = sugars, color = \"sugars_col\")) +\n  scale_color_manual(values = my_colors, labels = names(my_colors)) +\n  labs(x = \"Shelf\", y = \"\", subtitle = \"Mean Amount\", color = \"Nutrient\")\n\n\n\n\n\n\n\n\n\ncereal_long &lt;- cereal |&gt; \n  pivot_longer(cols = calories:vitamins,\n               names_to = \"Nutrient\",\n               values_to = \"Amount\") |&gt; \n  group_by(shelf, Nutrient) |&gt; \n  summarise(mean_amount = mean(Amount))\n\n\ncereal_long |&gt; \n  ggplot(aes(x = shelf, \n             y = mean_amount, \n             color = Nutrient)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Shelf\", y = \"\", subtitle = \"Mean Amount\")\n\n\n\n\n\n\n\n\n\nslo_rainfall |&gt; \n  pivot_longer(cols      = Sunday:Saturday,\n               names_to  = \"Day_of_Week\",\n               values_to = \"Daily_Rainfall\")\n\n# A tibble: 35 × 3\n    Week Day_of_Week Daily_Rainfall\n   &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt;\n 1     1 Sunday                0   \n 2     1 Monday                0.12\n 3     1 Tuesday               0   \n 4     1 Wednesday             1.58\n 5     1 Thursday              0.91\n 6     1 Friday                0   \n 7     1 Saturday              0.05\n 8     2 Sunday                0.27\n 9     2 Monday                4.26\n10     2 Tuesday               0.43\n# ℹ 25 more rows\n\n\n\nmean_protein &lt;- cereal |&gt; \n  group_by(manuf, shelf) |&gt; \n  summarize(mean_protein = mean(protein))\n\n\nmean_protein |&gt; \n  pivot_wider(id_cols = manuf,\n              names_from = shelf,\n              values_from = mean_protein)\n\n# A tibble: 7 × 4\n# Groups:   manuf [7]\n  manuf   `2`   `1`   `3`\n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A      4    NA    NA   \n2 G      1.29  3     2.67\n3 K      2.14  2.75  2.92\n4 N      2.5   2.67  4   \n5 P      1     1.5   3   \n6 Q      2     5     2.5 \n7 R     NA     2     3"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#extending-joins",
    "href": "slides/week-4/w4-notes.html#extending-joins",
    "title": "Week 4 Starter Notes",
    "section": "Extending Joins",
    "text": "Extending Joins\n\nmovies_directors |&gt; \n  inner_join(directors, \n             join_by(director_id == id)) |&gt; \n  inner_join(movies,\n             join_by(movie_id == id)) |&gt; \n  group_by(first_name, last_name) |&gt;\n  summarize(start_year = min(year),\n            end_year = max(year)) |&gt; \n  mutate(n_years_active = end_year - start_year) |&gt; \n  arrange(desc(n_years_active))\n\n# A tibble: 34 × 5\n# Groups:   first_name [31]\n   first_name  last_name start_year end_year n_years_active\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1 Quentin     Tarantino       1992     2004             12\n 2 James (I)   Cameron         1986     1997             11\n 3 Christopher Nolan           2000     2005              5\n 4 Ethan       Coen            1996     2000              4\n 5 Joel        Coen            1996     2000              4\n 6 Andrew      Adamson         2001     2001              0\n 7 Andy        Wachowski       1999     1999              0\n 8 Cameron     Crowe           2001     2001              0\n 9 Clint       Eastwood        2003     2003              0\n10 Darren      Aronofsky       1998     1998              0\n# ℹ 24 more rows\n\n\n\ndirectors |&gt; \n  inner_join(movies_directors, \n             join_by(id == director_id))\n\n# A tibble: 41 × 4\n      id first_name last_name movie_id\n   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;\n 1   429 Andrew     Adamson     300229\n 2  2931 Darren     Aronofsky   254943\n 3  9247 Zach       Braff       124110\n 4 11652 James (I)  Cameron      10920\n 5 11652 James (I)  Cameron     333856\n 6 14927 Ron        Clements    192017\n 7 15092 Ethan      Coen        109093\n 8 15092 Ethan      Coen        237431\n 9 15093 Joel       Coen        109093\n10 15093 Joel       Coen        237431\n# ℹ 31 more rows\n\n\n\nhead(species)\n\n# A tibble: 6 × 4\n  genus       species      taxa   species_id\n  &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;     \n1 Dipodomys   merriami     Rodent DM        \n2 Dipodomys   ordii        Rodent DO        \n3 Perognathus flavus       Rodent PF        \n4 Chaetodipus penicillatus Rodent PP        \n5 Peromyscus  eremicus     Rodent PE        \n6 Onychomys   leucogaster  Rodent OL        \n\nhead(measurements)\n\n# A tibble: 6 × 5\n  genus_name species  sex   hindfoot_length weight\n  &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1 Dipodomys  merriami M                  35     40\n2 Dipodomys  merriami M                  37     48\n3 Dipodomys  merriami F                  34     29\n4 Dipodomys  merriami F                  35     46\n5 Dipodomys  merriami M                  35     36\n6 Dipodomys  ordii    F                  32     52\n\n\n\nmeasurements |&gt; \n  inner_join(species, \n             by = join_by(genus_name == genus))\n\nWarning in inner_join(measurements, species, by = join_by(genus_name == : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 72,824 × 8\n   genus_name species.x sex   hindfoot_length weight species.y  taxa  species_id\n   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     \n 1 Dipodomys  merriami  M                  35     40 merriami   Rode… DM        \n 2 Dipodomys  merriami  M                  35     40 ordii      Rode… DO        \n 3 Dipodomys  merriami  M                  35     40 spectabil… Rode… DS        \n 4 Dipodomys  merriami  M                  37     48 merriami   Rode… DM        \n 5 Dipodomys  merriami  M                  37     48 ordii      Rode… DO        \n 6 Dipodomys  merriami  M                  37     48 spectabil… Rode… DS        \n 7 Dipodomys  merriami  F                  34     29 merriami   Rode… DM        \n 8 Dipodomys  merriami  F                  34     29 ordii      Rode… DO        \n 9 Dipodomys  merriami  F                  34     29 spectabil… Rode… DS        \n10 Dipodomys  merriami  F                  35     46 merriami   Rode… DM        \n# ℹ 72,814 more rows\n\n\n\nspecies |&gt; \n  full_join(measurements,\n            join_by(species == species, \n                    genus == genus_name))\n\n# A tibble: 30,463 × 7\n   genus     species  taxa   species_id sex   hindfoot_length weight\n   &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Dipodomys merriami Rodent DM         M                  35     40\n 2 Dipodomys merriami Rodent DM         M                  37     48\n 3 Dipodomys merriami Rodent DM         F                  34     29\n 4 Dipodomys merriami Rodent DM         F                  35     46\n 5 Dipodomys merriami Rodent DM         M                  35     36\n 6 Dipodomys merriami Rodent DM         F                  36     35\n 7 Dipodomys merriami Rodent DM         F                  32     22\n 8 Dipodomys merriami Rodent DM         F                  34     42\n 9 Dipodomys merriami Rodent DM         F                  35     41\n10 Dipodomys merriami Rodent DM         F                  37     37\n# ℹ 30,453 more rows"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#factors-with-forcats",
    "href": "slides/week-4/w4-notes.html#factors-with-forcats",
    "title": "Week 4 Starter Notes",
    "section": "Factors with forcats",
    "text": "Factors with forcats\nTo practice working with factor variables, we will use data on songs that Taylor Swift included in the Era’s Tour.\n\nfull_eras &lt;- read_excel(\"data/TS_data.xlsx\", sheet = \"full\")\n\nset.seed(2)\neras_data &lt;- full_eras |&gt; \n  slice_sample(n = 25) |&gt; \n  select(Song, Album)\n\n\neras_data |&gt; \n  mutate(Album = fct(Album)) |&gt; \n  pull(Album)\n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Red Reputation Lover Midnights 1989 Fearless Folklore ... Speak Now\n\n\n\neras_data |&gt; \n  mutate(Album = fct(Album,\n                     levels = c(\"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\", \"Reputation\",\"Lover\",\n                                \"Folklore\", \"Evermore\",\"Midnights\"))) |&gt; \n  pull(Album) \n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Fearless Speak Now Red 1989 Reputation Lover Folklore ... Midnights\n\n\n\neras_data |&gt; \n  mutate(Album = fct(Album, \n                     levels = c(\"Taylor Swift\",\n                                \"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\", \"Reputation\",\"Lover\",\n                                \"Folklore\", \"Evermore\",\"Midnights\",\n                                \"The Tortured Poets Department\"))) |&gt; \n  pull(Album) \n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n11 Levels: Taylor Swift Fearless Speak Now Red 1989 Reputation ... The Tortured Poets Department\n\n\n\neras_data |&gt;\n  mutate(Album = fct_recode(.f = Album,\n                            \"folklore\" = \"Folklore\",\n                            \"evermore\" = \"Evermore\",\n                            \"reputation\" = \"Reputation\")) |&gt;\n  pull(Album) \n\n [1] Red        reputation Lover      Midnights  1989       Fearless  \n [7] reputation folklore   Midnights  evermore   evermore   Lover     \n[13] Lover      Red        reputation reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   folklore  \n[25] Lover     \n9 Levels: 1989 evermore Fearless folklore Lover Midnights Red ... Speak Now\n\n\n\neras_data |&gt; \n  mutate(Genre = fct_collapse(.f= Album,\n                       \"country pop\" = c(\"Taylor Swift\", \"Fearless\"),\n                       \"pop rock\" = c(\"Speak Now\",\"Red\"),\n                       \"electropop\" = c(\"1989\",\"reputation\",\"Lover\"),\n                       \"folk pop\" = c(\"folklore\",\"evermore\"),\n                       \"alt-pop\" = \"Midnights\")) |&gt; \n  slice_sample(n = 6)\n\n# A tibble: 6 × 3\n  Song                                    Album      Genre      \n  &lt;chr&gt;                                   &lt;chr&gt;      &lt;fct&gt;      \n1 willow                                  Evermore   Evermore   \n2 You Belong With Me                      Fearless   country pop\n3 Lavender Haze                           Midnights  alt-pop    \n4 We Are Never Ever Getting Back Together Red        pop rock   \n5 illicit affairs                         Folklore   Folklore   \n6 Look What You Made Me Do                Reputation Reputation \n\n\n\neras_data |&gt; \n  mutate(Album = fct_relevel(.f = Album, \n                             c(\"Fearless\",\"1989\",\"Taylor Swift\",\n                               \"Speak Now\",\"Red\",\"Midnights\",\"reputation\",\n                               \"folklore\",\"Lover\",\"evermore\"))) |&gt;\n  pull(Album) |&gt;\n  levels()\n\n[1] \"Fearless\"   \"1989\"       \"Speak Now\"  \"Red\"        \"Midnights\" \n[6] \"Lover\"      \"Evermore\"   \"Folklore\"   \"Reputation\""
  },
  {
    "objectID": "slides/week-4/w4-notes.html#re-order-factors-for-plots",
    "href": "slides/week-4/w4-notes.html#re-order-factors-for-plots",
    "title": "Week 4 Starter Notes",
    "section": "Re-order Factors for Plots",
    "text": "Re-order Factors for Plots\n\nfull_eras |&gt; \n  mutate(Album = fct(Album,\n                     levels = c(\"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\",\"Reputation\",\"Lover\",\n                                \"Folklore\",\"Evermore\",\n                                \"Midnights\"))) |&gt; \n  ggplot() +\n  geom_bar(aes(y = Album), fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\nfull_eras |&gt; \n  ggplot() +\n  geom_bar(aes(y = fct_infreq(Album)), \n           fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\nfull_eras |&gt; \n  ggplot(aes(x = Length, \n             y = fct_reorder(.f = Album,\n                             .x = Length,\n                             .fun = mean), \n             fill = Album)) +\n  geom_density_ridges() +\n  theme_minimal() +\n  theme(legend.position = \"none\")+\n  labs(x = \"Song Length (mins)\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\ncereal_long |&gt; \n  ggplot(aes(x = shelf, \n             y = mean_amount, \n             color = fct_reorder2(.x = shelf,\n                                  .y = mean_amount,\n                                  .f = Nutrient))) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Shelf\", y = \"\", \n       subtitle = \"Mean Amount\",\n       color = \"Nutrient\")"
  },
  {
    "objectID": "practice-activities/pa5-1.html",
    "href": "practice-activities/pa5-1.html",
    "title": "PA 5.1: Scrambled Message",
    "section": "",
    "text": "Download starter qmd file\nlibrary(tidyverse)"
  },
  {
    "objectID": "practice-activities/pa5-1.html#pick-your-poison",
    "href": "practice-activities/pa5-1.html#pick-your-poison",
    "title": "PA 5.1: Scrambled Message",
    "section": "Pick your poison!",
    "text": "Pick your poison!\nYou may choose to work through Q1 - Q6 using a data.frame message_data and follow the dplyr pipeline syntax…\n\nmessage_data &lt;- read_csv(\"https://github.com/earobinson95/stat331-calpoly/raw/master/practice-activities/data/scrambled_message.txt\")\n\nclass(message_data)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\n…or you might prefer to work with the character vector message and use indexing – e.g. message[1] gives you the first element.\n\nmessage &lt;- message_data |&gt; \n  pull(Word)\n\nclass(message)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn this activity, a “word” is a set of characters with no white space. That is, even though many of elements of the scrambled mess vector are nonsense, and some have punctuation, you can consider each element to be a “word”."
  },
  {
    "objectID": "practice-activities/pa5-1.html#warm-up-exercises",
    "href": "practice-activities/pa5-1.html#warm-up-exercises",
    "title": "PA 5.1: Scrambled Message",
    "section": "Warm-up exercises",
    "text": "Warm-up exercises\n\nHow many characters are in the scrambled message?\nHow many words are in the scrambled message?\nPrint out every word in the scrambled message that starts with the letter “m”.\nPrint out every word in the scrambled message that ends with a punctuation mark.\nPrint out the longest word in the scrambled message.\nPrint out the punctuation symbols that are present in the scrambled message. (This one is the trickiest! You will need to use a number of steps and stringr functions.)"
  },
  {
    "objectID": "practice-activities/pa5-1.html#decode-the-message",
    "href": "practice-activities/pa5-1.html#decode-the-message",
    "title": "PA 5.1: Scrambled Message",
    "section": "Decode the Message",
    "text": "Decode the Message\n\n\n\n\n\n\nCaution\n\n\n\nYou likely want to work with the message character vector for decoding. You should still use piping to chain the steps together!\n\n\nComplete the following steps to decode the message.\n\nRemove any spaces before or after each word.\nNo word should be longer than 16 characters. Drop all extra characters off the end of each word.\nEvery time you see the word “ugh”, with any number of h’s, followed by a punctuation mark, delete this.\nReplace all instances of exactly 2 a’s with exactly 2 e’s.\nReplace all z’s with t’s.\nEvery word that ends in b, change that to a y.\nEvery word that starts with k (or K), change that to a v.\nRecombine all your words into a message with a stringr function.\nFind the movie this quote is from.\n\n\n\n\n\n\n\nCanvas Quiz Submission\n\n\n\nWhat is the name of the movie the quote is from?"
  },
  {
    "objectID": "practice-activities/pa5-2.html",
    "href": "practice-activities/pa5-2.html",
    "title": "PA 5.2: Jewel Heist",
    "section": "",
    "text": "Download starter qmd file\nlibrary(tidyverse)"
  },
  {
    "objectID": "practice-activities/pa5-2.html#solve-the-mystery",
    "href": "practice-activities/pa5-2.html#solve-the-mystery",
    "title": "PA 5.2: Jewel Heist",
    "section": "Solve the Mystery",
    "text": "Solve the Mystery\nJust down the road in Montecito, CA several rare jewels went missing. The jewels were stolen and replaced with fakes, but detectives have not been able to solve the case. They are now calling in a data scientist to help parse their clues.\nA camera was located near the building where the jewels went missing, so the detectives have provided you with a list of people who may have entered the building. This list includes the date and time they were spotted on the camera, in Pacific Standard Time (PST).\nUnfortunately, the date and time of the jewel heist is not known. You have been hired to crack the case. Use the clues below to discover the thief’s identity.\n\n# 214 total suspects\nsuspects &lt;- read_csv(\"https://raw.githubusercontent.com/zoerehnberg/STAT331-S23/main/practice_activities/suspects.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nTime Zones will be very important to find the right suspect!\n\n\n\nWhen data is read into R, dates are automatically read in as the UTC time zone. The first thing that we need to do is tell R that the times listed are actually in PST. Fill in the code below to do this.\n\n\nsuspects &lt;- suspects |&gt; \n  mutate(Time.Spotted = )\n\nError in quo_as_label(quo): argument \"expr\" is missing, with no default\n\n\n\nBased on the cleaning schedule for the room where the jewels are held, the heist was not committed in the morning (i.e. at 12:00pm PCT or later).\n\n\n# end with 112 suspects left\n\n\nThe room where the heist was committed is closed on Tuesdays and Thursdays (and there were no signs of forced entry), so the heist did not happen on those days.\n\n\n# end with 78 suspects left\n\n\nIt is believed that the heist was committed within 5 weeks (35 days) of Thanksgiving 2022 (before or after).\n\n\n\n\n\n\n\nHints\n\n\n\nPay attention to time zones!\nYou will want to look up the date of Thanksgiving 2022.\nI would recommend using an interval\n\n\n\n# end with 11 suspects left\n\n\nThe detectives partially decoded a message from the thief to a notorious fence in Iceland. In it, the thief said the job would be done “after the sun sets for you, but before midnight.”\n\n\n\n\n\n\n\nHints\n\n\n\nIn November, the sun sets at 4:00pm in Iceland.\nPay attention to time zones!\n\n\n\n# end with 4 suspects left\n\n\nThe thief left behind a receipt at the scene of the crime. The receipt is smudged, but the day of the month is shown to be 22. It is thought that the heist took place no more than three days after the receipt was issued.\n\n\n# end with 2 suspects left\n\n\nThe thief is amused by your efforts and has sent you a cryptic clue:\n\n\n“The exact number of seconds between midnight on Jan 1, 1970 and the time I arrived on the scene is divisible by 6.”\n\n\n\n\n\n\n\nHint\n\n\n\nCheck out how date-time objects are stored on the lubridate cheatsheet.\n\n\n\n# end with 1 suspect left\n\n\n\n\n\n\n\nCanvas Quiz Submission\n\n\n\nWho is the thief? Only one name should remain. Remember that you can check with classmates and me about the answer!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#tuesday-april-29",
    "href": "slides/week-5/week-5-strings.html#tuesday-april-29",
    "title": "Using stringr to Work with Strings",
    "section": "Tuesday, April 29",
    "text": "Tuesday, April 29\nToday we will…\n\nDifferent schedule this week & next\nNew material\n\nString variables\nFunctions for working with strings\nRegular expressions\n\nPA 5.1: Scrambled Message\n\n\n\n\n\n\n\nFollow along\n\n\nRemember to download, save, and open up the starter notes for this week!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#week-5-layout",
    "href": "slides/week-5/week-5-strings.html#week-5-layout",
    "title": "Using stringr to Work with Strings",
    "section": "Week 5 Layout",
    "text": "Week 5 Layout\n\nToday: Strings with stringr\n\nPractice Activity: Decoding a Message\n\n\n\n\nThursday: Dates with lubridate\n\nPractice Activity: Jewel Heist\nDiscuss midterm exam and project\n\n\n\n\n\nLab Assignment Solving a Murder Mystery\n\nUsing dplyr + stringr + ludridate\nDue (next) Monday\nMay only use 1 late day so that I can post solutions before the exam"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#week-6-layout",
    "href": "slides/week-5/week-5-strings.html#week-6-layout",
    "title": "Using stringr to Work with Strings",
    "section": "Week 6 Layout",
    "text": "Week 6 Layout\n\nTuesday: Version control with git\n\nPractice Activity - done in groups in class\nLast day to submit Lab 5\n\n\n\n\nThursday: Midterm Exam"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#what-is-a-string",
    "href": "slides/week-5/week-5-strings.html#what-is-a-string",
    "title": "Using stringr to Work with Strings",
    "section": "What is a string?",
    "text": "What is a string?\nA string is a bunch of characters.\n\nThere is a difference between…\n\n…a string (many characters, one object)…\nand\n…a character vector (vector of strings).\n\n\n\n\nmy_string &lt;- \"Hi, my name is Bond!\"\nmy_string\n\n[1] \"Hi, my name is Bond!\"\n\n\n\n\n\nmy_vector &lt;- c(\"Hi\", \"my\", \"name\", \"is\", \"Bond\")\nmy_vector\n\n[1] \"Hi\"   \"my\"   \"name\" \"is\"   \"Bond\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#stringr",
    "href": "slides/week-5/week-5-strings.html#stringr",
    "title": "Using stringr to Work with Strings",
    "section": "stringr",
    "text": "stringr\n\n\nCommon tasks\n\nIdentify strings containing a particular pattern.\nRemove or replace a pattern.\nEdit a string (e.g., make it lowercase).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe stringr package loads with tidyverse.\nAll functions are of the form str_xxx()."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#pattern",
    "href": "slides/week-5/week-5-strings.html#pattern",
    "title": "Using stringr to Work with Strings",
    "section": "pattern =",
    "text": "pattern =\nThe pattern argument appears in many stringr functions.\n\nThe pattern must be supplied inside quotes.\n\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_detect(my_vector, pattern = \"Bond\")\nstr_locate(my_vector, pattern = \"James Bond\")\nstr_match(my_vector, pattern = \"[bB]ond\")\nstr_extract(my_vector, pattern = \"[jJ]ames [bB]ond\")\n\n\n\n\nLet’s explore these functions!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_detect",
    "href": "slides/week-5/week-5-strings.html#str_detect",
    "title": "Using stringr to Work with Strings",
    "section": "str_detect()",
    "text": "str_detect()\nReturns a logical vector indicating whether the pattern was found in each element of the supplied vector.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\nstr_detect(my_vector, pattern = \"Bond\")\n\n[1] FALSE FALSE  TRUE  TRUE\n\n\n\n\n\n\nPairs well with filter().\nWorks with summarise() + sum (to get total matches) or mean (to get proportion of matches).\n\n\n\n\n\n\n\n\n\n\n\nRelated Function\n\n\nstr_which() returns the indexes of the strings that contain a match."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_match",
    "href": "slides/week-5/week-5-strings.html#str_match",
    "title": "Using stringr to Work with Strings",
    "section": "str_match()",
    "text": "str_match()\nReturns a character matrix containing either NA or the pattern, depending on if the pattern was found.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_match(my_vector, pattern = \"Bond\")\n\n     [,1]  \n[1,] NA    \n[2,] NA    \n[3,] \"Bond\"\n[4,] \"Bond\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_extract",
    "href": "slides/week-5/week-5-strings.html#str_extract",
    "title": "Using stringr to Work with Strings",
    "section": "str_extract()",
    "text": "str_extract()\nReturns a character vector with either NA or the pattern, depending on if the pattern was found.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_extract(my_vector, pattern = \"Bond\")\n\n[1] NA     NA     \"Bond\" \"Bond\"\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nstr_extract() only returns the first pattern match.\nUse str_extract_all() to return every pattern match."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#what-do-you-mean-by-the-first-match",
    "href": "slides/week-5/week-5-strings.html#what-do-you-mean-by-the-first-match",
    "title": "Using stringr to Work with Strings",
    "section": "What do you mean by the first match?",
    "text": "What do you mean by the first match?\nSuppose we had a slightly different vector…\n\nalt_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond, James Bond\")\n\n\nIf we were to extract every instance of \"Bond\" from the vector…\n\n\n\n\nstr_extract(alt_vector, \n            pattern = \"Bond\")\n\n[1] NA     NA     \"Bond\"\n\n\n\n\n\n\n\n\n\nstr_extract_all(alt_vector, \n                pattern = \"Bond\")\n\n[[1]]\ncharacter(0)\n\n[[2]]\ncharacter(0)\n\n[[3]]\n[1] \"Bond\" \"Bond\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_locate",
    "href": "slides/week-5/week-5-strings.html#str_locate",
    "title": "Using stringr to Work with Strings",
    "section": "str_locate()",
    "text": "str_locate()\nReturns a dateframe with two numeric variables – the starting and ending location of the pattern. The values are NA if the pattern is not found.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_locate(my_vector, pattern = \"Bond\")\n\n     start end\n[1,]    NA  NA\n[2,]    NA  NA\n[3,]     1   4\n[4,]     7  10\n\n\n\n\n\n\n\n\n\n\n\nRelated Function\n\n\nstr_sub() extracts values based on a starting and ending location."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_subset",
    "href": "slides/week-5/week-5-strings.html#str_subset",
    "title": "Using stringr to Work with Strings",
    "section": "str_subset()",
    "text": "str_subset()\nReturns a character vector containing a subset of the original character vector consisting of the elements where the pattern was found anywhere in the element.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_subset(my_vector, pattern = \"Bond\")\n\n[1] \"Bond\"       \"James Bond\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#try-it-out",
    "href": "slides/week-5/week-5-strings.html#try-it-out",
    "title": "Using stringr to Work with Strings",
    "section": "Try it out!",
    "text": "Try it out!\n\n\nmy_vector &lt;- c(\"I scream,\", \n               \"you scream\", \n               \"we all\",\n               \"scream\",\n               \"for\",\n               \"ice cream\")\n\nstr_detect(my_vector, pattern = \"cream\")\nstr_locate(my_vector, pattern = \"cream\")\nstr_match(my_vector, pattern = \"cream\")\nstr_extract(my_vector, pattern = \"cream\")\nstr_subset(my_vector, pattern = \"cream\")\n\n\n\n\n\n\n\nNote\n\n\nFor each of these functions, write down:\n\nthe object structure of the output.\nthe data type of the output.\na brief explanation of what they do."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#replace-remove-patterns",
    "href": "slides/week-5/week-5-strings.html#replace-remove-patterns",
    "title": "Using stringr to Work with Strings",
    "section": "Replace / Remove Patterns",
    "text": "Replace / Remove Patterns\n\nstr_replace()str_remove()\n\n\n\nReplace the first matched pattern in each string.\n\nPairs well with mutate().\n\n\nstr_replace(my_vector, \n            pattern = \"Bond\", \n            replace = \"Franco\")\n\n[1] \"Hello,\"       \"my name is\"   \"Franco\"       \"James Franco\"\n\n\n\n\n\n\n\n\n\n\n\nRelated Function\n\n\nstr_replace_all() replaces all matched patterns in each string.\n\n\n\n\n\n\n\nRemove the first matched pattern in each string.\n\nstr_remove(my_vector, \n           pattern = \"Bond\")\n\n[1] \"Hello,\"     \"my name is\" \"\"           \"James \"    \n\n\n\n\n\n\n\n\n\n\n\nRelated Functions\n\n\nThis is a special case of str_replace(x, pattern, replacement = \"\").\nstr_remove_all() removes all matched patterns in each string."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#edit-strings",
    "href": "slides/week-5/week-5-strings.html#edit-strings",
    "title": "Using stringr to Work with Strings",
    "section": "Edit Strings",
    "text": "Edit Strings\nConvert letters in a string to a specific capitalization format.\n\nlowerUPPERTitle\n\n\nstr_to_lower() converts all letters in a string to lowercase.\n\n\nstr_to_lower(my_vector)\n\n[1] \"hello,\"     \"my name is\" \"bond\"       \"james bond\"\n\n\n\n\nstr_to_upper() converts all letters in a string to uppercase.\n\n\nstr_to_upper(my_vector)\n\n[1] \"HELLO,\"     \"MY NAME IS\" \"BOND\"       \"JAMES BOND\"\n\n\n\n\nstr_to_title() converts the first letter of each word to uppercase.\n\n\nstr_to_title(my_vector)\n\n[1] \"Hello,\"     \"My Name Is\" \"Bond\"       \"James Bond\"\n\n\n\n\n\n\n\n\nThis is handy for axis labels!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#combine-strings",
    "href": "slides/week-5/week-5-strings.html#combine-strings",
    "title": "Using stringr to Work with Strings",
    "section": "Combine Strings",
    "text": "Combine Strings\n\nstr_c()str_flatten()str_glue()\n\n\nJoin multiple strings into a single character vector.\n\nprompt &lt;- \"Hello, my name is\"\nfirst  &lt;- \"James\"\nlast   &lt;- \"Bond\"\nstr_c(prompt, last, \",\", first, last, sep = \" \")\n\n[1] \"Hello, my name is Bond , James Bond\"\n\n\n\n\n\n\n\n\nNote\n\n\nSimilar to paste() and paste0().\n\n\n\n\n\nCombine a vector of strings into a single string.\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_flatten(my_vector, collapse = \" \")\n\n[1] \"Hello, my name is Bond James Bond\"\n\n\n\n\nUse variables in the environment to create a string based on {expressions}.\n\nfirst &lt;- \"James\"\nlast &lt;- \"Bond\"\nstr_glue(\"My name is {last}, {first} {last}\")\n\nMy name is Bond, James Bond\n\n\n\n\n\n\n\n\nTip\n\n\nFor more details, I would recommend looking up the glue R package!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#tips-for-string-success",
    "href": "slides/week-5/week-5-strings.html#tips-for-string-success",
    "title": "Using stringr to Work with Strings",
    "section": "Tips for String Success",
    "text": "Tips for String Success\n\nRefer to the stringr cheatsheet\nRemember that str_xxx functions need the first argument to be a vector of strings, not a dataset!\n\nYou will use these functions inside dplyr verbs like filter() or mutate().\n\n\n\ncereal |&gt; \n  mutate(is_bran = str_detect(name, \"Bran\"), \n         .after = name)\n\n\n\n\n\n\n\nname\nis_bran\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nTRUE\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n100% Natural Bran\nTRUE\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\nAll-Bran\nTRUE\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nTRUE\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nAlmond Delight\nFALSE\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nFALSE\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\nApple Jacks\nFALSE\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nBasic 4\nFALSE\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Chex\nTRUE\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\nBran Flakes\nTRUE\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\nCap'n'Crunch\nFALSE\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\nCheerios\nFALSE\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nFALSE\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nClusters\nFALSE\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\nCocoa Puffs\nFALSE\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\nCorn Chex\nFALSE\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nFALSE\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nCorn Pops\nFALSE\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\nCount Chocula\nFALSE\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\nCracklin' Oat Bran\nTRUE\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nCream of Wheat (Quick)\nFALSE\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nFALSE\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nCrispy Wheat & Raisins\nFALSE\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\nDouble Chex\nFALSE\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\nFroot Loops\nFALSE\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\nFrosted Flakes\nFALSE\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\nFrosted Mini-Wheats\nFALSE\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nFALSE\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\nFruitful Bran\nTRUE\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\nFruity Pebbles\nFALSE\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\nGolden Crisp\nFALSE\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nGolden Grahams\nFALSE\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\nGrape Nuts Flakes\nFALSE\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\nGrape-Nuts\nFALSE\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nFALSE\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nHoney Graham Ohs\nFALSE\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\nHoney Nut Cheerios\nFALSE\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\nHoney-comb\nFALSE\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\nJust Right Crunchy Nuggets\nFALSE\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nFALSE\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\nKix\nFALSE\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nLife\nFALSE\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\nLucky Charms\nFALSE\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\nMaypo\nFALSE\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nMuesli Raisins; Dates; & Almonds\nFALSE\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\nMuesli Raisins; Peaches; & Pecans\nFALSE\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nFALSE\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\nMulti-Grain Cheerios\nFALSE\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\nNut&Honey Crunch\nFALSE\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\nNutri-Grain Almond-Raisin\nFALSE\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\nNutri-grain Wheat\nFALSE\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nFALSE\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\nPost Nat. Raisin Bran\nTRUE\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nProduct 19\nFALSE\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nFALSE\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nFALSE\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oat Squares\nFALSE\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\nQuaker Oatmeal\nFALSE\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Bran\nTRUE\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\nRaisin Nut Bran\nTRUE\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\nRaisin Squares\nFALSE\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\nRice Chex\nFALSE\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nFALSE\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nFALSE\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nTRUE\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nFALSE\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\nSmacks\nFALSE\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nSpecial K\nFALSE\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nStrawberry Fruit Wheats\nFALSE\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\nTotal Corn Flakes\nFALSE\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Raisin Bran\nTRUE\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nTotal Whole Grain\nFALSE\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nFALSE\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nTrix\nFALSE\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\nWheat Chex\nFALSE\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nFALSE\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nFALSE\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#tips-for-string-success-1",
    "href": "slides/week-5/week-5-strings.html#tips-for-string-success-1",
    "title": "Using stringr to Work with Strings",
    "section": "Tips for String Success",
    "text": "Tips for String Success\nThe real power of these str_xxx functions comes when you specify the pattern using regular expressions!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#regular-expressions",
    "href": "slides/week-5/week-5-strings.html#regular-expressions",
    "title": "Using stringr to Work with Strings",
    "section": "Regular Expressions",
    "text": "Regular Expressions\n\n“Regexps are a very terse language that allow you to describe patterns in strings.”\nR for Data Science\n\n\nUse str_xxx functions + regular expressions!\n\nstr_detect(string  = my_string_vector,\n           pattern = \"p[ei]ck[a-z]\")\n\n\n\n\n\n\n\n\n\nTip\n\n\nYou might encounter gsub(), grep(), etc. from Base R, but I would highly recommending using functions from the stringr package instead."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#regular-expressions-1",
    "href": "slides/week-5/week-5-strings.html#regular-expressions-1",
    "title": "Using stringr to Work with Strings",
    "section": "Regular Expressions",
    "text": "Regular Expressions\n…are tricky!\n\nThere are lots of new symbols to keep straight.\nThere are a lot of cases to think through.\n\n\nThis web app for testing R regular expressions might be handy!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#special-characters",
    "href": "slides/week-5/week-5-strings.html#special-characters",
    "title": "Using stringr to Work with Strings",
    "section": "Special Characters",
    "text": "Special Characters\nThere is a set of characters that have a specific meaning when using regex.\n\nThe stringr package does not read these as normal characters.\nThese characters are:\n\n\n. ^ $ \\ | * + ? { } [ ] ( )"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#wild-card-character-.",
    "href": "slides/week-5/week-5-strings.html#wild-card-character-.",
    "title": "Using stringr to Work with Strings",
    "section": "Wild Card Character: .",
    "text": "Wild Card Character: .\nThis character can match any character.\n\nx &lt;- c(\"She\", \n       \"sells\", \n       \"seashells\", \n       \"by\", \n       \"the\", \n       \"seashore!\")\n\nstr_subset(x, pattern = \".ells\")\n\n[1] \"sells\"     \"seashells\"\n\n\n\n\n\nstr_extract(x, pattern = \".ells\")\n\n[1] NA      \"sells\" \"hells\" NA      NA      NA     \n\n\n\nThis matches strings that contain any character followed by “ells”."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#anchor-characters",
    "href": "slides/week-5/week-5-strings.html#anchor-characters",
    "title": "Using stringr to Work with Strings",
    "section": "Anchor Characters: ^ $",
    "text": "Anchor Characters: ^ $\n\n\n\n^ – looks at the beginning of a string.\n\nx &lt;- c(\"She\", \n       \"sells\", \n       \"seashells\", \n       \"by\", \n       \"the\", \n       \"seashore!\")\n\nstr_subset(x, pattern = \"^s\")\n\n[1] \"sells\"     \"seashells\" \"seashore!\"\n\n\nThis matches strings that start with “s”.\n\n\n\n\n\n\n$ – looks at the end of a string.\n\nx &lt;- c(\"She\", \n       \"sells\", \n       \"seashells\", \n       \"by\", \n       \"the\", \n       \"seashore!\")\n\nstr_subset(x, pattern = \"s$\")\n\n[1] \"sells\"     \"seashells\"\n\n\nThis matches strings that end with “s”."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#quantifier-characters",
    "href": "slides/week-5/week-5-strings.html#quantifier-characters",
    "title": "Using stringr to Work with Strings",
    "section": "Quantifier Characters: ? + *",
    "text": "Quantifier Characters: ? + *\n\n? – matches when the preceding character occurs 0 or 1 times in a row.\n\nx &lt;- c(\"shes\", \n       \"shels\", \n       \"shells\", \n       \"shellls\", \n       \"shelllls\")\n\nstr_subset(x, pattern = \"shel?s\")\n\n[1] \"shes\"  \"shels\"\n\n\n\n\n\n+ – occurs 1 or more times in a row.\n\nstr_subset(x, pattern = \"shel+s\")\n\n[1] \"shels\"    \"shells\"   \"shellls\"  \"shelllls\"\n\n\n\n\n\n\n* – occurs 0 or more times in a row.\n\nstr_subset(x, pattern = \"shel*s\")\n\n[1] \"shes\"     \"shels\"    \"shells\"   \"shellls\"  \"shelllls\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#quantifier-characters-1",
    "href": "slides/week-5/week-5-strings.html#quantifier-characters-1",
    "title": "Using stringr to Work with Strings",
    "section": "Quantifier Characters: {}",
    "text": "Quantifier Characters: {}\n\n{n} – matches when the preceding character occurs exactly n times in a row.\n\nx &lt;- c(\"shes\", \n       \"shels\", \n       \"shells\", \n       \"shellls\", \n       \"shelllls\")\n\nstr_subset(x, pattern = \"shel{2}s\")\n\n[1] \"shells\"\n\n\n\n\n\n{n,} – occurs at least n times in a row.\n\nstr_subset(x, pattern = \"shel{2,}s\")\n\n[1] \"shells\"   \"shellls\"  \"shelllls\"\n\n\n\n\n\n\n{n,m} – occurs between n and m times in a row.\n\nstr_subset(x, pattern = \"shel{1,3}s\")\n\n[1] \"shels\"   \"shells\"  \"shellls\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-groups",
    "href": "slides/week-5/week-5-strings.html#character-groups",
    "title": "Using stringr to Work with Strings",
    "section": "Character Groups: ()",
    "text": "Character Groups: ()\n\nGroups are created with ( ).\n\nWe can specify “either” / “or” within a group using |.\n\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\", \n       \"peck\",\n       \"of\", \n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p(e|i)ck\")\n\n[1] \"picked\"  \"peck\"    \"pickled\"\n\n\n\n\n\nThis matches strings that contain either “peck” or “pick”."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-groups-1",
    "href": "slides/week-5/week-5-strings.html#character-groups-1",
    "title": "Using stringr to Work with Strings",
    "section": "Character Groups: ()",
    "text": "Character Groups: ()\n\nWe can then reference groups in order with escaped numbers (\\\\1) to specify that certain groupings repeat.\n\n\nx &lt;- c(\"hannah\", \n       \"had\", \n       \"a\", \n       \"ball\", \n       \"on\",\n       \"a\", \n       \"race car\")\n\nstr_subset(x, pattern = \"^(.).*\\\\1$\")\n\n[1] \"hannah\"   \"race car\"\n\n\n\n\nThis matches strings that start and end with the same character."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-groups-2",
    "href": "slides/week-5/week-5-strings.html#character-groups-2",
    "title": "Using stringr to Work with Strings",
    "section": "Character Groups: ()",
    "text": "Character Groups: ()\n\nGroups also let us be very precise with extracting strings!\n\n\nshopping_list &lt;- c(\"apples x4\", \n                   \"bag of flour\", \n                   \"bag of sugar\", \n                   \"milk x2\")\n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\")\n\n[1] \"apples x4\" NA          NA          \"milk x2\"  \n\n\n\n\n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\", group = 1)\n\n[1] \"apples\" NA       NA       \"milk\"  \n\n\n\n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\", group = 2)\n\n[1] \"4\" NA  NA  \"2\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-classes",
    "href": "slides/week-5/week-5-strings.html#character-classes",
    "title": "Using stringr to Work with Strings",
    "section": "Character Classes: []",
    "text": "Character Classes: []\n\nCharacter classes let you specify multiple possible characters to match on.\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\",\n       \"peck\",\n       \"of\",\n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p[ei]ck\")\n\n[1] \"picked\"  \"peck\"    \"pickled\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#matches-you-dont-want",
    "href": "slides/week-5/week-5-strings.html#matches-you-dont-want",
    "title": "Using stringr to Work with Strings",
    "section": "Matches you don’t want",
    "text": "Matches you don’t want\n[^ ] – specifies characters not to match on (think except)\n\nstr_subset(x, pattern = \"p[^i]ck\")\n\n[1] \"peck\"\n\n\n\n\nBut remember that ^ outside of brackets specifies the first charatcter in a string.\n\nstr_subset(x, pattern = \"^p\")\n\n[1] \"picked\"   \"peck\"     \"pickled\"  \"peppers!\"\n\n\n\n\n\n\nstr_subset(x, pattern = \"^[^p]\")\n\n[1] \"Peter\" \"Piper\" \"a\"     \"of\"   \n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nWhy do “Peter” and “Piper” not match \"^[^p]\"?\nCapitilization matters!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-classes-1",
    "href": "slides/week-5/week-5-strings.html#character-classes-1",
    "title": "Using stringr to Work with Strings",
    "section": "Character Classes: []",
    "text": "Character Classes: []\n\n[ - ] – specifies a range of characters.\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\",\n       \"peck\",\n       \"of\",\n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p[ei]ck[a-z]\")\n\n[1] \"picked\"  \"pickled\"\n\n\n\n\n\n\n[A-Z] matches any capital letter.\n[a-z] matches any lowercase letter.\n[A-z] or [:alpha:] matches any letter\n[0-9] or [:digit:] matches any number"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#shortcuts",
    "href": "slides/week-5/week-5-strings.html#shortcuts",
    "title": "Using stringr to Work with Strings",
    "section": "Shortcuts",
    "text": "Shortcuts\n\n\n\\\\w – matches any “word” (\\\\W matches not “word”)\n\nA “word” contains any letters and numbers.\n\n\\\\d – matches any digit (\\\\D matches not digit)\n\\\\s – matches any whitespace (\\\\S matches not whitespace)\n\nWhitespace includes spaces, tabs, newlines, etc.\n\n\n\n\n\n\n\nx &lt;- \"phone number: 1234567899\"\n\nstr_extract(x, pattern = \"\\\\d+\")\n\n[1] \"1234567899\"\n\nstr_extract_all(x, pattern = \"\\\\S+\")\n\n[[1]]\n[1] \"phone\"      \"number:\"    \"1234567899\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#try-it-out-1",
    "href": "slides/week-5/week-5-strings.html#try-it-out-1",
    "title": "Using stringr to Work with Strings",
    "section": "Try it out!",
    "text": "Try it out!\nWhat regular expressions would match words that…\n\n\n\nend with a vowel?\nstart with x, y, or z?\ncontains at least one digit?\ncontains two of the same letters in a row?\n\n\n\n\n\nx &lt;- c(\"zebra\", \n       \"xray\", \n       \"apple\", \n       \"yellow\",\n       \"color\", \n       \"patt3rn\",\n       \"g2g\",\n       \"summarise\")"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#some-possible-solutions",
    "href": "slides/week-5/week-5-strings.html#some-possible-solutions",
    "title": "Using stringr to Work with Strings",
    "section": "Some Possible Solutions…",
    "text": "Some Possible Solutions…\n\nend with a vowel?\n\n\nstr_subset(x, \"[aeiouy]$\")\n\n\nstart with x, y, or z?\n\n\nstr_subset(x, \"^[xyz]\")\n\n\ncontain at least one digit?\n\n\nstr_subset(x, \"[:digit:]\")\n\n\ncontains two of the same letters in a row\n\n\nstr_subset(x, \"([:alpha:])\\\\1\")"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#escape",
    "href": "slides/week-5/week-5-strings.html#escape",
    "title": "Using stringr to Work with Strings",
    "section": "Escape: \\\\",
    "text": "Escape: \\\\\n\nTo match a special character, you need to escape it.\n\nx &lt;- c(\"How\",\n       \"much\", \n       \"wood\",\n       \"could\",\n       \"a\",\n       \"woodchuck\",\n       \"chuck\",\n       \"if\",\n       \"a\",\n       \"woodchuck\",\n       \"could\",\n       \"chuck\",\n       \"wood?\")\n\nstr_subset(x, pattern = \"?\")\n\nError in stri_subset_regex(string, pattern, omit_na = TRUE, negate = negate, : Syntax error in regex pattern. (U_REGEX_RULE_SYNTAX, context=`?`)"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#escape-1",
    "href": "slides/week-5/week-5-strings.html#escape-1",
    "title": "Using stringr to Work with Strings",
    "section": "Escape: \\\\",
    "text": "Escape: \\\\\nUse \\\\ to escape the ? – it is now read as a normal character.\n\nstr_subset(x, pattern = \"\\\\?\")\n\n[1] \"wood?\"\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nAlternatively, you could use []:\n\nstr_subset(x, pattern = \"[?]\")\n\n[1] \"wood?\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#when-in-doubt",
    "href": "slides/week-5/week-5-strings.html#when-in-doubt",
    "title": "Using stringr to Work with Strings",
    "section": "When in Doubt",
    "text": "When in Doubt\n\n\nUse the web app to test R regular expressions."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#tips-for-working-with-regex",
    "href": "slides/week-5/week-5-strings.html#tips-for-working-with-regex",
    "title": "Using stringr to Work with Strings",
    "section": "Tips for working with regex",
    "text": "Tips for working with regex\n\nRead the regular expressions out loud like a request.\n\n\n\nTest out your expressions on small examples first.\n\n\n\n\n\n\n\nstr_view()\n\n\n\nstr_view(c(\"shes\", \"shels\", \"shells\", \"shellls\", \"shelllls\"), \"l+\")\n\n[2] │ she&lt;l&gt;s\n[3] │ she&lt;ll&gt;s\n[4] │ she&lt;lll&gt;s\n[5] │ she&lt;llll&gt;s\n\n\n\n\n\n\n\n\nUse the stringr cheatsheet.\n\n\n\n\nBe kind to yourself!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#more-practice",
    "href": "slides/week-5/week-5-strings.html#more-practice",
    "title": "Using stringr to Work with Strings",
    "section": "More practice!",
    "text": "More practice!\nI want to join two datasets that have a county variable:\n\n\n\ncounty_pop\n\n\n\n\n\n\ncounty\npop\n\n\n\n\nSTORY\n100000\n\n\nBOONE\n40000\n\n\nMARSHALL\n120000\n\n\nPOLK\n500000\n\n\n\n\n\n\n\ncounty_loc\n\n\n\n\n\n\ncounty\nregion\n\n\n\n\nStory\nCentral\n\n\nBoone\nCentral\n\n\nMarshall\nEast\n\n\nPolk\nCentral\n\n\n\n\n\n\n\n\n\n\n\n\n\nPractice\n\n\nWhat stringr function will help me join the county_pop and county_loc by county?"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#more-practice-1",
    "href": "slides/week-5/week-5-strings.html#more-practice-1",
    "title": "Using stringr to Work with Strings",
    "section": "More practice!",
    "text": "More practice!\nWhat if I want to pull out only the area code in a phone number?\n\nphone_numbers &lt;- c(\"(515)242-1958\", \"(507)598-1395\", \"(805)938-7639\")\n\n\n\n\n\n\n\nPractice\n\n\nYou will need a stringr function and to use regular expressions!\n\n\n\n\n\nstr_extract(phone_numbers, \"\\\\(\\\\d{3}\\\\)\")\n\n[1] \"(515)\" \"(507)\" \"(805)\"\n\n\n\n\nWhat if I want just the numbers in the area code?\n\n\n\nstr_extract(phone_numbers, \"\\\\((\\\\d{3})\\\\)\", group = 1)\n\n[1] \"515\" \"507\" \"805\"\n\n\n\nphone_numbers |&gt; \n  str_extract(pattern = \"\\\\(\\\\d{3}\\\\)\") |&gt; \n  str_remove_all(pattern = \"[:punct:]\")\n\n[1] \"515\" \"507\" \"805\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#more-practice-last-one",
    "href": "slides/week-5/week-5-strings.html#more-practice-last-one",
    "title": "Using stringr to Work with Strings",
    "section": "More practice! (last one)",
    "text": "More practice! (last one)\n\n\n\nawards_dat\n\n\n\n\n\n\n\nawards\n\n\n\n\nBeyonce: 35G, 0A, 0E\n\n\nKendrick Lamar: 22G, 0A, 1E\n\n\nCharli XCX: 2G, 0A, 0E\n\n\nCynthia Erivo: 1G, 0A, 1E\n\n\nViola Davis: 1G, 1A, 1E\n\n\nElton John: 6G, 2A, 1E\n\n\n\n\n\n\n\n\n\n\n\n\n\nThat’s annoying…\n\n\nCreate a variable with just the artist name and a variable with the number of Grammys won."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#more-practice-last-one-1",
    "href": "slides/week-5/week-5-strings.html#more-practice-last-one-1",
    "title": "Using stringr to Work with Strings",
    "section": "More practice! (last one)",
    "text": "More practice! (last one)\n\n\n\nawards_dat\n\n\n\n\n\n\n\nawards\n\n\n\n\nBeyonce: 35G, 0A, 0E\n\n\nKendrick Lamar: 22G, 0A, 1E\n\n\nCharli XCX: 2G, 0A, 0E\n\n\nCynthia Erivo: 1G, 0A, 1E\n\n\nViola Davis: 1G, 1A, 1E\n\n\nElton John: 6G, 2A, 1E\n\n\n\n\n\n\n\n\n\n\n\n\n\nThat’s annoying…\n\n\nCreate a variable with just the artist name and a variable with the number of Grammys won.\n\n\n\n\n\nawards_dat |&gt; \n  mutate(artist = str_extract(awards, \"[A-z\\\\s]+\"),\n         grammies = str_extract(awards, \"([1-9]+)G\", \n                                group = 1)) |&gt; \n  select(artist, grammies)\n\n\n\n\n\n\n\nartist\ngrammies\n\n\n\n\nBeyonce\n35\n\n\nKendrick Lamar\n22\n\n\nCharli XCX\n2\n\n\nCynthia Erivo\n1\n\n\nViola Davis\n1\n\n\nElton John\n6"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#to-do",
    "href": "slides/week-5/week-5-strings.html#to-do",
    "title": "Using stringr to Work with Strings",
    "section": "To do…",
    "text": "To do…\n\nPA 5.1: Scrambled Message\n\nDue Thursday before class\n\nLA 5: Murder in SQL City\n\nDue Monday at 11:59 pm\nYou can use maximum 1 late day on this lab!\n\nLook out for exam information posted on Canvas - we will discuss on Thursday"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#wednesday-febrary-5",
    "href": "slides/week-5/week-5-dates.html#wednesday-febrary-5",
    "title": "Using lubridate to Work with Dates",
    "section": "Wednesday, Febrary 5",
    "text": "Wednesday, Febrary 5\nToday we will…\n\nMidterm Exam - What to expect\nNew Material\n\nWorking with Date & Time Variables\n\nPA 5.2: Jewel Heist"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-exam---wed-212",
    "href": "slides/week-5/week-5-dates.html#midterm-exam---wed-212",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Exam - Wed 2/12",
    "text": "Midterm Exam - Wed 2/12\n\n\nThis is a three-part exam\nFirst two sections are completed in the one hour and 50 minute class period\n\nYou will first complete a General Questions section on paper and without your computer.\nAfter you turn that in, you will complete a Short Answer section with your computer.\n\nThird section is “takehome” and due 48 hours after the end of class.\n\nThe Open-Ended Analysis is completed out of class (should not take more than 3 hours)"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-exam---wed-212-1",
    "href": "slides/week-5/week-5-dates.html#midterm-exam---wed-212-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Exam - Wed 2/12",
    "text": "Midterm Exam - Wed 2/12\n\n\nReview the “What to Expect” document thoroughly as it includes\n\ndetailed expectations\nthe dataset you will be working with\n\nSet yourself up with a dedicated directory that has the data in it\nMake sure to bring to the exam:\n\nsomething to write with (black/blue pen or pencils)\nyour laptop (& a charging chord)\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\nWhile the coding tasks are open-resource, you will likely run out of time if you have to look everything up. Know what functions you might need and where to find documentation for implementing these functions."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-preparation-suggestions",
    "href": "slides/week-5/week-5-dates.html#midterm-preparation-suggestions",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Preparation Suggestions",
    "text": "Midterm Preparation Suggestions\n\n\nReview course slides & Check-Ins\nQuiz each other on the uses of different functions\nTry to re-do parts of the PAs or LAs from scratch\nStart working with the data\n\nHAVE CODE SET UP THAT READS IN THE DATA\nAsk some questions about the data and try to answer them\n\nSave example code for things you find tricky in a place you can find it\nGet sleep and feed yourself! 🛌🥞🥙🍛"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#project",
    "href": "slides/week-5/week-5-dates.html#project",
    "title": "Using lubridate to Work with Dates",
    "section": "Project",
    "text": "Project\n\n\nDetailed information about the project is posted on Canvas\nYou will complete the project in groups of 4\nThe project is scaffolded into 5 “Checkpoints”\n\nThe bulk of the work will be in Weeks 8-10\n\nFirst Checkpoint due Monday 2/10 at 11:59pm\n\nFill out a survey to form groups\nYou can specify if there are people you want to work with or have me place you in a group"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#lubridate",
    "href": "slides/week-5/week-5-dates.html#lubridate",
    "title": "Using lubridate to Work with Dates",
    "section": "lubridate",
    "text": "lubridate\n\n\n\nConvert a date-like variable (“May 8, 1995”) to a date or date-time object.\nFind the weekday, month, year, etc from a date-time object.\nConvert between time zones.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe lubridate package installs and loads with the tidyverse."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#why-are-dates-and-times-tricky",
    "href": "slides/week-5/week-5-dates.html#why-are-dates-and-times-tricky",
    "title": "Using lubridate to Work with Dates",
    "section": "Why are dates and times tricky?",
    "text": "Why are dates and times tricky?\n\n\nWhen parsing dates and times, we have to consider complicating factors like…\n\nDaylight Savings Time.\n\nOne day a year is 23 hours; one day a year is 25 hours.\nSome places use it, some don’t.\n\nLeap years – most years have 365 days, some have 366.\nTime zones."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#date-time-objects",
    "href": "slides/week-5/week-5-dates.html#date-time-objects",
    "title": "Using lubridate to Work with Dates",
    "section": "date-time Objects",
    "text": "date-time Objects\nThere are multiple data types for dates and times.\n\nA date:\n\ndate or Date\n\nA date and a time (identifies a unique instant in time):\n\ndtm\nPOSIXlt – stores date-times as the number of seconds since January 1, 1970 (“Unix Epoch”)\nPOSIXct – stores date-times as a list with elements for second, minute, hour, day, month, year, etc."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#creating-date-time-objects",
    "href": "slides/week-5/week-5-dates.html#creating-date-time-objects",
    "title": "Using lubridate to Work with Dates",
    "section": "Creating date-time Objects",
    "text": "Creating date-time Objects\n\n\n\n\n\n\nBig Picture\n\n\nThere are a lot of diferent ways to create date-time objects!\n\n\n\n\nCreate a date from individual components:\n\nmake_date(year = 1995, month = 05, day = 08)\n\n[1] \"1995-05-08\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#create-a-date-time-object-from-a-string",
    "href": "slides/week-5/week-5-dates.html#create-a-date-time-object-from-a-string",
    "title": "Using lubridate to Work with Dates",
    "section": "Create a date-time Object from a String",
    "text": "Create a date-time Object from a String\n\n\nmdy(\"August 29, 1991\")\n\n[1] \"1991-08-29\"\n\n\n\n\n\n\ndmy(\"29-August-1991\", \n    tz = \"America/Denver\")\n\n[1] \"1991-08-29 MDT\"\n\n\n\n\n\n\n\ndmy_hms(\"29-August-1991 9:32:12\", \n        tz = \"America/Denver\")\n\n[1] \"1991-08-29 09:32:12 MDT\"\n\n\n\n\n\n\n\nas_datetime(\"91-08-29\", \n            format = \"%y-%m-%d\")\n\n[1] \"1991-08-29 UTC\"\n\n\n\n\n\n\n\nparse_datetime(\"8/29/1991\", \n               format = \"%m/%d/%Y\")\n\n[1] \"1991-08-29 UTC\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#creating-date-time-objects-1",
    "href": "slides/week-5/week-5-dates.html#creating-date-time-objects-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Creating date-time Objects",
    "text": "Creating date-time Objects"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#common-mistake-with-dates",
    "href": "slides/week-5/week-5-dates.html#common-mistake-with-dates",
    "title": "Using lubridate to Work with Dates",
    "section": "Common Mistake with Dates",
    "text": "Common Mistake with Dates\n\n\n\nas_datetime(2023-02-6)\n\n[1] \"1970-01-01 00:33:35 UTC\"\n\n\n\n\n\n\nmy_date &lt;- 2023-02-6\nmy_date\n\n[1] 2015\n\n\n\n\n\nWhat’s wrong here?\n\n\n\nMake sure you use quotes!\n\n2,015 seconds \\(\\approx\\) 33.5 minutes"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#extracting-date-time-components",
    "href": "slides/week-5/week-5-dates.html#extracting-date-time-components",
    "title": "Using lubridate to Work with Dates",
    "section": "Extracting date-time Components",
    "text": "Extracting date-time Components\n\nbday &lt;- ymd_hms(\"1995-02-27 07:03:12\", \n                tz = \"America/Chicago\")\nbday\n\n[1] \"1995-02-27 07:03:12 CST\"\n\n\n\n\n\n\n\n\nyear(bday)\n\n[1] 1995\n\nmonth(bday)\n\n[1] 2\n\nday(bday)\n\n[1] 27\n\n\n\n\n\n\n\nwday(bday)\n\n[1] 2\n\nwday(bday, \n     label = TRUE, \n     abbr = FALSE)\n\n[1] Monday\n7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#subtraction-with-date-time-objects",
    "href": "slides/week-5/week-5-dates.html#subtraction-with-date-time-objects",
    "title": "Using lubridate to Work with Dates",
    "section": "Subtraction with date-time Objects",
    "text": "Subtraction with date-time Objects\nDoing subtraction gives you a difftime object.\ndifftime objects do not always have the same units – it depends on the scale of the objects you are working with.\n\nHow old am I?\n\ntoday() - mdy(\"02-27-1995\")\n\nTime difference of 11021 days\n\n\n\n\n\nHow long did it take me to type this slide?\n\nbegin &lt;- mdy_hms(\"10/21/2024 20:40:34\")\nfinish &lt;- mdy_hms(\"10/21/2024 20:43:11\")\n\nfinish - begin\n\nTime difference of 2.616667 mins"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#durations-and-periods",
    "href": "slides/week-5/week-5-dates.html#durations-and-periods",
    "title": "Using lubridate to Work with Dates",
    "section": "Durations and Periods",
    "text": "Durations and Periods\n\n\nDurations will always give the time span in an exact number of seconds.\n\nas.duration(\n  today() - mdy(\"02-27-1995\")\n            )\n\n[1] \"952214400s (~30.17 years)\"\n\n\n\n\n\n\nPeriods will give the time span in more approximate, but human readable times.\n\nas.period(\n  today() - mdy(\"02-27-1995\")\n  )\n\n[1] \"11021d 0H 0M 0S\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#durations-and-periods-1",
    "href": "slides/week-5/week-5-dates.html#durations-and-periods-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Durations and Periods",
    "text": "Durations and Periods\n\n\nWe can also add time to date-time objects:\n\ndays(), years(), etc. will add a period of time.\nddays(), dyears(), etc. will add a duration of time.\n\n\n\n\n\nBecause durations use the exact number of seconds to represent days and years, you might get unexpected results.\n\nWhen is is my 99th birthday?\n\nmdy(\"02/27/1995\") + years(99)\n\n[1] \"2094-02-27\"\n\n\n\nmdy(\"02/27/1995\") + dyears(99)\n\n[1] \"2094-02-26 18:00:00 UTC\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#time-zones",
    "href": "slides/week-5/week-5-dates.html#time-zones",
    "title": "Using lubridate to Work with Dates",
    "section": "Time Zones…",
    "text": "Time Zones…\n…are complicated!\n\nSpecify time zones in the form:\n\n{continent}/{city} – “America/Denver”, “Africa/Nairobi”\n{ocean}/{city} – “Pacific/Auckland”\n\n\nWhat time zone does R think I’m in?\n\nSys.timezone()\n\n[1] \"America/Los_Angeles\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#time-zones-1",
    "href": "slides/week-5/week-5-dates.html#time-zones-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Time Zones",
    "text": "Time Zones\nYou can change the time zone of a date in two ways:\n\nx &lt;- ymd_hms(\"2024-10-24 18:00:00\", \n             tz = \"Europe/Copenhagen\")\n\n\n\n\nwith_tz()\n\nKeeps the instant in time the same, but changes the visual representation.\n\nx |&gt; \n  with_tz()\n\n[1] \"2024-10-24 09:00:00 PDT\"\n\nx |&gt; \n  with_tz(tzone = \"Asia/Kolkata\")\n\n[1] \"2024-10-24 21:30:00 IST\"\n\n\n\n\n\n\n\nforce_tz()\n\nChanges the instant in time by forcing a time zone change.\n\nx |&gt; \n  force_tz()\n\n[1] \"2024-10-24 18:00:00 PDT\"\n\nx |&gt; \n  force_tz(tzone = \"Asia/Kolkata\")\n\n[1] \"2024-10-24 18:00:00 IST\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#common-mistake-with-dates-1",
    "href": "slides/week-5/week-5-dates.html#common-mistake-with-dates-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Common Mistake with Dates",
    "text": "Common Mistake with Dates\nWhen you read data in or create a new date-time object, the default time zone (if not specified) is UTC (Universal Time Coordinated)*.\n\nSo, make sure you specify your desired time zone!\n\nx &lt;- mdy(\"11/20/1993\")\ntz(x)\n\n[1] \"UTC\"\n\n\n\nx &lt;- mdy(\"11/20/1993\", \n         tz = \"America/Los_Angeles\")\ntz(x)\n\n[1] \"America/Los_Angeles\"\n\n\n\n*UTC is the same as GMT (Greenwich Mean Time)"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#tips-for-working-with-dates",
    "href": "slides/week-5/week-5-dates.html#tips-for-working-with-dates",
    "title": "Using lubridate to Work with Dates",
    "section": "Tips for Working with Dates",
    "text": "Tips for Working with Dates\n\nAlways just check that you are getting results that you expect!\nPay attention to time zones\nUse the lubridate cheatsheet"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#pa-5.2-jewel-heist",
    "href": "slides/week-5/week-5-dates.html#pa-5.2-jewel-heist",
    "title": "Using lubridate to Work with Dates",
    "section": "PA 5.2: Jewel Heist",
    "text": "PA 5.2: Jewel Heist\n\n\n\n\nUse dates from clues to find the jewel thief!\nMake sure to pay attention to time zones ⏰"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#la-5-murder-in-sql-city",
    "href": "slides/week-5/week-5-dates.html#la-5-murder-in-sql-city",
    "title": "Using lubridate to Work with Dates",
    "section": "LA 5: Murder in SQL City",
    "text": "LA 5: Murder in SQL City\n\n\n\n\nThis lab looks different!\nYou will need a number of steps to follow the clues - it won’t be done in one pipeline\nRead the instructions carefully\nAt the end, try to delete any code or output that you don’t actually need\nCheck with others if you are stuck! You can see if they get the witness or clues answers at that step."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#to-do",
    "href": "slides/week-5/week-5-dates.html#to-do",
    "title": "Using lubridate to Work with Dates",
    "section": "To do…",
    "text": "To do…\n\nPA 5.2: Jewel Heist\n\ndue Friday (5/2) at 11:59pm\n\nLab 5: Murder in SQL City\n\ndue Monday (5/5) at 11:59pm\n\nRead Chapter 6: Version Control\n\nCheck-in 6.1 - 6.2 due Tuesday (5/6) before class\n\nProject Checkpoint 1: Group Formation Survey\n\ndue Tuesday (5/6) at 11:59pm"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-exam---thu-58",
    "href": "slides/week-5/week-5-dates.html#midterm-exam---thu-58",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Exam - Thu 5/8",
    "text": "Midterm Exam - Thu 5/8\n\n\nThis is a three-part exam\nFirst two sections are completed in the one hour and 50 minute class period\n\nYou will first complete a General Questions section on paper and without your computer.\nAfter you turn that in, you will complete a Short Answer section with your computer.\n\nThird section is “takehome” and due 48 hours after the end of class.\n\nThe Take-Home Analysis is completed out of class (should not take more than 3 hours)"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-exam---thu-58-1",
    "href": "slides/week-5/week-5-dates.html#midterm-exam---thu-58-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Exam - Thu 5/8",
    "text": "Midterm Exam - Thu 5/8\n\n\nReview the “What to Expect” document thoroughly as it includes\n\ndetailed expectations\nthe dataset you will be working with\n\nSet yourself up with a dedicated directory that has the data in it\nMake sure to bring to the exam:\n\nsomething to write with (black/blue pen or pencils)\nyour laptop (& a charging chord)\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\nWhile the coding tasks are open-resource, you will likely run out of time if you have to look everything up. Know what functions you might need and where to find documentation for implementing these functions."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html",
    "href": "slides/week-5/week-5-dates.html",
    "title": "Using lubridate to Work with Dates",
    "section": "",
    "text": "Today we will…\n\nLab 4 Tips\nMidterm Exam - What to expect\nNew Material\n\nWorking with Date & Time Variables\n\nPA 5.2: Jewel Heist"
  },
  {
    "objectID": "slides/week-4/w4-factors.html",
    "href": "slides/week-4/w4-factors.html",
    "title": "Extending Data Joins + Factors",
    "section": "",
    "text": "Today we will…\n\nNotes on Lab 3\nProject Info\nNew Material\n\nExtensions to Data Joins\nFactors with forcats\nClean Variable Names\nLifecycle Stages\n\nLab 4: Childcare Costs in California"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#project",
    "href": "slides/week-4/w4-factors.html#project",
    "title": "Extending Data Joins + Factors",
    "section": "Project",
    "text": "Project\n\n\nDetailed information about the project is posted on Canvas\nYou will complete the project in groups of 4\nThe project is scaffolded into 5 “Checkpoints”\n\nThe bulk of the work will be in Weeks 8-10\n\nFirst Checkpoint due 6th Tuesday (5/6) at 11:59pm\n\nFill out a survey to form groups\nYou can specify if there are people you want to work with or have me place you in a group"
  },
  {
    "objectID": "practice-activities/pa5-2-test.html",
    "href": "practice-activities/pa5-2-test.html",
    "title": "PA 5.2: Jewel Heist",
    "section": "",
    "text": "Download starter qmd file\nlibrary(tidyverse)"
  },
  {
    "objectID": "practice-activities/pa5-2-test.html#solve-the-mystery",
    "href": "practice-activities/pa5-2-test.html#solve-the-mystery",
    "title": "PA 5.2: Jewel Heist",
    "section": "Solve the Mystery",
    "text": "Solve the Mystery\nJust down the road in Montecito, CA several rare jewels went missing. The jewels were stolen and replaced with fakes, but detectives have not been able to solve the case. They are now calling in a data scientist to help parse their clues.\nA camera was located near the building where the jewels went missing, so the detectives have provided you with a list of people who may have entered the building. This list includes the date and time they were spotted on the camera, in Pacific Standard Time (PST).\nUnfortunately, the date and time of the jewel heist is not known. You have been hired to crack the case. Use the clues below to discover the thief’s identity.\n\n# 214 total suspects\nsuspects &lt;- read_csv(\"https://raw.githubusercontent.com/zoerehnberg/STAT331-S23/main/practice_activities/suspects.csv\")\n\n\nWhen data is read into R dates are automatically read in as XX time zone. The first thing that we need to do is tell R that the times listed are in PST.\n\n\nsuspects |&gt; \n  mutate(Time.Spotted = force_tz(Time.Spotted)) |&gt; \n  slice_head() |&gt; \n  pull(Time.Spotted)\n\n[1] \"2022-01-29 12:41:00 PST\"\n\n\n\nsuspects &lt;- suspects |&gt; \n  mutate(Time.Spotted = force_tz(Time.Spotted))\n\n\nBased on the cleaning schedule for the room where the jewels are held, the heist was not committed in the morning (i.e. at 12:00pm or later).\n\n\nsuspects &lt;- suspects |&gt; \n  filter(pm(Time.Spotted) == TRUE)\n# end with 112 suspects left\n\n\nThe room where the heist was committed is closed on Tuesdays and Thursdays (and there were no signs of forced entry), so the heist did not happen on those days.\n\n\n# end with 78 suspects left\nsuspects &lt;- suspects |&gt; \n  mutate(weekday = wday(Time.Spotted, \n                        label = TRUE, \n                        abbr = TRUE)) |&gt; \n  filter(!weekday %in% c(\"Tue\", \"Thu\"))\n\n\nIt is believed that the heist was committed within 5 weeks (35 days) of Thanksgiving 2022 (before or after).\n\n\n\n\n\n\n\nHints\n\n\n\nPay attention to time zones!\nYou will want to look up the date of Thanksgiving 2022.\nI would recommend using an interval\n\n\n\n# thankgiving 2022 in PCT\ntg &lt;- mdy(\"11-24-2022\", tz = \"America/Los_Angeles\")\n\n# create interval of 35 days before / after\ntg_interval &lt;- (tg - days(35)) %--% (tg + days(35))\n\nsuspects &lt;- suspects |&gt; \n  filter(Time.Spotted %within% tg_interval)\n# end with 11 suspects left\n\n\nThe detectives partially decoded a message from the thief to a notorious fence in Iceland. In it, the thief said the job would be done “after the sun sets for you, but before midnight.” In November, the sun sets in Iceland at 4:00pm.\n\n\n\n\n\n\n\nHints\n\n\n\nPay attention to time zones!\n\n\n\n# end with 4 suspects left\n\nsuspects &lt;- suspects |&gt; \n  filter(hour(with_tz(Time.Spotted, tzone = \"UTC\")) &gt; 16) \n\n\nThe thief left behind a receipt at the scene of the crime. The receipt is smudged, but the day of the month is shown to be 22. It is thought that the heist took place no more than three days after the receipt was issued.\n\n\n# end with 2 suspects left\n\nsuspects &lt;- suspects |&gt; \n  filter(day(Time.Spotted) %in% 22:25)\n\n\nThe thief is amused by your efforts and has sent you a cryptic clue:\n\n\n“The exact number of seconds between midnight UTC on Jan 1, 1970 and the time I arrived on the scene is divisible by 6.”\n\n\n\n\n\n\n\nHint\n\n\n\nCheck out how date-time objects are stored on the lubridate cheatsheet.\n\n\n\n# end with 1 suspect left\n\nsuspects |&gt; \n  filter(as.numeric(Time.Spotted) %% 6 == 0)\n\n# A tibble: 1 × 4\n  Name        Occupation Time.Spotted        weekday\n  &lt;chr&gt;       &lt;chr&gt;      &lt;dttm&gt;              &lt;ord&gt;  \n1 Danny Ocean idea man   2022-11-25 12:20:30 Fri    \n\n\n\n\n\n\n\n\nCanvas Quiz Submission\n\n\n\nWho is the thief? Only one name should remain. Remember that you can check with classmates and me about the answer!"
  },
  {
    "objectID": "slides/week-5/w5-notes.html",
    "href": "slides/week-5/w5-notes.html",
    "title": "Week 5 - Strings - Starter Notes",
    "section": "",
    "text": "library(tidyverse)\nlibrary(liver)\nlibrary(knitr)\n\ndata(cereal)"
  },
  {
    "objectID": "slides/week-5/w5-notes.html#stringr-functions",
    "href": "slides/week-5/w5-notes.html#stringr-functions",
    "title": "Week 5 - Strings - Starter Notes",
    "section": "stringr Functions",
    "text": "stringr Functions\n\nmy_vector &lt;- c(\"Hello,\",\n               \"my name is\",\n               \"Bond\",\n               \"James Bond\")\n\nstr_\n\nError: object 'str_' not found\n\n\n\nstr_detect()\n\n\nstr_detect(my_vector, pattern = \"Bond\")\n\n[1] FALSE FALSE  TRUE  TRUE\n\n\n\nstr_match()\n\n\nstr_match(my_vector, pattern = \"Bond\")\n\n     [,1]  \n[1,] NA    \n[2,] NA    \n[3,] \"Bond\"\n[4,] \"Bond\"\n\n\n\nstr_extract\n\n\nstr_extract(my_vector, pattern = \"Bond\")\n\n[1] NA     NA     \"Bond\" \"Bond\"\n\n\n\nalt_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond, James Bond\")\n               \nstr_extract(alt_vector, \n            pattern = \"Bond\")\n\n[1] NA     NA     \"Bond\"\n\nstr_extract_all(alt_vector, \n                pattern = \"Bond\")\n\n[[1]]\ncharacter(0)\n\n[[2]]\ncharacter(0)\n\n[[3]]\n[1] \"Bond\" \"Bond\"\n\n\n\nstr_locate\n\n\nstr_locate(my_vector, pattern = \"Bond\")\n\n     start end\n[1,]    NA  NA\n[2,]    NA  NA\n[3,]     1   4\n[4,]     7  10\n\n\n\nstr_subset\n\n\nstr_subset(my_vector, pattern = \"Bond\")\n\n[1] \"Bond\"       \"James Bond\"\n\n\n\nTry it out!\n\n\n\n\n\n\nNote\n\n\n\nFor each of these functions, write down:\n\nthe object structure of the output.\nthe data type of the output.\na brief explanation of what they do.\n\n\n\n\nmy_vector &lt;- c(\"I scream,\",\n               \"you scream\",\n               \"we all\",\n               \"scream\",\n               \"for\",\n               \"ice cream\")\n\nstr_detect(my_vector, pattern = \"cream\")\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n\nstr_locate(my_vector, pattern = \"cream\")\n\n     start end\n[1,]     4   8\n[2,]     6  10\n[3,]    NA  NA\n[4,]     2   6\n[5,]    NA  NA\n[6,]     5   9\n\nstr_match(my_vector, pattern = \"cream\")\n\n     [,1]   \n[1,] \"cream\"\n[2,] \"cream\"\n[3,] NA     \n[4,] \"cream\"\n[5,] NA     \n[6,] \"cream\"\n\nstr_extract(my_vector, pattern = \"cream\")\n\n[1] \"cream\" \"cream\" NA      \"cream\" NA      \"cream\"\n\nstr_subset(my_vector, pattern = \"cream\")\n\n[1] \"I scream,\"  \"you scream\" \"scream\"     \"ice cream\" \n\n\n\nReplace / Remove Patterns\n\n\nstr_replace(my_vector, \n            pattern = \"Bond\", \n            replace = \"Franco\")\n\n[1] \"I scream,\"  \"you scream\" \"we all\"     \"scream\"     \"for\"       \n[6] \"ice cream\" \n\n\n\nstr_remove(my_vector, \n           pattern = \"Bond\")\n\n[1] \"I scream,\"  \"you scream\" \"we all\"     \"scream\"     \"for\"       \n[6] \"ice cream\" \n\n\n\nEdit string cases\n\n\nstr_to_lower(my_vector)\n\n[1] \"i scream,\"  \"you scream\" \"we all\"     \"scream\"     \"for\"       \n[6] \"ice cream\" \n\nstr_to_upper(my_vector)\n\n[1] \"I SCREAM,\"  \"YOU SCREAM\" \"WE ALL\"     \"SCREAM\"     \"FOR\"       \n[6] \"ICE CREAM\" \n\nstr_to_title(my_vector)\n\n[1] \"I Scream,\"  \"You Scream\" \"We All\"     \"Scream\"     \"For\"       \n[6] \"Ice Cream\" \n\n\n\nCombining Strings\n\n\nprompt &lt;- \"Hello, my name is\"\nfirst  &lt;- \"James\"\nlast   &lt;- \"Bond\"\nstr_c(prompt, last, \",\", first, last, sep = \" \")\n\n[1] \"Hello, my name is Bond , James Bond\"\n\n\n\nstr_flatten(my_vector, collapse = \" \")\n\n[1] \"I scream, you scream we all scream for ice cream\"\n\n\n\nfirst &lt;- \"James\"\nlast &lt;- \"Bond\"\nstr_glue(\"My name is {last}, {first} {last}\")\n\nMy name is Bond, James Bond\n\n\n\nCreating new variables\n\n\ncereal |&gt;\n  mutate(is_bran = str_detect(name, \"Bran\"),\n         .after = name) |&gt; \n  slice_head(n = 5) |&gt; \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nis_bran\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nTRUE\nN\ncold\n70\n4\n1\n130\n10\n5\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\n100% Natural Bran\nTRUE\nQ\ncold\n120\n3\n5\n15\n2\n8\n8\n135\n0\n3\n1\n1.00\n33.98368\n\n\nAll-Bran\nTRUE\nK\ncold\n70\n4\n1\n260\n9\n7\n5\n320\n25\n3\n1\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nTRUE\nK\ncold\n50\n4\n0\n140\n14\n8\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\nAlmond Delight\nFALSE\nR\ncold\n110\n2\n2\n200\n1\n14\n8\n-1\n25\n3\n1\n0.75\n34.38484"
  },
  {
    "objectID": "slides/week-5/w5-notes.html#regular-expressions",
    "href": "slides/week-5/w5-notes.html#regular-expressions",
    "title": "Week 5 - Strings - Starter Notes",
    "section": "Regular Expressions",
    "text": "Regular Expressions\n\nwild card .\n\n\nx &lt;- c(\"She\", \n       \"sells\", \n       \"seashells\", \n       \"by\", \n       \"the\", \n       \"seashore!\")\n\nstr_subset(x, pattern = \".ells\")\n\n[1] \"sells\"     \"seashells\"\n\nstr_extract(x, pattern = \".ells\")\n\n[1] NA      \"sells\" \"hells\" NA      NA      NA     \n\n\n\nanchors\n\n\nstr_subset(x, pattern = \"^s\")\n\n[1] \"sells\"     \"seashells\" \"seashore!\"\n\nstr_subset(x, pattern = \"s$\")\n\n[1] \"sells\"     \"seashells\"\n\n\n\nrepeated characters\n\n\nx &lt;- c(\"shes\", \n       \"shels\", \n       \"shells\", \n       \"shellls\", \n       \"shelllls\")\n\nstr_subset(x, pattern = \"shel?s\")\n\n[1] \"shes\"  \"shels\"\n\nstr_subset(x, pattern = \"shel+s\")\n\n[1] \"shels\"    \"shells\"   \"shellls\"  \"shelllls\"\n\nstr_subset(x, pattern = \"shel*s\")\n\n[1] \"shes\"     \"shels\"    \"shells\"   \"shellls\"  \"shelllls\"\n\nstr_subset(x, pattern = \"shel{2}s\")\n\n[1] \"shells\"\n\nstr_subset(x, pattern = \"shel{2,}s\")\n\n[1] \"shells\"   \"shellls\"  \"shelllls\"\n\nstr_subset(x, pattern = \"shel{1,3}s\")\n\n[1] \"shels\"   \"shells\"  \"shellls\"\n\n\n\ncharacter groups ()\n\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\", \n       \"peck\",\n       \"of\", \n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p(e|i)ck\")\n\n[1] \"picked\"  \"peck\"    \"pickled\"\n\n\n\nx &lt;- c(\"hannah\", \n       \"had\", \n       \"a\", \n       \"ball\", \n       \"on\",\n       \"a\", \n       \"race car\")\n\nstr_subset(x, pattern = \"^(.).*\\\\1$\")\n\n[1] \"hannah\"   \"race car\"\n\n\n\nshopping_list &lt;- c(\"apples x4\", \n                   \"bag of flour\", \n                   \"bag of sugar\", \n                   \"milk x2\")\n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\")\n\n[1] \"apples x4\" NA          NA          \"milk x2\"  \n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\", group = 1)\n\n[1] \"apples\" NA       NA       \"milk\"  \n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\", group = 2)\n\n[1] \"4\" NA  NA  \"2\"\n\n\n\ncharacter classes []\nanti-match [^]\n\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\",\n       \"peck\",\n       \"of\",\n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p[ei]ck\")\n\n[1] \"picked\"  \"peck\"    \"pickled\"\n\nstr_subset(x, pattern = \"p[^i]ck\")\n\n[1] \"peck\"\n\nstr_subset(x, pattern = \"^p\")\n\n[1] \"picked\"   \"peck\"     \"pickled\"  \"peppers!\"\n\nstr_subset(x, pattern = \"^[^p]\")\n\n[1] \"Peter\" \"Piper\" \"a\"     \"of\"   \n\nstr_subset(x, pattern = \"p[ei]ck[a-z]\")\n\n[1] \"picked\"  \"pickled\"\n\n\n\nshortcuts\n\n\nx &lt;- \"phone number: 1234567899\"\n\nstr_extract(x, pattern = \"\\\\d+\")\n\n[1] \"1234567899\"\n\nstr_extract_all(x, pattern = \"\\\\S+\")\n\n[[1]]\n[1] \"phone\"      \"number:\"    \"1234567899\"\n\n\n\nTry it out!\n\nx &lt;- c(\"zebra\", \n       \"xray\", \n       \"apple\", \n       \"yellow\",\n       \"color\", \n       \"colour\",\n       \"summarize\",\n       \"summarise\")\n\nWhat regular expressions would match words that… + end with a vowel? + start with x, y, or z? + contains two of the same letters in a row? + contain British spelling?\n\nstr_subset(x, pattern = \"[aeiou]$\")\n\n[1] \"zebra\"     \"apple\"     \"summarize\" \"summarise\"\n\nstr_subset(x, pattern = \"^[xyz]\")\n\n[1] \"zebra\"  \"xray\"   \"yellow\"\n\nstr_subset(x, pattern = \"(.)\\\\1\")\n\n[1] \"apple\"     \"yellow\"    \"summarize\" \"summarise\"\n\nstr_subset(x, pattern = \".{2}\")\n\n[1] \"zebra\"     \"xray\"      \"apple\"     \"yellow\"    \"color\"     \"colour\"   \n[7] \"summarize\" \"summarise\"\n\nstr_subset(x, pattern = \"our$|ise$\")\n\n[1] \"colour\"    \"summarise\"\n\nstr_subset(x, pattern = \"our|i[zs]e\")\n\n[1] \"colour\"    \"summarize\" \"summarise\"\n\n\n\nescape characters \\\\\n\n\nx &lt;- c(\"How\",\n       \"much\", \n       \"wood\",\n       \"could\",\n       \"a\",\n       \"woodchuck\",\n       \"chuck\",\n       \"if\",\n       \"a\",\n       \"woodchuck\",\n       \"could\",\n       \"chuck\",\n       \"wood?\")\n\nstr_subset(x, pattern = \"?\")\n\nError in stri_subset_regex(string, pattern, omit_na = TRUE, negate = negate, : Syntax error in regex pattern. (U_REGEX_RULE_SYNTAX, context=`?`)\n\nstr_subset(x, pattern = \"\\\\?\")\n\n[1] \"wood?\"\n\nstr_subset(x, pattern = \"[?]\")\n\n[1] \"wood?\"\n\n\n\ntesting regular expressions\n\n\nstr_view(c(\"shes\", \"shels\", \"shells\", \"shellls\", \"shelllls\"), \"l+\")\n\n[2] │ she&lt;l&gt;s\n[3] │ she&lt;ll&gt;s\n[4] │ she&lt;lll&gt;s\n[5] │ she&lt;llll&gt;s\n\n\n\n\nMore practice 1\n\ncounty_pop &lt;- data.frame(county = c(\"STORY\", \"BOONE\", \"MARSHALL\", \"POLK\"),\n                         pop = c(100000, 40000, 120000, 500000))\n\ncounty_loc &lt;- data.frame(county = c(\"Story\", \"Boone\", \"Marshall\", \"Polk\"),\n                         region = c(\"Central\", \"Central\", \"East\", \"Central\"))\n\nJoin the county_pop and county_loc by county\n\ncounty_pop |&gt; \n  mutate(county = str_to_title(county)) |&gt; \n  left_join(county_loc, by = \"county\")\n\n    county    pop  region\n1    Story 100000 Central\n2    Boone  40000 Central\n3 Marshall 120000    East\n4     Polk 500000 Central\n\n\n\n\nMore practice 2\n\nphone_numbers &lt;- c(\"(515)242-1958\", \"(507)598-1395\", \"(805)938-7639\")\n\nPull out only the area code in a phone number.\n\n# code\n\n\n\nMore practice 3\n\nawards_dat &lt;- data.frame(awards = c(\"Beyonce: 35G,  0A, 0E\",\n                                    \"Kendrick Lamar: 22G, 0A, 1E\",\n                                    \"Charli XCX: 2G, 0A, 0E\",\n                                    \"Cynthia Erivo: 1G, 0A, 1E\",\n                                    \"Viola Davis: 1G, 1A, 1E\",\n                                    \"Elton John: 6G, 2A, 1E\"))\n\nCreate a variable with just the artist name and a variable with the number of Grammys won.\n\nawards_dat |&gt; \n  mutate(artist = str_extract(awards, \".*:\"))\n\n                       awards          artist\n1       Beyonce: 35G,  0A, 0E        Beyonce:\n2 Kendrick Lamar: 22G, 0A, 1E Kendrick Lamar:\n3      Charli XCX: 2G, 0A, 0E     Charli XCX:\n4   Cynthia Erivo: 1G, 0A, 1E  Cynthia Erivo:\n5     Viola Davis: 1G, 1A, 1E    Viola Davis:\n6      Elton John: 6G, 2A, 1E     Elton John:"
  },
  {
    "objectID": "slides/week-5/w5-notes.html#dates",
    "href": "slides/week-5/w5-notes.html#dates",
    "title": "Week 5 - Strings - Starter Notes",
    "section": "Dates",
    "text": "Dates\n\nload(\"ca-childcare.Rdata\")\n\nError in readChar(con, 5L, useBytes = TRUE): cannot open the connection"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#clean-and-combine-the-data",
    "href": "labs/lab5/lab5-murder.html#clean-and-combine-the-data",
    "title": "Lab 5: Murder in SQL City",
    "section": "Clean and Combine the Data",
    "text": "Clean and Combine the Data\nLet’s set ourselves up to solve this crime lickity-split!\n0.1 Use a stringr function(s) and a regular expression(s) to create address_number and address_street_name columns in the person dataset. Convert the address_number variable to numeric.\n\n# code for Q0.1\n\n0.2 Design and implement a check that you created the address_number and address_street_name columns correctly.\n\n\n\n\n\n\nHint\n\n\n\nFor example, if you re-combine the address_number and address_street_name columns, you should get the same value as original address column exactly.\n\n\n\n# code for Q0.2\n\n0.3 Create two new datasets:\n\nget_fit_now_full\n\nevery row represents one visit to the “Get Fit Now” gym.\nall member information is included (e.g. check in times, names, and membership information)\nshould have 2,703 rows and 8 columns\n\nsuspects_all\n\neach row represents one person\nincludes their address, driver’s licence information, income, and interview with the police, if they have one\ndrop the address column\nshould have 10,011 rows and 16 columns\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t worry about missing values! We are just gathering all of the information that we have about everyone.\n\n\n\n# code to create get_fit_now_full\n\n\n# code to create suspects_all"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#tuesday-may-5",
    "href": "slides/week-6/w6-version-control.html#tuesday-may-5",
    "title": "Version Control",
    "section": "Tuesday, May 5",
    "text": "Tuesday, May 5\nToday we will…\n\nOpen-Ended Analysis from Lab 4\nQuestions about Midterm?\nNew Material\n\ngit/GitHub\nConnect GitHub to RStudio\n\nPA 6: Merge Conflicts – Collaborating within a GitHub Repo"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#open-ended-analysis-from-lab-4",
    "href": "slides/week-6/w6-version-control.html#open-ended-analysis-from-lab-4",
    "title": "Version Control",
    "section": "Open-Ended Analysis from Lab 4",
    "text": "Open-Ended Analysis from Lab 4\nResearch Question\n\n\nKeep it general\nWe are doing an exploratory analysis - not statistical testing\n\n\nWritten Description\n\n\nDo not use variable names or R function names in your written text.\nBreaking up sections with headers can help with organization and flow.\nDo not print out the data!!!"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#open-ended-analysis-from-week-5",
    "href": "slides/week-6/w6-version-control.html#open-ended-analysis-from-week-5",
    "title": "Version Control",
    "section": "Open-Ended Analysis from Week 5",
    "text": "Open-Ended Analysis from Week 5\nDiscussing Data\n\n\nWhat would you need to tell something if they knew nothing about the data already?? Probably should include:\n\nData source\nObservational unit / level (e.g. county and year)\nOverview of what is included (e.g. demographic incormation and weekly median childcare costs for each county and year)\nYears or geographies included (e.g. 2008-2018, CA only)\n\nIf you are taking a statistical summary you should be clear what the summary is taken over"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#open-ended-analysis-from-week-5-1",
    "href": "slides/week-6/w6-version-control.html#open-ended-analysis-from-week-5-1",
    "title": "Version Control",
    "section": "Open-Ended Analysis from Week 5",
    "text": "Open-Ended Analysis from Week 5\n\nTable Design\n\nThink about the number of rows/columns – is it readable?\nHow many decimal points are needed?\nChange row/column names to be understandable.\n\nPlot Design\n\nWhat can I investigate with a plot that is difficult with a table?\nWhat type of plot will best display the data?\nWhat order of elements will best display the comparison you want to make?\nThink about: colors, order of categories, if a legend is needed, etc."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#what-is-version-control",
    "href": "slides/week-6/w6-version-control.html#what-is-version-control",
    "title": "Version Control",
    "section": "What is version control?",
    "text": "What is version control?\n\n\nA process of tracking changes to a file or set of files over time so that you can recall specific versions later."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#git-vs-github",
    "href": "slides/week-6/w6-version-control.html#git-vs-github",
    "title": "Version Control",
    "section": "Git vs GitHub",
    "text": "Git vs GitHub\n\n\n\n\n\n\n\n\n\n\n\n\nA system for version control that manages a collection of files in a structured way.\nUses the command line or a GUI.\nGit is local."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#git-vs-github-1",
    "href": "slides/week-6/w6-version-control.html#git-vs-github-1",
    "title": "Version Control",
    "section": "Git vs GitHub",
    "text": "Git vs GitHub\n\n\n\n\n\n\n\n\n\n\n\n\nA system for version control that manages a collection of files in a structured way.\nUses the command line or a GUI.\nGit is local.\n\n\n\n\n\n\n\n\n\n\n\n\nA cloud-based service that lets you use git across many computers.\nBasic services are free, advanced services are paid (like RStudio!).\nGitHub is remote."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#why-learn-github",
    "href": "slides/week-6/w6-version-control.html#why-learn-github",
    "title": "Version Control",
    "section": "Why Learn GitHub?",
    "text": "Why Learn GitHub?\n\n\nGitHub provides a structured way for tracking changes to files over the course of a project.\n\n\nThink Google Docs or Dropbox history, but more structured and powerful!\n\n\nShare your work transparently!\nDesigned for programming collaboration and project management.\nYou can host a URL of fun things (like the class text, these slides, a personal website, etc.) with GitHub pages."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#in-this-class",
    "href": "slides/week-6/w6-version-control.html#in-this-class",
    "title": "Version Control",
    "section": "In this class…",
    "text": "In this class…\n\nWe just want to introduce you to the basics of Git and GitHub\nThere is a lot more cool functionality in both!\nCome chat with me if you want to learn more"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#git-repositories",
    "href": "slides/week-6/w6-version-control.html#git-repositories",
    "title": "Version Control",
    "section": "Git Repositories",
    "text": "Git Repositories\nGit is based on repositories.\n\n\n\nThink of a repository (repo) as a directory (folder) for a single project.\n\nThis directory will likely contain code, documentation, data, to do lists, etc. associated with the project.\nYou can link a local repo with a remote copy on GitHub.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo create a repository, you can start with your local computer or you can start with the remote copy."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#git-repositories-1",
    "href": "slides/week-6/w6-version-control.html#git-repositories-1",
    "title": "Version Control",
    "section": "Git Repositories",
    "text": "Git Repositories\n\nLocal repoRemote copy on GitHub"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#what-does-git-do-very-basics",
    "href": "slides/week-6/w6-version-control.html#what-does-git-do-very-basics",
    "title": "Version Control",
    "section": "What does Git do?? (very basics)",
    "text": "What does Git do?? (very basics)\nBy default:\n\nGit tracks changes in any documents in a given repo\nGit records any changes to lines in the document since the last version of the document was saved (committed)\n\nYou need to:\n\nTell Git if there are files you don’t want it to track (.gitignore)\nTell Git when to save changes to the repo (commit)\n\nOnce you do that, you can always look back on your previous versions and changes!"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#gitignore",
    "href": "slides/week-6/w6-version-control.html#gitignore",
    "title": "Version Control",
    "section": ".gitignore",
    "text": ".gitignore\nSometimes there are files that you do not want to track.\n\nA .gitignore file specifies the files that git should intentionally ignore.\n\nNote that annoyingly a .gitignore is an “invisible file” in many file browsers\n\nOften you want to ignore machine generated files (e.g., /bin, .DS_Store) or files/directories that you do not want to be shared (e.g., solutions/).\nWe want to ignore .Rproj files!"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#gitignore-example",
    "href": "slides/week-6/w6-version-control.html#gitignore-example",
    "title": "Version Control",
    "section": ".gitignore example",
    "text": ".gitignore example\n\nDr. C’s .gitignore for her STAT 331 materials repo"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#cloning-a-repo",
    "href": "slides/week-6/w6-version-control.html#cloning-a-repo",
    "title": "Version Control",
    "section": "Cloning a Repo",
    "text": "Cloning a Repo\n\n\n\nCreate an exact copy of a remote repo on your local machine."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#committing-changes",
    "href": "slides/week-6/w6-version-control.html#committing-changes",
    "title": "Version Control",
    "section": "Committing Changes",
    "text": "Committing Changes\nTell git you have made changes you want to add (save) to the repo.\n\nAlso provide a commit message – a short label describing what the changes are and why they exist.\n\n\n\nThe red line is a change we commit (add) to the repo.\n\n\n\n\n\n\n\n\n\n\n\n\nThe log of these changes (and the file history) is called your git commit history.\n\nYou can always go back to old copies!"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#commit-tips",
    "href": "slides/week-6/w6-version-control.html#commit-tips",
    "title": "Version Control",
    "section": "Commit Tips",
    "text": "Commit Tips\n\nUse short, but informative commit messages.\nCommit small blocks of changes – commit every time you accomplish a small task.\n\nYou’ll have a set of bite-sized changes (with description) to serve as a record of what you’ve done.\n\nWith frequent commits its easier to\n\nfind the issue when you mess up!\nread back through what you changed!"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#pushing-changes",
    "href": "slides/week-6/w6-version-control.html#pushing-changes",
    "title": "Version Control",
    "section": "Pushing Changes",
    "text": "Pushing Changes\n\n\n\nUpdate the copy of your repo on GitHub so it has the most recent changes you’ve made on your machine."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#pulling-changes",
    "href": "slides/week-6/w6-version-control.html#pulling-changes",
    "title": "Version Control",
    "section": "Pulling Changes",
    "text": "Pulling Changes\n\n\n\nUpdate the local copy of your repo (the copy on your computer) with the version on GitHub."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#pushing-and-pulling",
    "href": "slides/week-6/w6-version-control.html#pushing-and-pulling",
    "title": "Version Control",
    "section": "Pushing and Pulling",
    "text": "Pushing and Pulling"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#workflow",
    "href": "slides/week-6/w6-version-control.html#workflow",
    "title": "Version Control",
    "section": "Workflow",
    "text": "Workflow\nWhen you have an existing local repo:\n\n\nPull the repo (especially if collaborating).\nMake some changes locally.\nCommit the changes to git.\nPull any changes from the remote repository (again!).\nResolve any merge conflicts.\nPush your changes to GitHub."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#section",
    "href": "slides/week-6/w6-version-control.html#section",
    "title": "Version Control",
    "section": "",
    "text": "Artwork by Allison Horst"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#merge-conflicts-1",
    "href": "slides/week-6/w6-version-control.html#merge-conflicts-1",
    "title": "Version Control",
    "section": "Merge Conflicts",
    "text": "Merge Conflicts\nThese occur when git encounters conflicting changes."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#merge-conflicts-2",
    "href": "slides/week-6/w6-version-control.html#merge-conflicts-2",
    "title": "Version Control",
    "section": "Merge Conflicts",
    "text": "Merge Conflicts\n\nMaybe you are working in real time on the same line of code or text as a collaborator.\nMaybe you forgot to push your changes the last time you finished working.\nMaybe you forgot to pull your changes before you started working this time."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#merge-conflicts-3",
    "href": "slides/week-6/w6-version-control.html#merge-conflicts-3",
    "title": "Version Control",
    "section": "Merge Conflicts",
    "text": "Merge Conflicts\nWe will work on resolving merge conflicts today!\n\n\nBut when all else fails…\n\ndelete your local repo and clone again.\n\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#tips-for-avoiding-merge-conflicts",
    "href": "slides/week-6/w6-version-control.html#tips-for-avoiding-merge-conflicts",
    "title": "Version Control",
    "section": "Tips for Avoiding Merge Conflicts",
    "text": "Tips for Avoiding Merge Conflicts\n\nAlways pull before you start working and always push after you are done working!\n\nIf you do this, you will only have problems if two people are making local changes to the same line in the same file at the same time.\n\n\n\n\nIf you are working with collaborators in real time, pull, commit, and push often.\n\n\n\n\nGit commits lines – lines of code, lines of text, etc.\n\nPractice good code format – no overly long lines!"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#install-load-r-packages",
    "href": "slides/week-6/w6-version-control.html#install-load-r-packages",
    "title": "Version Control",
    "section": "Install + Load R Packages",
    "text": "Install + Load R Packages\nWork in your console or an Rscript for this.\n\nInstall and load the usethis package.\n\n\ninstall.packages(\"usethis\")\nlibrary(usethis)\n\n\nInstall and load the gitcreds Package.\n\n\ninstall.packages(\"gitcreds\")\nlibrary(gitcreds)"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#configure-git",
    "href": "slides/week-6/w6-version-control.html#configure-git",
    "title": "Version Control",
    "section": "Configure git",
    "text": "Configure git\n\nTell git your email and GitHub username.\n\n\nuse_git_config(user.name = \"JaneDoe2\", user.email = \"jane@example.org\")\n\n(Nothing should happen.)"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#generate-your-personal-access-token",
    "href": "slides/week-6/w6-version-control.html#generate-your-personal-access-token",
    "title": "Version Control",
    "section": "Generate your Personal Access Token",
    "text": "Generate your Personal Access Token\n\nGenerate a PAT.\n\n\ncreate_github_token()\n\n\nThis will open GitHub and ask you to log in.\nFill in a Note and an Expiration (AT LEAST 60 days from now).\nClick Generate Token."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#store-your-pat",
    "href": "slides/week-6/w6-version-control.html#store-your-pat",
    "title": "Version Control",
    "section": "Store your PAT",
    "text": "Store your PAT\n\nCopy your PAT.\n\n\n\nRun the following code.\n\n\ngitcreds_set()\n\nWhen prompted to Enter password or token:, paste your PAT."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#verify-your-pat",
    "href": "slides/week-6/w6-version-control.html#verify-your-pat",
    "title": "Version Control",
    "section": "Verify your PAT",
    "text": "Verify your PAT\n\nLet’s verify.\n\n\ngit_sitrep()"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#pa-6-merge-conflicts",
    "href": "slides/week-6/w6-version-control.html#pa-6-merge-conflicts",
    "title": "Version Control",
    "section": "PA 6: Merge Conflicts",
    "text": "PA 6: Merge Conflicts\nYou will be completing this activity in groups of 4.\n\n\n\n\n\n\nIMPORTANT\n\n\nThis activity will only work if you follow the directions in the exact order that I have specified them. Do not work ahead of your group members!\n\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#to-do",
    "href": "slides/week-6/w6-version-control.html#to-do",
    "title": "Version Control",
    "section": "To do…",
    "text": "To do…\n\nPA 6: Merge Conflicts\n\nDue Monday, 5/6 at 11:59pm – TODAY.\n\nMidterm Exam\n\nWednesday, 5/8 + 48 hours.\n\n\n\n\n\n\n\n\nOffice Hours\n\n\nWednesday from 9-10 am and 1-2 pm\nNone scheduled on Friday but available upon request."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#tuesday-may-6",
    "href": "slides/week-6/w6-version-control.html#tuesday-may-6",
    "title": "Version Control",
    "section": "Tuesday, May 6",
    "text": "Tuesday, May 6\nToday we will…\n\nOpen-Ended Analysis from Lab 4\nQuestions about Midterm?\nNew Material\n\ngit/GitHub\nConnect GitHub to RStudio\n\nPA 6: Merge Conflicts – Collaborating within a GitHub Repo"
  },
  {
    "objectID": "practice-activities/pa6.html",
    "href": "practice-activities/pa6.html",
    "title": "PA 6: Merge Conflicts",
    "section": "",
    "text": "In this practice activity, you will be working in groups to create a new GitHub repository. You will practice pushing, pulling, and resolving conflicts as a team."
  },
  {
    "objectID": "practice-activities/pa6.html#get-into-groups",
    "href": "practice-activities/pa6.html#get-into-groups",
    "title": "PA 6: Merge Conflicts",
    "section": "Get into Groups!",
    "text": "Get into Groups!\nForm groups of four people. Designate each person one of the suits:\n\n\n\nAs you work through the activity, you will complete the steps assigned to your suit. Make sure you complete the steps in order and only complete the steps assigned to you!\n\n\n\n\n\n\nNote\n\n\n\nIf you only have 3 group members here, assign one person both  and ."
  },
  {
    "objectID": "practice-activities/pa6.html#repository-setup",
    "href": "practice-activities/pa6.html#repository-setup",
    "title": "PA 6: Merge Conflicts",
    "section": "Repository Setup",
    "text": "Repository Setup\n\n1. Create a Repo on GitHub.\n\n\nCreate a new Github repo: Repositories &gt; New .\n\nName the repo stat331-PA6.\nYou can choose to make it Public or Private.\nSelect .gitignore template: R.\n\nAfter creating the repo, go to Settings &gt; Collaborators &gt; Add people.\n\nAdd your group members using their username or email.\n\n\n\n\n2. Access the Remote Repo.\n  \n\nAccept the repo invite in your email – View invite &gt; Accept invite.\nOpen the repo on GitHub.\n\n\n\n3. Clone the Remote Repo Locally.\n   \n\nIn Rstudio: File &gt; New Project &gt; Version Control &gt; Git.\nIn GitHub: click &lt;&gt; Code and copy the HTTPS address.\nIn Rstudio: paste the address as the Repository URL. Leave the directory name box blank.\nClick Browse and create this new project on your desktop.\n\nDo not save this in your STAT 331 folder!!! We don’t want to embed an Rproj within another Rproj.\n\nCreate Project."
  },
  {
    "objectID": "practice-activities/pa6.html#collaborating-in-github",
    "href": "practice-activities/pa6.html#collaborating-in-github",
    "title": "PA 6: Merge Conflicts",
    "section": "Collaborating in GitHub",
    "text": "Collaborating in GitHub\n\n4. Add Documents to the Repo.\n\n\nIn RStudio, create a new Quarto file.\n\nChange the title to “Practice Activity 6”.\nResist the urge to add authors.\nSave as PA6.qmd in your new stat331-PA6 folder on your desktop.\nAdd embed-resources: true to the YAML.\nKeep the default template as is.\nRender the document.\n\nIn RStudio, open and edit the .gitignore file to include *.Rproj and *.html.\n\nYour directory stat331-PA6 should have the following files:\n\n.gitignore\nPA6.qmd\nPA6.html\nstat331-PA6.Rproj\n\n\n\n5. Push Documents to GitHub.\n\n\nRstudio: Git pane.\n\nStage (checkmark) the .gitignore &gt; Commit &gt; add a commit message (“ignore all .Rproj files and .html files”) &gt; Commit &gt; Close.\nStage (checkmark) PA6.qmd &gt; Commit &gt; add a commit message (“create PA quarto file”) &gt; Commit &gt; Close.\n\nRstudio: Git pane &gt; Push the changes to the remote repo.\n\n\n\n6. Pull Changes from GitHub.\n  \n\nRstudio: Git pane &gt; Pull the changes that were made!\n\nEveryone should now have the .qmd and updated .gitignore files in their local repo!\n\nLook in your Files pane to make sure.\n\n\n\n7. Make a Change.\n\n\nDirectly under the title: line, add author: to the YAML and include everyone’s first names.\nRender the document.\nRstudio: Git pane &gt; Stage (checkmark) files &gt; Commit &gt; add commit message &gt; Commit &gt; Close.\n\nUse a commit message like “add first names”.\n\nRstudio: Git pane &gt; Push the changes.\n\n\n\n8. Forget to Pull.\n  \nDo NOT pull the changes that were made!\n\n\n9. Make the Same Change.\n\n\nDirectly under the title: line, add author: to the YAML and include everyone’s first and last names.\nRender the document.\nRstudio: Git pane &gt; Stage (checkmark) files &gt; Commit &gt; add commit message &gt; Commit &gt; Close.\n\nUse a commit message like “add first and last names”.\n\nRstudio: Git pane &gt; Push the changes.\n\n\n\n\n\n\n\nOh No!\n\n\n\nYou got an error! Ugh. We forgot to pull before we started making changes.\n\n\n\n\n\n10. Resolve the Merge Conflict.\n\nRstudio: Git pane &gt; Pull the changes from the repo.\n\n\n\n\n\n\nREAD THIS - did it work??\n\n\n\nIf your Git Pull window does NOT look like this…\n\nbut maybe it looks like this:\n\nthen…\n\ncopy-paste the first command: git config pull.rebase false into the Terminal in RStudio pane and hit Enter,\nand Pull again.\n\n\n\nYour Quarto file should now look like this…\n\n\n\n\n\n\n\nTip\n\n\n\nNote how the conflicting lines are marked! You might need to submit this to Canvas…\n\n\n\nEdit the .qmd file to resolve the conflict with your preferred change. Render.\nNote that in the Rstudio Git window, your files will be marked with “U”s to indicate a merge conflict.\n\n\n\nCommit your changes.\nPush your changes to GitHub.\n\n\n\n11. Forget to Pull.\n  \nDo NOT pull the changes that were made!\n\n\n12. Make a Different Change.\n\n\nEdit the first code chunk to find the product of \\(13 \\times 13\\).\nRender the document.\nCommit your changes and Push your changes to GitHub.\n\n\n\n\n\n\n\nWarning\n\n\n\nYou will get an error, read it and Pull.\n\n\n\nNo merge conflicts should occur – the changes were auto-merged!\n\nYour merge may have been made by a different strategy, but that’s okay.\n\n\n\n\nPush your changes again.\n\n\n\n13. Forget to Pull.\n  \nDo NOT pull the changes that were made!\n\n\n14. Make the Same Change (Again).\n\n\nEdit the first code chunk to find the product of \\(11 \\times 11\\).\nRender the document.\nCommit your changes and Push your changes to GitHub.\n\n\n\n\n\n\n\nWarning\n\n\n\nYou will get an error. Ugh!!!! We forgot to pull again!\n\n\n\nPull the changes from GitHub.\nEdit the .qmd file to resolve the conflict with the preferred change.\nCommit your changes and Push your changes to GitHub.\n\n\n\n15. Final Document\n   \nPull the changes and look at your final document.\n\n\n\n\n\n\nCanvas Quiz Submission\n\n\n\nHow does Git mark the start of lines with a merge conflict?\n\nSpecifically, I want the four capital characters with which every conflict is marked."
  },
  {
    "objectID": "slides/week-6/w6-midterm-exam.html",
    "href": "slides/week-6/w6-midterm-exam.html",
    "title": "Midterm Exam",
    "section": "",
    "text": "Right now, the only thing on your desk should be something to write with.\nI will pass out a hard copy of the exam.\nDo not look past the first page until I say you can start.\nCanvas will unlock the .qmd template at the beginning of class.\n\nYou are great!!"
  },
  {
    "objectID": "slides/week-6/w6-midterm-exam.html#wednesday-feb-12-midterm-exam",
    "href": "slides/week-6/w6-midterm-exam.html#wednesday-feb-12-midterm-exam",
    "title": "Midterm Exam",
    "section": "Wednesday, Feb 12 – Midterm Exam",
    "text": "Wednesday, Feb 12 – Midterm Exam\nSection 1: General Questions\n\nCannot work on Section 2 until hand Section 1 to me.\n\nSection 2: Short Answer\n\nNow you can use anything you want except other people and AI.\nDownload .qmd template from Canvas.\nSubmit .qmd and .html files on Canvas by the end of class.\n\nSection 3: Open-Ended Analysis – After Class"
  },
  {
    "objectID": "slides/week-6/w6-midterm-exam.html#wednesday-feb-12-midterm-exam-1",
    "href": "slides/week-6/w6-midterm-exam.html#wednesday-feb-12-midterm-exam-1",
    "title": "Midterm Exam",
    "section": "Wednesday, Feb 12 – Midterm Exam",
    "text": "Wednesday, Feb 12 – Midterm Exam\nSection 1: General Questions\n\nCannot work on Section 2 until hand Section 1 to me.\n\nSection 2: Short Answer\n\nNow you can use anything you want except other people and ChatGPT.\nDownload .qmd template from Canvas.\nSubmit .qmd and .html files on Canvas by the end of class.\n\nSection 3: Open-Ended Analysis – After Class"
  },
  {
    "objectID": "slides/week-6/w6-midterm-exam.html#to-do",
    "href": "slides/week-6/w6-midterm-exam.html#to-do",
    "title": "Midterm Exam",
    "section": "To do…",
    "text": "To do…\n\nRead Chapter 7: Writing Functions\n\nCheck-in 7.1 due Tuesday, 5/13 before class\n\nFinal Project Group Contract\n\nI assigned groups and posted them on Canvas\nFind some time to meet or coordinate with your assigned group to work on this next week\nDue next Friday, 5/16 at 11:59pm"
  },
  {
    "objectID": "slides/week-6/w6-midterm-exam.html#thursday-may-8-midterm-exam",
    "href": "slides/week-6/w6-midterm-exam.html#thursday-may-8-midterm-exam",
    "title": "Midterm Exam",
    "section": "Thursday, May 8 – Midterm Exam",
    "text": "Thursday, May 8 – Midterm Exam\n\nRight now, the only thing on your desk should be something to write with.\nI will pass out a hard copy of the exam.\nDo not look past the first page until I say you can start.\nCanvas will unlock the .qmd template at the beginning of class.\n\nYou are great!!"
  },
  {
    "objectID": "slides/week-6/w6-midterm-exam.html#thursday-may-8-midterm-exam-1",
    "href": "slides/week-6/w6-midterm-exam.html#thursday-may-8-midterm-exam-1",
    "title": "Midterm Exam",
    "section": "Thursday, May 8 – Midterm Exam",
    "text": "Thursday, May 8 – Midterm Exam\nSection 1: General Questions\n\nCannot work on Section 2 until hand Section 1 to me.\n\nSection 2: Short Answer\n\nNow you can use anything you want except other people and AI.\nDownload the .qmd template from Canvas.\nSubmit .qmd and .html files on Canvas by the end of class.\nReturn the question sheet to me ehrn you finish.\n\nSection 3: Open-Ended Analysis – After Class"
  },
  {
    "objectID": "labs/lab7/la7-functions.html",
    "href": "labs/lab7/la7-functions.html",
    "title": "Lab 7: Functions + Fish",
    "section": "",
    "text": "Download .qmd starter file\nDownload BlackfootFish.csv\nThe goal of this lab is learn more about exploring missing data and writing modular code.\nlibrary(tidyverse)\nfish &lt;- read.csv(\"BlackfootFish.csv\")"
  },
  {
    "objectID": "labs/lab7/la7-functions.html#the-data",
    "href": "labs/lab7/la7-functions.html#the-data",
    "title": "Lab 7: Functions + Fish",
    "section": "The Data",
    "text": "The Data\nThis lab’s data concerns mark-recapture data on four species of trout from the Blackfoot River outside of Helena, Montana. These four species are rainbow trout (RBT), westslope cutthroat trout (WCT), bull trout, and brown trout.\n\nMark-recapture is a common method used by ecologists to estimate a population’s size when it is impossible to conduct a census (count every animal). This method works by tagging animals with a tracking device so that scientists can track their movement and presence."
  },
  {
    "objectID": "labs/lab7/la7-functions.html#data-exploration",
    "href": "labs/lab7/la7-functions.html#data-exploration",
    "title": "Lab 7: Functions + Fish",
    "section": "Data Exploration",
    "text": "Data Exploration\nThe measurements of each captured fish were taken by a biologist on a raft in the river. The lack of a laboratory setting opens the door to the possibility of measurement errors.\n1. Let’s look for missing values in the dataset. Output ONE table that answers BOTH of the following questions:\n\nHow many observations have missing values?\nWhat variable(s) have missing values present?\n\n\n\n\n\n\n\nTip\n\n\n\nHint: use across().\n\n\n\n# Code for Q1.\n\n2. Create ONE thoughtful visualization that explores the frequency of missing values across the different years, sections, and trips.\n\n# Code for Q2."
  },
  {
    "objectID": "labs/lab7/la7-functions.html#rescaling-the-data",
    "href": "labs/lab7/la7-functions.html#rescaling-the-data",
    "title": "Lab 7: Functions + Fish",
    "section": "Rescaling the Data",
    "text": "Rescaling the Data\nIf I wanted to rescale every quantitative variable in my dataset so that they only have values between 0 and 1, I could use this formula:\n\n\\[y_{scaled} = \\frac{y_i - min\\{y_1, y_2,..., y_n\\}}{max\\{y_1, y_2,..., y_n\\}\n- min\\{y_1, y_2,..., y_n\\}}\\]\n\nI might write the following R code to carry out the rescaling procedure for the length and weight columns of the BlackfootFish data:\n\nfish &lt;- fish |&gt; \n  mutate(length = (length - min(length, na.rm = TRUE)) / \n           (max(length, na.rm = TRUE) - min(length, na.rm = TRUE)), \n         weight = (weight - min(weight, na.rm = TRUE)) / \n           (max(weight, na.rm = TRUE) - min(length, na.rm = TRUE)))\n\nThis process of duplicating an action multiple times can make it difficult to understand the intent of the process. Additionally, it can make it very difficult to spot mistakes.\n3. What is the mistake I made in the above rescaling code?\nWhen you find yourself copy-pasting lines of code, it’s time to write a function, instead!\n4. Transform the repeated process above into a rescale_01() function. Your function should…\n\n… take a single vector as input.\n… return the rescaled vector.\n\n\n\n\n\n\n\nTip\n\n\n\nThink about the efficiency of your function. Are you calling the same function multiple times?\nLook into the function range().\n\n\n\n# Code for Q4 and Q5.\n\n5. Let’s incorporate some input validation into your function. Modify your previous code so that the function stops if …\n\n… the input vector is not numeric.\n… the length of the input vector is not greater than 1.\n\n\n\n\n\n\n\nTip\n\n\n\nDo not create a new code chunk here – simply add these stops to your function above!"
  },
  {
    "objectID": "labs/lab7/la7-functions.html#test-your-function",
    "href": "labs/lab7/la7-functions.html#test-your-function",
    "title": "Lab 7: Functions + Fish",
    "section": "Test Your Function",
    "text": "Test Your Function\n6. Run the code below to test your function. Verify that the maximum of your rescaled vector is 1 and the minimum is 0!\n\nx &lt;- c(1:25, NA)\n\nrescaled &lt;- rescale_01(x)\n\nError in rescale_01(x): could not find function \"rescale_01\"\n\nmin(rescaled, na.rm = TRUE)\n\nError: object 'rescaled' not found\n\nmax(rescaled, na.rm = TRUE)\n\nError: object 'rescaled' not found\n\n\nNext, let’s test the function on the length column of the BlackfootFish data.\n7. The code below makes a histogram of the original values of length. Add a plot of the rescaled values of length. Output your plots side-by-side, so the reader can confirm the only aspect that has changed is the scale.\n\n\n\n\n\n\nWarning\n\n\n\nThis will require you to call your rescale_01() function within a mutate() statement in order to create a length_scaled variable.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nSet the y-axis limits for both plots to go from 0 to 4000 to allow for direct comparison across plots.\nPay attention to binwidth! Adjust it so that the plots are comparable (they may not look exactly the same).\nLook for a Quarto code-chunk option to put the plots side-by-side.\n\n\n\n\nfish |&gt;  \n  ggplot(aes(x = length)) + \n  geom_histogram(binwidth = 45) +\n  labs(x = \"Original Values of Fish Length (mm)\") +\n  scale_y_continuous(limits = c(0,4000))\n\n\n\n\n\n\n\n# Code for Q7 plot."
  },
  {
    "objectID": "labs/lab7/la7-functions.html#use-variables-within-a-dataset",
    "href": "labs/lab7/la7-functions.html#use-variables-within-a-dataset",
    "title": "Lab 7: Functions + Fish",
    "section": "Use Variables within a Dataset",
    "text": "Use Variables within a Dataset\nSuppose you would like for your rescale() function to perform operations on a variable within a dataset. Ideally, your function would take in a dataframe and a variable name as inputs and return a dataframe where the variable has been rescaled.\n8. Create a rescale_column() function that accepts two arguments: (1) a dataframe and (2) the name(s) of the variable(s) to be rescaled. The body of the function should call the original rescale_01() function you wrote previously. Your solution MUST use one of the rlang options from class.\n\n\n\n\n\n\nTip\n\n\n\nIf you are struggling with this task, I recommend looking here and at the slides from class on Wednesday!\n\n\n\n# Code for Q8.\n\n9. Use your rescale_column() function to rescale both the length and weight columns.\n\n\n\n\n\n\nWarning\n\n\n\nI expect that you carry out this process by calling the rescale_column() function only ONE time!\n\n\n\n# original values\nfish |&gt; \n select(length:weight) |&gt; \n head()\n\n  length weight\n1    288    175\n2    288    190\n3    285    245\n4    322    275\n5    312    300\n6    363    380\n\n# rescaled values\n\n# Code for Q9."
  },
  {
    "objectID": "labs/lab7/la7-functions.html#condition-index",
    "href": "labs/lab7/la7-functions.html#condition-index",
    "title": "Lab 7: Functions + Fish",
    "section": "Condition Index",
    "text": "Condition Index\nA frequently used measurement for fish health is a condition index (Wikipedia). The following equation can be used to calculate the approximate condition index of a fish:\n\\[\\text{condition index} = \\frac{weight}{length^3} \\times 100\\]\n10. When calculating the condition index, fish length must be in centimeters and fish weight must be in grams. The weight data for the Blackfoot River fish were collected in grams, but the length data were collected in millimeters. Transform the length column to the correct units.\n\n# Code for Q10.\n\n11. Collecting data of this sort can be very messy! Write a function that will replace unlikely length and weight measurements with NA. Your function should accept at least three inputs:\n\na vector of measurements,\nthe minimum reasonable value,\nthe maximum reasonable value.\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are struggling with the structure of your function, I would suggest reading the Mutating Function from R4DS.\n\n\n\n# Code for Q11.\n\n12. After consulting the Montana Record Table for the 4 species of trout included in these data, I have conjectured that it is unlikely to have measurements for fish below 5 cm and above 80 cm in length or below 10 g and above 4,000 g in weight. Use your function to modify the length and weight columns of the fish dataset based on my cutoffs.\n\n# Code for Q12.\n\n13. Write a function to calculate the condition index of a fish, given inputs of weight and length. Show that it works on your modified fish dataset\n\n\n\n\n\n\nWarning\n\n\n\nConsider whether your function will accept vectors as inputs or if it will accept variable names as inputs!\nTo show that your function works, do not print a full dataset! Just apply the function to your data and then output a couple of rows.\n\n\n\n# Code for Q13."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html",
    "href": "slides/week-6/w6-version-control.html",
    "title": "Version Control",
    "section": "",
    "text": "Today we will…\n\nOpen-Ended Analysis from Lab 4\nQuestions about Midterm?\nNew Material\n\ngit/GitHub\nConnect GitHub to RStudio\n\nPA 6: Merge Conflicts – Collaborating within a GitHub Repo"
  },
  {
    "objectID": "labs/lab7/lab7-functions.html",
    "href": "labs/lab7/lab7-functions.html",
    "title": "Lab 7: Functions + Fish",
    "section": "",
    "text": "Download .qmd starter file\nDownload BlackfootFish.csv\nThe goal of this lab is learn more about exploring missing data and writing modular code.\nlibrary(tidyverse)\nfish &lt;- read.csv(\"BlackfootFish.csv\")"
  },
  {
    "objectID": "labs/lab7/lab7-functions.html#the-data",
    "href": "labs/lab7/lab7-functions.html#the-data",
    "title": "Lab 7: Functions + Fish",
    "section": "The Data",
    "text": "The Data\nThis lab’s data concerns mark-recapture data on four species of trout from the Blackfoot River outside of Helena, Montana. These four species are rainbow trout (RBT), westslope cutthroat trout (WCT), bull trout, and brown trout.\n\nMark-recapture is a common method used by ecologists to estimate a population’s size when it is impossible to conduct a census (count every animal). This method works by tagging animals with a tracking device so that scientists can track their movement and presence."
  },
  {
    "objectID": "labs/lab7/lab7-functions.html#data-exploration",
    "href": "labs/lab7/lab7-functions.html#data-exploration",
    "title": "Lab 7: Functions + Fish",
    "section": "Data Exploration",
    "text": "Data Exploration\nThe measurements of each captured fish were taken by a biologist on a raft in the river. The lack of a laboratory setting opens the door to the possibility of measurement errors.\n1. Let’s look for missing values in the dataset. Output ONE table that answers BOTH of the following questions:\n\nHow many observations have missing values?\nWhat variable(s) have missing values present?\n\n\n\n\n\n\n\nTip\n\n\n\nHint: use across().\n\n\n\n# Code for Q1.\n\n2. Create ONE thoughtful visualization that explores the frequency of missing values across the different years, sections, and trips.\n\n# Code for Q2."
  },
  {
    "objectID": "labs/lab7/lab7-functions.html#rescaling-the-data",
    "href": "labs/lab7/lab7-functions.html#rescaling-the-data",
    "title": "Lab 7: Functions + Fish",
    "section": "Rescaling the Data",
    "text": "Rescaling the Data\nIf I wanted to rescale every quantitative variable in my dataset so that they only have values between 0 and 1, I could use this formula:\n\n\\[y_{scaled} = \\frac{y_i - min\\{y_1, y_2,..., y_n\\}}{max\\{y_1, y_2,..., y_n\\}\n- min\\{y_1, y_2,..., y_n\\}}\\]\n\nI might write the following R code to carry out the rescaling procedure for the length and weight columns of the BlackfootFish data:\n\nfish &lt;- fish |&gt; \n  mutate(length = (length - min(length, na.rm = TRUE)) / \n           (max(length, na.rm = TRUE) - min(length, na.rm = TRUE)), \n         weight = (weight - min(weight, na.rm = TRUE)) / \n           (max(weight, na.rm = TRUE) - min(length, na.rm = TRUE)))\n\nThis process of duplicating an action multiple times can make it difficult to understand the intent of the process. Additionally, it can make it very difficult to spot mistakes.\n3. What is the mistake I made in the above rescaling code?\nWhen you find yourself copy-pasting lines of code, it’s time to write a function, instead!\n4. Transform the repeated process above into a rescale_01() function. Your function should…\n\n… take a single vector as input.\n… return the rescaled vector.\n\n\n\n\n\n\n\nTip\n\n\n\nThink about the efficiency of your function. Are you calling the same function multiple times?\nLook into the function range().\n\n\n\n# Code for Q4 and Q5.\n\n5. Let’s incorporate some input validation into your function. Modify your previous code so that the function stops if …\n\n… the input vector is not numeric.\n… the length of the input vector is not greater than 1.\n\n\n\n\n\n\n\nTip\n\n\n\nDo not create a new code chunk here – simply add these stops to your function above!"
  },
  {
    "objectID": "labs/lab7/lab7-functions.html#test-your-function",
    "href": "labs/lab7/lab7-functions.html#test-your-function",
    "title": "Lab 7: Functions + Fish",
    "section": "Test Your Function",
    "text": "Test Your Function\n6. Run the code below to test your function. Verify that the maximum of your rescaled vector is 1 and the minimum is 0!\n\nx &lt;- c(1:25, NA)\n\nrescaled &lt;- rescale_01(x)\n\nError in rescale_01(x): could not find function \"rescale_01\"\n\nmin(rescaled, na.rm = TRUE)\n\nError: object 'rescaled' not found\n\nmax(rescaled, na.rm = TRUE)\n\nError: object 'rescaled' not found\n\n\nNext, let’s test the function on the length column of the BlackfootFish data.\n7. The code below makes a histogram of the original values of length. Add a plot of the rescaled values of length. Output your plots side-by-side, so the reader can confirm the only aspect that has changed is the scale.\n\n\n\n\n\n\nWarning\n\n\n\nThis will require you to call your rescale_01() function within a mutate() statement in order to create a length_scaled variable.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nSet the y-axis limits for both plots to go from 0 to 4000 to allow for direct comparison across plots.\nPay attention to binwidth! Adjust it so that the plots are comparable (they may not look exactly the same).\nLook for a Quarto code-chunk option to put the plots side-by-side.\n\n\n\n\nfish |&gt;  \n  ggplot(aes(x = length)) + \n  geom_histogram(binwidth = 45) +\n  labs(x = \"Original Values of Fish Length (mm)\") +\n  scale_y_continuous(limits = c(0,4000))\n\n\n\n\n\n\n\n# Code for Q7 plot."
  },
  {
    "objectID": "labs/lab7/lab7-functions.html#use-variables-within-a-dataset",
    "href": "labs/lab7/lab7-functions.html#use-variables-within-a-dataset",
    "title": "Lab 7: Functions + Fish",
    "section": "Use Variables within a Dataset",
    "text": "Use Variables within a Dataset\nSuppose you would like for your rescale() function to perform operations on a variable within a dataset. Ideally, your function would take in a dataframe and a variable name as inputs and return a dataframe where the variable has been rescaled.\n8. Create a rescale_column() function that accepts two arguments: (1) a dataframe and (2) the name(s) of the variable(s) to be rescaled. The body of the function should call the original rescale_01() function you wrote previously. Your solution MUST use one of the rlang options from class.\n\n\n\n\n\n\nTip\n\n\n\nIf you are struggling with this task, I recommend looking here and at the slides from class on Wednesday!\n\n\n\n# Code for Q8.\n\n9. Use your rescale_column() function to rescale both the length and weight columns.\n\n\n\n\n\n\nWarning\n\n\n\nI expect that you carry out this process by calling the rescale_column() function only ONE time!\n\n\n\n# original values\nfish |&gt; \n select(length:weight) |&gt; \n head()\n\n  length weight\n1    288    175\n2    288    190\n3    285    245\n4    322    275\n5    312    300\n6    363    380\n\n# rescaled values\n\n# Code for Q9."
  },
  {
    "objectID": "labs/lab7/lab7-functions.html#condition-index",
    "href": "labs/lab7/lab7-functions.html#condition-index",
    "title": "Lab 7: Functions + Fish",
    "section": "Condition Index",
    "text": "Condition Index\nA frequently used measurement for fish health is a condition index (Wikipedia). The following equation can be used to calculate the approximate condition index of a fish:\n\\[\\text{condition index} = \\frac{weight}{length^3} \\times 100\\]\n10. When calculating the condition index, fish length must be in centimeters and fish weight must be in grams. The weight data for the Blackfoot River fish were collected in grams, but the length data were collected in millimeters. Transform the length column to the correct units.\n\n# Code for Q10.\n\n11. Collecting data of this sort can be very messy! Write a function that will replace unlikely length and weight measurements with NA. Your function should accept at least three inputs:\n\na vector of measurements,\nthe minimum reasonable value,\nthe maximum reasonable value.\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are struggling with the structure of your function, I would suggest reading the Mutating Function from R4DS.\n\n\n\n# Code for Q11.\n\n12. After consulting the Montana Record Table for the 4 species of trout included in these data, I have conjectured that it is unlikely to have measurements for fish below 5 cm and above 80 cm in length or below 10 g and above 4,000 g in weight. Use your function to modify the length and weight columns of the fish dataset based on my cutoffs.\n\n# Code for Q12.\n\n13. Write a function to calculate the condition index of a fish, given inputs of weight and length. Show that it works on your modified fish dataset\n\n\n\n\n\n\nWarning\n\n\n\nConsider whether your function will accept vectors as inputs or if it will accept variable names as inputs!\nTo show that your function works, do not print a full dataset! Just apply the function to your data and then output a couple of rows.\n\n\n\n# Code for Q13."
  },
  {
    "objectID": "practice-activities/pa7.html",
    "href": "practice-activities/pa7.html",
    "title": "PA 7: Writing Functions",
    "section": "",
    "text": "Download starter .qmd template\nYou will write several small functions, then use them to unscramble a message. Many of the functions have been started for you below, but none of them are complete as is.\n1. Write code to manipulate the vector of numbers nums. Your code should divide each element in the vector by the smallest element and round the results to the nearest whole number. This code should not be a function.\n\nnums &lt;- 3:12\n\n2. Turn your code from Q1 into a function called divide_and_round(). Fill in the skeleton below.\n\ndivide_and_round &lt;- function(vec){\n  \n}\n\n3. Test your function by running the code below. If you don’t get what you expect - edit your function!\n\ntest &lt;- c(5:10, NA)\ndivide_and_round(test)\n\nNULL\n\n\n4. Write code to manipulate the vector of numbers nums. Your code should, for each element, return TRUE if the number is NOT divisible by 9 or 12, and return FALSE otherwise. This code should not be a function.\n\n# Write your code for Q4 here.\n\n5. Turn your code from Q4 into a function called no_nines_or_twelves().\n\n# Write your code for Q5 here.\n\n6. Test your function by running the code below.\n\ntest &lt;- c(3:12*5, NA)\nno_nines_or_twelves(test)\n\nError in no_nines_or_twelves(test): could not find function \"no_nines_or_twelves\"\n\n\n7. Write a function called every_other(). This function should take in a vector and return every other value in the vector. Include an optional argument called start which lets you choose where to start skipping; that is, if start = 1, the function returns the 1st, 3rd, 5th, etc. values and if start = 2, the function returns the 2nd, 4th, 6th, etc. values. Fill in the skeleton below.\n\n\n\n\n\n\nWarning\n\n\n\nDo not use a for() loop to do this! Accomplish this with bracket indexing ([]) and modulus arithmetic (%%).\n\n\n\nevery_other &lt;- function(vec){\n  \n  if(start == 2){\n\n    \n  } else if(start == 1) {\n\n    \n  }\n  \n}\n\n8. Test your function by running the code below.\n\ntest &lt;- c(1:10)\n\nevery_other(test)\n\nError in start == 2: comparison (==) is possible only for atomic and list types\n\nevery_other(test, start = 2)\n\nError in every_other(test, start = 2): unused argument (start = 2)\n\n\n9. Write a function called shorten(). This function should take in a vector, and only return values from the original vector for which the cumulative sum for that element is greater than a provided number.\n\n\n\n\n\n\nWarning\n\n\n\nDo not use a while() loop to do this! Accomplish this with the cumsum() function and bracketing.\n\n\n\n# Write your code for Q9 here.\n\n10. Write code to test your function.\n\n# Write code to test the shorten() function here.\n\n11. Once you have written your four functions correctly, run the following code:\n\nmy_vec &lt;- c(39, 1.87, 48, 11, 8, 45, 21, 5, 12, 33, 9, 11, 108,\n            4, 18, 5, 16, 17, 8, 48, 27, 24, 4, 22, 12, 27, 23,\n            46, 42, 35, 15, 34, 36, 26, 18, 10, 18.21, 72.04,\n            36.9, 41.81, 29, 89.75, 34.03, 20.18, 48.74, 15.76,\n            31.86, 83.6, 43.55, 39.99, 23.55, 8.54, 24.71, 22.02,\n            9.71, 62.14, 35.46, 16.61, 15.66, 21.29, 30.52,\n            201.07, 45.81, 7.85, 30.13, 34.14, 22.62, 10.2, 6.02,\n            30.12, 10.64, 31.72, 24.57, 14.43, 43.37, 89.93,\n            44.72, 51.32, 13.62, 45.56, 22.96, 7.05, 29.99, 41.38,\n            26.59, 23.04, 19.82, 50.73, 39.56, 43.79, 30.22, 85.85,\n            5.78, 78.85, 29.52, 66.27, 44.06, 27.28, 24.43, 64.32,\n            3.35, 67.45, 46.72, 48.44, 48.65, 33.3, 40.28, 19.04)\n\nmy_vec &lt;- every_other(my_vec, start = 2)\n\nError in every_other(my_vec, start = 2): unused argument (start = 2)\n\n# Should have 54 elements! \n\nmy_vec &lt;- divide_and_round(my_vec)\n\nmy_vec &lt;- every_other(my_vec, start = 1)\n\nError in every_other(my_vec, start = 1): unused argument (start = 1)\n\n# Should have 27 elements!\n\nmy_vec &lt;- shorten(my_vec, 350)\n\nError in shorten(my_vec, 350): could not find function \"shorten\"\n\n# Should have 12 elements!\n\nmy_vec &lt;- my_vec[no_nines_or_twelves(my_vec)]\n\nError in no_nines_or_twelves(my_vec): could not find function \"no_nines_or_twelves\"\n\n# Should have 6 elements! \n\nmy_vec &lt;- sort(my_vec)\n\nmy_vec\n\nNULL\n\n\n\n\n\n\n\n\nCanvas Submission\n\n\n\nIf you have done everything correctly, your final vector will be six numbers long. Google these six numbers to find a TV show as your final answer and submit to Canvas."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#tuesday-may-13",
    "href": "slides/week-7/w7-functions.html#tuesday-may-13",
    "title": "Writing Functions",
    "section": "Tuesday, May 13",
    "text": "Tuesday, May 13\nToday we will…\n\nLecture\n\nFunction Basics\nVariable Scope + Environment\nPA 7: Writing Functions throughout!\n\n\n\n\n\n\n\n\nFollow along\n\n\nRemember to download, save, and open up the starter notes for this week!"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#why-write-functions",
    "href": "slides/week-7/w7-functions.html#why-write-functions",
    "title": "Writing Functions",
    "section": "Why write functions?",
    "text": "Why write functions?\nFunctions allow you to automate common tasks!\n\nWe’ve been using functions since Day 1, but when we write our own, we can customize them!\nHave you found yourself copy-pasting code and only changing small parts?\n\n\nWriting functions has 3 big advantages over copy-paste:\n\nYour code is easier to read.\nTo change your analysis, simply change one function.\nYou avoid mistakes from copy-paste."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#function-syntax",
    "href": "slides/week-7/w7-functions.html#function-syntax",
    "title": "Writing Functions",
    "section": "Function Syntax",
    "text": "Function Syntax"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#function-syntax-1",
    "href": "slides/week-7/w7-functions.html#function-syntax-1",
    "title": "Writing Functions",
    "section": "Function Syntax",
    "text": "Function Syntax"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#a-very-simple-function",
    "href": "slides/week-7/w7-functions.html#a-very-simple-function",
    "title": "Writing Functions",
    "section": "A (very) Simple Function",
    "text": "A (very) Simple Function\nLet’s define the function.\n\nYou must run the code to define the function just once.\n\n\nadd_two &lt;- function(x){\n  x + 2\n}\n\n\n\nLet’s call the function!\n\nadd_two(5)\n\n[1] 7"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#naming-add_two--",
    "href": "slides/week-7/w7-functions.html#naming-add_two--",
    "title": "Writing Functions",
    "section": "Naming: add_two <-",
    "text": "Naming: add_two &lt;-\nThe name of the function is chosen by the author.\n\nadd_two &lt;- function(x){\n  x + 2\n}\n\n\nCaution: Function names have no inherent meaning.\n\nThe name you give to a function does not affect what the function does.\n\n\nadd_three &lt;- function(x){\n  x + 7\n}\n\n\nadd_three(5)\n\n[1] 12"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#arguments",
    "href": "slides/week-7/w7-functions.html#arguments",
    "title": "Writing Functions",
    "section": "Arguments",
    "text": "Arguments\nThe argument(s) of the function are chosen by the author.\n\nArguments are how we pass external values into the function.\nThey are temporary variables that only exist inside the function body.\n\n\n\n\nWe give them general names:\n\nx, y, z – vectors\ndf – dataframe\ni, j – indices\n\n\n\n\n\nadd_two &lt;- function(x){\n  x + 2\n}"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#body",
    "href": "slides/week-7/w7-functions.html#body",
    "title": "Writing Functions",
    "section": "Body: {  }",
    "text": "Body: {  }\nThe body of the function is where the action happens.\n\nThe body must be specified within a set of curly brackets.\nThe code in the body will be executed (in order) whenever the function is called.\n\n\nadd_two &lt;- function(x){\n  x + 2\n}"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#output-return",
    "href": "slides/week-7/w7-functions.html#output-return",
    "title": "Writing Functions",
    "section": "Output: return()",
    "text": "Output: return()\nYour function will give back what would normally print out…\n\nadd_two &lt;- function(x){\n  x + 2\n}\n\n\n\n\n\n7 + 2\n\n[1] 9\n\n\n\n\nadd_two(7)\n\n[1] 9\n\n\n\n\n\n…but it’s better to be explicit and use return().\n\nadd_two &lt;- function(x){\n  return(x + 2)\n}"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#output-return-1",
    "href": "slides/week-7/w7-functions.html#output-return-1",
    "title": "Writing Functions",
    "section": "Output: return()",
    "text": "Output: return()\nIf you need to return more than one object from a function, wrap those objects in a list.\n\nmin_max &lt;- function(x){\n  lowest &lt;- min(x)\n  highest &lt;- max(x)\n  return(list(min = lowest, max = highest))\n}\n\nvec &lt;- c(346,547,865,346,6758,78,79,362)\nmin_max(vec)\n\n$min\n[1] 78\n\n$max\n[1] 6758"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#pa7-q1-6",
    "href": "slides/week-7/w7-functions.html#pa7-q1-6",
    "title": "Writing Functions",
    "section": "PA7 Q1-6",
    "text": "PA7 Q1-6\n\n\n\n\n\n\nStart Practicing!\n\n\nWrite a function to divide each element in a vector by the smallest element and round the results to the nearest whole number and return the resulting vector.\nWrite a function that, for each element in a vector, returns TRUE if the number is NOT divisible by 9 or 12, and returns FALSE otherwise\n\n\n\nThink through…\n\nWhat are arguments?\nWhat should the function return?"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#arguments-cont.",
    "href": "slides/week-7/w7-functions.html#arguments-cont.",
    "title": "Writing Functions",
    "section": "Arguments Cont.",
    "text": "Arguments Cont.\n\nOptional argumentsRequired arguments\n\n\nIf we supply a default value when defining the function, the argument is optional when calling the function.\n\nadd_something &lt;- function(x, something = 2){\n  return(x + something)\n}\n\n\nIf a value is not supplied, something defaults to 2.\n\n\nadd_something(x = 5)\n\n[1] 7\n\n\n\nadd_something(x = 5, something = 6)\n\n[1] 11\n\n\n\n\nIf we do not supply a default value when defining the function, the argument is required when calling the function.\n\nadd_something &lt;- function(x, something){\n  x + something\n}\n\nadd_something(x = 2)\n\nError in add_something(x = 2): argument \"something\" is missing, with no default"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#input-validation",
    "href": "slides/week-7/w7-functions.html#input-validation",
    "title": "Writing Functions",
    "section": "Input Validation",
    "text": "Input Validation\nWhen a function requires an input of a specific data type, check that the supplied argument is valid.\n\n stopifnot()  if() + stop() Multiple validations\n\n\n\nadd_something &lt;- function(x, something){\n  stopifnot(is.numeric(x))\n  return(x + something)\n}\n\nadd_something(x = \"statistics\", something = 5)\n\nError in add_something(x = \"statistics\", something = 5): is.numeric(x) is not TRUE\n\n\n\n\n\nadd_something &lt;- function(x, something){\n  if(!is.numeric(x)){\n    stop(\"Please provide a numeric input for the x argument.\")\n  }\n  return(x + something)\n}\n\nadd_something(x = \"statistics\", something = 5)\n\nError in add_something(x = \"statistics\", something = 5): Please provide a numeric input for the x argument.\n\n\n\n\n\nadd_something &lt;- function(x, something){\n  if(!is.numeric(x) | !is.numeric(something)){\n    stop(\"Please provide numeric inputs for both arguments.\")\n  }\n  return(x + something)\n}\n\nadd_something(x = 2, something = \"R\")\n\nError in add_something(x = 2, something = \"R\"): Please provide numeric inputs for both arguments.\n\n\n\nadd_something &lt;- function(x, something){\n  stopifnot(is.numeric(x), is.numeric(something))\n  return(x + something)\n}\n\nadd_something(x = \"statistics\", something = \"R\")\n\nError in add_something(x = \"statistics\", something = \"R\"): is.numeric(x) is not TRUE"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#pa7-q7-8",
    "href": "slides/week-7/w7-functions.html#pa7-q7-8",
    "title": "Writing Functions",
    "section": "PA7 Q7-8",
    "text": "PA7 Q7-8\n\n\n\n\n\n\nPracticing with optional v. required arguments\n\n\nWrite a function called every_other(). This function should take in a vector and return every other value in the vector. Include an optional argument called start which lets you choose where to start skipping; that is, if start = 1, the function returns the 1st, 3rd, 5th, etc. values and if start = 2, the function returns the 2nd, 4th, 6th, etc. values.\n\n\n\n\n\n\n\n\n\nAdd some input validation if you have time!\n\n\nfirst argument: vec should be a vector (length more than 1?)\nsecond argument: start only takes values of 1 or 2"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#variable-scope",
    "href": "slides/week-7/w7-functions.html#variable-scope",
    "title": "Writing Functions",
    "section": "Variable Scope",
    "text": "Variable Scope\nThe location (environment) in which we can find and access a variable is called its scope.\n\nWe need to think about the scope of variables when we write functions.\nWhat variables can we access inside a function?\nWhat variables can we access outside a function?"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#global-environment",
    "href": "slides/week-7/w7-functions.html#global-environment",
    "title": "Writing Functions",
    "section": "Global Environment",
    "text": "Global Environment\n\nThe top right pane of Rstudio shows you the global environment.\n\nThis is the current state of all objects you have created.\nThese objects can be accessed anywhere."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#function-environment",
    "href": "slides/week-7/w7-functions.html#function-environment",
    "title": "Writing Functions",
    "section": "Function Environment",
    "text": "Function Environment\n\nThe code inside a function executes in the function environment.\n\nFunction arguments and any variables created inside the function only exist inside the function.\n\nThey disappear when the function code is complete.\n\nWhat happens in the function environment does not affect things in the global environment."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#function-environment-1",
    "href": "slides/week-7/w7-functions.html#function-environment-1",
    "title": "Writing Functions",
    "section": "Function Environment",
    "text": "Function Environment\nWe cannot access variables created inside a function outside of the function.\n\nadd_two &lt;- function(x) {\n  my_result &lt;- x + 2\n  return(my_result)\n}\n\nadd_two(9)\n\n[1] 11\n\nmy_result\n\nError: object 'my_result' not found"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#name-masking",
    "href": "slides/week-7/w7-functions.html#name-masking",
    "title": "Writing Functions",
    "section": "Name Masking",
    "text": "Name Masking\nName masking occurs when an object in the function environment has the same name as an object in the global environment.\n\nadd_two &lt;- function(x) {\n  my_result &lt;- x + 2\n  return(my_result)\n}\n\n\nmy_result &lt;- 2000\n\n\nThe my_result created inside the function is different from the my_result created outside.\n\n\n\nadd_two(5)\n\n[1] 7\n\n\n\n\nmy_result\n\n[1] 2000"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#dynamic-lookup",
    "href": "slides/week-7/w7-functions.html#dynamic-lookup",
    "title": "Writing Functions",
    "section": "Dynamic Lookup",
    "text": "Dynamic Lookup\nFunctions look for objects FIRST in the function environment and SECOND in the global environment.\n\nIf the object doesn’t exist in either, the code will give an error.\n\n\n\n\nadd_two &lt;- function() {\n  return(x + 2)\n}\n\nadd_two()\n\nError in add_two(): object 'x' not found\n\n\n\n\nx &lt;- 10\n\nadd_two()\n\n[1] 12\n\n\n\n\nIt is not good practice to rely on global environment objects inside a function!"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#pa-7-q9---11",
    "href": "slides/week-7/w7-functions.html#pa-7-q9---11",
    "title": "Writing Functions",
    "section": "PA 7 Q9 - 11",
    "text": "PA 7 Q9 - 11\n\n\n\n\n\n\nFinish PA7\n\n\nWrite a function called shorten(). This function should take in a vector, and only return values from the original vector for which the cumulative sum for that element is greater than a provided number.\n\n\n\nThink through for your function:\n\nWhat are the arguments and what kinds of values do they take?\nAre any of the arguments optional?\nWhat should it return?"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#pair-our-function-with-dplyr",
    "href": "slides/week-7/w7-functions.html#pair-our-function-with-dplyr",
    "title": "Writing Functions",
    "section": "Pair Our Function with dplyr",
    "text": "Pair Our Function with dplyr\nConsider the penguins Data\n\nlibrary(palmerpenguins)\ndata(penguins)\npenguins |&gt; \n  head()\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#function-to-standardize-data",
    "href": "slides/week-7/w7-functions.html#function-to-standardize-data",
    "title": "Writing Functions",
    "section": "Function to Standardize Data",
    "text": "Function to Standardize Data\nWe want to take in a vector of numbers and standardize it – make all values be between 0 and 1.\n\n\nstd_to_01 &lt;- function(var) {\n  stopifnot(is.numeric(var))\n  \n  num &lt;- var - min(var, na.rm = TRUE)\n  denom &lt;- max(var, na.rm = TRUE) - min(var, na.rm = TRUE)\n  \n  return(num / denom)\n}"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#standardizing-variables",
    "href": "slides/week-7/w7-functions.html#standardizing-variables",
    "title": "Writing Functions",
    "section": "Standardizing Variables",
    "text": "Standardizing Variables\nIs it a good idea to standardize (scale) variables in a data analysis?\n\n\nWhy standardize?\n\nEasier to compare across variables.\nEasier to model – standardizes the amount of variability.\n\n\nWhy not standardize?\n\nMore difficult to interpret the values.\n\n\n\nE.g., a penguin with a bill length of 35 mm (std to 0.11) and a mass of 5500 g (std to 0.78)."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#pair-our-function-with-dplyr-1",
    "href": "slides/week-7/w7-functions.html#pair-our-function-with-dplyr-1",
    "title": "Writing Functions",
    "section": "Pair Our Function with dplyr",
    "text": "Pair Our Function with dplyr\nLet’s standardize penguin measurements.\n\npenguins |&gt; \n  mutate(bill_length_mm    = std_to_01(bill_length_mm), \n         bill_depth_mm     = std_to_01(bill_depth_mm), \n         flipper_length_mm = std_to_01(flipper_length_mm), \n         body_mass_g       = std_to_01(body_mass_g))\n\n\nUgh. Still copy-pasting!\n\n\nRecall across()!\n\npenguins |&gt; \n  mutate(across(.cols = bill_length_mm:body_mass_g,\n                .fns = ~ std_to_01(.x))) |&gt; \n  slice_head(n = 4)\n\n# A tibble: 4 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen          0.255         0.667             0.153       0.292\n2 Adelie  Torgersen          0.269         0.512             0.237       0.306\n3 Adelie  Torgersen          0.298         0.583             0.390       0.153\n4 Adelie  Torgersen         NA            NA                NA          NA    \n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#use-variables-as-function-arguments",
    "href": "slides/week-7/w7-functions.html#use-variables-as-function-arguments",
    "title": "Writing Functions",
    "section": "Use variables as function arguments?",
    "text": "Use variables as function arguments?\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n  \n  data &lt;- data |&gt; \n    mutate(variable = std_to_01(variable))\n  return(data)\n}\n\n\n\n\n\n\n\nNote\n\n\nI used the existing function std_to_01() inside the new function for clarity!\n\n\n\n\nBut it didn’t work…\n\nstd_column_01(penguins, body_mass_g)\n\nError in `mutate()`:\nℹ In argument: `variable = std_to_01(variable)`.\nCaused by error:\n! object 'body_mass_g' not found"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#tidy-evaluation",
    "href": "slides/week-7/w7-functions.html#tidy-evaluation",
    "title": "Writing Functions",
    "section": "Tidy Evaluation",
    "text": "Tidy Evaluation\nFunctions using unquoted variable names as arguments are said to use nonstandard evaluation or tidy evaluation.\n\n\nTidy:\n\npenguins |&gt; \n  pull(body_mass_g)\n\n  OR\n\npenguins$body_mass_g\n\n\nUntidy:\n\npenguins[, \"body_mass_g\"]\n\n  OR\n\npenguins[[\"body_mass_g\"]]\n\n\n\n\nTidy evaluation isn’t naturally supported when writing your own functions."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#defused-r-code",
    "href": "slides/week-7/w7-functions.html#defused-r-code",
    "title": "Writing Functions",
    "section": "Defused R Code",
    "text": "Defused R Code\nWhen a piece of code is defused, R doesn’t return its value like normal.\n\nInstead it returns an expression that describes how to evaluate it.\n\n\n\n\nEvaluated code:\n\n1 + 1\n\n[1] 2\n\n\n\nDefused code:\n\nexpr(1 + 1)\n\n1 + 1\n\n\n\n\n\nWe produce defused code when we use tidy evaluation and our own functions don’t know how to handle it."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#solution-1",
    "href": "slides/week-7/w7-functions.html#solution-1",
    "title": "Writing Functions",
    "section": "Solution 1",
    "text": "Solution 1\nDon’t use tidy evaluation in your own functions.\n\nThis is more complicated to read and use, but it’s safe.\n\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n  \n  data[[variable]] &lt;- std_to_01(data[[variable]])\n  return(data)\n}\n\nstd_column_01(penguins, \"bill_length_mm\")"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#solution-2-rlang",
    "href": "slides/week-7/w7-functions.html#solution-2-rlang",
    "title": "Writing Functions",
    "section": "Solution 2: rlang",
    "text": "Solution 2: rlang\nUse the rlang package!\n\n\n\nThis package provides operators that simplify writing functions around tidyverse pipelines.\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead more about using this package for function writing here!"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#solution-2-rlang-1",
    "href": "slides/week-7/w7-functions.html#solution-2-rlang-1",
    "title": "Writing Functions",
    "section": "Solution 2: rlang",
    "text": "Solution 2: rlang\nTwo ways to get around the issue of defused code:\n\nEmbrace Operator ({ })\n\n\nWith { }, you can transport a variable from one function to another.\n\n\n\nDefuse and Inject\n\n\nYou can first use enquo(arg) to defuse the variable.\nThen use !!arg to inject the variable."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#solution-2-rlang-2",
    "href": "slides/week-7/w7-functions.html#solution-2-rlang-2",
    "title": "Writing Functions",
    "section": "Solution 2: rlang",
    "text": "Solution 2: rlang\nIf we use either of these solutions, we also need to use the walrus operator (:=).\n\nThis means we have to use := instead of = in any dplyr verb containing one of these rlang fixes."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#recall-our-broken-function",
    "href": "slides/week-7/w7-functions.html#recall-our-broken-function",
    "title": "Writing Functions",
    "section": "Recall Our Broken Function",
    "text": "Recall Our Broken Function\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n  \n  data &lt;- data |&gt; \n    mutate(variable = std_to_01(variable))\n  return(data)\n}\n\nstd_column_01(penguins, body_mass_g)\n\nError in `mutate()`:\nℹ In argument: `variable = std_to_01(variable)`.\nCaused by error:\n! object 'body_mass_g' not found\n\n\n\nThe code is defused, so mutate() doesn’t know what body_mass_g is.\nWe need to modify variable to make this work correctly!"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#fixing-our-broken-function",
    "href": "slides/week-7/w7-functions.html#fixing-our-broken-function",
    "title": "Writing Functions",
    "section": "Fixing Our Broken Function",
    "text": "Fixing Our Broken Function\n\nEmbrace OperatorDefuse + Inject\n\n\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n\n  data &lt;- data |&gt;\n    mutate({{variable}} := std_to_01({{variable}}))\n  return(data)\n}\n\nstd_column_01(penguins, body_mass_g)\n\n\n\n# A tibble: 6 × 7\n  species island    bill_length_mm bill_depth_mm body_mass_g sex     year\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7       0.292 male    2007\n2 Adelie  Torgersen           39.5          17.4       0.306 female  2007\n3 Adelie  Torgersen           40.3          18         0.153 female  2007\n4 Adelie  Torgersen           NA            NA        NA     &lt;NA&gt;    2007\n5 Adelie  Torgersen           36.7          19.3       0.208 female  2007\n6 Adelie  Torgersen           39.3          20.6       0.264 male    2007\n\n\n\n\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n  \n  variable &lt;- enquo(variable)\n\n  data &lt;- data |&gt;\n    mutate(!!variable := std_to_01(!!variable))\n  return(data)\n}\n\nstd_column_01(penguins, body_mass_g)\n\n\n\n# A tibble: 6 × 7\n  species island    bill_length_mm bill_depth_mm body_mass_g sex     year\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7       0.292 male    2007\n2 Adelie  Torgersen           39.5          17.4       0.306 female  2007\n3 Adelie  Torgersen           40.3          18         0.153 female  2007\n4 Adelie  Torgersen           NA            NA        NA     &lt;NA&gt;    2007\n5 Adelie  Torgersen           36.7          19.3       0.208 female  2007\n6 Adelie  Torgersen           39.3          20.6       0.264 male    2007"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#inject-multiple-variables",
    "href": "slides/week-7/w7-functions.html#inject-multiple-variables",
    "title": "Writing Functions",
    "section": "Inject Multiple Variables",
    "text": "Inject Multiple Variables\nWhat if I want to modify multiple columns?\n\nUse across()!\n\n\nstd_column_01 &lt;- function(data, variables) {\n  stopifnot(is.data.frame(data))\n  \n  data &lt;- data |&gt; \n    mutate(across(.cols = {{variables}},\n                  .fns = ~ std_to_01(.x)))\n  return(data)\n}\n\nstd_column_01(penguins, bill_length_mm:body_mass_g)\n\n\n\n# A tibble: 5 × 7\n  species island    bill_length_mm bill_depth_mm body_mass_g sex     year\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  &lt;int&gt;\n1 Adelie  Torgersen          0.255         0.667       0.292 male    2007\n2 Adelie  Torgersen          0.269         0.512       0.306 female  2007\n3 Adelie  Torgersen          0.298         0.583       0.153 female  2007\n4 Adelie  Torgersen         NA            NA          NA     &lt;NA&gt;    2007\n5 Adelie  Torgersen          0.167         0.738       0.208 female  2007"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#debugging-1",
    "href": "slides/week-7/w7-functions.html#debugging-1",
    "title": "Writing Functions",
    "section": "Debugging",
    "text": "Debugging\nYou will make mistakes (create bugs) when coding.\n\nUnfortunately, it becomes more and more complicated to debug your code as your code gets more sophisticated.\nThis is especially true with functions!"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#debugging-strategies",
    "href": "slides/week-7/w7-functions.html#debugging-strategies",
    "title": "Writing Functions",
    "section": "Debugging Strategies",
    "text": "Debugging Strategies\n\nInteractive coding\n\nHighlight lines within your function and run them one-by-one to see what happens.\n\n\n\n\nprint() debugging\n\nAdd print() statements throughout your code to make sure the values are what you expect.\n\n\n\n\n\nRubber Ducking\n\nVerbally explain your code line by line to a rubber duck (or a human)."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#debugging-strategies-1",
    "href": "slides/week-7/w7-functions.html#debugging-strategies-1",
    "title": "Writing Functions",
    "section": "Debugging Strategies",
    "text": "Debugging Strategies\nWhen you have a concept that you want to turn into a function…\n\nWrite a simple example of the code without the function framework.\nGeneralize the example by assigning variables.\nWrite the code into a function.\nCall the function on the desired arguments\n\nThis structure allows you to address issues as you go."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#an-example",
    "href": "slides/week-7/w7-functions.html#an-example",
    "title": "Writing Functions",
    "section": "An Example",
    "text": "An Example\nWrite a function called find_car_make() that takes in the name of a car and returns the “make” of the car (the company that created it).\n\nfind_car_make(\"Toyota Camry\") should return “Toyota”.\nfind_car_make(\"Ford Anglica\") should return “Ford”."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#an-example-1",
    "href": "slides/week-7/w7-functions.html#an-example-1",
    "title": "Writing Functions",
    "section": "An Example",
    "text": "An Example\n\nSimple ExamplesGeneralizeWrite + Call Function\n\n\n\nmake &lt;- str_extract(string = \"Toyota Camry\",\n                    pattern = \"[:alpha:]*\")\nmake\n\n[1] \"Toyota\"\n\nmake &lt;- str_extract(string = \"Ford Anglica\",\n                    pattern = \"[:alpha:]*\")\nmake\n\n[1] \"Ford\"\n\n\n\n\n\ncar_name &lt;- \"Toyota Camry\"\n\nmake &lt;- str_extract(string = car_name, \n                    pattern = \"[:alpha:]*\")\nmake\n\n[1] \"Toyota\"\n\n\n\n\n\nfind_car_make &lt;- function(car_name){\n  make &lt;- str_extract(string = car_name, \n                      pattern = \"[:alpha:]*\")\n  return(make)\n}\n\n\nfind_car_make(\"Toyota Camry\")\n\n[1] \"Toyota\"\n\nfind_car_make(\"Ford Anglica\")\n\n[1] \"Ford\""
  },
  {
    "objectID": "slides/week-7/w7-functions.html#types-of-missing-data",
    "href": "slides/week-7/w7-functions.html#types-of-missing-data",
    "title": "Writing Functions",
    "section": "Types of Missing Data",
    "text": "Types of Missing Data\n\nMissing Completely at Random (MCAR)\n\nNo difference between missing and observed values.\nMissing observations are a random subset of all observations.\n\nMissing at Random (MAR)\n\nSystematic difference between missing and observed values, but can be entirely explained by other observed variables.\n\nMissing Not at Random (MNAR)\n\nMissingness is directly related to the unobserved value."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#types-of-missing-data-1",
    "href": "slides/week-7/w7-functions.html#types-of-missing-data-1",
    "title": "Writing Functions",
    "section": "Types of Missing Data",
    "text": "Types of Missing Data\nConsider a study of depression.\n\nMissing Completely at Random (MCAR)\n\nSome subjects have missing lab values because a batch of samples was processed improperly.\n\nMissing at Random (MAR)\n\nSubjects who identify as men are less likely to complete a survey on depression severity.\n\nMissing Not at Random (MNAR)\n\nSubjects with more severe depression are less likely to complete a survey on depression severity."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#when-we-remove-missing-data",
    "href": "slides/week-7/w7-functions.html#when-we-remove-missing-data",
    "title": "Writing Functions",
    "section": "When we remove missing data…",
    "text": "When we remove missing data…\nWe implicitly assume observations are missing completely at random!\n\nWe might be mostly removing data from subjects who identify as men.\nWe might be mostly removing data from subjects with severe depression.\nWe are inadvertently making our data less representative.\n\n\nWe need to take more care when dealing with missing values!"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#dealing-with-missing-data",
    "href": "slides/week-7/w7-functions.html#dealing-with-missing-data",
    "title": "Writing Functions",
    "section": "Dealing with Missing Data",
    "text": "Dealing with Missing Data\n\nLook for patterns!\n\nDo observations with missing values have similar traits?\n\n\n\n\nConsider outside explanations!\n\nWhy might missing data exist?\nShould we have a “missing” category in our analysis?\n\n\n\n\n\nCan we impute values?\n\nIf depression is MCAR within gender, age, and education level, then the distribution of depression will be similar for people of the same gender, age, and education level."
  },
  {
    "objectID": "slides/week-7/w7-functions.html#lab-7-functions-fish",
    "href": "slides/week-7/w7-functions.html#lab-7-functions-fish",
    "title": "Writing Functions",
    "section": "Lab 7: Functions + Fish",
    "text": "Lab 7: Functions + Fish"
  },
  {
    "objectID": "slides/week-7/w7-functions.html#to-do",
    "href": "slides/week-7/w7-functions.html#to-do",
    "title": "Writing Functions",
    "section": "To do…",
    "text": "To do…\n\nPA 7: Writing Functions\n\nDue Thursday before class\n\nFinal Project Group Contract\n\nDue Friday, 5/16 at 11:59pm.\n\nLab 7: Functions + Fish\n\nDue Mon 5/19 at 11:59pm."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#tuesday-may-13",
    "href": "slides/week-7/w7-data-functions.html#tuesday-may-13",
    "title": "Writing Functions",
    "section": "Tuesday, May 13",
    "text": "Tuesday, May 13\nToday we will…\n\nHousekeeping\nLecture\n\nFunction Basics\nVariable Scope + Environment\nPA 7: Writing Functions throughout!"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#why-write-functions",
    "href": "slides/week-7/w7-data-functions.html#why-write-functions",
    "title": "Writing Functions",
    "section": "Why write functions?",
    "text": "Why write functions?\nFunctions allow you to automate common tasks!\n\nWe’ve been using functions since Day 1, but when we write our own, we can customize them!\nHave you found yourself copy-pasting code and only changing small parts?\n\n\nWriting functions has 3 big advantages over copy-paste:\n\nYour code is easier to read.\nTo change your analysis, simply change one function.\nYou avoid mistakes from copy-paste."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#function-syntax",
    "href": "slides/week-7/w7-data-functions.html#function-syntax",
    "title": "Writing Functions",
    "section": "Function Syntax",
    "text": "Function Syntax"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#function-syntax-1",
    "href": "slides/week-7/w7-data-functions.html#function-syntax-1",
    "title": "Writing Functions",
    "section": "Function Syntax",
    "text": "Function Syntax"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#a-very-simple-function",
    "href": "slides/week-7/w7-data-functions.html#a-very-simple-function",
    "title": "Writing Functions",
    "section": "A (very) Simple Function",
    "text": "A (very) Simple Function\nLet’s define the function.\n\nYou must run the code to define the function just once.\n\n\nadd_two &lt;- function(x){\n  x + 2\n}\n\n\n\nLet’s call the function!\n\nadd_two(5)\n\n[1] 7"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#naming-add_two--",
    "href": "slides/week-7/w7-data-functions.html#naming-add_two--",
    "title": "Writing Functions",
    "section": "Naming: add_two <-",
    "text": "Naming: add_two &lt;-\nThe name of the function is chosen by the author.\n\nadd_two &lt;- function(x){\n  x + 2\n}\n\n\nCaution: Function names have no inherent meaning.\n\nThe name you give to a function does not affect what the function does.\n\n\nadd_three &lt;- function(x){\n  x + 7\n}\n\n\nadd_three(5)\n\n[1] 12"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#arguments",
    "href": "slides/week-7/w7-data-functions.html#arguments",
    "title": "Writing Functions",
    "section": "Arguments",
    "text": "Arguments\nThe argument(s) of the function are chosen by the author.\n\nArguments are how we pass external values into the function.\nThey are temporary variables that only exist inside the function body.\n\n\n\n\nWe give them general names:\n\nx, y, z – vectors\ndf – dataframe\ni, j – indices\n\n\n\n\n\nadd_two &lt;- function(x){\n  x + 2\n}"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#body",
    "href": "slides/week-7/w7-data-functions.html#body",
    "title": "Writing Functions",
    "section": "Body: {  }",
    "text": "Body: {  }\nThe body of the function is where the action happens.\n\nThe body must be specified within a set of curly brackets.\nThe code in the body will be executed (in order) whenever the function is called.\n\n\nadd_two &lt;- function(x){\n  x + 2\n}"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#output-return",
    "href": "slides/week-7/w7-data-functions.html#output-return",
    "title": "Writing Functions",
    "section": "Output: return()",
    "text": "Output: return()\nYour function will give back what would normally print out…\n\nadd_two &lt;- function(x){\n  x + 2\n}\n\n\n\n\n\n7 + 2\n\n[1] 9\n\n\n\n\nadd_two(7)\n\n[1] 9\n\n\n\n\n\n…but it’s better to be explicit and use return().\n\nadd_two &lt;- function(x){\n  return(x + 2)\n}"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#output-return-1",
    "href": "slides/week-7/w7-data-functions.html#output-return-1",
    "title": "Writing Functions",
    "section": "Output: return()",
    "text": "Output: return()\nIf you need to return more than one object from a function, wrap those objects in a list.\n\nmin_max &lt;- function(x){\n  lowest &lt;- min(x)\n  highest &lt;- max(x)\n  return(list(min = lowest, max = highest))\n}\n\nvec &lt;- c(346,547,865,346,6758,78,79,362)\nmin_max(vec)\n\n$min\n[1] 78\n\n$max\n[1] 6758"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#pa7-q1-6",
    "href": "slides/week-7/w7-data-functions.html#pa7-q1-6",
    "title": "Writing Functions",
    "section": "PA7 Q1-6",
    "text": "PA7 Q1-6\n\n\n\n\n\n\nStart Practicing!\n\n\nWrite a function to divide each element in a vector by the smallest element and round the results to the nearest whole number and return the resulting vector.\nWrite a function that, for each element in a vector, returns TRUE if the number is NOT divisible by 9 or 12, and returns FALSE otherwise\n\n\n\nThink through…\n\nWhat are arguments?\nWhat should the function return?"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#arguments-cont.",
    "href": "slides/week-7/w7-data-functions.html#arguments-cont.",
    "title": "Writing Functions",
    "section": "Arguments Cont.",
    "text": "Arguments Cont.\n\nOptional argumentsRequired arguments\n\n\nIf we supply a default value when defining the function, the argument is optional when calling the function.\n\nadd_something &lt;- function(x, something = 2){\n  return(x + something)\n}\n\n\nIf a value is not supplied, something defaults to 2.\n\n\nadd_something(x = 5)\n\n[1] 7\n\n\n\nadd_something(x = 5, something = 6)\n\n[1] 11\n\n\n\n\nIf we do not supply a default value when defining the function, the argument is required when calling the function.\n\nadd_something &lt;- function(x, something){\n  x + something\n}\n\nadd_something(x = 2)\n\nError in add_something(x = 2): argument \"something\" is missing, with no default"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#input-validation",
    "href": "slides/week-7/w7-data-functions.html#input-validation",
    "title": "Writing Functions",
    "section": "Input Validation",
    "text": "Input Validation\nWhen a function requires an input of a specific data type, check that the supplied argument is valid.\n\n stopifnot()  if() + stop() Multiple validations\n\n\n\nadd_something &lt;- function(x, something){\n  stopifnot(is.numeric(x))\n  return(x + something)\n}\n\nadd_something(x = \"statistics\", something = 5)\n\nError in add_something(x = \"statistics\", something = 5): is.numeric(x) is not TRUE\n\n\n\n\n\nadd_something &lt;- function(x, something){\n  if(!is.numeric(x)){\n    stop(\"Please provide a numeric input for the x argument.\")\n  }\n  return(x + something)\n}\n\nadd_something(x = \"statistics\", something = 5)\n\nError in add_something(x = \"statistics\", something = 5): Please provide a numeric input for the x argument.\n\n\n\n\n\nadd_something &lt;- function(x, something){\n  if(!is.numeric(x) | !is.numeric(something)){\n    stop(\"Please provide numeric inputs for both arguments.\")\n  }\n  return(x + something)\n}\n\nadd_something(x = 2, something = \"R\")\n\nError in add_something(x = 2, something = \"R\"): Please provide numeric inputs for both arguments.\n\n\n\nadd_something &lt;- function(x, something){\n  stopifnot(is.numeric(x), is.numeric(something))\n  return(x + something)\n}\n\nadd_something(x = \"statistics\", something = \"R\")\n\nError in add_something(x = \"statistics\", something = \"R\"): is.numeric(x) is not TRUE"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#pa7-q7-8",
    "href": "slides/week-7/w7-data-functions.html#pa7-q7-8",
    "title": "Writing Functions",
    "section": "PA7 Q7-8",
    "text": "PA7 Q7-8\n\n\n\n\n\n\nPracticing with optional v. required arguments\n\n\nWrite a function called every_other(). This function should take in a vector and return every other value in the vector. Include an optional argument called start which lets you choose where to start skipping; that is, if start = 1, the function returns the 1st, 3rd, 5th, etc. values and if start = 2, the function returns the 2nd, 4th, 6th, etc. values.\n\n\n\n\n\n\n\n\n\nAdd some input validation if you have time!\n\n\nfirst argument: vec should be a vector (length more than 1?)\nsecond argument: start only takes values of 1 or 2"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#variable-scope",
    "href": "slides/week-7/w7-data-functions.html#variable-scope",
    "title": "Writing Functions",
    "section": "Variable Scope",
    "text": "Variable Scope\nThe location (environment) in which we can find and access a variable is called its scope.\n\nWe need to think about the scope of variables when we write functions.\nWhat variables can we access inside a function?\nWhat variables can we access outside a function?"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#global-environment",
    "href": "slides/week-7/w7-data-functions.html#global-environment",
    "title": "Writing Functions",
    "section": "Global Environment",
    "text": "Global Environment\n\nThe top right pane of Rstudio shows you the global environment.\n\nThis is the current state of all objects you have created.\nThese objects can be accessed anywhere."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#function-environment",
    "href": "slides/week-7/w7-data-functions.html#function-environment",
    "title": "Writing Functions",
    "section": "Function Environment",
    "text": "Function Environment\n\nThe code inside a function executes in the function environment.\n\nFunction arguments and any variables created inside the function only exist inside the function.\n\nThey disappear when the function code is complete.\n\nWhat happens in the function environment does not affect things in the global environment."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#function-environment-1",
    "href": "slides/week-7/w7-data-functions.html#function-environment-1",
    "title": "Writing Functions",
    "section": "Function Environment",
    "text": "Function Environment\nWe cannot access variables created inside a function outside of the function.\n\nadd_two &lt;- function(x) {\n  my_result &lt;- x + 2\n  return(my_result)\n}\n\nadd_two(9)\n\n[1] 11\n\nmy_result\n\nError: object 'my_result' not found"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#name-masking",
    "href": "slides/week-7/w7-data-functions.html#name-masking",
    "title": "Writing Functions",
    "section": "Name Masking",
    "text": "Name Masking\nName masking occurs when an object in the function environment has the same name as an object in the global environment.\n\nadd_two &lt;- function(x) {\n  my_result &lt;- x + 2\n  return(my_result)\n}\n\n\nmy_result &lt;- 2000\n\n\nThe my_result created inside the function is different from the my_result created outside.\n\n\n\nadd_two(5)\n\n[1] 7\n\n\n\n\nmy_result\n\n[1] 2000"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#dynamic-lookup",
    "href": "slides/week-7/w7-data-functions.html#dynamic-lookup",
    "title": "Writing Functions",
    "section": "Dynamic Lookup",
    "text": "Dynamic Lookup\nFunctions look for objects FIRST in the function environment and SECOND in the global environment.\n\nIf the object doesn’t exist in either, the code will give an error.\n\n\n\n\nadd_two &lt;- function() {\n  return(x + 2)\n}\n\nadd_two()\n\nError in add_two(): object 'x' not found\n\n\n\n\nx &lt;- 10\n\nadd_two()\n\n[1] 12\n\n\n\n\nIt is not good practice to rely on global environment objects inside a function!"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#pa-7-q9---11",
    "href": "slides/week-7/w7-data-functions.html#pa-7-q9---11",
    "title": "Writing Functions",
    "section": "PA 7 Q9 - 11",
    "text": "PA 7 Q9 - 11\n\n\n\n\n\n\nFinish PA7\n\n\nWrite a function called shorten(). This function should take in a vector, drop all values BEFORE the cumulative sum is greater than a provided number, and return the remaining values from the original vector.\n\n\n\nThink through for your function:\n\nWhat are the arguments and what kinds of values do they take?\nAre any of the arguments optional?\nWhat should it return?"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#pair-our-function-with-dplyr",
    "href": "slides/week-7/w7-data-functions.html#pair-our-function-with-dplyr",
    "title": "Writing Functions",
    "section": "Pair Our Function with dplyr",
    "text": "Pair Our Function with dplyr\nConsider the penguins Data\n\nlibrary(palmerpenguins)\ndata(penguins)\npenguins |&gt; \n  head()\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#function-to-standardize-data",
    "href": "slides/week-7/w7-data-functions.html#function-to-standardize-data",
    "title": "Writing Functions",
    "section": "Function to Standardize Data",
    "text": "Function to Standardize Data\nWe want to take in a vector of numbers and standardize it – make all values be between 0 and 1.\n\n\nstd_to_01 &lt;- function(var) {\n  stopifnot(is.numeric(var))\n  \n  num &lt;- var - min(var, na.rm = TRUE)\n  denom &lt;- max(var, na.rm = TRUE) - min(var, na.rm = TRUE)\n  \n  return(num / denom)\n}"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#standardizing-variables",
    "href": "slides/week-7/w7-data-functions.html#standardizing-variables",
    "title": "Writing Functions",
    "section": "Standardizing Variables",
    "text": "Standardizing Variables\nIs it a good idea to standardize (scale) variables in a data analysis?\n\n\nWhy standardize?\n\nEasier to compare across variables.\nEasier to model – standardizes the amount of variability.\n\n\nWhy not standardize?\n\nMore difficult to interpret the values.\n\n\n\nE.g., a penguin with a bill length of 35 mm (std to 0.11) and a mass of 5500 g (std to 0.78)."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#pair-our-function-with-dplyr-1",
    "href": "slides/week-7/w7-data-functions.html#pair-our-function-with-dplyr-1",
    "title": "Writing Functions",
    "section": "Pair Our Function with dplyr",
    "text": "Pair Our Function with dplyr\nLet’s standardize penguin measurements.\n\npenguins |&gt; \n  mutate(bill_length_mm    = std_to_01(bill_length_mm), \n         bill_depth_mm     = std_to_01(bill_depth_mm), \n         flipper_length_mm = std_to_01(flipper_length_mm), \n         body_mass_g       = std_to_01(body_mass_g))\n\n\nUgh. Still copy-pasting!\n\n\nRecall across()!\n\npenguins |&gt; \n  mutate(across(.cols = bill_length_mm:body_mass_g,\n                .fns = ~ std_to_01(.x))) |&gt; \n  slice_head(n = 4)\n\n# A tibble: 4 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen          0.255         0.667             0.153       0.292\n2 Adelie  Torgersen          0.269         0.512             0.237       0.306\n3 Adelie  Torgersen          0.298         0.583             0.390       0.153\n4 Adelie  Torgersen         NA            NA                NA          NA    \n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#use-variables-as-function-arguments",
    "href": "slides/week-7/w7-data-functions.html#use-variables-as-function-arguments",
    "title": "Writing Functions",
    "section": "Use variables as function arguments?",
    "text": "Use variables as function arguments?\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n  \n  data &lt;- data |&gt; \n    mutate(variable = std_to_01(variable))\n  return(data)\n}\n\n\n\n\n\n\n\nNote\n\n\nI used the existing function std_to_01() inside the new function for clarity!\n\n\n\n\nBut it didn’t work…\n\nstd_column_01(penguins, body_mass_g)\n\nError in `mutate()`:\nℹ In argument: `variable = std_to_01(variable)`.\nCaused by error:\n! object 'body_mass_g' not found"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#tidy-evaluation",
    "href": "slides/week-7/w7-data-functions.html#tidy-evaluation",
    "title": "Writing Functions",
    "section": "Tidy Evaluation",
    "text": "Tidy Evaluation\nFunctions using unquoted variable names as arguments are said to use nonstandard evaluation or tidy evaluation.\n\n\nTidy:\n\npenguins |&gt; \n  pull(body_mass_g)\n\n  OR\n\npenguins$body_mass_g\n\n\nUntidy:\n\npenguins[, \"body_mass_g\"]\n\n  OR\n\npenguins[[\"body_mass_g\"]]\n\n\n\n\nTidy evaluation isn’t naturally supported when writing your own functions."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#defused-r-code",
    "href": "slides/week-7/w7-data-functions.html#defused-r-code",
    "title": "Writing Functions",
    "section": "Defused R Code",
    "text": "Defused R Code\nWhen a piece of code is defused, R doesn’t return its value like normal.\n\nInstead it returns an expression that describes how to evaluate it.\n\n\n\n\nEvaluated code:\n\n1 + 1\n\n[1] 2\n\n\n\nDefused code:\n\nexpr(1 + 1)\n\n1 + 1\n\n\n\n\n\nWe produce defused code when we use tidy evaluation and our own functions don’t know how to handle it."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#solution-1",
    "href": "slides/week-7/w7-data-functions.html#solution-1",
    "title": "Writing Functions",
    "section": "Solution 1",
    "text": "Solution 1\nDon’t use tidy evaluation in your own functions.\n\nThis is more complicated to read and use, but it’s safe.\n\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n  \n  data[[variable]] &lt;- std_to_01(data[[variable]])\n  return(data)\n}\n\nstd_column_01(penguins, \"bill_length_mm\")"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#solution-2-rlang",
    "href": "slides/week-7/w7-data-functions.html#solution-2-rlang",
    "title": "Writing Functions",
    "section": "Solution 2: rlang",
    "text": "Solution 2: rlang\nUse the rlang package!\n\n\n\nThis package provides operators that simplify writing functions around tidyverse pipelines.\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead more about using this package for function writing here!"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#solution-2-rlang-1",
    "href": "slides/week-7/w7-data-functions.html#solution-2-rlang-1",
    "title": "Writing Functions",
    "section": "Solution 2: rlang",
    "text": "Solution 2: rlang\nTwo ways to get around the issue of defused code:\n\nEmbrace Operator ({ })\n\n\nWith { }, you can transport a variable from one function to another.\n\n\n\nDefuse and Inject\n\n\nYou can first use enquo(arg) to defuse the variable.\nThen use !!arg to inject the variable.\n\n\n\n\n\n\n\nNote\n\n\nI am going to just focus on using the embrace operator for the rest of class, but know what difuse/inject is another option!"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#solution-2-rlang-2",
    "href": "slides/week-7/w7-data-functions.html#solution-2-rlang-2",
    "title": "Writing Functions",
    "section": "Solution 2: rlang",
    "text": "Solution 2: rlang\nIf we use either of these solutions, we also need to use the walrus operator (:=).\n\nThis means we have to use := instead of = in any dplyr verb containing one of these rlang fixes."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#recall-our-broken-function",
    "href": "slides/week-7/w7-data-functions.html#recall-our-broken-function",
    "title": "Writing Functions",
    "section": "Recall Our Broken Function",
    "text": "Recall Our Broken Function\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n  \n  data &lt;- data |&gt; \n    mutate(variable = std_to_01(variable))\n  return(data)\n}\n\nstd_column_01(penguins, body_mass_g) |&gt; \n  slice_head(n = 5)\n\nError in `mutate()`:\nℹ In argument: `variable = std_to_01(variable)`.\nCaused by error:\n! object 'body_mass_g' not found\n\n\n\nThe code is defused, so mutate() doesn’t know what body_mass_g is.\nWe need to modify variable to make this work correctly!"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#fixing-our-broken-function",
    "href": "slides/week-7/w7-data-functions.html#fixing-our-broken-function",
    "title": "Writing Functions",
    "section": "Fixing Our Broken Function",
    "text": "Fixing Our Broken Function\nUse the Embrace Operator:\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n\n  data &lt;- data |&gt;\n    mutate({{variable}} := std_to_01({{variable}}))\n  return(data)\n}\n\nstd_column_01(penguins, body_mass_g) |&gt; \n  slice_head(n = 5)\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181       0.292\n2 Adelie  Torgersen           39.5          17.4               186       0.306\n3 Adelie  Torgersen           40.3          18                 195       0.153\n4 Adelie  Torgersen           NA            NA                  NA      NA    \n5 Adelie  Torgersen           36.7          19.3               193       0.208\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#inject-multiple-variables",
    "href": "slides/week-7/w7-data-functions.html#inject-multiple-variables",
    "title": "Writing Functions",
    "section": "Inject Multiple Variables",
    "text": "Inject Multiple Variables\nWhat if I want to modify multiple columns?\n\nUse across()!\n\n\nstd_column_01 &lt;- function(data, variables) {\n  stopifnot(is.data.frame(data))\n  \n  data &lt;- data |&gt; \n    mutate(across(.cols = {{variables}},\n                  .fns = ~ std_to_01(.x)))\n  return(data)\n}\n\nstd_column_01(penguins, bill_length_mm:body_mass_g)\n\n\n\n# A tibble: 5 × 7\n  species island    bill_length_mm bill_depth_mm body_mass_g sex     year\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  &lt;int&gt;\n1 Adelie  Torgersen          0.255         0.667       0.292 male    2007\n2 Adelie  Torgersen          0.269         0.512       0.306 female  2007\n3 Adelie  Torgersen          0.298         0.583       0.153 female  2007\n4 Adelie  Torgersen         NA            NA          NA     &lt;NA&gt;    2007\n5 Adelie  Torgersen          0.167         0.738       0.208 female  2007"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#debugging-1",
    "href": "slides/week-7/w7-data-functions.html#debugging-1",
    "title": "Writing Functions",
    "section": "Debugging",
    "text": "Debugging\nYou will make mistakes (create bugs) when coding.\n\nUnfortunately, it becomes more and more complicated to debug your code as your code gets more sophisticated.\nThis is especially true with functions!"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#debugging-strategies",
    "href": "slides/week-7/w7-data-functions.html#debugging-strategies",
    "title": "Writing Functions",
    "section": "Debugging Strategies",
    "text": "Debugging Strategies\n\nInteractive coding\n\nHighlight lines within your function and run them one-by-one to see what happens.\n\n\n\n\nprint() debugging\n\nAdd print() statements throughout your code to make sure the values are what you expect.\n\n\n\n\n\nRubber Ducking\n\nVerbally explain your code line by line to a rubber duck (or a human)."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#debugging-strategies-1",
    "href": "slides/week-7/w7-data-functions.html#debugging-strategies-1",
    "title": "Writing Functions",
    "section": "Debugging Strategies",
    "text": "Debugging Strategies\nWhen you have a concept that you want to turn into a function…\n\nWrite a simple example of the code without the function framework.\nGeneralize the example by assigning variables.\nWrite the code into a function.\nCall the function on the desired arguments\n\nThis structure allows you to address issues as you go."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#an-example",
    "href": "slides/week-7/w7-data-functions.html#an-example",
    "title": "Writing Functions",
    "section": "An Example",
    "text": "An Example\nWrite a function called find_car_make() that takes in the name of a car and returns the “make” of the car (the company that created it).\n\nfind_car_make(\"Toyota Camry\") should return “Toyota”.\nfind_car_make(\"Ford Anglica\") should return “Ford”."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#an-example-1",
    "href": "slides/week-7/w7-data-functions.html#an-example-1",
    "title": "Writing Functions",
    "section": "An Example",
    "text": "An Example\n\nSimple ExamplesGeneralizeWrite + Call Funciton\n\n\n\nmake &lt;- str_extract(string = \"Toyota Camry\",\n                    pattern = \"[:alpha:]*\")\nmake\n\n[1] \"Toyota\"\n\nmake &lt;- str_extract(string = \"Ford Anglica\",\n                    pattern = \"[:alpha:]*\")\nmake\n\n[1] \"Ford\"\n\n\n\n\n\ncar_name &lt;- \"Toyota Camry\"\n\nmake &lt;- str_extract(string = car_name, \n                    pattern = \"[:alpha:]*\")\nmake\n\n[1] \"Toyota\"\n\n\n\n\n\nfind_car_make &lt;- function(car_name){\n  make &lt;- str_extract(string = car_name, \n                      pattern = \"[:alpha:]*\")\n  return(make)\n}\n\n\nfind_car_make(\"Toyota Camry\")\n\n[1] \"Toyota\"\n\nfind_car_make(\"Ford Anglica\")\n\n[1] \"Ford\""
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#types-of-missing-data",
    "href": "slides/week-7/w7-data-functions.html#types-of-missing-data",
    "title": "Writing Functions",
    "section": "Types of Missing Data",
    "text": "Types of Missing Data\n\nMissing Completely at Random (MCAR)\n\nNo difference between missing and observed values.\nMissing observations are a random subset of all observations.\n\nMissing at Random (MAR)\n\nSystematic difference between missing and observed values, but can be entirely explained by other observed variables.\n\nMissing Not at Random (MNAR)\n\nMissingness is directly related to the unobserved value."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#types-of-missing-data-1",
    "href": "slides/week-7/w7-data-functions.html#types-of-missing-data-1",
    "title": "Writing Functions",
    "section": "Types of Missing Data",
    "text": "Types of Missing Data\nConsider a study of depression.\n\nMissing Completely at Random (MCAR)\n\nSome subjects have missing lab values because a batch of samples was processed improperly.\n\nMissing at Random (MAR)\n\nSubjects who identify as men are less likely to complete a survey on depression severity.\n\nMissing Not at Random (MNAR)\n\nSubjects with more severe depression are less likely to complete a survey on depression severity."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#when-we-remove-missing-data",
    "href": "slides/week-7/w7-data-functions.html#when-we-remove-missing-data",
    "title": "Writing Functions",
    "section": "When we remove missing data…",
    "text": "When we remove missing data…\nWe implicitly assume observations are missing completely at random!\n\nWe might be mostly removing data from subjects who identify as men.\nWe might be mostly removing data from subjects with severe depression.\nWe are inadvertently making our data less representative.\n\n\nWe need to take more care when dealing with missing values!"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#dealing-with-missing-data",
    "href": "slides/week-7/w7-data-functions.html#dealing-with-missing-data",
    "title": "Writing Functions",
    "section": "Dealing with Missing Data",
    "text": "Dealing with Missing Data\n\nLook for patterns!\n\nDo observations with missing values have similar traits?\n\n\n\n\nConsider outside explanations!\n\nWhy might missing data exist?\nShould we have a “missing” category in our analysis?\n\n\n\n\n\nCan we impute values?\n\nIf depression is MCAR within gender, age, and education level, then the distribution of depression will be similar for people of the same gender, age, and education level."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#lab-7-functions-fish",
    "href": "slides/week-7/w7-data-functions.html#lab-7-functions-fish",
    "title": "Writing Functions",
    "section": "Lab 7: Functions + Fish",
    "text": "Lab 7: Functions + Fish"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#to-do",
    "href": "slides/week-7/w7-data-functions.html#to-do",
    "title": "Writing Functions",
    "section": "To do…",
    "text": "To do…\n\nFinal Project Group Contract\n\nDue Tomorrow Friday, 5/16 at 11:59pm.\n\nLab 7: Functions + Fish\n\nDue Monday 5/19 at 11:59pm.\n\nRead Chapter 8: Iteration and Simulation\n\nCheck-in 8.1 & 8.2 due Tuesday 5/20 before class."
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#thursday-may-15",
    "href": "slides/week-7/w7-data-functions.html#thursday-may-15",
    "title": "Writing Functions",
    "section": "Thursday, May 15",
    "text": "Thursday, May 15\nToday we will…\n\nNew Material\n\nCalling Functions on Datasets\nrlang Tidy Evaluation\nMissing Data\n\nLab 7: Functions + Fish"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#fixing-our-broken-function-embrace-operator",
    "href": "slides/week-7/w7-data-functions.html#fixing-our-broken-function-embrace-operator",
    "title": "Writing Functions",
    "section": "Fixing Our Broken Function (Embrace Operator)",
    "text": "Fixing Our Broken Function (Embrace Operator)\n\nstd_column_01 &lt;- function(data, variable) {\n  stopifnot(is.data.frame(data))\n\n  data &lt;- data |&gt;\n    mutate({{variable}} := std_to_01({{variable}}))\n  return(data)\n}\n\nstd_column_01(penguins, body_mass_g)"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html#transport-multiple-variables",
    "href": "slides/week-7/w7-data-functions.html#transport-multiple-variables",
    "title": "Writing Functions",
    "section": "Transport Multiple Variables",
    "text": "Transport Multiple Variables\nWhat if I want to modify multiple columns?\n\nUse across()!\n\n\nstd_column_01 &lt;- function(data, variables) {\n  stopifnot(is.data.frame(data))\n  \n  data &lt;- data |&gt; \n    mutate(across(.cols = {{variables}},\n                  .fns = ~ std_to_01(.x)))\n  return(data)\n}\n\nstd_column_01(penguins, bill_length_mm:body_mass_g) |&gt; \n  slice_head(n = 5)\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen          0.255         0.667             0.153       0.292\n2 Adelie  Torgersen          0.269         0.512             0.237       0.306\n3 Adelie  Torgersen          0.298         0.583             0.390       0.153\n4 Adelie  Torgersen         NA            NA                NA          NA    \n5 Adelie  Torgersen          0.167         0.738             0.356       0.208\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#thursday-may-1",
    "href": "slides/week-5/week-5-dates.html#thursday-may-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Thursday, May 1",
    "text": "Thursday, May 1\nToday we will…\n\nMidterm Exam - What to expect\nNew Material\n\nWorking with Date & Time Variables\n\nPA 5.2: Jewel Heist"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#open-ended-analysis-from-lab-4-1",
    "href": "slides/week-6/w6-version-control.html#open-ended-analysis-from-lab-4-1",
    "title": "Version Control",
    "section": "Open-Ended Analysis from Lab 4",
    "text": "Open-Ended Analysis from Lab 4\nDiscussing Data\n\n\nWhat would you need to tell something if they knew nothing about the data already?? Probably should include:\n\nData source\nObservational unit / level (e.g. county and year)\nOverview of what is included (e.g. demographic information and weekly median childcare costs for each county and year)\nYears or geographies included (e.g. 2008-2018, CA only)"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#open-ended-analysis-from-lab-4-2",
    "href": "slides/week-6/w6-version-control.html#open-ended-analysis-from-lab-4-2",
    "title": "Version Control",
    "section": "Open-Ended Analysis from Lab 4",
    "text": "Open-Ended Analysis from Lab 4\n\nTable Design\n\nThink about the number of rows/columns – is it readable?\nHow many decimal points are needed?\nChange row/column names to be understandable.\n\nPlot Design\n\nWhat can I investigate with a plot that is difficult with a table?\nWhat type of plot will best display the data?\nWhat order of elements will best display the comparison you want to make?\nThink about: colors, order of categories, if a legend is needed, etc."
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#open-ended-analysis-from-lab-4-3",
    "href": "slides/week-6/w6-version-control.html#open-ended-analysis-from-lab-4-3",
    "title": "Version Control",
    "section": "Open-Ended Analysis from Lab 4",
    "text": "Open-Ended Analysis from Lab 4\n\nDiscussing Figures\n\nDescribe / explain what your table / plot is showing before analyzing it\nIf you are taking a statistical summary you should be clear what the summary is taken over\nMake it clear what one point on your plot represents"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#describing-tables",
    "href": "slides/week-6/w6-version-control.html#describing-tables",
    "title": "Version Control",
    "section": "Describing Tables",
    "text": "Describing Tables\n\n\nCode\nca_childcare_long &lt;- ca_childcare |&gt; \n  select(county_name, study_year, mc_infant:mfcc_preschool,\n         total_property_taxes, total_pop, me_2018) |&gt;\n  pivot_longer(cols = starts_with(\"mc\") | starts_with(\"mfcc\"),\n               names_to = c(\"type\", \"age_group\"),\n               names_sep = \"_\",\n               values_to = \"med_cost\") |&gt; \n  filter(!is.na(total_property_taxes)) |&gt; \n  mutate(tax_per_cap = total_property_taxes / total_pop,\n         wealth_level = case_when(tax_per_cap &lt;= quantile(tax_per_cap, .25) ~ \"Lower 1/4\",\n                                  tax_per_cap &lt;= quantile(tax_per_cap, .75) ~ \"Middle Half\",\n                                                                       TRUE ~ \"Upper 1/4\"))\n\nca_childcare_long |&gt; \n  group_by(wealth_level, type, age_group) |&gt; \n  summarize(mean_cost = mean(med_cost)) |&gt; \n  pivot_wider(values_from = mean_cost,\n              names_from = type) |&gt; \n  filter(age_group != \"preschool\") |&gt; \n  mutate(age_group = str_to_title(age_group),\n         perc_dif = mc /mfcc) |&gt; \n  rename(price_center = mc,\n         price_family = mfcc) |&gt; \n  kable(digits = 2)\n\n\n\n\n\nwealth_level\nage_group\nprice_center\nprice_family\nperc_dif\n\n\n\n\nLower 1/4\nInfant\n254.67\n158.89\n1.60\n\n\nLower 1/4\nToddler\n184.26\n148.55\n1.24\n\n\nMiddle Half\nInfant\n272.55\n172.92\n1.58\n\n\nMiddle Half\nToddler\n194.56\n159.85\n1.22\n\n\nUpper 1/4\nInfant\n276.37\n182.78\n1.51\n\n\nUpper 1/4\nToddler\n196.26\n170.12\n1.15\n\n\n\n\n\n\n\n\n\n\n\nCan you tell??\n\n\nWithout looking at the code, what does each cell in this table represent?"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#describing-plots",
    "href": "slides/week-6/w6-version-control.html#describing-plots",
    "title": "Version Control",
    "section": "Describing Plots",
    "text": "Describing Plots\n\n\nCode\nca_childcare_long |&gt; \n  filter(age_group != \"preschool\") |&gt; \n  mutate(age_group = str_to_title(age_group),\n         type = fct_recode(type,\n                           \"Center-Based\" = \"mc\",\n                           \"Family-Based\" = \"mfcc\")) |&gt; \n  group_by(wealth_level, age_group, type, study_year) |&gt; \n  summarize(upper_q = quantile(med_cost, .75),\n            lower_q = quantile(med_cost, .25),\n            med_cost = median(med_cost),\n            ) |&gt; \n  ggplot(aes(x = study_year, y = med_cost,\n             group = interaction(type, wealth_level))) +\n  geom_ribbon(aes(ymin = lower_q, ymax = upper_q, fill = type),\n                alpha = .15,\n                linetype = 0) +\n  geom_line(aes(color = type)) +\n  geom_point(aes(shape = fct_reorder2(wealth_level, \n                                      .x = study_year,\n                                      .y = med_cost),\n                color = type)) +\n  facet_wrap(vars(age_group)) +\n  scale_color_manual(name = \"Childcare Type\",\n                     values = c(\"#045a8d\",\"#fd8d3c\")) +\n  scale_fill_manual(name = \"Childcare Type\",\n                     values = c(\"#045a8d\",\"#fd8d3c\")) +\n  labs(subtitle = \"Median Weekly Cost ($)\",\n       y = \"\",\n       x = \"Year\",\n       shape = \"County Wealth\") +\n  scale_x_continuous(breaks = c(2008, 2010, 2012, 2014, 2016, 2018))"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#describing-plots-1",
    "href": "slides/week-6/w6-version-control.html#describing-plots-1",
    "title": "Version Control",
    "section": "Describing Plots",
    "text": "Describing Plots\n\n\nCode\nca_childcare_long |&gt; \n  filter(age_group != \"preschool\") |&gt; \n  mutate(age_group = str_to_title(age_group),\n         type = fct_recode(type,\n                           \"Center-Based\" = \"mc\",\n                           \"Family-Based\" = \"mfcc\")) |&gt; \n  mutate(week_income = me_2018 / 52,\n         cost_income_rat = med_cost / week_income) |&gt; \n  filter(study_year == 2018) |&gt; \n  ggplot(aes(x = type,\n             y = cost_income_rat,\n             fill = wealth_level)) +\n  geom_boxplot() +\n  facet_wrap(vars(age_group)) +\n  labs(x = \"Childcare Type\",\n       subtitle = \"Ratio of Median Weekly Childcare Cost to\\nMedian Weekly Income\",\n       y = \"\",\n       fill = \"County Tax Income\")"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#example-answering-a-research-question",
    "href": "slides/week-6/w6-version-control.html#example-answering-a-research-question",
    "title": "Version Control",
    "section": "Example: Answering a Research Question",
    "text": "Example: Answering a Research Question"
  },
  {
    "objectID": "slides/week-6/w6-version-control.html#example-answering-a-research-question-1",
    "href": "slides/week-6/w6-version-control.html#example-answering-a-research-question-1",
    "title": "Version Control",
    "section": "Example: Answering a Research Question",
    "text": "Example: Answering a Research Question"
  },
  {
    "objectID": "slides/week-7/w7-functions.html",
    "href": "slides/week-7/w7-functions.html",
    "title": "Writing Functions",
    "section": "",
    "text": "Today we will…\n\nLecture\n\nFunction Basics\nVariable Scope + Environment\nPA 7: Writing Functions throughout!\n\n\n\n\n\n\n\n\nFollow along\n\n\n\nRemember to download, save, and open up the starter notes for this week!"
  },
  {
    "objectID": "practice-activities/pa8-1.html",
    "href": "practice-activities/pa8-1.html",
    "title": "PA 8.1: The Twelve Days of Christmas",
    "section": "",
    "text": "Download starter .qmd template\nDownload xmas.csv data"
  },
  {
    "objectID": "practice-activities/pa8-1.html#introduction",
    "href": "practice-activities/pa8-1.html#introduction",
    "title": "PA 8.1: The Twelve Days of Christmas",
    "section": "Introduction",
    "text": "Introduction\nThe song The Twelve Days of Christmas, written around 1780, tells the tale of the many gifts one person receives in the days after Christmas (link to lyrics).\n\n\n\n\n\n\nNote\n\n\n\nYou can watch a video of The Twelve Days of Christmas being performed at the Cambria Christmas Market.\n\n\nThe gifts in this song repeat and compound. For example, on the first day, the narrator receives:\nA partridge in a pear tree.\nOn the twelfth day, they receive:\nTwelve Drummers Drumming\nEleven Pipers Piping\nTen Lords a Leaping\nNine Ladies Waiting\nEight Maids a Milking\nSeven Swans a Swimming\nSix Geese a Laying\nFive Golden Rings\nFour Calling Birds\nThree French Hens\nTwo Turtle Doves\nAnd a Partridge in a Pear Tree\nThis week, your task is to write functions that will automatically sing this very repetitive song. In the practice activity, we will start by writing two helper functions."
  },
  {
    "objectID": "practice-activities/pa8-1.html#dataset",
    "href": "practice-activities/pa8-1.html#dataset",
    "title": "PA 8.1: The Twelve Days of Christmas",
    "section": "Dataset",
    "text": "Dataset\nSave the xmas.csv on your computer (in a place that makes sense!) and edit the provided code to load a dataset called xmas. This dataset contains the crucial information about each gift in the song. We will use this dataset to test our functions as we work on them.\n\nxmas &lt;- read.csv(\"xmas.csv\")\n\nError in file(file, \"rt\"): cannot open the connection\n\n\n\n\n\n\n\n\nAdvice\n\n\n\n\nWorkflow\n\nMake smaller versions of the xmas dataset (e.g., the first two days) to test your functions before testing them on the full data set.\nYour functions should reference each other. That is, don’t duplicate code; use earlier, smaller functions inside your larger functions.\n\n\n\nBuild from small pieces\n\nIf you have some trouble getting started, I recommend writing a function that works in one case (e.g., for day 3), and then trying to generalize it.\n\n\n\nDon’t sweat the small stuff\n\nThere’s a lot you can do to polish the way the song prints, but we’re going to leave that be.\nAt this point, don’t get bogged down in details like how the song displays, or small grammar rules (like commas!)."
  },
  {
    "objectID": "practice-activities/pa8-1.html#plurals-pluralize_gift",
    "href": "practice-activities/pa8-1.html#plurals-pluralize_gift",
    "title": "PA 8.1: The Twelve Days of Christmas",
    "section": "1 Plurals – pluralize_gift()",
    "text": "1 Plurals – pluralize_gift()\nIn the xmas dataset, the gifts are listed as singular. For example, on day 5, the narrator in the song receives “five golden rings”, but the entry in the dataset for gift 5 simply says “ring”.\n\n\n\n\n\n\nHint\n\n\n\nThe gifts on days six and nine have unusual pluralization (not just adding an “s”). You may assume that in any other dataset we might apply this function to, there will be no additional special cases beyond these two types.\n\n\n\n\n\n\n\n\nImportant!\n\n\n\nYou should absolutely not hard-code anything into this function. It should work in general, not just for the items in the traditional version of The Twelve Days of Christmas.\nFor example, the word “ring” should not appear anywhere in the function. I should be able to give your function any gift and get back the plural of that gift.\n\n\nComplete the pluralize_gift() function below. This function should take in a gift (or a vector of gifts) and return the appropriate plural(s).\n\n# Function that takes a noun and makes it plural\n# Arguments: gift -- a string or vector of strings\n# Return:    a string or vector of strings with the pluralized words\n\npluralize_gift &lt;- function(gift){\n\n  \n  \n\n  return(gift)\n}\n\n\n\n\n\n\n\nTest Your Function\n\n\n\nTry your function on a smaller and then on the full gift dataset.\n\n# If your function is vectorized:\npluralize_gift(xmas$Gift.Item)\n\nError: object 'xmas' not found\n\n# If your function is not vectorized:\nmap_chr(xmas$Gift.Item, pluralize_gift)\n\nError: object 'xmas' not found"
  },
  {
    "objectID": "practice-activities/pa8-1.html#creating-sentences-make_phrase",
    "href": "practice-activities/pa8-1.html#creating-sentences-make_phrase",
    "title": "PA 8.1: The Twelve Days of Christmas",
    "section": "2 Creating Sentences – make_phrase()",
    "text": "2 Creating Sentences – make_phrase()\nWrite a function called make_phrase() that takes in the necessary information and returns a phrase. For example:\nmake_phrase(num       = 10,\n            item      = \"lord\", \n            verb      = \"a-leaping\", \n            adjective = \"\", \n            location  = \"\")\nshould return\n\"ten lords a-leaping\"\n\n\n\n\n\n\nTip\n\n\n\nThe Day.in.Words variable isn’t quite what you want. You want 12 to say \"twelve\" not \"twelfth\". I suggest using the english package to create number words from number digits.\nIf you get a frustrating error from the english package, try wrapping as.character() around your new number word.\n\n\n\nmake_phrase &lt;- function(num, item, verb, adjective, location) {\n  \n  ## Step 1: Replace NAs with blank strings.\n  verb &lt;- str_replace_na(verb, \"\")\n  \n  \n  ## Step 2: If the day number is larger than 1, the gift must be plural.\n  ### Hint: call the function you created above!\n  \n  \n  ## Step 3: Figure out if the gift starts with a vowel.\n  \n  \n  ## Step 4: For day 1, if the gift starts with a vowel, make day_word be \"an\" and if the gift does not start with a vowel, make the day_word be \"a\" (e.g. a partridge in a pear tree).\n  ### For the other days, make day_word be the number word (e.g. ten lords a-leaping).\n  ### See the tip above about turning numbers into words (e.g. 10 into ten).\n  day_word\n  \n  ## Step 5: Glue all of the pieces together into one string and return!\n  \n  return(phrase)\n}\n\n\n\n\n\n\n\nTest Your Function\n\n\n\nTry your function out on the xmas data by making a new variable containing the daily phrases. I’ve provided you with skeleton code to iterate through each row of the dataset – all you need to do is provide the necessary inputs.\n\nxmas2 &lt;- xmas |&gt; \n  mutate(full_phrase = pmap_chr(.l = list(num       = ______,\n                                          item      = ______, \n                                          verb      = ______, \n                                          adjective = ______, \n                                          location  = ______), \n                                .f = make_phrase))\nxmas2\n\nError in parse(text = input): &lt;text&gt;:2:56: unexpected input\n1: xmas2 &lt;- xmas |&gt; \n2:   mutate(full_phrase = pmap_chr(.l = list(num       = __\n                                                          ^"
  },
  {
    "objectID": "practice-activities/pa8-1.html#canvas-submission",
    "href": "practice-activities/pa8-1.html#canvas-submission",
    "title": "PA 8.1: The Twelve Days of Christmas",
    "section": "Canvas Submission",
    "text": "Canvas Submission\n\nYour full_phrase column is the answer to this week’s practice activity.\nTake a screenshot of your full_phrase column to show me the phrases you made!"
  },
  {
    "objectID": "practice-activities/pa9.html",
    "href": "practice-activities/pa9.html",
    "title": "PA 9: Mystery Animal",
    "section": "",
    "text": "Download starter .qmd template"
  },
  {
    "objectID": "practice-activities/pa9.html#data",
    "href": "practice-activities/pa9.html#data",
    "title": "PA 9: Mystery Animal",
    "section": "1 Data",
    "text": "1 Data\nThe data contain the weights of a particular animal species before and after a year of eating only roasted duck.\n\nmystery_animal &lt;- read_csv(\"https://raw.githubusercontent.com/zoerehnberg/STAT331-S23/main/practice_activities/mystery_animal.csv\")"
  },
  {
    "objectID": "practice-activities/pa9.html#visualize-the-data",
    "href": "practice-activities/pa9.html#visualize-the-data",
    "title": "PA 9: Mystery Animal",
    "section": "2 Visualize the Data",
    "text": "2 Visualize the Data\nLet’s start by visualizing the data. Create a scatterplot of the weights and fit a linear regression line. Make sure you use good graphic design principles in your plot!\n\n# Create your plot here."
  },
  {
    "objectID": "practice-activities/pa9.html#linear-regression",
    "href": "practice-activities/pa9.html#linear-regression",
    "title": "PA 9: Mystery Animal",
    "section": "3 Linear Regression",
    "text": "3 Linear Regression\nNow let’s look at the model. Fit a linear regression to determine if the Duck Diet is associated with the animal species gaining weight, losing weight, or neither.\n\n# Fit your linear regression model here.\n\nBased on the linear regression model, these animals tend to ____________ weight on the Duck Diet."
  },
  {
    "objectID": "practice-activities/pa9.html#residuals",
    "href": "practice-activities/pa9.html#residuals",
    "title": "PA 9: Mystery Animal",
    "section": "4 Residuals",
    "text": "4 Residuals\nFinally, let’s look at model fit. Extract the residuals (observed value minus predicted value) of your linear model. Plot the residuals versus weight_before.\n\n\n\n\n\n\nTip\n\n\n\nThere are a few different ways to obtain your residuals. My favorite is the augment() function from the broom package. I like this option because it gives you all of the information from your linear regression in a tidy tibble!\n\n\n\n# Extract and plot the residuals here."
  },
  {
    "objectID": "practice-activities/pa9.html#canvas-submission-mystery-animal",
    "href": "practice-activities/pa9.html#canvas-submission-mystery-animal",
    "title": "PA 9: Mystery Animal",
    "section": "5 Canvas Submission: Mystery Animal",
    "text": "5 Canvas Submission: Mystery Animal\n\nWhat animal do you see in the residual plot?"
  },
  {
    "objectID": "course-info/stud-info/project_groups.html",
    "href": "course-info/stud-info/project_groups.html",
    "title": "Reformat 331 Project Groups",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readxl)\n\n\nproj_groups &lt;- read_excel(\"stud_info.xlsx\", sheet = \"project_groups\")\n\n\nproj_groups_wide &lt;- proj_groups |&gt; \n  mutate(last_initial = str_sub(Student, start = 1, end = 1),\n         first_name = str_extract(Student, \",\\\\s([:alpha:]*)\",group = 1),\n         name = str_c(first_name,\" \", last_initial, \".\")) |&gt; \n  select(name, section = Section, group = Group) |&gt; \n  group_by(group) |&gt; \n  mutate(n_sec = n_distinct(section),\n         n_stud = row_number()) |&gt; \n  mutate(type = case_when(n_sec == 2 ~ \"Both Sections\",\n                         section == 70 ~ \"Section 70\",\n                         TRUE ~ \"Section 71\"),\n         type = fct_relevel(type,\n                            c(\"Section 70\",\n                            \"Both Sections\",\n                            \"Section 71\")))  |&gt; \n  select(-section, -n_sec)  |&gt; \n  pivot_wider(names_from = n_stud,\n              values_from = name,\n              names_prefix = \"member_\") |&gt; \n  arrange(type, group) |&gt; \n  select(type, everything())\n\nWarning: There were 20 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `type = fct_relevel(type, c(\"Section 70\", \"Both Sections\",\n  \"Section 71\"))`.\nℹ In group 1: `group = \"A\"`.\nCaused by warning:\n! 2 unknown levels in `f`: Both Sections and Section 71\nℹ Run `dplyr::last_dplyr_warnings()` to see the 19 remaining warnings.\n\n\n\nwrite_csv(proj_groups_wide, \"project_groups.csv\")"
  },
  {
    "objectID": "practice-activities/pa8-2.html",
    "href": "practice-activities/pa8-2.html",
    "title": "PA 8.2: Instrument Con",
    "section": "",
    "text": "Download starter .qmd template\nProfessor Harold Hill wanders into your small town. He claims to be selling top-quality instruments for a marching band. He begins selling his instruments to all the children in town.\nYou are suspicious of Professor Hill, and think that perhaps he is selling instruments made of sub-par materials to scam the townsfolk.\nYou do some research on the weights of properly crafted brass instruments, and you learn the following facts:"
  },
  {
    "objectID": "practice-activities/pa8-2.html#warm-up",
    "href": "practice-activities/pa8-2.html#warm-up",
    "title": "PA 8.2: Instrument Con",
    "section": "Warm-up",
    "text": "Warm-up\n1. What is the 95th percentile for trumpet weight?\n\n# Q1 code\n\n2. What is the 10th percentile for trombone weight?\n\n# Q2 code\n\n3. About what percent of trombones do you expect to be more than 5 pounds?\n\n# Q3 code\n\n4. About what percent of reed instruments do you expect to be more than 5 pounds?\n\n# Q4 code\n\n5. Simulate 100 random trombone weights. How many of them were below 4 pounds?\n\n# Q5 code"
  },
  {
    "objectID": "practice-activities/pa8-2.html#catching-a-con",
    "href": "practice-activities/pa8-2.html#catching-a-con",
    "title": "PA 8.2: Instrument Con",
    "section": "Catching a Con",
    "text": "Catching a Con\nYou manage to intercept a shipping notice for a delivery to Professor Hill. It says the following:\nWells Fargo Shipment 1957\n\nTo:  Harold Hill, Mason City, Iowa\nFrom:  Music Factory, Gary, Indiana\n\nItems included:\n    Trombones: 76\n    Cornets: 110\n    Saxophones: 542\n    Clarinets: 318\n    Bassoons: 175\n    \nTotal Shipped Weight: 4532 lbs.\nThis is your chance to catch Professor Hill in his lie!\n6. Write a function that samples the correct number of trombones, cornets (trumpets), and reed instruments (saxophones, clarinets, bassoons), and then returns the total weight of the shipment.\n\nmusic_man &lt;- function(n_tromb, n_cor, n_reed){\n  \n  trombones &lt;- rnorm(n_tromb, ...)\n  cornets   &lt;- ...\n  reeds     &lt;- ...\n  \n  ...\n  \n  return()\n  \n}\n\n7. Use the function you just wrote to create random samples of the total weight of 1000 possible shipments by finishing the code below.\n\n\n\n\n\n\nCaution\n\n\n\nDo not change the seed in the code provided below!\n\n\n\nset.seed(1957)\n\nmy_weights &lt;- map_dbl(.x = ... , \n                      .f = ~ music_man(n_tromb = 76, ...))\n\nError: '...' used in an incorrect context"
  },
  {
    "objectID": "practice-activities/pa8-2.html#canvas-submission",
    "href": "practice-activities/pa8-2.html#canvas-submission",
    "title": "PA 8.2: Instrument Con",
    "section": "Canvas submission",
    "text": "Canvas submission\n\nHow many of these samples had a weight less than or equal to Professor Hill’s shipment?\nDo you beleive Professor Hill ordered genuine instruments?\n\n\n# Canvas submission code"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#tuesday-520",
    "href": "slides/week-8/w8-iteration.html#tuesday-520",
    "title": "Iteration",
    "section": "Tuesday, 5/20",
    "text": "Tuesday, 5/20\nToday we will…\n\nProject Proposal + Data\nNew Material1\n\nIteration aka Performing Repeated Tasks\nVectorization\nEfficient Iteration: the map() family\n\nMidterm Feedback\nPA 8.1: The Twelve Days of Christmas\n\nMaterial and images for today’s lecture were modified from Dr. Theobold and Hansjörg Neth’s ds4psy text"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#project-proposal-data",
    "href": "slides/week-8/w8-iteration.html#project-proposal-data",
    "title": "Iteration",
    "section": "Project Proposal + Data",
    "text": "Project Proposal + Data\nYou must complete the objectives and write up the written components outlined under Section 1 on the Project Details page on Canvas.\n\nChoose variables that you think would feasibly be related (you have a hypothesis)\nYou may want to check there isn’t a huge amount of missing data\nDue on Canvas by 11:59pm on Friday, 5/23\n“Group” Canvas assignment, so only one person needs to submit it in your group"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#repetition",
    "href": "slides/week-8/w8-iteration.html#repetition",
    "title": "Iteration",
    "section": "Repetition",
    "text": "Repetition\nType out the task over and over.\n\n\n\n\n\nhttps://bookdown.org/hneth/ds4psyl\n\n\n\n\n\nDo not do this."
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#iteration",
    "href": "slides/week-8/w8-iteration.html#iteration",
    "title": "Iteration",
    "section": "Iteration",
    "text": "Iteration\nRepeatedly execute the same operation over and over.\n\nLoops (e.g., for() and while()) allow us to iterate.\n\n\n\n\nfor(i in 1:6){\n  print(i^2)\n}\n\n[1] 1\n[1] 4\n[1] 9\n[1] 16\n[1] 25\n[1] 36\n\n\n\n\n\n\n\n\nhttps://bookdown.org/hneth/ds4psyl"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#iteration-1",
    "href": "slides/week-8/w8-iteration.html#iteration-1",
    "title": "Iteration",
    "section": "Iteration",
    "text": "Iteration\nRepeatedly execute the same operation over and over.\n\nLoops (e.g., for() and while()) allow us to iterate.\n\n\n\n\nfor(i in 1:6){\n  print(i^2)\n}\n\n[1] 1\n[1] 4\n[1] 9\n[1] 16\n[1] 25\n[1] 36\n\n\n\nBut loops tend to be slow!\n\n\n\n\n\n\n\nhttps://bookdown.org/hneth/ds4psyl"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#vectorization",
    "href": "slides/week-8/w8-iteration.html#vectorization",
    "title": "Iteration",
    "section": "Vectorization",
    "text": "Vectorization\nMany operations in R are vectorized.\n\nThese functions operate on vectors of values rather than a single value.\nWe can iterate without writing a loop.\n\n\n\nx &lt;- seq(from = -4, to = 6)\nx\n\n [1] -4 -3 -2 -1  0  1  2  3  4  5  6\n\n\n\n\nLoop:\n\nfor(i in 1:length(x)){\n  x[i] &lt;- abs(x[i])\n}\nx\n\n [1] 4 3 2 1 0 1 2 3 4 5 6"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#vectorization-1",
    "href": "slides/week-8/w8-iteration.html#vectorization-1",
    "title": "Iteration",
    "section": "Vectorization",
    "text": "Vectorization\nMany operations in R are vectorized.\n\nThese functions operate on vectors of values rather than a single value.\nWe can iterate without writing a loop.\n\n\nx &lt;- seq(from = -4, to = 6)\nx\n\n [1] -4 -3 -2 -1  0  1  2  3  4  5  6\n\n\n\n\nLoop:\n\nfor(i in 1:length(x)){\n  x[i] &lt;- abs(x[i])\n}\nx\n\n [1] 4 3 2 1 0 1 2 3 4 5 6\n\n\n\nVectorized:\n\nabs(x)\n\n [1] 4 3 2 1 0 1 2 3 4 5 6"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#vectorization-2",
    "href": "slides/week-8/w8-iteration.html#vectorization-2",
    "title": "Iteration",
    "section": "Vectorization",
    "text": "Vectorization\nNot every function is vectorized.\n\nE.g., a function using if() statements cannot operate on vectors.\n\n\n\n\n\npos_neg_zero &lt;- function(x){\n  if(x &gt; 0){\n    return(\"Greater than 0!\")\n  } else if (x &lt; 0){\n    return(\"Less than 0!\")\n  } else {\n    return(\"Equal to 0!\")\n  }\n}\n\nx &lt;- seq(from = -4, to = 4)\npos_neg_zero(x)\n\nError in if (x &gt; 0) {: the condition has length &gt; 1\n\n\n\nThe if(x &gt; 0) statement can only be checked for something of length 1 (a single number, not a vector)."
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#vectorization-3",
    "href": "slides/week-8/w8-iteration.html#vectorization-3",
    "title": "Iteration",
    "section": "Vectorization",
    "text": "Vectorization\nNot every function is vectorized.\n\nE.g., a function using if() statements cannot operate on vectors.\n\n\n\n\npos_neg_zero &lt;- function(x){\n  if(x &gt; 0){\n    return(\"Greater than 0!\")\n  } else if (x &lt; 0){\n    return(\"Less than 0!\")\n  } else {\n    return(\"Equal to 0!\")\n  }\n}\n\nx &lt;- seq(from = -4, to = 3)\npos_neg_zero(x)\n\nError in if (x &gt; 0) {: the condition has length &gt; 1\n\n\n\n\nresult &lt;- rep(NA, length(x))\nfor(i in 1:length(x)){\n  result[i] &lt;- pos_neg_zero(x[i])\n}\n\nresult\n\n[1] \"Less than 0!\"    \"Less than 0!\"    \"Less than 0!\"    \"Less than 0!\"   \n[5] \"Equal to 0!\"     \"Greater than 0!\" \"Greater than 0!\" \"Greater than 0!\""
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#vectorization-4",
    "href": "slides/week-8/w8-iteration.html#vectorization-4",
    "title": "Iteration",
    "section": "Vectorization",
    "text": "Vectorization\nNot every function is vectorized.\n\nVectorized versions of if() statements?\n\n\nif_else() and case_when()\n\n\npos_neg_zero &lt;- function(x){\n  state &lt;- case_when(x &gt; 0 ~ \"Greater than 0!\", \n                     x &lt; 0 ~ \"Less than 0!\", \n                     .default = \"Equal to 0!\")\n  return(state)\n}\n\nx &lt;- seq(from = -4, to = 3)\npos_neg_zero(x)\n\n[1] \"Less than 0!\"    \"Less than 0!\"    \"Less than 0!\"    \"Less than 0!\"   \n[5] \"Equal to 0!\"     \"Greater than 0!\" \"Greater than 0!\" \"Greater than 0!\""
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#some-functions-cannot-be-vectorized",
    "href": "slides/week-8/w8-iteration.html#some-functions-cannot-be-vectorized",
    "title": "Iteration",
    "section": "Some functions cannot be vectorized!",
    "text": "Some functions cannot be vectorized!\nApplying class() to a single variable in a dataframe returns the data type of that column:\n\nclass(penguins[[1]])\n\n[1] \"factor\"\n\nclass(penguins$species)\n\n[1] \"factor\"\n\n\nTrying to apply class() to every variable in a dataframe returns the data type of the dataframe:\n\nclass(penguins)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#what-can-we-do-instead",
    "href": "slides/week-8/w8-iteration.html#what-can-we-do-instead",
    "title": "Iteration",
    "section": "What can we do instead?",
    "text": "What can we do instead?\nWrite a for() loop…\n\ndata_type &lt;- rep(NA, length = ncol(penguins))\nfor(i in 1:ncol(penguins)){\n  data_type[i] &lt;- class(penguins[[i]])\n}\n\n# format table nicely\ndata.frame(column = names(penguins), \n       type = data_type) |&gt; \n  pivot_wider(names_from = column, \n              values_from = type) |&gt;  \n  knitr::kable() |&gt;\n  kableExtra::kable_styling(font_size = 30)\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nfactor\nfactor\nnumeric\nnumeric\ninteger\ninteger\nfactor\ninteger\n\n\n\n\n\n\n\n\n… but loops are computationally intensive!"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#what-can-we-do-instead-1",
    "href": "slides/week-8/w8-iteration.html#what-can-we-do-instead-1",
    "title": "Iteration",
    "section": "What can we do instead?",
    "text": "What can we do instead?\nWhat about across()?\n\nEasily perform the same operation on multiple columns.\n\n\npenguins |&gt; \n  summarise(across(.cols = everything(), \n                   .fns = class)) |&gt; \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nfactor\nfactor\nnumeric\nnumeric\ninteger\ninteger\nfactor\ninteger\n\n\n\n\n\n\nUgh. Internally, across() uses a for() loop!\nfor (j in seq_fns) {\n  fn &lt;- fns[[j]]\n  out[[k]] &lt;- fn(col, ...)\n  k &lt;- k + 1L"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#what-can-we-do-instead-2",
    "href": "slides/week-8/w8-iteration.html#what-can-we-do-instead-2",
    "title": "Iteration",
    "section": "What can we do instead?",
    "text": "What can we do instead?\n\n…"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#functional-programming-1",
    "href": "slides/week-8/w8-iteration.html#functional-programming-1",
    "title": "Iteration",
    "section": "Functional Programming",
    "text": "Functional Programming\nWhat’s the big picture?\n\nWe will use functions as the arguments to other functions!\n\n\n\n\n\n\n\n\nNote\n\n\nThere are a slew of apply() functions you will likely come across.\nWe will instead focus on the purrr package and the map() family of functions."
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#purrr",
    "href": "slides/week-8/w8-iteration.html#purrr",
    "title": "Iteration",
    "section": "purrr",
    "text": "purrr\nThe purrr package breaks common list manipulations into small, independent pieces."
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#brief-review-lists",
    "href": "slides/week-8/w8-iteration.html#brief-review-lists",
    "title": "Iteration",
    "section": "Brief Review: Lists",
    "text": "Brief Review: Lists\nA list is a 1-dimensional, heterogeneous data structure.\n\nThere are no restrictions on what data type or structure it can contain – values, vectors, other lists, dataframes, etc.\nLists are indexed with [] or [[]].\n\n\n\n\n\n\n[[1]]\n[1]  TRUE FALSE  TRUE  TRUE\n\n[[2]]\n     [,1] [,2]\n[1,] 6.70  4.4\n[2,] 5.58  6.0\n\n[[3]]\n[1] \"A\"\n\n\n\n\nmy_list[1]\n\n[[1]]\n[1]  TRUE FALSE  TRUE  TRUE\n\nmy_list[[2]]\n\n     [,1] [,2]\n[1,] 6.70  4.4\n[2,] 5.58  6.0\n\nmy_list[[2]][1,2]\n\n[1] 4.4"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#brief-review-lists-1",
    "href": "slides/week-8/w8-iteration.html#brief-review-lists-1",
    "title": "Iteration",
    "section": "Brief Review: Lists",
    "text": "Brief Review: Lists\nA dataframe / tibble is a specially formatted list of columns!\n\nsmall_penguins &lt;- penguins[1:8,]\nsmall_penguins[3]\n\n# A tibble: 8 × 1\n  bill_length_mm\n           &lt;dbl&gt;\n1           39.1\n2           39.5\n3           40.3\n4           NA  \n5           36.7\n6           39.3\n7           38.9\n8           39.2\n\nsmall_penguins[[3]]\n\n[1] 39.1 39.5 40.3   NA 36.7 39.3 38.9 39.2\n\n\n\nThe purrr package works for lists, so it works for dataframes."
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#map",
    "href": "slides/week-8/w8-iteration.html#map",
    "title": "Iteration",
    "section": "map()",
    "text": "map()\nThe map() function iterates through each item in a list (or vector) and applies a function, then returns the new list.\n\n\n\n\n\n\n\n\n\nNote: the first argument in map() is the list, so if we pipe into it, we only specify the function!"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#map-dataframes",
    "href": "slides/week-8/w8-iteration.html#map-dataframes",
    "title": "Iteration",
    "section": "map() + Dataframes",
    "text": "map() + Dataframes\nA dataframe is just a list of columns – map() will apply a function to every column.\n\n\npenguins |&gt; \n  select(bill_length_mm:body_mass_g) |&gt;\n  map(~ mean(.x, na.rm = TRUE))\n\n$bill_length_mm\n[1] 43.92193\n\n$bill_depth_mm\n[1] 17.15117\n\n$flipper_length_mm\n[1] 200.9152\n\n$body_mass_g\n[1] 4201.754\n\n\nUse a lambda function (with ~ and .x), just like in  across()!"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#the-map-family",
    "href": "slides/week-8/w8-iteration.html#the-map-family",
    "title": "Iteration",
    "section": "The map() Family",
    "text": "The map() Family\nThe map_xxx() variants allow you to specify the type of output you want.\n\nmap() creates a list.\nmap_chr() creates a character vector.\nmap_lgl() creates an logical vector.\nmap_int() creates a integer vector.\nmap_dbl() creates a numeric vector.\n\nAll take in a list or vector and a function as arguments."
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#map-penguins",
    "href": "slides/week-8/w8-iteration.html#map-penguins",
    "title": "Iteration",
    "section": "map() + penguins",
    "text": "map() + penguins\n\nmap_dbl()map_int()map_lgl()Choosing a map\n\n\nCalculate the mean of each column.\n\npenguins |&gt; \n  select(bill_length_mm:body_mass_g) |&gt; \n  map_dbl(~ mean(.x, na.rm = TRUE))\n\n   bill_length_mm     bill_depth_mm flipper_length_mm       body_mass_g \n         43.92193          17.15117         200.91520        4201.75439 \n\n\nOutput is a vector of doubles.\n\n\nCalculate the number of NAs in each column.\n\npenguins |&gt; \n  map_int(~ sum(is.na(.x)))\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 2                 2 \nflipper_length_mm       body_mass_g               sex              year \n                2                 2                11                 0 \n\n\nOutput is a vector of integers.\n\n\nCalculate if there are any NAs in each column.\n\npenguins |&gt; \n  map_lgl(~ sum(is.na(.x)) &gt; 0)\n\n          species            island    bill_length_mm     bill_depth_mm \n            FALSE             FALSE              TRUE              TRUE \nflipper_length_mm       body_mass_g               sex              year \n             TRUE              TRUE              TRUE             FALSE \n\n\nOutput is a vector of booleans.\n\n\nCalculate the number of NAs in each column.\n\npenguins |&gt; \n  map_lgl(~ sum(is.na(.x)))\n\nError in `map_lgl()`:\nℹ In index: 3.\nℹ With name: bill_length_mm.\nCaused by error:\n! Can't coerce from an integer to a logical.\n\n\nR returns an error if the output is of the wrong type!"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#map_if",
    "href": "slides/week-8/w8-iteration.html#map_if",
    "title": "Iteration",
    "section": "map_if()",
    "text": "map_if()\nThe map_if() function allows us to conditionally apply a function to each item in a list.\n\n\nacross()map_if()map_if() to data (tibble)\n\n\n\npenguins |&gt; \n  mutate(across(.cols = where(is.numeric), \n                .fns = scale))\n\n\n\n# A tibble: 8 × 5\n  species island    bill_length_mm[,1] bill_depth_mm[,1] sex   \n  &lt;fct&gt;   &lt;fct&gt;                  &lt;dbl&gt;             &lt;dbl&gt; &lt;fct&gt; \n1 Adelie  Torgersen             -0.883             0.784 male  \n2 Adelie  Torgersen             -0.810             0.126 female\n3 Adelie  Torgersen             -0.663             0.430 female\n4 Adelie  Torgersen             NA                NA     &lt;NA&gt;  \n5 Adelie  Torgersen             -1.32              1.09  female\n6 Adelie  Torgersen             -0.847             1.75  male  \n7 Adelie  Torgersen             -0.920             0.329 female\n8 Adelie  Torgersen             -0.865             1.24  male  \n\n\n\n\n\npenguins |&gt; \n  map_if(is.numeric, scale)\n\n$species\n  [1] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n  [8] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [15] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [22] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [29] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [36] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [43] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [50] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [57] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [64] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [71] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [78] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [85] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [92] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [99] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[106] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[113] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[120] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[127] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[134] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[141] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[148] Adelie    Adelie    Adelie    Adelie    Adelie    Gentoo    Gentoo   \n[155] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[162] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[169] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[176] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[183] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[190] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[197] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[204] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[211] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[218] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[225] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[232] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[239] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[246] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[253] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[260] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[267] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[274] Gentoo    Gentoo    Gentoo    Chinstrap Chinstrap Chinstrap Chinstrap\n[281] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[288] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[295] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[302] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[309] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[316] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[323] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[330] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[337] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[344] Chinstrap\nLevels: Adelie Chinstrap Gentoo\n\n$island\n  [1] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen\n  [8] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen\n [15] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Biscoe   \n [22] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n [29] Biscoe    Biscoe    Dream     Dream     Dream     Dream     Dream    \n [36] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n [43] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n [50] Dream     Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n [57] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n [64] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Torgersen Torgersen\n [71] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen\n [78] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen\n [85] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n [92] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n [99] Dream     Dream     Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[106] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[113] Biscoe    Biscoe    Biscoe    Biscoe    Torgersen Torgersen Torgersen\n[120] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen\n[127] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Dream    \n[134] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[141] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[148] Dream     Dream     Dream     Dream     Dream     Biscoe    Biscoe   \n[155] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[162] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[169] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[176] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[183] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[190] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[197] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[204] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[211] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[218] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[225] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[232] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[239] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[246] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[253] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[260] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[267] Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe    Biscoe   \n[274] Biscoe    Biscoe    Biscoe    Dream     Dream     Dream     Dream    \n[281] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[288] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[295] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[302] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[309] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[316] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[323] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[330] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[337] Dream     Dream     Dream     Dream     Dream     Dream     Dream    \n[344] Dream    \nLevels: Biscoe Dream Torgersen\n\n$bill_length_mm\n              [,1]\n  [1,] -0.88320467\n  [2,] -0.80993901\n  [3,] -0.66340769\n  [4,]          NA\n  [5,] -1.32279862\n  [6,] -0.84657184\n  [7,] -0.91983750\n  [8,] -0.86488825\n  [9,] -1.79902541\n [10,] -0.35202864\n [11,] -1.12131806\n [12,] -1.12131806\n [13,] -0.51687637\n [14,] -0.97478674\n [15,] -1.70744334\n [16,] -1.34111504\n [17,] -0.95647033\n [18,] -0.26044656\n [19,] -1.74407616\n [20,]  0.38062795\n [21,] -1.12131806\n [22,] -1.13963448\n [23,] -1.46932994\n [24,] -1.04805240\n [25,] -0.93815391\n [26,] -1.57922843\n [27,] -0.60845845\n [28,] -0.62677486\n [29,] -1.10300165\n [30,] -0.62677486\n [31,] -0.80993901\n [32,] -1.23121655\n [33,] -0.80993901\n [34,] -0.55350920\n [35,] -1.37774787\n [36,] -0.86488825\n [37,] -0.93815391\n [38,] -0.31539581\n [39,] -1.15795089\n [40,] -0.75498976\n [41,] -1.35943145\n [42,] -0.57182562\n [43,] -1.45101353\n [44,]  0.03261607\n [45,] -1.26784938\n [46,] -0.79162259\n [47,] -0.51687637\n [48,] -1.17626731\n [49,] -1.45101353\n [50,] -0.29707939\n [51,] -0.79162259\n [52,] -0.70004052\n [53,] -1.63417768\n [54,] -0.35202864\n [55,] -1.72575975\n [56,] -0.46192713\n [57,] -0.90152108\n [58,] -0.60845845\n [59,] -1.35943145\n [60,] -1.15795089\n [61,] -1.50596277\n [62,] -0.48024354\n [63,] -1.15795089\n [64,] -0.51687637\n [65,] -1.37774787\n [66,] -0.42529430\n [67,] -1.54259560\n [68,] -0.51687637\n [69,] -1.46932994\n [70,] -0.38866147\n [71,] -1.90892390\n [72,] -0.77330618\n [73,] -0.79162259\n [74,]  0.34399512\n [75,] -1.54259560\n [76,] -0.20549732\n [77,] -0.55350920\n [78,] -1.23121655\n [79,] -1.41438070\n [80,] -0.33371222\n [81,] -1.70744334\n [82,] -0.18718091\n [83,] -1.32279862\n [84,] -1.61586126\n [85,] -1.21290014\n [86,] -0.48024354\n [87,] -1.39606428\n [88,] -1.28616579\n [89,] -1.02973599\n [90,] -0.91983750\n [91,] -1.50596277\n [92,] -0.51687637\n [93,] -1.81734182\n [94,] -0.79162259\n [95,] -1.41438070\n [96,] -0.57182562\n [97,] -1.06636882\n [98,] -0.66340769\n [99,] -1.98218956\n[100,] -0.13223166\n[101,] -1.63417768\n[102,] -0.53519279\n[103,] -1.13963448\n[104,] -1.12131806\n[105,] -1.10300165\n[106,] -0.77330618\n[107,] -0.97478674\n[108,] -1.04805240\n[109,] -1.06636882\n[110,] -0.13223166\n[111,] -1.06636882\n[112,]  0.30736229\n[113,] -0.77330618\n[114,] -0.31539581\n[115,] -0.79162259\n[116,] -0.22381374\n[117,] -0.97478674\n[118,] -1.21290014\n[119,] -1.50596277\n[120,] -0.51687637\n[121,] -1.41438070\n[122,] -1.13963448\n[123,] -0.68172411\n[124,] -0.46192713\n[125,] -1.59754485\n[126,] -0.60845845\n[127,] -0.93815391\n[128,] -0.44361071\n[129,] -0.90152108\n[130,]  0.03261607\n[131,] -0.99310316\n[132,] -0.15054808\n[133,] -1.30448221\n[134,] -1.17626731\n[135,] -1.06636882\n[136,] -0.51687637\n[137,] -1.52427919\n[138,] -0.68172411\n[139,] -1.26784938\n[140,] -0.77330618\n[141,] -0.68172411\n[142,] -0.60845845\n[143,] -2.16535371\n[144,] -0.59014203\n[145,] -1.21290014\n[146,] -0.90152108\n[147,] -0.86488825\n[148,] -1.34111504\n[149,] -1.45101353\n[150,] -1.12131806\n[151,] -1.45101353\n[152,] -0.44361071\n[153,]  0.39894437\n[154,]  1.11328455\n[155,]  0.87517115\n[156,]  1.11328455\n[157,]  0.67369059\n[158,]  0.47221003\n[159,]  0.27072946\n[160,]  0.50884286\n[161,] -0.11391525\n[162,]  0.52715927\n[163,] -0.55350920\n[164,]  0.93012040\n[165,]  0.28904588\n[166,]  0.82022191\n[167,]  0.34399512\n[168,]  0.98506964\n[169,] -0.35202864\n[170,]  0.96675323\n[171,]  0.41726078\n[172,]  0.87517115\n[173,]  1.14991738\n[174,]  0.21578022\n[175,]  0.47221003\n[176,]  0.43557720\n[177,] -0.18718091\n[178,]  0.39894437\n[179,]  0.10588173\n[180,]  0.71032342\n[181,]  0.78358908\n[182,]  1.11328455\n[183,]  0.61874135\n[184,] -0.20549732\n[185,]  0.21578022\n[186,]  2.87166037\n[187,]  0.94843681\n[188,]  0.82022191\n[189,] -0.24213015\n[190,]  0.08756532\n[191,]  0.01429966\n[192,]  0.87517115\n[193,] -0.22381374\n[194,]  1.04001889\n[195,]  0.25241305\n[196,]  1.04001889\n[197,]  1.20486662\n[198,] -0.05896600\n[199,]  0.28904588\n[200,]  1.20486662\n[201,]  0.17914739\n[202,]  0.23409663\n[203,]  0.49052644\n[204,]  0.83853832\n[205,]  0.21578022\n[206,]  1.13160096\n[207,]  0.47221003\n[208,]  0.19746381\n[209,] -0.02233317\n[210,]  0.28904588\n[211,] -0.13223166\n[212,]  1.18655021\n[213,]  0.25241305\n[214,]  0.41726078\n[215,]  0.32567871\n[216,]  1.90089038\n[217,]  0.34399512\n[218,]  1.07665172\n[219,]  0.41726078\n[220,]  1.02170247\n[221,] -0.07728242\n[222,]  1.24149945\n[223,]  0.69200701\n[224,]  0.45389361\n[225,]  0.78358908\n[226,]  0.47221003\n[227,]  0.45389361\n[228,]  0.85685474\n[229,]  0.65537418\n[230,]  1.31476511\n[231,]  0.23409663\n[232,]  0.23409663\n[233,]  0.94843681\n[234,]  1.57119492\n[235,]  0.63705776\n[236,]  1.11328455\n[237,]  0.17914739\n[238,]  1.25981586\n[239,] -0.09559883\n[240,]  1.35139794\n[241,]  0.65537418\n[242,]  1.49792926\n[243,]  0.65537418\n[244,]  1.51624567\n[245,]  0.28904588\n[246,]  1.02170247\n[247,]  0.10588173\n[248,]  1.25981586\n[249,]  1.00338606\n[250,]  0.54547569\n[251,]  0.82022191\n[252,]  1.31476511\n[253,]  0.83853832\n[254,]  2.19395302\n[255,]  0.60042493\n[256,]  0.94843681\n[257,]  0.61874135\n[258,]  0.52715927\n[259,] -0.40697788\n[260,]  1.73604265\n[261,] -0.11391525\n[262,]  0.76527266\n[263,]  1.20486662\n[264,]  1.07665172\n[265,] -0.07728242\n[266,]  1.38803077\n[267,]  0.41726078\n[268,]  2.04742170\n[269,]  0.10588173\n[270,]  0.89348757\n[271,]  0.60042493\n[272,]          NA\n[273,]  0.52715927\n[274,]  1.18655021\n[275,]  0.23409663\n[276,]  1.09496813\n[277,]  0.47221003\n[278,]  1.11328455\n[279,]  1.35139794\n[280,]  0.27072946\n[281,]  1.60782775\n[282,]  0.23409663\n[283,]  0.39894437\n[284,]  1.35139794\n[285,]  0.38062795\n[286,]  1.35139794\n[287,]  0.49052644\n[288,]  1.42466360\n[289,]  0.56379210\n[290,]  1.47961284\n[291,]  0.36231154\n[292,]  1.20486662\n[293,]  1.16823379\n[294,]  2.57859773\n[295,]  0.45389361\n[296,]  0.96675323\n[297,] -0.27876298\n[298,]  0.83853832\n[299,] -0.13223166\n[300,]  1.22318303\n[301,]  0.50884286\n[302,]  1.47961284\n[303,]  1.20486662\n[304,]  1.02170247\n[305,]  0.45389361\n[306,]  1.62614416\n[307,] -0.55350920\n[308,]  1.88257397\n[309,] -0.26044656\n[310,]  1.29644869\n[311,]  1.05833530\n[312,]  0.65537418\n[313,]  0.67369059\n[314,]  1.47961284\n[315,]  0.54547569\n[316,]  1.75435906\n[317,]  0.93012040\n[318,]  0.41726078\n[319,]  1.27813228\n[320,]  0.28904588\n[321,]  1.27813228\n[322,]  1.25981586\n[323,]  1.13160096\n[324,]  0.93012040\n[325,]  1.38803077\n[326,]  1.07665172\n[327,]  0.76527266\n[328,]  1.36971435\n[329,]  0.32567871\n[330,]  1.24149945\n[331,] -0.26044656\n[332,]  1.51624567\n[333,]  0.23409663\n[334,]  0.98506964\n[335,]  1.14991738\n[336,]  0.30736229\n[337,]  1.46129643\n[338,]  0.52715927\n[339,]  0.32567871\n[340,]  2.17563660\n[341,] -0.07728242\n[342,]  1.04001889\n[343,]  1.25981586\n[344,]  1.14991738\nattr(,\"scaled:center\")\n[1] 43.92193\nattr(,\"scaled:scale\")\n[1] 5.459584\n\n$bill_depth_mm\n              [,1]\n  [1,]  0.78430007\n  [2,]  0.12600328\n  [3,]  0.42983257\n  [4,]          NA\n  [5,]  1.08812936\n  [6,]  1.74642615\n  [7,]  0.32855614\n  [8,]  1.24004400\n  [9,]  0.48047078\n [10,]  1.54387329\n [11,] -0.02591137\n [12,]  0.07536506\n [13,]  0.22727971\n [14,]  2.05025544\n [15,]  1.99961722\n [16,]  0.32855614\n [17,]  0.93621471\n [18,]  1.79706436\n [19,]  0.63238542\n [20,]  2.20217008\n [21,]  0.58174721\n [22,]  0.78430007\n [23,]  1.03749114\n [24,]  0.48047078\n [25,]  0.02472685\n [26,]  0.88557650\n [27,]  0.73366185\n [28,]  0.37919435\n [29,]  0.73366185\n [30,]  0.88557650\n [31,] -0.22846423\n [32,]  0.48047078\n [33,]  0.32855614\n [34,]  0.88557650\n [35,] -0.07654958\n [36,]  1.99961722\n [37,]  1.44259686\n [38,]  0.68302364\n [39,]  1.08812936\n [40,]  0.98685293\n [41,]  0.42983257\n [42,]  0.63238542\n [43,]  0.68302364\n [44,]  1.29068222\n [45,] -0.12718780\n [46,]  0.83493828\n [47,]  0.93621471\n [48,]  0.88557650\n [49,]  0.37919435\n [50,]  2.05025544\n [51,]  0.27791792\n [52,]  0.88557650\n [53,]  0.37919435\n [54,]  1.18940579\n [55,]  0.48047078\n [56,]  0.73366185\n [57,]  0.17664149\n [58,]  0.83493828\n [59,] -0.27910244\n [60,]  0.98685293\n [61,] -0.12718780\n [62,]  1.99961722\n [63,] -0.07654958\n [64,]  0.53110900\n [65,] -0.02591137\n [66,]  0.42983257\n [67,] -0.48165530\n [68,]  0.98685293\n [69,] -0.27910244\n [70,]  1.13876757\n [71,]  0.93621471\n [72,]  0.63238542\n [73,]  0.02472685\n [74,]  0.88557650\n [75,]  0.17664149\n [76,]  0.68302364\n [77,] -0.17782601\n [78,]  1.13876757\n [79,] -0.53229351\n [80,]  0.98685293\n [81,]  0.02472685\n [82,]  0.22727971\n [83,]  0.83493828\n [84,]  1.13876757\n [85,]  0.32855614\n [86,]  1.59451151\n [87,]  1.18940579\n [88,]  0.73366185\n [89,]  1.03749114\n [90,]  0.83493828\n [91,]  0.42983257\n [92,]  0.48047078\n [93,] -0.02591137\n [94,]  0.48047078\n [95,]  0.07536506\n [96,]  0.88557650\n [97,]  0.73366185\n [98,]  0.68302364\n [99,] -0.53229351\n[100,]  0.68302364\n[101,]  0.37919435\n[102,]  1.44259686\n[103,] -0.58293173\n[104,]  1.44259686\n[105,]  0.73366185\n[106,]  0.88557650\n[107,]  0.02472685\n[108,]  1.44259686\n[109,] -0.07654958\n[110,]  0.93621471\n[111,] -0.32974066\n[112,]  1.59451151\n[113,]  0.27791792\n[114,]  1.18940579\n[115,]  1.79706436\n[116,]  0.58174721\n[117,] -0.07654958\n[118,]  1.69578793\n[119,] -0.07654958\n[120,]  0.73366185\n[121,]  0.02472685\n[122,]  1.34132043\n[123,] -0.07654958\n[124,]  0.68302364\n[125,] -0.63356994\n[126,]  0.93621471\n[127,]  0.22727971\n[128,]  0.58174721\n[129,] -0.02591137\n[130,]  0.42983257\n[131,]  0.37919435\n[132,]  1.03749114\n[133,]  0.68302364\n[134,]  0.68302364\n[135,]  0.22727971\n[136,]  0.17664149\n[137,]  0.17664149\n[138,]  1.49323508\n[139,] -0.32974066\n[140,]  0.37919435\n[141,] -0.02591137\n[142,]  0.02472685\n[143,] -0.83612280\n[144,] -0.07654958\n[145,] -0.17782601\n[146,]  0.78430007\n[147,]  0.73366185\n[148,]  0.63238542\n[149,]  0.32855614\n[150,]  0.48047078\n[151,] -0.02591137\n[152,]  0.68302364\n[153,] -2.00080174\n[154,] -0.43101709\n[155,] -1.54505781\n[156,] -0.98803745\n[157,] -1.34250495\n[158,] -1.84888710\n[159,] -1.29186674\n[160,] -0.93739923\n[161,] -1.89952531\n[162,] -0.88676102\n[163,] -1.74761067\n[164,] -0.53229351\n[165,] -1.74761067\n[166,] -1.29186674\n[167,] -1.29186674\n[168,] -0.73484637\n[169,] -1.84888710\n[170,] -0.98803745\n[171,] -1.34250495\n[172,] -1.03867566\n[173,] -1.44378138\n[174,] -1.34250495\n[175,] -1.34250495\n[176,] -0.68420816\n[177,] -2.05143996\n[178,] -1.03867566\n[179,] -1.44378138\n[180,] -1.08931388\n[181,] -1.44378138\n[182,] -0.93739923\n[183,] -0.93739923\n[184,] -1.49441960\n[185,] -1.34250495\n[186,] -0.07654958\n[187,] -1.19059031\n[188,] -0.43101709\n[189,] -1.74761067\n[190,]  0.07536506\n[191,] -1.79824888\n[192,] -0.73484637\n[193,] -1.74761067\n[194,] -0.58293173\n[195,] -1.74761067\n[196,] -1.08931388\n[197,] -0.63356994\n[198,] -1.64633424\n[199,] -1.64633424\n[200,] -0.63356994\n[201,] -1.95016353\n[202,] -0.68420816\n[203,] -1.49441960\n[204,] -1.54505781\n[205,] -1.39314317\n[206,] -1.08931388\n[207,] -1.39314317\n[208,] -0.88676102\n[209,] -1.64633424\n[210,] -1.08931388\n[211,] -1.34250495\n[212,] -0.93739923\n[213,] -1.69697245\n[214,] -1.13995209\n[215,] -1.64633424\n[216,] -0.73484637\n[217,] -1.49441960\n[218,] -0.17782601\n[219,] -1.39314317\n[220,] -0.48165530\n[221,] -1.49441960\n[222,] -1.08931388\n[223,] -1.08931388\n[224,] -0.78548459\n[225,] -0.78548459\n[226,] -1.19059031\n[227,] -1.08931388\n[228,] -0.58293173\n[229,] -1.49441960\n[230,] -0.43101709\n[231,] -1.69697245\n[232,] -0.38037887\n[233,] -1.34250495\n[234,] -0.78548459\n[235,] -1.29186674\n[236,] -0.63356994\n[237,] -1.69697245\n[238,]  0.07536506\n[239,] -1.39314317\n[240,] -1.49441960\n[241,] -1.59569603\n[242,] -0.07654958\n[243,] -1.08931388\n[244,] -0.02591137\n[245,] -1.34250495\n[246,] -0.53229351\n[247,] -1.24122852\n[248,] -0.73484637\n[249,] -0.68420816\n[250,] -1.29186674\n[251,] -1.39314317\n[252,] -0.32974066\n[253,] -1.08931388\n[254,] -0.07654958\n[255,] -0.83612280\n[256,] -1.08931388\n[257,] -1.69697245\n[258,] -0.53229351\n[259,] -1.24122852\n[260,] -0.68420816\n[261,] -1.59569603\n[262,] -1.03867566\n[263,] -0.98803745\n[264,] -0.63356994\n[265,] -0.98803745\n[266,] -0.43101709\n[267,] -1.54505781\n[268,] -0.58293173\n[269,] -0.73484637\n[270,] -0.48165530\n[271,] -1.74761067\n[272,]          NA\n[273,] -1.44378138\n[274,] -0.73484637\n[275,] -1.19059031\n[276,] -0.53229351\n[277,]  0.37919435\n[278,]  1.18940579\n[279,]  1.03749114\n[280,]  0.78430007\n[281,]  1.34132043\n[282,]  0.32855614\n[283,]  0.53110900\n[284,]  0.53110900\n[285,]  0.88557650\n[286,]  1.39195865\n[287,]  0.32855614\n[288,]  1.59451151\n[289,]  0.07536506\n[290,]  0.48047078\n[291,] -0.02591137\n[292,]  1.24004400\n[293,]  1.44259686\n[294,]  0.32855614\n[295,]  0.73366185\n[296,]  0.53110900\n[297,]  0.07536506\n[298,]  0.17664149\n[299,] -0.27910244\n[300,]  1.13876757\n[301,]  0.37919435\n[302,]  0.93621471\n[303,]  0.63238542\n[304,]  0.93621471\n[305,]  0.32855614\n[306,]  1.44259686\n[307,] -0.27910244\n[308,]  1.84770258\n[309,] -0.22846423\n[310,]  0.83493828\n[311,]  0.73366185\n[312,] -0.17782601\n[313,]  0.58174721\n[314,]  1.79706436\n[315,] -0.27910244\n[316,]  1.39195865\n[317,]  1.18940579\n[318,]  0.17664149\n[319,]  0.98685293\n[320,] -0.07654958\n[321,]  0.37919435\n[322,]  0.68302364\n[323,]  0.37919435\n[324,]  1.24004400\n[325,]  0.78430007\n[326,]  0.07536506\n[327,] -0.38037887\n[328,]  0.93621471\n[329,]  0.07536506\n[330,]  1.29068222\n[331,]  0.07536506\n[332,]  0.83493828\n[333,] -0.27910244\n[334,]  1.39195865\n[335,]  0.83493828\n[336,]  1.13876757\n[337,]  1.18940579\n[338,] -0.32974066\n[339,] -0.07654958\n[340,]  1.34132043\n[341,]  0.48047078\n[342,]  0.53110900\n[343,]  0.93621471\n[344,]  0.78430007\nattr(,\"scaled:center\")\n[1] 17.15117\nattr(,\"scaled:scale\")\n[1] 1.974793\n\n$flipper_length_mm\n               [,1]\n  [1,] -1.416271525\n  [2,] -1.060696087\n  [3,] -0.420660299\n  [4,]           NA\n  [5,] -0.562890474\n  [6,] -0.776235737\n  [7,] -1.416271525\n  [8,] -0.420660299\n  [9,] -0.562890474\n [10,] -0.776235737\n [11,] -1.060696087\n [12,] -1.487386613\n [13,] -1.345156438\n [14,] -0.705120649\n [15,] -0.207315036\n [16,] -1.131811175\n [17,] -0.420660299\n [18,] -0.278430124\n [19,] -1.202926262\n [20,] -0.491775386\n [21,] -1.914077138\n [22,] -1.487386613\n [23,] -0.847350824\n [24,] -1.131811175\n [25,] -1.487386613\n [26,] -0.989581000\n [27,] -1.274041350\n [28,] -0.989581000\n [29,] -2.056307313\n [30,] -1.487386613\n [31,] -1.629616788\n [32,] -1.629616788\n [33,] -0.918465912\n [34,] -1.202926262\n [35,] -0.420660299\n [36,] -0.349545211\n [37,] -0.776235737\n [38,] -1.487386613\n [39,] -1.416271525\n [40,] -1.202926262\n [41,] -1.345156438\n [42,] -0.420660299\n [43,] -1.060696087\n [44,] -0.349545211\n [45,] -1.131811175\n [46,] -0.776235737\n [47,] -1.345156438\n [48,] -1.558501700\n [49,] -0.776235737\n [50,] -0.705120649\n [51,] -1.060696087\n [52,] -0.918465912\n [53,] -0.776235737\n [54,] -0.065084861\n [55,] -0.989581000\n [56,] -0.705120649\n [57,] -1.060696087\n [58,] -0.562890474\n [59,] -1.416271525\n [60,] -0.491775386\n [61,] -1.131811175\n [62,] -0.420660299\n [63,] -1.131811175\n [64,] -0.634005562\n [65,] -1.202926262\n [66,] -0.634005562\n [67,] -0.420660299\n [68,] -0.918465912\n [69,] -0.776235737\n [70,] -0.207315036\n [71,] -0.776235737\n [72,] -0.776235737\n [73,] -0.349545211\n [74,] -0.278430124\n [75,] -0.776235737\n [76,] -0.420660299\n [77,] -0.705120649\n [78,] -1.202926262\n [79,] -0.989581000\n [80,] -0.420660299\n [81,] -0.847350824\n [82,] -0.349545211\n [83,] -0.989581000\n [84,] -0.562890474\n [85,] -0.705120649\n [86,] -0.491775386\n [87,] -0.776235737\n [88,] -0.847350824\n [89,] -0.847350824\n [90,] -0.776235737\n [91,]  0.077145314\n [92,]  0.290490577\n [93,] -1.131811175\n [94,] -1.060696087\n [95,] -0.989581000\n [96,]  0.503835840\n [97,] -0.776235737\n [98,] -0.349545211\n [99,] -1.629616788\n[100,] -0.634005562\n[101,] -0.634005562\n[102,]  0.148260402\n[103,] -1.274041350\n[104,] -0.776235737\n[105,] -0.562890474\n[106,] -1.202926262\n[107,] -0.136199948\n[108,] -0.776235737\n[109,] -1.416271525\n[110,] -0.278430124\n[111,] -0.207315036\n[112,] -0.705120649\n[113,] -0.562890474\n[114,] -0.278430124\n[115,] -0.705120649\n[116,] -0.349545211\n[117,] -0.918465912\n[118,] -0.136199948\n[119,] -0.847350824\n[120,] -0.847350824\n[121,] -0.989581000\n[122,] -0.207315036\n[123,] -1.771846963\n[124,]  0.077145314\n[125,] -1.060696087\n[126,] -0.136199948\n[127,] -0.705120649\n[128,] -0.420660299\n[129,] -0.705120649\n[130,]  0.646066015\n[131,] -0.776235737\n[132,] -0.278430124\n[133,] -0.562890474\n[134,] -0.136199948\n[135,] -0.989581000\n[136,] -0.776235737\n[137,] -0.705120649\n[138,] -0.065084861\n[139,] -1.131811175\n[140,] -0.562890474\n[141,] -0.562890474\n[142,] -0.989581000\n[143,] -0.918465912\n[144,] -0.776235737\n[145,] -0.634005562\n[146,] -1.131811175\n[147,] -0.776235737\n[148,] -1.202926262\n[149,] -0.420660299\n[150,] -0.562890474\n[151,] -0.989581000\n[152,]  0.006030227\n[153,]  0.717181103\n[154,]  2.068367767\n[155,]  0.646066015\n[156,]  1.214986716\n[157,]  1.001641453\n[158,]  0.646066015\n[159,]  0.717181103\n[160,]  1.286101803\n[161,]  0.574950927\n[162,]  1.001641453\n[163,]  0.930526365\n[164,]  1.072756541\n[165,]  0.930526365\n[166,]  0.859411278\n[167,]  0.646066015\n[168,]  1.143871628\n[169,]  0.646066015\n[170,]  1.428331979\n[171,]  0.574950927\n[172,]  1.499447066\n[173,]  1.214986716\n[174,]  1.001641453\n[175,]  0.859411278\n[176,]  1.001641453\n[177,]  1.001641453\n[178,]  1.001641453\n[179,]  1.072756541\n[180,]  1.001641453\n[181,]  0.646066015\n[182,]  1.357216891\n[183,]  1.499447066\n[184,]  0.574950927\n[185,]  0.432720752\n[186,]  2.068367767\n[187,]  1.357216891\n[188,]  1.357216891\n[189,]  0.859411278\n[190,]  1.286101803\n[191,]  0.503835840\n[192,]  0.503835840\n[193,]  0.503835840\n[194,]  1.712792329\n[195,]  0.646066015\n[196,]  1.072756541\n[197,]  1.499447066\n[198,]  1.143871628\n[199,]  0.646066015\n[200,]  1.712792329\n[201,]  0.859411278\n[202,]  1.001641453\n[203,]  0.646066015\n[204,]  1.357216891\n[205,]  0.646066015\n[206,]  1.712792329\n[207,]  1.143871628\n[208,]  1.357216891\n[209,]  0.503835840\n[210,]  1.357216891\n[211,]  0.503835840\n[212,]  1.641677241\n[213,]  0.503835840\n[214,]  1.428331979\n[215,]  0.930526365\n[216,]  2.139482854\n[217,]  1.286101803\n[218,]  2.068367767\n[219,]  0.930526365\n[220,]  1.997252679\n[221,]  1.357216891\n[222,]  1.570562154\n[223,]  1.072756541\n[224,]  1.428331979\n[225,]  1.428331979\n[226,]  1.143871628\n[227,]  1.072756541\n[228,]  2.068367767\n[229,]  0.574950927\n[230,]  1.357216891\n[231,]  1.001641453\n[232,]  1.570562154\n[233,]  0.788296190\n[234,]  1.428331979\n[235,]  0.788296190\n[236,]  1.641677241\n[237,]  0.788296190\n[238,]  1.926137592\n[239,]  1.214986716\n[240,]  1.214986716\n[241,]  0.788296190\n[242,]  2.068367767\n[243,]  1.214986716\n[244,]  1.926137592\n[245,]  0.788296190\n[246,]  1.641677241\n[247,]  0.930526365\n[248,]  1.783907417\n[249,]  1.072756541\n[250,]  1.499447066\n[251,]  0.148260402\n[252,]  1.712792329\n[253,]  1.286101803\n[254,]  1.926137592\n[255,]  1.001641453\n[256,]  1.926137592\n[257,]  1.072756541\n[258,]  1.001641453\n[259,]  0.646066015\n[260,]  1.286101803\n[261,]  0.503835840\n[262,]  0.574950927\n[263,]  1.072756541\n[264,]  1.997252679\n[265,]  0.859411278\n[266,]  2.068367767\n[267,]  1.143871628\n[268,]  2.068367767\n[269,]  1.143871628\n[270,]  1.499447066\n[271,]  0.930526365\n[272,]           NA\n[273,]  1.001641453\n[274,]  1.499447066\n[275,]  0.788296190\n[276,]  0.859411278\n[277,] -0.634005562\n[278,] -0.349545211\n[279,] -0.562890474\n[280,] -0.918465912\n[281,] -0.278430124\n[282,] -0.207315036\n[283,] -1.629616788\n[284,] -0.278430124\n[285,] -0.420660299\n[286,] -0.207315036\n[287,] -0.562890474\n[288,] -0.491775386\n[289,] -1.131811175\n[290,]  0.006030227\n[291,] -0.776235737\n[292,]  0.006030227\n[293,] -0.278430124\n[294,] -1.416271525\n[295,] -0.776235737\n[296,] -0.420660299\n[297,] -1.416271525\n[298,] -0.705120649\n[299,] -0.989581000\n[300,] -0.562890474\n[301,] -0.420660299\n[302,] -0.278430124\n[303,] -0.065084861\n[304,] -0.065084861\n[305,] -0.705120649\n[306,]  0.290490577\n[307,] -0.989581000\n[308,]  0.006030227\n[309,] -0.989581000\n[310,]  0.148260402\n[311,] -0.420660299\n[312,] -0.136199948\n[313,] -0.420660299\n[314,]  0.646066015\n[315,] -0.634005562\n[316,]  0.290490577\n[317,]  0.646066015\n[318,] -0.989581000\n[319,] -0.349545211\n[320,] -0.349545211\n[321,] -0.349545211\n[322,]  0.006030227\n[323,] -0.776235737\n[324,]  0.788296190\n[325,] -0.989581000\n[326,] -0.207315036\n[327,] -0.136199948\n[328,]  0.006030227\n[329,] -0.562890474\n[330,]  0.148260402\n[331,] -0.989581000\n[332,] -0.278430124\n[333,] -0.705120649\n[334,]  0.148260402\n[335,]  0.077145314\n[336,] -0.491775386\n[337,]  0.361605665\n[338,] -0.847350824\n[339,] -0.420660299\n[340,]  0.432720752\n[341,]  0.077145314\n[342,] -0.562890474\n[343,]  0.646066015\n[344,] -0.207315036\nattr(,\"scaled:center\")\n[1] 200.9152\nattr(,\"scaled:scale\")\n[1] 14.06171\n\n$body_mass_g\n               [,1]\n  [1,] -0.563316704\n  [2,] -0.500969030\n  [3,] -1.186793445\n  [4,]           NA\n  [5,] -0.937402749\n  [6,] -0.688012052\n  [7,] -0.719185889\n  [8,]  0.590115266\n  [9,] -0.906228912\n [10,]  0.060160036\n [11,] -1.124445771\n [12,] -0.625664378\n [13,] -1.249141119\n [14,] -0.500969030\n [15,]  0.247203059\n [16,] -0.625664378\n [17,] -0.937402749\n [18,]  0.371898407\n [19,] -1.093271934\n [20,] -0.002187638\n [21,] -0.999750423\n [22,] -0.750359726\n [23,] -0.500969030\n [24,] -0.313926008\n [25,] -0.500969030\n [26,] -0.500969030\n [27,] -0.812707400\n [28,] -1.249141119\n [29,] -1.311488793\n [30,] -0.313926008\n [31,] -1.186793445\n [32,] -0.376273682\n [33,] -1.124445771\n [34,] -0.376273682\n [35,] -1.093271934\n [36,] -0.064535312\n [37,] -0.313926008\n [38,] -0.812707400\n [39,] -1.124445771\n [40,]  0.558941429\n [41,] -1.311488793\n [42,] -0.376273682\n [43,] -1.373836467\n [44,]  0.247203059\n [45,] -1.498531815\n [46,]  0.496593755\n [47,] -0.968576586\n [48,] -1.529705652\n [49,] -0.937402749\n [50,] -0.064535312\n [51,] -0.875055074\n [52,]  0.122507710\n [53,] -0.937402749\n [54,] -0.189230660\n [55,] -1.623227163\n [56,] -0.625664378\n [57,] -0.812707400\n [58,] -0.500969030\n [59,] -1.685574837\n [60,] -0.563316704\n [61,] -1.311488793\n [62,]  0.247203059\n [63,] -0.750359726\n [64,] -0.189230660\n [65,] -1.685574837\n [66,] -0.313926008\n [67,] -1.062098097\n [68,] -0.126882986\n [69,] -1.436184141\n [70,]  0.309550733\n [71,] -0.750359726\n [72,] -0.376273682\n [73,] -0.812707400\n [74,] -0.064535312\n [75,] -0.625664378\n [76,]  0.060160036\n [77,] -0.625664378\n [78,] -0.376273682\n [79,] -0.812707400\n [80,] -0.251578334\n [81,] -1.249141119\n [82,]  0.621289103\n [83,] -0.500969030\n [84,] -0.002187638\n [85,] -1.062098097\n [86,] -0.812707400\n [87,] -0.500969030\n [88,] -0.875055074\n [89,] -0.313926008\n [90,] -0.750359726\n [91,] -0.812707400\n [92,]  0.122507710\n [93,] -0.999750423\n [94,]  0.309550733\n [95,] -1.124445771\n [96,]  0.122507710\n [97,] -0.625664378\n [98,]  0.184855384\n [99,] -1.623227163\n[100,] -0.126882986\n[101,] -0.594490541\n[102,]  0.652462940\n[103,] -1.405010304\n[104,]  0.060160036\n[105,] -1.592053326\n[106,] -0.812707400\n[107,] -0.563316704\n[108,] -0.376273682\n[109,] -1.280314956\n[110,]  0.714810614\n[111,] -0.469795193\n[112,]  0.496593755\n[113,] -1.249141119\n[114,]  0.091333873\n[115,] -0.376273682\n[116,] -0.158056823\n[117,] -1.623227163\n[118,] -0.532142867\n[119,] -1.062098097\n[120,] -1.093271934\n[121,] -1.311488793\n[122,] -0.875055074\n[123,] -0.937402749\n[124,] -0.407447519\n[125,] -1.436184141\n[126,] -0.251578334\n[127,] -1.155619608\n[128,]  0.122507710\n[129,] -1.436184141\n[130,] -0.251578334\n[131,] -1.093271934\n[132,] -0.875055074\n[133,] -0.875055074\n[134,]  0.340724570\n[135,] -0.968576586\n[136,] -0.376273682\n[137,] -1.280314956\n[138,] -0.282752171\n[139,] -0.999750423\n[140,]  0.060160036\n[141,] -0.999750423\n[142,] -0.906228912\n[143,] -1.436184141\n[144,] -0.594490541\n[145,] -1.498531815\n[146,] -0.688012052\n[147,]  0.060160036\n[148,] -0.906228912\n[149,] -0.937402749\n[150,] -0.563316704\n[151,] -0.625664378\n[152,] -0.251578334\n[153,]  0.371898407\n[154,]  1.868242584\n[155,]  0.309550733\n[156,]  1.868242584\n[157,]  1.494156540\n[158,]  0.434246081\n[159,]  0.745984451\n[160,]  1.244765843\n[161,]  0.247203059\n[162,]  1.182418169\n[163,]  0.558941429\n[164,]  1.681199562\n[165,]  0.558941429\n[166,]  2.055285606\n[167,] -0.002187638\n[168,]  2.055285606\n[169,] -0.064535312\n[170,]  2.616414673\n[171,]  0.745984451\n[172,]  1.431808866\n[173,]  1.868242584\n[174,]  0.995375147\n[175,]  0.247203059\n[176,]  1.057722821\n[177,]  0.995375147\n[178,]  1.120070495\n[179,] -0.126882986\n[180,]  1.805894910\n[181,]  0.496593755\n[182,]  1.681199562\n[183,]  1.307113518\n[184,]  0.621289103\n[185,]  1.057722821\n[186,]  2.304676302\n[187,]  1.182418169\n[188,]  1.494156540\n[189,]  0.933027473\n[190,]  1.307113518\n[191,]  0.184855384\n[192,]  1.431808866\n[193,] -0.313926008\n[194,]  1.868242584\n[195,]  0.122507710\n[196,]  0.683636777\n[197,]  1.681199562\n[198,]  0.870679799\n[199,] -0.002187638\n[200,]  1.494156540\n[201,]  1.120070495\n[202,]  1.369461192\n[203,]  0.808332125\n[204,]  1.369461192\n[205,]  0.247203059\n[206,]  0.995375147\n[207,]  0.870679799\n[208,]  1.057722821\n[209,]  0.122507710\n[210,]  0.995375147\n[211,]  0.309550733\n[212,]  1.681199562\n[213,] -0.002187638\n[214,]  1.369461192\n[215,]  0.247203059\n[216,]  1.805894910\n[217,]  0.621289103\n[218,]  1.868242584\n[219,]  0.558941429\n[220,]  1.992937932\n[221,]  0.621289103\n[222,]  1.681199562\n[223,]  0.683636777\n[224,]  0.995375147\n[225,]  1.120070495\n[226,]  1.244765843\n[227,]  0.621289103\n[228,]  1.992937932\n[229,]  0.496593755\n[230,]  2.242328628\n[231,]  0.683636777\n[232,]  2.179980954\n[233,]  0.527767592\n[234,]  1.556504214\n[235,]  0.652462940\n[236,]  1.431808866\n[237,]  0.683636777\n[238,]  1.743547236\n[239,]  0.496593755\n[240,]  1.369461192\n[241,]  0.839505962\n[242,]  1.681199562\n[243,]  0.933027473\n[244,]  1.494156540\n[245,]  0.683636777\n[246,]  1.805894910\n[247,]  0.808332125\n[248,]  1.244765843\n[249,]  0.901853636\n[250,]  0.839505962\n[251,]  0.527767592\n[252,]  1.307113518\n[253,]  0.808332125\n[254,]  1.743547236\n[255,]  0.964201310\n[256,]  1.618851888\n[257,]  0.652462940\n[258,]  1.618851888\n[259,]  0.621289103\n[260,]  1.618851888\n[261,]  0.465419918\n[262,]  1.618851888\n[263,]  0.995375147\n[264,]  2.179980954\n[265,]  0.558941429\n[266,]  1.618851888\n[267,]  0.216029222\n[268,]  2.055285606\n[269,]  0.839505962\n[270,]  2.242328628\n[271,]  0.901853636\n[272,]           NA\n[273,]  0.808332125\n[274,]  1.930590258\n[275,]  1.244765843\n[276,]  1.494156540\n[277,] -0.875055074\n[278,] -0.376273682\n[279,] -0.688012052\n[280,] -0.843881237\n[281,] -0.594490541\n[282,] -0.313926008\n[283,] -1.186793445\n[284,] -0.563316704\n[285,] -0.064535312\n[286,] -0.625664378\n[287,] -0.500969030\n[288,] -0.532142867\n[289,] -0.625664378\n[290,] -0.189230660\n[291,] -0.781533563\n[292,] -0.189230660\n[293,] -1.124445771\n[294,] -0.625664378\n[295,] -0.937402749\n[296,]  0.247203059\n[297,] -0.750359726\n[298,] -0.999750423\n[299,] -1.623227163\n[300,] -0.500969030\n[301,] -1.124445771\n[302,] -0.064535312\n[303,] -0.999750423\n[304,] -0.500969030\n[305,] -0.625664378\n[306,]  0.434246081\n[307,] -1.249141119\n[308,]  0.122507710\n[309,] -1.062098097\n[310,] -0.126882986\n[311,] -0.750359726\n[312,] -0.376273682\n[313,] -0.438621356\n[314,]  0.745984451\n[315,] -1.872617859\n[316,]  0.371898407\n[317,] -0.313926008\n[318,] -0.688012052\n[319,] -0.812707400\n[320,] -0.875055074\n[321,] -0.656838215\n[322,]  0.309550733\n[323,] -0.999750423\n[324,]  0.122507710\n[325,] -1.186793445\n[326,] -0.656838215\n[327,] -1.093271934\n[328,] -0.313926008\n[329,] -0.750359726\n[330,] -0.189230660\n[331,] -1.062098097\n[332,] -0.937402749\n[333,] -1.186793445\n[334,] -0.189230660\n[335,] -0.500969030\n[336,] -0.843881237\n[337,] -0.313926008\n[338,] -0.688012052\n[339,] -0.688012052\n[340,] -0.251578334\n[341,] -0.999750423\n[342,] -0.532142867\n[343,] -0.126882986\n[344,] -0.532142867\nattr(,\"scaled:center\")\n[1] 4201.754\nattr(,\"scaled:scale\")\n[1] 801.9545\n\n$sex\n  [1] male   female female &lt;NA&gt;   female male   female male   &lt;NA&gt;   &lt;NA&gt;  \n [11] &lt;NA&gt;   &lt;NA&gt;   female male   male   female female male   female male  \n [21] female male   female male   male   female male   female female male  \n [31] female male   female male   female male   male   female female male  \n [41] female male   female male   female male   male   &lt;NA&gt;   female male  \n [51] female male   female male   female male   female male   female male  \n [61] female male   female male   female male   female male   female male  \n [71] female male   female male   female male   female male   female male  \n [81] female male   female male   female male   male   female male   female\n [91] female male   female male   female male   female male   female male  \n[101] female male   female male   female male   female male   female male  \n[111] female male   female male   female male   female male   female male  \n[121] female male   female male   female male   female male   female male  \n[131] female male   female male   female male   female male   female male  \n[141] female male   female male   female male   male   female female male  \n[151] female male   female male   female male   male   female female male  \n[161] female male   female male   female male   female male   female male  \n[171] female male   male   female female male   female male   &lt;NA&gt;   male  \n[181] female male   male   female female male   female male   female male  \n[191] female male   female male   female male   male   female female male  \n[201] female male   female male   female male   female male   female male  \n[211] female male   female male   female male   female male   &lt;NA&gt;   male  \n[221] female male   female male   male   female female male   female male  \n[231] female male   female male   female male   female male   female male  \n[241] female male   female male   female male   female male   male   female\n[251] female male   female male   female male   &lt;NA&gt;   male   female male  \n[261] female male   female male   female male   female male   &lt;NA&gt;   male  \n[271] female &lt;NA&gt;   female male   female male   female male   male   female\n[281] male   female female male   female male   female male   female male  \n[291] female male   male   female female male   female male   female male  \n[301] female male   female male   female male   female male   female male  \n[311] male   female female male   female male   male   female male   female\n[321] female male   female male   male   female female male   female male  \n[331] female male   female male   male   female male   female female male  \n[341] female male   male   female\nLevels: female male\n\n$year\n              [,1]\n  [1,] -1.25748435\n  [2,] -1.25748435\n  [3,] -1.25748435\n  [4,] -1.25748435\n  [5,] -1.25748435\n  [6,] -1.25748435\n  [7,] -1.25748435\n  [8,] -1.25748435\n  [9,] -1.25748435\n [10,] -1.25748435\n [11,] -1.25748435\n [12,] -1.25748435\n [13,] -1.25748435\n [14,] -1.25748435\n [15,] -1.25748435\n [16,] -1.25748435\n [17,] -1.25748435\n [18,] -1.25748435\n [19,] -1.25748435\n [20,] -1.25748435\n [21,] -1.25748435\n [22,] -1.25748435\n [23,] -1.25748435\n [24,] -1.25748435\n [25,] -1.25748435\n [26,] -1.25748435\n [27,] -1.25748435\n [28,] -1.25748435\n [29,] -1.25748435\n [30,] -1.25748435\n [31,] -1.25748435\n [32,] -1.25748435\n [33,] -1.25748435\n [34,] -1.25748435\n [35,] -1.25748435\n [36,] -1.25748435\n [37,] -1.25748435\n [38,] -1.25748435\n [39,] -1.25748435\n [40,] -1.25748435\n [41,] -1.25748435\n [42,] -1.25748435\n [43,] -1.25748435\n [44,] -1.25748435\n [45,] -1.25748435\n [46,] -1.25748435\n [47,] -1.25748435\n [48,] -1.25748435\n [49,] -1.25748435\n [50,] -1.25748435\n [51,] -0.03552216\n [52,] -0.03552216\n [53,] -0.03552216\n [54,] -0.03552216\n [55,] -0.03552216\n [56,] -0.03552216\n [57,] -0.03552216\n [58,] -0.03552216\n [59,] -0.03552216\n [60,] -0.03552216\n [61,] -0.03552216\n [62,] -0.03552216\n [63,] -0.03552216\n [64,] -0.03552216\n [65,] -0.03552216\n [66,] -0.03552216\n [67,] -0.03552216\n [68,] -0.03552216\n [69,] -0.03552216\n [70,] -0.03552216\n [71,] -0.03552216\n [72,] -0.03552216\n [73,] -0.03552216\n [74,] -0.03552216\n [75,] -0.03552216\n [76,] -0.03552216\n [77,] -0.03552216\n [78,] -0.03552216\n [79,] -0.03552216\n [80,] -0.03552216\n [81,] -0.03552216\n [82,] -0.03552216\n [83,] -0.03552216\n [84,] -0.03552216\n [85,] -0.03552216\n [86,] -0.03552216\n [87,] -0.03552216\n [88,] -0.03552216\n [89,] -0.03552216\n [90,] -0.03552216\n [91,] -0.03552216\n [92,] -0.03552216\n [93,] -0.03552216\n [94,] -0.03552216\n [95,] -0.03552216\n [96,] -0.03552216\n [97,] -0.03552216\n [98,] -0.03552216\n [99,] -0.03552216\n[100,] -0.03552216\n[101,]  1.18644003\n[102,]  1.18644003\n[103,]  1.18644003\n[104,]  1.18644003\n[105,]  1.18644003\n[106,]  1.18644003\n[107,]  1.18644003\n[108,]  1.18644003\n[109,]  1.18644003\n[110,]  1.18644003\n[111,]  1.18644003\n[112,]  1.18644003\n[113,]  1.18644003\n[114,]  1.18644003\n[115,]  1.18644003\n[116,]  1.18644003\n[117,]  1.18644003\n[118,]  1.18644003\n[119,]  1.18644003\n[120,]  1.18644003\n[121,]  1.18644003\n[122,]  1.18644003\n[123,]  1.18644003\n[124,]  1.18644003\n[125,]  1.18644003\n[126,]  1.18644003\n[127,]  1.18644003\n[128,]  1.18644003\n[129,]  1.18644003\n[130,]  1.18644003\n[131,]  1.18644003\n[132,]  1.18644003\n[133,]  1.18644003\n[134,]  1.18644003\n[135,]  1.18644003\n[136,]  1.18644003\n[137,]  1.18644003\n[138,]  1.18644003\n[139,]  1.18644003\n[140,]  1.18644003\n[141,]  1.18644003\n[142,]  1.18644003\n[143,]  1.18644003\n[144,]  1.18644003\n[145,]  1.18644003\n[146,]  1.18644003\n[147,]  1.18644003\n[148,]  1.18644003\n[149,]  1.18644003\n[150,]  1.18644003\n[151,]  1.18644003\n[152,]  1.18644003\n[153,] -1.25748435\n[154,] -1.25748435\n[155,] -1.25748435\n[156,] -1.25748435\n[157,] -1.25748435\n[158,] -1.25748435\n[159,] -1.25748435\n[160,] -1.25748435\n[161,] -1.25748435\n[162,] -1.25748435\n[163,] -1.25748435\n[164,] -1.25748435\n[165,] -1.25748435\n[166,] -1.25748435\n[167,] -1.25748435\n[168,] -1.25748435\n[169,] -1.25748435\n[170,] -1.25748435\n[171,] -1.25748435\n[172,] -1.25748435\n[173,] -1.25748435\n[174,] -1.25748435\n[175,] -1.25748435\n[176,] -1.25748435\n[177,] -1.25748435\n[178,] -1.25748435\n[179,] -1.25748435\n[180,] -1.25748435\n[181,] -1.25748435\n[182,] -1.25748435\n[183,] -1.25748435\n[184,] -1.25748435\n[185,] -1.25748435\n[186,] -1.25748435\n[187,] -0.03552216\n[188,] -0.03552216\n[189,] -0.03552216\n[190,] -0.03552216\n[191,] -0.03552216\n[192,] -0.03552216\n[193,] -0.03552216\n[194,] -0.03552216\n[195,] -0.03552216\n[196,] -0.03552216\n[197,] -0.03552216\n[198,] -0.03552216\n[199,] -0.03552216\n[200,] -0.03552216\n[201,] -0.03552216\n[202,] -0.03552216\n[203,] -0.03552216\n[204,] -0.03552216\n[205,] -0.03552216\n[206,] -0.03552216\n[207,] -0.03552216\n[208,] -0.03552216\n[209,] -0.03552216\n[210,] -0.03552216\n[211,] -0.03552216\n[212,] -0.03552216\n[213,] -0.03552216\n[214,] -0.03552216\n[215,] -0.03552216\n[216,] -0.03552216\n[217,] -0.03552216\n[218,] -0.03552216\n[219,] -0.03552216\n[220,] -0.03552216\n[221,] -0.03552216\n[222,] -0.03552216\n[223,] -0.03552216\n[224,] -0.03552216\n[225,] -0.03552216\n[226,] -0.03552216\n[227,] -0.03552216\n[228,] -0.03552216\n[229,] -0.03552216\n[230,] -0.03552216\n[231,] -0.03552216\n[232,] -0.03552216\n[233,]  1.18644003\n[234,]  1.18644003\n[235,]  1.18644003\n[236,]  1.18644003\n[237,]  1.18644003\n[238,]  1.18644003\n[239,]  1.18644003\n[240,]  1.18644003\n[241,]  1.18644003\n[242,]  1.18644003\n[243,]  1.18644003\n[244,]  1.18644003\n[245,]  1.18644003\n[246,]  1.18644003\n[247,]  1.18644003\n[248,]  1.18644003\n[249,]  1.18644003\n[250,]  1.18644003\n[251,]  1.18644003\n[252,]  1.18644003\n[253,]  1.18644003\n[254,]  1.18644003\n[255,]  1.18644003\n[256,]  1.18644003\n[257,]  1.18644003\n[258,]  1.18644003\n[259,]  1.18644003\n[260,]  1.18644003\n[261,]  1.18644003\n[262,]  1.18644003\n[263,]  1.18644003\n[264,]  1.18644003\n[265,]  1.18644003\n[266,]  1.18644003\n[267,]  1.18644003\n[268,]  1.18644003\n[269,]  1.18644003\n[270,]  1.18644003\n[271,]  1.18644003\n[272,]  1.18644003\n[273,]  1.18644003\n[274,]  1.18644003\n[275,]  1.18644003\n[276,]  1.18644003\n[277,] -1.25748435\n[278,] -1.25748435\n[279,] -1.25748435\n[280,] -1.25748435\n[281,] -1.25748435\n[282,] -1.25748435\n[283,] -1.25748435\n[284,] -1.25748435\n[285,] -1.25748435\n[286,] -1.25748435\n[287,] -1.25748435\n[288,] -1.25748435\n[289,] -1.25748435\n[290,] -1.25748435\n[291,] -1.25748435\n[292,] -1.25748435\n[293,] -1.25748435\n[294,] -1.25748435\n[295,] -1.25748435\n[296,] -1.25748435\n[297,] -1.25748435\n[298,] -1.25748435\n[299,] -1.25748435\n[300,] -1.25748435\n[301,] -1.25748435\n[302,] -1.25748435\n[303,] -0.03552216\n[304,] -0.03552216\n[305,] -0.03552216\n[306,] -0.03552216\n[307,] -0.03552216\n[308,] -0.03552216\n[309,] -0.03552216\n[310,] -0.03552216\n[311,] -0.03552216\n[312,] -0.03552216\n[313,] -0.03552216\n[314,] -0.03552216\n[315,] -0.03552216\n[316,] -0.03552216\n[317,] -0.03552216\n[318,] -0.03552216\n[319,] -0.03552216\n[320,] -0.03552216\n[321,]  1.18644003\n[322,]  1.18644003\n[323,]  1.18644003\n[324,]  1.18644003\n[325,]  1.18644003\n[326,]  1.18644003\n[327,]  1.18644003\n[328,]  1.18644003\n[329,]  1.18644003\n[330,]  1.18644003\n[331,]  1.18644003\n[332,]  1.18644003\n[333,]  1.18644003\n[334,]  1.18644003\n[335,]  1.18644003\n[336,]  1.18644003\n[337,]  1.18644003\n[338,]  1.18644003\n[339,]  1.18644003\n[340,]  1.18644003\n[341,]  1.18644003\n[342,]  1.18644003\n[343,]  1.18644003\n[344,]  1.18644003\nattr(,\"scaled:center\")\n[1] 2008.029\nattr(,\"scaled:scale\")\n[1] 0.8183559\n\n\n\n\n\npenguins |&gt; \n  map_if(is.numeric, scale) |&gt; \n  bind_cols()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nsex\n\n\n\n\nAdelie\nTorgersen\n-0.8832047\n0.7843001\nmale\n\n\nAdelie\nTorgersen\n-0.8099390\n0.1260033\nfemale\n\n\nAdelie\nTorgersen\n-0.6634077\n0.4298326\nfemale\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\n\n\nAdelie\nTorgersen\n-1.3227986\n1.0881294\nfemale\n\n\nAdelie\nTorgersen\n-0.8465718\n1.7464261\nmale\n\n\nAdelie\nTorgersen\n-0.9198375\n0.3285561\nfemale\n\n\nAdelie\nTorgersen\n-0.8648883\n1.2400440\nmale"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#but-dr.-c-we-just-figured-out-across",
    "href": "slides/week-8/w8-iteration.html#but-dr.-c-we-just-figured-out-across",
    "title": "Iteration",
    "section": "BUT DR. C we just figured out across() 😭😭😭!!!",
    "text": "BUT DR. C we just figured out across() 😭😭😭!!!\n\nI promise there are good reasons to learn purrr!\n\nFunctional programming is computationally faster than across()\nYou can complete a larger variety of data manipulations with map() functions\nacross() is just for datasets, while functional programming can be used for many different tasks\n\n\n\n\n\n\n\n\n\nTip\n\n\nThis doesn’t mean that across() is bad practice at all, just that there are times when using functional programming will be much better!"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#comparing-speed",
    "href": "slides/week-8/w8-iteration.html#comparing-speed",
    "title": "Iteration",
    "section": "Comparing Speed",
    "text": "Comparing Speed\nUsing functional programming can be much faster than using for loops.\n\nfor()across()map()RunCompare\n\n\n\nloop_func &lt;- function(d){\n  typ &lt;- rep(NA, ncol(d))\n  for(i in 1:ncol(d)){\n    typ[i] &lt;- class(d[,i])\n  }\n  return(typ)\n}\n\n\n\n\nacross_func &lt;- function(d){\n  typ &lt;- d |&gt; \n    summarize(across(.cols = everything(),\n                     .fns = class))\n  return(typ)\n}\n\n\n\n\nmap_func &lt;- function(d){\n  typ &lt;- map_chr(d, class)\n  return(typ)\n}\n\n\n\n\ndf &lt;- as.data.frame(matrix(1,\n                           nrow = 5,\n                           ncol = 7))\n\nloop_func(df)\n\n[1] \"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\"\n\nacross_func(df)\n\n       V1      V2      V3      V4      V5      V6      V7\n1 numeric numeric numeric numeric numeric numeric numeric\n\nmap_func(df)\n\n       V1        V2        V3        V4        V5        V6        V7 \n\"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \n\n\n\n\n\ndf &lt;- as.data.frame(matrix(1,\n                           nrow = 5,\n                           ncol = 100000))\n\nmicrobenchmark::microbenchmark(loop_func(df),\n                               across_func(df),\n                               map_func(df),\n                               times = 20)"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#the-pmap-family",
    "href": "slides/week-8/w8-iteration.html#the-pmap-family",
    "title": "Iteration",
    "section": "The pmap() Family",
    "text": "The pmap() Family\nThese functions take in a list of vectors and a function.\n\nThe function must accept a number of arguments equal to the length of the list,"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#the-pmap-family-1",
    "href": "slides/week-8/w8-iteration.html#the-pmap-family-1",
    "title": "Iteration",
    "section": "The pmap() Family",
    "text": "The pmap() Family\nThe vectors need to have the same names as the arguments of the function you are applying.\n\nfruit &lt;- data.frame(string = c(\"apple\", \"banana\", \"cherry\"),\n                    pattern = c(\"p\", \"n\", \"h\"),\n                    replacement = c(\"P\", \"N\", \"H\"))\nfruit\n\n  string pattern replacement\n1  apple       p           P\n2 banana       n           N\n3 cherry       h           H\n\n\n\nfruit |&gt; \n  pmap_chr(str_replace_all)\n\n[1] \"aPPle\"  \"baNaNa\" \"cHerry\""
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#the-map-and-pmap-family",
    "href": "slides/week-8/w8-iteration.html#the-map-and-pmap-family",
    "title": "Iteration",
    "section": "The map() and pmap() Family",
    "text": "The map() and pmap() Family\n\nThere are so many functions – check out the purrr cheatsheet!"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#use-functional-programming",
    "href": "slides/week-8/w8-iteration.html#use-functional-programming",
    "title": "Iteration",
    "section": "Use functional programming!",
    "text": "Use functional programming!\n\n\n\n\n\nhttps://bookdown.org/hneth/ds4psy"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#pa-8-the-twelve-days-of-christmas",
    "href": "slides/week-8/w8-iteration.html#pa-8-the-twelve-days-of-christmas",
    "title": "Iteration",
    "section": "PA 8: The Twelve Days of Christmas",
    "text": "PA 8: The Twelve Days of Christmas\n\n\n\n\n\nhttps://studioplayhouse.org/the-12-days-of-christmas/"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#glue",
    "href": "slides/week-8/w8-iteration.html#glue",
    "title": "Iteration",
    "section": "glue()",
    "text": "glue()\n\n\nThe glue package embeds R expressions in curly brackets that are then evaluated and inserted into the argument string.\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(glue)\n\nname &lt;- \"Dr. C\"\nglue('My name is {name}.')\n\nMy name is Dr. C.\n\n\n\nThis will be a handy function (and package) for putting our song together!"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#an-example",
    "href": "slides/week-8/w8-iteration.html#an-example",
    "title": "Iteration",
    "section": "An Example",
    "text": "An Example\n99 bottles of beer on the wall, 99 bottles of beer. Take one down, pass it around, 98 bottles of beer on the wall…\n\nLyricsSongAlternate EndingFinal Song\n\n\n\nbottles_lyrics &lt;- function(n){\n  lyrics &lt;- glue(\"{n} bottles of beer on the wall, {n} bottles of beer \\nTake one down, pass it around, {n -1} bottles of beer on the wall\")\n  return(lyrics)\n}\n\nbottles_lyrics(3)\n\n3 bottles of beer on the wall, 3 bottles of beer \nTake one down, pass it around, 2 bottles of beer on the wall\n\n\n\n\n\nbottles_song &lt;- function(n){\n  song &lt;- map_chr(n:0, bottles_lyrics)\n  return(glue(\"{song}\"))\n}\n\nbottles_song(3)\n\n3 bottles of beer on the wall, 3 bottles of beer \nTake one down, pass it around, 2 bottles of beer on the wall\n2 bottles of beer on the wall, 2 bottles of beer \nTake one down, pass it around, 1 bottles of beer on the wall\n1 bottles of beer on the wall, 1 bottles of beer \nTake one down, pass it around, 0 bottles of beer on the wall\n0 bottles of beer on the wall, 0 bottles of beer \nTake one down, pass it around, -1 bottles of beer on the wall\n\n\n\n\nNo more bottles of beer on the wall, no more bottles of beer. Go to the store, buy some more, 99 bottles of beer on the wall…\n\nbottles_lyrics &lt;- function(n){\n  if(n == 0){\n    lyrics &lt;- glue(\"No more bottles of beer on the wall, no more bottles of beer. \\nGo to the store, buy some more, 99 bottles of beer on the wall...\")\n  } else{\n    lyrics &lt;- glue(\"{n} bottles of beer on the wall, {n} bottles of beer \\nTake one down, pass it around, {n -1} bottles of beer on the wall\")\n  }\n  return(lyrics)\n}\n\n\n\n\nbottles_song(4)\n\n4 bottles of beer on the wall, 4 bottles of beer \nTake one down, pass it around, 3 bottles of beer on the wall\n3 bottles of beer on the wall, 3 bottles of beer \nTake one down, pass it around, 2 bottles of beer on the wall\n2 bottles of beer on the wall, 2 bottles of beer \nTake one down, pass it around, 1 bottles of beer on the wall\n1 bottles of beer on the wall, 1 bottles of beer \nTake one down, pass it around, 0 bottles of beer on the wall\nNo more bottles of beer on the wall, no more bottles of beer. \nGo to the store, buy some more, 99 bottles of beer on the wall..."
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#to-do",
    "href": "slides/week-8/w8-iteration.html#to-do",
    "title": "Iteration",
    "section": "To do…",
    "text": "To do…\n\nPA 8.1: The Twelve Days of Christmas\n\nDue Thursday 5/22 before class.\n\nProject Proposal + Data\n\nDue Friday 5/23 at 11:59pm.\n\nLab 8: Searching for Efficiency\n\nDue Tuesday 5/27 at 11:59pm."
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#pa-8.1-the-twelve-days-of-christmas",
    "href": "slides/week-8/w8-iteration.html#pa-8.1-the-twelve-days-of-christmas",
    "title": "Iteration",
    "section": "PA 8.1: The Twelve Days of Christmas",
    "text": "PA 8.1: The Twelve Days of Christmas\n\n\n\n\n\nhttps://studioplayhouse.org/the-12-days-of-christmas/"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#wednesday-feb-26",
    "href": "slides/week-8/w8-simulation.html#wednesday-feb-26",
    "title": "Simulation + Nice Tables",
    "section": "Wednesday, Feb 26",
    "text": "Wednesday, Feb 26\nToday we will…\n\nDebugging Functions\n\nEx: PA8\n\nStatistical Distributions\nSimulating Data\nCommunicating Findings from Statistical Computing\n\nDescribing data\nDescribing plots & tables\nDesigning Plots\nReport-ready tables\n\nLab 8: Searching for Efficiency"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#a-couple-of-strategies",
    "href": "slides/week-8/w8-simulation.html#a-couple-of-strategies",
    "title": "Simulation + Nice Tables",
    "section": "A couple of strategies",
    "text": "A couple of strategies\n\n\nDon’t write a whole function at once (if it is complicated)!\n\nWrite small parts and test each\ntest often\n\nSet up intermediate tests\nPrint a lot\nJust staring at your code probably won’t help"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#statistical-distributions-1",
    "href": "slides/week-8/w8-simulation.html#statistical-distributions-1",
    "title": "Simulation + Nice Tables",
    "section": "Statistical Distributions",
    "text": "Statistical Distributions\nRecall from your statistics classes…\n\nRandom VariableDistribution\n\n\nA random variable is a value we don’t know until we observe an instance.\n\nCoin flip: could be heads (0) or tails (1)\nPerson’s height: could be anything from 0 feet to 10 feet.\nAnnual income of a US worker: could be anything from $0 to $1.6 billion\n\n\n\nThe distribution of a random variable tells us its possible values and how likely they are.\n\n\n\nCoin flip: 50% chance of heads and tails.\nHeights follow a bell curve centered at 5 foot 7.\nMost American workers make under $100,000."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#statistical-distributions-with-names",
    "href": "slides/week-8/w8-simulation.html#statistical-distributions-with-names",
    "title": "Simulation + Nice Tables",
    "section": "Statistical Distributions with Names!",
    "text": "Statistical Distributions with Names!\n\nunifnormtchisqbinom\n\n\nUniform Distribution\n\n\n\nWhen you know the range of values, but not much else.\nAll values in the range are equally likely to occur.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormal Distribution\n\n\n\nWhen you expect values to fall near the center.\nFrequency of values follows a bell shaped curve.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt-Distribution\n\n\n\nA slightly wider bell curve.\nBasically used in the same context as the normal distribution, but more common with real data (when the standard deviation is unknown).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChi-Square Distribution\n\n\n\nSomewhat skewed, and only allows values above zero.\nCommonly used in statistical testing.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinomial Distribution\n\n\n\nThere are two possible outcomes, and you are counting how many times one of the outcomes occured out of a fixed number of trials.\nTakes discrete values from 0 to the number of trials."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#how-do-we-use-distributions",
    "href": "slides/week-8/w8-simulation.html#how-do-we-use-distributions",
    "title": "Simulation + Nice Tables",
    "section": "How do we use distributions?",
    "text": "How do we use distributions?\n\nFind the probability of an event.\n\nIf I flip 10 coins, what are the chances I get all heads?\n\nEstimate a proportion of a population.\n\nAbout what proportion of people are above 6 feet tall?\n\nQuantify the evidence in your data.\n\nIn my survey of 100 people, 67 said they were voting for Measure A. How confident am I that Measure A will pass?"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#distribution-functions-in-r",
    "href": "slides/week-8/w8-simulation.html#distribution-functions-in-r",
    "title": "Simulation + Nice Tables",
    "section": "Distribution Functions in R",
    "text": "Distribution Functions in R\n\nrpqd\n\n\nr is for random sampling.\n\nGenerate random values from a distribution.\nWe use this to simulate data (create pretend observations).\n\n\n\n\nrunif(n = 3, min = 10, max = 20)\n\n[1] 15.03247 14.88801 11.20575\n\nrnorm(n = 3)\n\n[1]  0.7725824 -0.7609517  0.1138140\n\nrnorm(n = 3, mean = -100, sd = 50)\n\n[1]  -53.90008 -122.61353  -79.15539\n\n\n\n\nrt(n = 3, df = 11)\n\n[1]  0.8496523 -1.3417337 -2.7849670\n\nrbinom(n = 3, size = 10, prob = 0.7)\n\n[1] 9 8 7\n\nrchisq(n = 3, df = 11)\n\n[1] 14.90499 16.98204 15.21053\n\n\n\n\n\np is for probability.\n\nCompute the chances of observing a value less than x: \\(P(X &lt; x)\\)\nWe use this for calculating p-values.\n\n\n\n\npnorm(q = 70, mean = 67, sd = 3)\n\n[1] 0.8413447\n\n1 - pnorm(q = 70, mean = 67, sd = 3)\n\n[1] 0.1586553\n\npnorm(q = 70, mean = 67, sd = 3, lower.tail = FALSE)\n\n[1] 0.1586553\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nq is for quantile.\n\nGiven a probability \\(p\\), compute \\(x\\) such that \\(P(X &lt; x) = p\\).\nThe q functions are “backwards” of the p functions.\n\n\nqnorm(p = 0.95)\n\n[1] 1.644854\n\nqnorm(p = 0.95, mean = 67, sd = 3)\n\n[1] 71.93456\n\n\n\n\nd is for density.\n\nCompute the height of a distribution curve at a given \\(x\\).\nFor discrete dist: probability of getting exactly \\(x\\).\nFor continuous dist: usually meaningless.\n\nProbability of exactly 12 heads in 20 coin tosses, with a 70% chance of tails?\n\ndbinom(x = 12, size = 20, prob = 0.3)\n\n[1] 0.003859282"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#empirical-vs.-theoretical-distributions",
    "href": "slides/week-8/w8-simulation.html#empirical-vs.-theoretical-distributions",
    "title": "Simulation + Nice Tables",
    "section": "Empirical vs. Theoretical Distributions",
    "text": "Empirical vs. Theoretical Distributions\n\nEmpirical DistributionTheoretical Distributions\n\n\nEmpirical: the observed data.\n\n\nCode\ndata %&gt;%\n  ggplot(aes(x = height)) +\n  geom_histogram(aes(y = ..density..), bins = 10, color = \"white\") \n\n\n\n\n\n\n\n\n\n\n\nTheoretical: the distribution curve.\n\n\nCode\ndata %&gt;%\n  ggplot(aes(x = height)) +\n  stat_function(fun = ~dnorm(.x, mean = 67, sd = 3),\n                col = \"steelblue\", lwd = 2) +\n  stat_function(fun = ~dnorm(.x, mean = 67, sd = 2),\n                col = \"orange2\", lwd = 2)"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#plotting-both-distributions",
    "href": "slides/week-8/w8-simulation.html#plotting-both-distributions",
    "title": "Simulation + Nice Tables",
    "section": "Plotting Both Distributions",
    "text": "Plotting Both Distributions\n\n geom_histogram  dnorm  ..density.. \n\n\n\n\n\ndata |&gt; \n  ggplot(aes(x = height)) +\n  geom_histogram(bins = 10, color = \"white\")\n\n\n\n\n\n\n\n\n\n\nPlot your data.\n\n\n\n\n\n\n\ndata |&gt; \n  ggplot(aes(x = height)) +\n  geom_histogram(bins = 10, color = \"white\") +\n  stat_function(fun = ~ dnorm(.x, mean = 67, sd = 3),\n                color = \"steelblue\", lwd = 2)\n\n\n\n\n\n\n\n\n\n\nAdd a density curve.\n\n\n\n\n\n\n\ndata |&gt; \n  ggplot(aes(x = height)) +\n  geom_histogram(aes(y = after_stat(density)),\n                 bins = 10, color = \"white\") +\n  stat_function(fun = ~ dnorm(.x, mean = 67, sd = 3),\n                color = \"steelblue\", lwd = 2)\n\n\n\n\n\n\n\n\n\n\nChange the y-axis of the histogram to match the y-axis of the density."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#generating-simulated-data---the-idea",
    "href": "slides/week-8/w8-simulation.html#generating-simulated-data---the-idea",
    "title": "Simulation + Nice Tables",
    "section": "Generating Simulated Data - The Idea",
    "text": "Generating Simulated Data - The Idea\n\nWe can generate fake (“synthetic”) data based on the assumption that a variable follows a certain distribution.\nWe randomly sample observations from the distribution.\n\n\nage &lt;- runif(1000, min = 15, max = 75)"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#reproducible-samples-set.seed",
    "href": "slides/week-8/w8-simulation.html#reproducible-samples-set.seed",
    "title": "Simulation + Nice Tables",
    "section": "Reproducible samples: set.seed()",
    "text": "Reproducible samples: set.seed()\nSince there is randomness involved, we will get a different result each time we run the code.\n\n\n\nrunif(3, min = 15, max = 75)\n\n[1] 50.72983 66.67432 68.35707\n\n\n\n\nrunif(3, min = 15, max = 75)\n\n[1] 67.11051 25.35165 35.57557\n\n\n\n\n\nTo generate a reproducible random sample, we first set the seed:\n\n\n\nset.seed(94301)\n\nrunif(3, min = 15, max = 75)\n\n[1] 59.68333 30.27768 38.29962\n\n\n\n\nset.seed(94301)\n\nrunif(3, min = 15, max = 75)\n\n[1] 59.68333 30.27768 38.29962\n\n\n\n\n\n\n\n\n\n\n\nWhenever you are doing an analysis that involves a random element, you should set the seed!"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#simulate-a-dataset",
    "href": "slides/week-8/w8-simulation.html#simulate-a-dataset",
    "title": "Simulation + Nice Tables",
    "section": "Simulate a Dataset",
    "text": "Simulate a Dataset\n\ntibblevisualize\n\n\n\nset.seed(435)\nfake_data &lt;- tibble(names   = charlatan::ch_name(1000),\n        height  = rnorm(1000, mean = 67, sd = 3),\n        age     = runif(1000, min = 15, max = 75),\n        measure = rbinom(1000, size = 1, prob = 0.6)) |&gt; \n  mutate(supports_measure_A = ifelse(measure == 1, \"yes\", \"no\"))\n\n\nhead(fake_data) \n\n\n\n\n \n  \n    names \n    height \n    age \n    measure \n    supports_measure_A \n  \n \n\n  \n    Elbridge Kautzer \n    67.43632 \n    66.29460 \n    1 \n    yes \n  \n  \n    Brandon King \n    64.99480 \n    61.53720 \n    0 \n    no \n  \n  \n    Phyllis Thompson \n    68.09035 \n    53.83715 \n    1 \n    yes \n  \n  \n    Humberto Corwin \n    67.45541 \n    33.87560 \n    1 \n    yes \n  \n  \n    Theresia Koelpin \n    71.37196 \n    16.12199 \n    1 \n    yes \n  \n  \n    Hayden O'Reilly-Johns \n    66.17853 \n    36.96293 \n    0 \n    no \n  \n\n\n\n\n\n\n\nCheck to see the ages look uniformly distributed.\n\n\nCode\nfake_data |&gt; \n  ggplot(aes( x = age,\n             fill = supports_measure_A)) +\n  geom_histogram(show.legend = F) +\n  facet_wrap(~ supports_measure_A,\n             ncol = 1) +\n  scale_fill_brewer(palette = \"Paired\") +\n  theme_bw() +\n  labs(x = \"Age (years)\",\n       y = \"\",\n       subtitle = \"Support for Measure A\",)"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-1",
    "href": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-1",
    "title": "Simulation + Nice Tables",
    "section": "Simulate Multiple Datasets - Step 1",
    "text": "Simulate Multiple Datasets - Step 1\n\nWrite a function to simulate height data from a population with some mean and SD height.\nThe user should be able to input:\n\nhow many observations to simulate\nthe mean and standard deviation of the Normal distribution to use when simulating\n\n\n\n\n\n\n\nsim_ht &lt;- function(n = 200, avg, std){\n  tibble(person = 1:n,\n         ht = rnorm(n = n, mean = avg, sd = std))\n}\n\n\n\n\n\n\n\n\n\nsim_ht(n = 5, \n        avg = 66, \n        std = 3)\n\n# A tibble: 5 × 2\n  person    ht\n   &lt;int&gt; &lt;dbl&gt;\n1      1  67.9\n2      2  62.2\n3      3  66.5\n4      4  72.3\n5      5  66.2"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-2",
    "href": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-2",
    "title": "Simulation + Nice Tables",
    "section": "Simulate Multiple Datasets - Step 2",
    "text": "Simulate Multiple Datasets - Step 2\nCreate a set of parameters (mean and SD) for each population.\n\ncrossing(mean_ht = seq(from = 60, to = 78, by = 6),\n            std_ht  = c(3, 6))\n\n# A tibble: 8 × 2\n  mean_ht std_ht\n    &lt;dbl&gt;  &lt;dbl&gt;\n1      60      3\n2      60      6\n3      66      3\n4      66      6\n5      72      3\n6      72      6\n7      78      3\n8      78      6"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-3",
    "href": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-3",
    "title": "Simulation + Nice Tables",
    "section": "Simulate Multiple Datasets - Step 3",
    "text": "Simulate Multiple Datasets - Step 3\nSimulate datasets with different mean and SD heights.\n\n\ncrossing(mean_ht = seq(from = 60, to = 78, by = 6),\n         std_ht  = c(3, 6)\n         ) |&gt; \n mutate(ht_data = pmap(.l = list(avg = mean_ht, std = std_ht), \n                       .f = sim_ht\n                       )\n        )\n\n# A tibble: 8 × 3\n  mean_ht std_ht ht_data           \n    &lt;dbl&gt;  &lt;dbl&gt; &lt;list&gt;            \n1      60      3 &lt;tibble [200 × 2]&gt;\n2      60      6 &lt;tibble [200 × 2]&gt;\n3      66      3 &lt;tibble [200 × 2]&gt;\n4      66      6 &lt;tibble [200 × 2]&gt;\n5      72      3 &lt;tibble [200 × 2]&gt;\n6      72      6 &lt;tibble [200 × 2]&gt;\n7      78      3 &lt;tibble [200 × 2]&gt;\n8      78      6 &lt;tibble [200 × 2]&gt;\n\n\n\n\n\n\n\n\n\n\n\nWhy am I getting a tibble in the ht_data column?"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-4",
    "href": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-4",
    "title": "Simulation + Nice Tables",
    "section": "Simulate Multiple Datasets - Step 4",
    "text": "Simulate Multiple Datasets - Step 4\nExtract the contents of each list!\n\n\ncrossing(mean_ht = seq(from = 60, to = 78, by = 6),\n         std_ht  = c(3, 6)\n         ) |&gt; \n mutate(ht_data = pmap(.l = list(avg = mean_ht, std = std_ht), \n                       .f = sim_ht\n                       )\n        ) |&gt; \n  unnest(cols = ht_data) |&gt; \n  slice_sample(n = 10)\n\n\n\n\n\n\n\n# A tibble: 10 × 4\n   mean_ht std_ht person    ht\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;int&gt; &lt;dbl&gt;\n 1      60      3      1  51.0\n 2      60      3      2  57.6\n 3      60      3      3  64.9\n 4      60      3      4  63.1\n 5      60      3      5  62.0\n 6      60      3      6  64.5\n 7      60      3      7  64.2\n 8      60      3      8  60.6\n 9      60      3      9  62.6\n10      60      3     10  63.7\n\n\n\n\n\n\n\n\nWhy do I now have person and ht columns?\n\n\nHow many rows should I have for each mean_ht, std_ht combo?"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#a-note-nest-and-unnest",
    "href": "slides/week-8/w8-simulation.html#a-note-nest-and-unnest",
    "title": "Simulation + Nice Tables",
    "section": "A note: nest() and unnest()",
    "text": "A note: nest() and unnest()\n\nWe can pair functions from the map() family very nicely with two tidyr functions: nest() and unnest().\nThese allow us to easily map functions onto subsets of the data.\n\n\n\nnest() subsets of the data (as tibbles) inside a tibble.\n\n\nmtcars |&gt; \n  nest(.by = cyl)\n\n# A tibble: 3 × 2\n    cyl data              \n  &lt;dbl&gt; &lt;list&gt;            \n1     6 &lt;tibble [7 × 10]&gt; \n2     4 &lt;tibble [11 × 10]&gt;\n3     8 &lt;tibble [14 × 10]&gt;\n\n\n\n\n\nunnest() the data by row binding the subsets back together."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-5",
    "href": "slides/week-8/w8-simulation.html#simulate-multiple-datasets---step-5",
    "title": "Simulation + Nice Tables",
    "section": "Simulate Multiple Datasets - Step 5",
    "text": "Simulate Multiple Datasets - Step 5\nPlot the samples simulated from each population.\n\n\n\nCode\nfake_ht_data |&gt; \n  mutate(across(.cols = mean_ht:std_ht, \n                .fns = ~as.character(.x)), \n         mean_ht = fct_recode(mean_ht, \n                              `Mean = 60` = \"60\", \n                              `Mean = 66` = \"66\", \n                              `Mean = 72` = \"72\", \n                              `Mean = 78` = \"78\"), \n         std_ht = fct_recode(std_ht, \n                             `Std = 3` = \"3\", \n                             `Std = 6` = \"6\")\n         ) |&gt; \n  ggplot(mapping = aes(x = ht)) +\n  geom_histogram(color = \"white\") +\n  facet_grid(std_ht ~ mean_ht) +\n  labs(x = \"Height (in)\",\n       y = \"\",\n       subtitle = \"Frequency of Observations\",\n       title = \"Simulated Heights from Eight Different Populations\")"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#draw-a-random-sample",
    "href": "slides/week-8/w8-simulation.html#draw-a-random-sample",
    "title": "Simulation + Nice Tables",
    "section": "Draw a Random Sample",
    "text": "Draw a Random Sample\nUse sample() to take a random sample of values from a vector.\n\nmy_vec &lt;- c(\"dog\", \"cat\", \"bunny\", \"horse\", \"goat\", \"chicken\")\n\nsample(x = my_vec, size = 3)\n\n[1] \"horse\"   \"cat\"     \"chicken\"\n\nset.seed(1)\nsample(x = my_vec, size = 5, replace = T)\n\n[1] \"dog\"   \"horse\" \"dog\"   \"cat\"   \"goat\" \n\nsample(c(0, 1), size = 10, \n       prob = c(.8, .2), replace = T)\n\n [1] 1 0 0 0 0 0 0 0 0 0\n\n\n\n\n\n\n\n\n\nWarning\n\n\nWhenever you take a sample, think about if you want to take a sample with or without replacement. The default is to sample without replacement."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#draw-a-random-sample-1",
    "href": "slides/week-8/w8-simulation.html#draw-a-random-sample-1",
    "title": "Simulation + Nice Tables",
    "section": "Draw a Random Sample",
    "text": "Draw a Random Sample\nUse slice_sample() to take a random sample of observations (rows) from a dataset.\n\nfake_data |&gt; \n  slice_sample(n = 3) \n\n\n\n\n\n \n  \n    names \n    height \n    age \n    measure \n    supports_measure_A \n  \n \n\n  \n    Alexander Nicolas \n    60.78593 \n    25.87201 \n    0 \n    no \n  \n  \n    Marnie Witting \n    67.55575 \n    48.26608 \n    1 \n    yes \n  \n  \n    Liddie Wiza-Pouros \n    66.36513 \n    29.91378 \n    1 \n    yes \n  \n\n\n\n\n\n\n\n\nfake_data |&gt; \n  slice_sample(prop = .005) \n\n\n\n\n\n\n \n  \n    names \n    height \n    age \n    measure \n    supports_measure_A \n  \n \n\n  \n    Debera Kirlin \n    70.01628 \n    20.18689 \n    0 \n    no \n  \n  \n    Demario Muller \n    69.03207 \n    34.78672 \n    1 \n    yes \n  \n  \n    Alvera Mayert \n    66.06743 \n    57.62611 \n    0 \n    no \n  \n  \n    Dr. Duwayne Gleichner \n    64.79083 \n    31.31543 \n    0 \n    no \n  \n  \n    Dr. Bethany Fisher \n    71.70982 \n    33.81118 \n    1 \n    yes"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#example-birthday-simulation",
    "href": "slides/week-8/w8-simulation.html#example-birthday-simulation",
    "title": "Simulation + Nice Tables",
    "section": "Example: Birthday Simulation",
    "text": "Example: Birthday Simulation\nSuppose there is a group of 50 people.\n\nSimulate the approximate probability that at least two people have the same birthday (same day of the year, not considering year of birth or leap years)."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#example-birthday-simulation-1",
    "href": "slides/week-8/w8-simulation.html#example-birthday-simulation-1",
    "title": "Simulation + Nice Tables",
    "section": "Example: Birthday Simulation",
    "text": "Example: Birthday Simulation\nWrite a function to …\n\n… simulate the birthdays of 50 random people (assuming it is equally likely to be born any day of the year).\n… count how many birthdays are shared.\n… return whether or not a shared birthday exists.\n\n\n\nbDays &lt;- function(n = 50){\n  bday_data &lt;- tibble(person = 1:n,\n                      bday   = sample(1:365, size = n, replace = T))\n  \n  double_bdays &lt;- bday_data |&gt; \n    count(bday) |&gt; \n    filter(n &gt;= 2) |&gt; \n    nrow()\n  \n  return(double_bdays &gt; 0)\n}"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#example-birthday-simulation-2",
    "href": "slides/week-8/w8-simulation.html#example-birthday-simulation-2",
    "title": "Simulation + Nice Tables",
    "section": "Example: Birthday Simulation",
    "text": "Example: Birthday Simulation\nUse a map() function to repeat this simulation 1,000 times.\n\nWhat proportion of these datasets contain at least two people with the same birthday?\n\n\nsim_results &lt;- map_lgl(.x = 1:1000,\n                       .f = ~ bDays(n = 50))\n\nmean(sim_results)\n\n[1] 0.969"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#in-line-code",
    "href": "slides/week-8/w8-simulation.html#in-line-code",
    "title": "Simulation + Nice Tables",
    "section": "In-line Code",
    "text": "In-line Code\nWe can automatically include code output in the written portion of a Quarto document using `r `.\n\nThis ensures reproducibility when you have results from a random generation process.\n\n\nmean(sim_results)\n\n[1] 0.969\n\n\nType this: `r mean(sim_results)*100`% of the datasets contain at least two people with the same birthday.\nTo get this: 96.9% of the datasets contain at least two people with the same birthday."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#remember-the-data-science-process",
    "href": "slides/week-8/w8-simulation.html#remember-the-data-science-process",
    "title": "Simulation + Nice Tables",
    "section": "Remember the Data Science Process",
    "text": "Remember the Data Science Process\n\n\n\n\n\n\n\n\n\n\nCommunicating about your analysis and findings is a key element of statistical computing."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#describing-data",
    "href": "slides/week-8/w8-simulation.html#describing-data",
    "title": "Simulation + Nice Tables",
    "section": "Describing data",
    "text": "Describing data\n\nData source(s)\nObservational unit / level (e.g. county and year)\nOverview of what is included (e.g. demographic incormation and weekly median childcare costs for each county and year)\nYears or geographies included (e.g. 2008-2018, CA only)"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#describing-data-cleaning",
    "href": "slides/week-8/w8-simulation.html#describing-data-cleaning",
    "title": "Simulation + Nice Tables",
    "section": "Describing data cleaning",
    "text": "Describing data cleaning\n\nWhat does the audience need to know about any choices / decisions that you make while cleaning the data?\n\nhow did you handle missing data?\nhow did you define variables?\ndid you drop any observations? How many and why?\n\n\n\n\nThis doesn’t include\n\ndiscussing specific file, variable, or function names\ndata cleaning that has no impact on interpretating the resulting analysis\n\ne.g. changing the type of a variable"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#describing-data-cleaning-1",
    "href": "slides/week-8/w8-simulation.html#describing-data-cleaning-1",
    "title": "Simulation + Nice Tables",
    "section": "Describing data cleaning",
    "text": "Describing data cleaning\nWhich is clearer to a general audience?:\n\nIn this analysis, we use data from the US Department of Labor which includes a variety of measurements of a state’s minimum wage for US states and territories by year. We additionally include information from a dataset provided by the Harvard Dataverse on state party leanings by year. Our analysis includes the years 1976 - 2020 and the 50 US states.\n\n\nIn this analysis, we use inner_join() to join us-party-data.csv and us-minimum-wage-data.csv by year and state."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#plot-design",
    "href": "slides/week-8/w8-simulation.html#plot-design",
    "title": "Simulation + Nice Tables",
    "section": "Plot Design",
    "text": "Plot Design\nStepping back…\n\nWhat do you want to be very easy to see from your plot?\nWhat aesthetics will help make comparisons?\nYou may want to try a couple of different aesthetic choices to see which is clearer\nA clear plot will often look “boring” to you!"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#plot-design-1",
    "href": "slides/week-8/w8-simulation.html#plot-design-1",
    "title": "Simulation + Nice Tables",
    "section": "Plot Design",
    "text": "Plot Design\n\nCode\nsec.cols &lt;- c(\"#fdb462\", \"#b3de69\")\ntrip.cols &lt;- c(\"#fb8072\", \"#80b1d3\")\n\n\nfish &lt;- fish |&gt;\n  mutate(trip = str_c(\"Trip \", trip)) |&gt;\n  mutate(across(.cols = c(trip, section, species),\n                .fns = ~ as.factor(.x)))\n\nfish |&gt;\n  filter(if_any(.cols = everything(),\n                .fns = ~ is.na(.x))) |&gt;\n  ggplot(aes(x = year,\n             fill = trip)) +\n  geom_bar() +\n  facet_grid(~ section) +\n  scale_fill_manual(values = trip.cols) +\n  labs(y = \"\",\n       subtitle = \"Number of Missing Weight Values\",\n       x = \"Year\",\n       fill = \"Trip Number\")\nfish |&gt;\n  filter(if_any(.cols = everything(),\n                .fns = ~ is.na(.x))) |&gt;\n  ggplot(aes(x = year,\n             fill = trip)) +\n  geom_bar(position = \"dodge\") +\n  facet_grid(~ section) +\n  scale_fill_manual(values = trip.cols) +\n  labs(y = \"\",\n       subtitle = \"Number of Missing Weight Values\",\n       x = \"Year\",\n       fill = \"Trip Number\") +\n  theme(legend.position = \"bottom\")\nfish |&gt;\n  filter(if_any(.cols = everything(),\n                .fns = ~ is.na(.x))) |&gt;\n  ggplot(aes(x = year,\n             fill = section)) +\n  geom_bar() +\n  facet_grid(~ trip) +\n  scale_fill_manual(values =  sec.cols) +\n  labs(y = \"\",\n       subtitle = \"Number of Missing Weight Values\",\n       x = \"Year\",\n       fill = \"Section\")\nfish |&gt;\n  filter(if_any(.cols = everything(),\n                .fns = ~ is.na(.x))) |&gt;\n  ggplot(aes(x = year,\n             fill = section)) +\n  geom_bar(position = \"dodge\") +\n  facet_grid(~ trip) +\n  scale_fill_manual(values = sec.cols) +\n  labs(y = \"\",\n       subtitle = \"Number of Missing Weight Values\",\n       x = \"Year\",\n       fill = \"Section\") +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#plot-design-2",
    "href": "slides/week-8/w8-simulation.html#plot-design-2",
    "title": "Simulation + Nice Tables",
    "section": "Plot Design",
    "text": "Plot Design\n\nCode\nfish_sum &lt;- fish |&gt;\n  group_by(year, section, trip) |&gt;\n  summarize(n_miss = sum(is.na(weight)))\n\nfish_sum |&gt;\n  ggplot(aes(x = year,\n             y = n_miss,\n             color = trip)) +\n  geom_line(linewidth = 1) +\n  geom_point() +\n  facet_grid(cols = vars(section)) +\n  scale_color_manual(values = trip.cols) +\n  theme_bw() +\n  labs(y = \"\",\n       subtitle = \"Number of Missing Weight Values\",\n       x = \"Year\",\n       color = \"Trip\")\nfish_sum |&gt;\n  ggplot(aes(x = year,\n             y = n_miss,\n             color = section)) +\n  geom_line(linewidth = 1) +\n  geom_point() +\n  facet_grid(cols = vars(trip)) +\n  scale_color_manual(values = sec.cols) +\n  theme_bw() +\n  labs(y = \"\",\n       subtitle = \"Number of Missing Weight Values\",\n       x = \"Year\",\n       color = \"Section\")\nfish_sum |&gt;\n  ggplot(aes(x = year,\n             y = n_miss)) +\n  geom_line(linewidth = 1) +\n  geom_point() +\n  facet_grid(cols = vars(trip),\n             rows = vars(section)) +\n  theme_bw() +\n  labs(y = \"\",\n       subtitle = \"Number of Missing Weight Values\",\n       x = \"Year\")\nfish_sum |&gt;\n  ggplot(aes(x = year,\n             y = n_miss,\n             color = section,\n             linetype = trip)) +\n  geom_line(linewidth = 1) +\n  geom_point() +\n  scale_color_manual(values = sec.cols) +\n  scale_linetype_manual(values = c(2, 1)) +\n  theme_bw() +\n  labs(y = \"\",\n       subtitle = \"Number of Missing Weight Values\",\n       x = \"Year\",\n       color = \"Section\",\n       linetype = \"Trip\")"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#table-design",
    "href": "slides/week-8/w8-simulation.html#table-design",
    "title": "Simulation + Nice Tables",
    "section": "Table Design",
    "text": "Table Design\n\nWhat do you want to communicate / emphasize?\nWhat should the rows and columns be?\n\nWhat are clear labels?\nOrder of rows and columns?\n\nIs there any grouping of rows and/or columns that would be helpful?"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#report-ready-tables-in-r",
    "href": "slides/week-8/w8-simulation.html#report-ready-tables-in-r",
    "title": "Simulation + Nice Tables",
    "section": "Report Ready Tables in R",
    "text": "Report Ready Tables in R\n\nWe have just shown data tables directly, midly formatting for html using kable()\n\n\n\nWe can make report-ready tables using kableExtra or gt!"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#yay-reproducibility",
    "href": "slides/week-8/w8-simulation.html#yay-reproducibility",
    "title": "Simulation + Nice Tables",
    "section": "Yay reproducibility!",
    "text": "Yay reproducibility!\n\nFormatting tables in code makes them completely reproducible\nNo need to update results manually in a table\nNo room for copy-paste error\nCan integrate directly into a report / paper"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#yay-reproducibility-1",
    "href": "slides/week-8/w8-simulation.html#yay-reproducibility-1",
    "title": "Simulation + Nice Tables",
    "section": "Yay reproducibility!",
    "text": "Yay reproducibility!\n\n\n\n\n\nA table for one of my papers, produced directly in R"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#nice-tables-with-kable-and-kableextra-functions",
    "href": "slides/week-8/w8-simulation.html#nice-tables-with-kable-and-kableextra-functions",
    "title": "Simulation + Nice Tables",
    "section": "Nice tables with kable() and kableExtra functions",
    "text": "Nice tables with kable() and kableExtra functions\n\n\n\nGreat for tables that don’t need to be super fancy but you want to clean up a bit\nDefault options look nice in html\nNice options for changing rows / columns individually\nGet started with these resources (1) (2)"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#nice-tables-with-the-gt-package",
    "href": "slides/week-8/w8-simulation.html#nice-tables-with-the-gt-package",
    "title": "Simulation + Nice Tables",
    "section": "Nice tables with the gt package",
    "text": "Nice tables with the gt package\n\n\n\nFancy, report tables\nLots of formatting options for common variable types\nSyntax less error-prone\nCreate labels directly with markdown!\nGet started\nFull index of functions"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#table-design-example",
    "href": "slides/week-8/w8-simulation.html#table-design-example",
    "title": "Simulation + Nice Tables",
    "section": "Table Design Example",
    "text": "Table Design Example\n“Raw” Table:\n\n\nCode\ntab_dat &lt;- fish |&gt; \n  group_by(species) |&gt; \n  summarize(avg_weight = mean(weight, na.rm = T),\n            sd_weight = sd(weight, na.rm = T),\n            n = n()) \n\ntab_dat |&gt; \n  kable()\n\n\n\n\n\nspecies\navg_weight\nsd_weight\nn\n\n\n\n\nBrown\n425.9385\n381.7946\n3171\n\n\nBull\n598.4199\n635.4400\n553\n\n\nRBT\n183.2303\n182.3361\n12341\n\n\nWCT\n266.3916\n179.5302\n2287"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#table-design-example---kableextra",
    "href": "slides/week-8/w8-simulation.html#table-design-example---kableextra",
    "title": "Simulation + Nice Tables",
    "section": "Table Design Example - kableExtra",
    "text": "Table Design Example - kableExtra\n\n\nCode\ntab_dat |&gt; \n  arrange(desc(avg_weight)) |&gt; \n  kable(digits = c(0, 1, 1, 0),\n        col.names = c(\"Species\", \"Mean\", \"SD\", \"N. Samples\"),\n        caption = \"Summaries of fish weights by species across all sampling years (between 1989 - 2006) trips and sites.\") |&gt;\n  kable_classic(full_width = F,\n                bootstrap_options = \"striped\") |&gt; \n  add_header_above(c(\" \" = 1, \"Weight (g)\" = 2,\" \" = 1),\n                   bold = TRUE) |&gt; \n  row_spec(row = 0, bold = T, align = \"c\")\n\n\n\nSummaries of fish weights by species across all sampling years (between 1989 - 2006) trips and sites.\n \n\n\nWeight (g)\n\n\n  \n    Species \n    Mean \n    SD \n    N. Samples \n  \n \n\n  \n    Bull \n    598.4 \n    635.4 \n    553 \n  \n  \n    Brown \n    425.9 \n    381.8 \n    3171 \n  \n  \n    WCT \n    266.4 \n    179.5 \n    2287 \n  \n  \n    RBT \n    183.2 \n    182.3 \n    12341"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#table-design-example---gt",
    "href": "slides/week-8/w8-simulation.html#table-design-example---gt",
    "title": "Simulation + Nice Tables",
    "section": "Table Design Example - gt",
    "text": "Table Design Example - gt\n\n\nCode\ntab_dat |&gt; \n  arrange(desc(avg_weight)) |&gt; \n  gt() |&gt; \n  tab_options(table.font.size = 32) |&gt; \n  tab_header(\n    title = \"Summary of Fish Weights by Species\",\n    subtitle = \"all sampling years, trips, and sites\"\n  ) |&gt; \n  tab_spanner(label = md(\"**Weight (g)**\"), \n              columns = c(avg_weight, sd_weight)) |&gt; \n  tab_style(style = cell_text(align = \"center\"),\n    locations = cells_column_labels()) |&gt; \n  cols_align(align = \"left\",\n             columns = species) |&gt; \n  fmt_number(columns = c(avg_weight, sd_weight),\n             decimals = 1) |&gt; \n  fmt_number(columns = n,\n             decimals = 0) |&gt; \n  cols_label(\n    \"avg_weight\" = md(\"**Mean**\"),\n    \"sd_weight\" = md(\"**SD**\"),\n    \"n\" = md(\"**N. Samples**\"),\n    \"species\" = md(\"**Species**\")\n  )\n\n\n\n\n\n  \n    \n      Summary of Fish Weights by Species\n    \n    \n      all sampling years, trips, and sites\n    \n    \n      Species\n      \n        Weight (g)\n      \n      N. Samples\n    \n    \n      Mean\n      SD\n    \n  \n  \n    Bull\n598.4\n635.4\n553\n    Brown\n425.9\n381.8\n3,171\n    WCT\n266.4\n179.5\n2,287\n    RBT\n183.2\n182.3\n12,341"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#pa-8.2-instrument-con",
    "href": "slides/week-8/w8-simulation.html#pa-8.2-instrument-con",
    "title": "Simulation + Nice Tables",
    "section": "PA 8.2: Instrument Con",
    "text": "PA 8.2: Instrument Con\n\n\nWork with statistical distributions to determine if an instrument salesman is lying."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#lab-8-searching-for-efficiency",
    "href": "slides/week-8/w8-simulation.html#lab-8-searching-for-efficiency",
    "title": "Simulation + Nice Tables",
    "section": "Lab 8: Searching for Efficiency",
    "text": "Lab 8: Searching for Efficiency\nRevisit previous lab problems through the lens of efficiency\n\nUse functions from map() instead of across()\nReduce separate pipelines into a single pipeline\nMake nice tables!"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#to-do",
    "href": "slides/week-8/w8-simulation.html#to-do",
    "title": "Simulation + Nice Tables",
    "section": "To do…",
    "text": "To do…\n\nProject Proposal + Data\n\nDue Tomorrow, Friday 5/23 at 11:59pm.\n\nLab 8: Searching for Efficiency\n\nDue Tuesday 5/27 at 11:59pm.\n\nRead Chapter 9: Linear Regression\n\nCheck-in 9 due Thursday 5/29 before class.\n\n\n\n\n\n\n\n\nSee you in a week!\n\n\nEnjoy the long weekend! A reminder that we do not have class on Tuesday 5/27."
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#thursday-xx",
    "href": "slides/week-8/w8-simulation.html#thursday-xx",
    "title": "Simulation + Nice Tables",
    "section": "Thursday, XX",
    "text": "Thursday, XX\nToday we will…\n\nDebugging Functions\nStatistical Distributions\nSimulating Data\nCommunicating Findings from Statistical Computing\n\nDescribing data\nDesigning Plots\nReport-ready tables\n\nPA 8.2: Instrument Con"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#thursday-may-xx",
    "href": "slides/week-9/w9-regression.html#thursday-may-xx",
    "title": "Linear Regression",
    "section": "Thursday, May XX",
    "text": "Thursday, May XX\nToday we will…\n\nData Intro + Cleaning: Feedback\nNew Material\n\nReview of Simple Linear Regression\nAssessing Model Fit\n\nWork Time\n\nPA 9: Mystery Animal\nPC4: Linear Regression"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#nc-births-data",
    "href": "slides/week-9/w9-regression.html#nc-births-data",
    "title": "Linear Regression",
    "section": "NC Births Data",
    "text": "NC Births Data\nThis dataset contains a random sample of 1,000 births from North Carolina in 2004 (sampled from a larger dataset).\n\nEach case describes the birth of a single child, including characteristics of the:\n\nchild (birth weight, length of gestation, etc.).\nbirth parents (age, weight gained during pregnancy, smoking habits, etc.)."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#nc-births-data-1",
    "href": "slides/week-9/w9-regression.html#nc-births-data-1",
    "title": "Linear Regression",
    "section": "NC Births Data",
    "text": "NC Births Data\n\nlibrary(openintro)\ndata(ncbirths)\nslice_sample(ncbirths, n = 10) |&gt; \n  knitr::kable() |&gt; \n  kableExtra::scroll_box(height = \"400px\") |&gt; \n  kableExtra::kable_styling(font_size = 30)\n\n\n \n  \n    fage \n    mage \n    mature \n    weeks \n    premie \n    visits \n    marital \n    gained \n    weight \n    lowbirthweight \n    gender \n    habit \n    whitemom \n  \n \n\n  \n    37 \n    33 \n    younger mom \n    38 \n    full term \n    13 \n    married \n    18 \n    8.63 \n    not low \n    male \n    nonsmoker \n    white \n  \n  \n    33 \n    28 \n    younger mom \n    41 \n    full term \n    10 \n    married \n    30 \n    8.13 \n    not low \n    male \n    nonsmoker \n    not white \n  \n  \n    32 \n    31 \n    younger mom \n    37 \n    full term \n    13 \n    married \n    30 \n    10.38 \n    not low \n    male \n    nonsmoker \n    white \n  \n  \n    38 \n    33 \n    younger mom \n    39 \n    full term \n    12 \n    married \n    25 \n    9.25 \n    not low \n    male \n    nonsmoker \n    not white \n  \n  \n    38 \n    33 \n    younger mom \n    38 \n    full term \n    14 \n    married \n    30 \n    5.88 \n    not low \n    male \n    nonsmoker \n    white \n  \n  \n    25 \n    24 \n    younger mom \n    40 \n    full term \n    15 \n    married \n    29 \n    8.50 \n    not low \n    female \n    nonsmoker \n    white \n  \n  \n    31 \n    26 \n    younger mom \n    36 \n    premie \n    18 \n    married \n    40 \n    8.00 \n    not low \n    male \n    nonsmoker \n    white \n  \n  \n    33 \n    34 \n    younger mom \n    40 \n    full term \n    13 \n    married \n    25 \n    8.25 \n    not low \n    male \n    nonsmoker \n    white \n  \n  \n    NA \n    19 \n    younger mom \n    39 \n    full term \n    9 \n    not married \n    35 \n    7.75 \n    not low \n    male \n    nonsmoker \n    not white \n  \n  \n    32 \n    27 \n    younger mom \n    43 \n    full term \n    11 \n    married \n    30 \n    6.56 \n    not low \n    female \n    nonsmoker \n    not white"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#relationships-between-variables-1",
    "href": "slides/week-9/w9-regression.html#relationships-between-variables-1",
    "title": "Linear Regression",
    "section": "Relationships Between Variables",
    "text": "Relationships Between Variables\nIn statistical models, we generally have one variable that is the response and one or more variables that are explanatory.\n\n\n\nResponse variable\n\nAlso: \\(y\\), dependent variable\nThis is the quantity we want to understand.\n\n\n\n\nExplanatory variable\n\nAlso: \\(x\\), independent variable, predictor\nThis is something we think might be related to the response."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#visualizing-a-relationship",
    "href": "slides/week-9/w9-regression.html#visualizing-a-relationship",
    "title": "Linear Regression",
    "section": "Visualizing a Relationship",
    "text": "Visualizing a Relationship\nThe scatterplot has been called the most “generally useful invention in the history of statistical graphics.”\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterizing Relationships\n\nForm: linear, quadratic, non-linear?\nDirection: positive, negative?\nStrength: how much scatter/noise?\nUnusual observations: do points not fit the overall pattern?"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#your-turn",
    "href": "slides/week-9/w9-regression.html#your-turn",
    "title": "Linear Regression",
    "section": "Your turn!",
    "text": "Your turn!\nHow would you characterize this relationship?\n\n\n\nShape?\nDirection?\nStrength?\nOutliers?\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: Much of what we are doing at this stage involves making judgment calls!\n\nAs we work through these, please keep in mind that much of what we are doing at this stage involves making judgment calls. This is part of the nature of statistics, and while it can be frustrating - especially as a beginner - it is inescapable. For better or for worse, statistics is not a field where there is one right answer. There are of course an infinite number of indefensible claims, but many judgments are open to interpretation.\nThere isn’t a universal, hard-and-fast definition of what constitutes an outlier, but they are often easy to spot in a scatterplot.\n\nWhat observations would you consider to be outliers?\nHow would you go about removing these outliers from the data?"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#fitting-a-model",
    "href": "slides/week-9/w9-regression.html#fitting-a-model",
    "title": "Linear Regression",
    "section": "Fitting a Model",
    "text": "Fitting a Model\nWe often assume the value of our response variable is some function of our explanatory variable, plus some random noise.\n\\[response = f(explanatory) + noise\\]\n\nThere is a mathematical function \\(f\\) that can translate values of one variable into values of another.\nBut there is some randomness in the process."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#simple-linear-regression-slr",
    "href": "slides/week-9/w9-regression.html#simple-linear-regression-slr",
    "title": "Linear Regression",
    "section": "Simple Linear Regression (SLR)",
    "text": "Simple Linear Regression (SLR)\nIf we assume the relationship between \\(x\\) and \\(y\\) takes the form of a linear function…\n\\[\n  response = intercept + slope \\times explanatory + noise\n\\]\n\nWe use the following notation for this model:\n\n\nPopulation Regression Model\n\\(Y = \\beta_0 + \\beta_1 X + \\varepsilon\\)\nwhere \\(\\varepsilon \\sim N(0, \\sigma)\\) is the random noise.\n\nFitted Regression Model\n\\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\\)\nwhere   \\(\\hat{}\\)   indicates the value was estimated."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#fitting-an-slr-model",
    "href": "slides/week-9/w9-regression.html#fitting-an-slr-model",
    "title": "Linear Regression",
    "section": "Fitting an SLR Model",
    "text": "Fitting an SLR Model\n\nQuestion geom_smooth  lm \n\n\nRegress baby birthweight (response variable) on the pregnant parent’s weight gain (explanatory variable).\n\nWe are assuming there is a linear relationship between how much weight the parent gains and how much the baby weighs at birth.\n\n\n\nWhen visualizing data, fit a regression line (\\(y\\) on \\(x\\)) to your scatterplot.\n\nncbirths |&gt; \n  ggplot(aes(x = gained, y = weight)) +\n  geom_jitter() + \n  geom_smooth(method = \"lm\") \n\n\n\n\n\n\n\n\n\n\nThe lm() function fits a linear regression model.\n\nWe use formula notation to specify the response variable (LHS) and the explanatory variable (RHS).\nThis code creates an lm object.\n\n\nncbirth_lm &lt;- lm(weight ~ gained, \n                 data = ncbirths)"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#model-outputs",
    "href": "slides/week-9/w9-regression.html#model-outputs",
    "title": "Linear Regression",
    "section": "Model Outputs",
    "text": "Model Outputs\n\nlm objectCoefficients broomResiduals\n\n\n\nsummary(ncbirth_lm)\n\n\nCall:\nlm(formula = weight ~ gained, data = ncbirths)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4085 -0.6950  0.1643  0.9222  4.5158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.63003    0.11120  59.620  &lt; 2e-16 ***\ngained       0.01614    0.00332   4.862 1.35e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.474 on 971 degrees of freedom\n  (27 observations deleted due to missingness)\nMultiple R-squared:  0.02377,   Adjusted R-squared:  0.02276 \nF-statistic: 23.64 on 1 and 971 DF,  p-value: 1.353e-06\n\n\n\n\n\nbroom::tidy(ncbirth_lm)\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    6.6300336 \n    0.1112054 \n    59.619718 \n    0.0e+00 \n  \n  \n    gained \n    0.0161405 \n    0.0033195 \n    4.862253 \n    1.4e-06 \n  \n\n\n\n\n\n\n\n\nIntercept: expected mean of \\(y\\), when \\(x\\) is 0.\n\nSomeone gaining 0 lb, will have a baby weighing 6.63 lbs, on average.\n\n\n\n\nSlope: expected change in the mean of \\(y\\), when \\(x\\) increases by 1 unit.\n\nFor each pound gained, the baby will weigh 0.016 lbs more, on average.\n\n\n\n\n\nThe difference between observed (point) and expected (line).\n\n\n\n\nncbirth_lm$residuals |&gt; \n  head(3)\n\n         1          2          3 \n 0.3866279  0.9271567 -0.6133721 \n\n\n\n\nresid(ncbirth_lm) |&gt; \n  head(3)\n\n         1          2          3 \n 0.3866279  0.9271567 -0.6133721 \n\n\n\n\nbroom::augment(ncbirth_lm) |&gt; \n  head(3)\n\n\n\n\n \n  \n    .rownames \n    weight \n    gained \n    .fitted \n    .resid \n    .hat \n    .sigma \n    .cooksd \n    .std.resid \n  \n \n\n  \n    1 \n    7.63 \n    38 \n    7.243372 \n    0.3866279 \n    0.0013265 \n    1.474586 \n    0.0000458 \n    0.2624942 \n  \n  \n    2 \n    7.88 \n    20 \n    6.952843 \n    0.9271567 \n    0.0015686 \n    1.474337 \n    0.0003113 \n    0.6295530 \n  \n  \n    3 \n    6.63 \n    38 \n    7.243372 \n    -0.6133721 \n    0.0013265 \n    1.474506 \n    0.0001152 \n    -0.4164381"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#model-diagnostics",
    "href": "slides/week-9/w9-regression.html#model-diagnostics",
    "title": "Linear Regression",
    "section": "Model Diagnostics",
    "text": "Model Diagnostics\nThere are four conditions that must be met for a linear regression model to be appropriate:\n\nLinear relationship.\nIndependent observations.\nNormally distributed residuals.\nEqual variance of residuals."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#model-diagnostics-1",
    "href": "slides/week-9/w9-regression.html#model-diagnostics-1",
    "title": "Linear Regression",
    "section": "Model Diagnostics",
    "text": "Model Diagnostics\n\nLinearityIndependenceNormalityEqual Variance\n\n\nIs the relationship linear?\n\n\n\nAlmost nothing will look perfectly linear.\nBe careful with relationships that have curvature.\nTry transforming your variables!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre the observations independent?   Difficult to tell!\n\n\nWhat does independence mean?\nShould not be able to know the \\(y\\) value for one observation based on the \\(y\\) value for another observation.\n\nIndependence violations:\n\nStock market prices over time.\nGeographical similarities.\nBiological conditions of family members.\nRepeated observations.\n\n\n\n\nAre the residuals normally distributed?\nLess important than linearity or independence:\n\n\n\n\n\n\n\n\n\n\n\nDo the residuals have equal (constant) variance?\n\n\n\nThe variability of points around the regression line is roughly constant.\nData with non-equal variance across the range of \\(x\\) can seriously mis-estimate the variability of the slope.\n\n\n\nncbirth_lm |&gt; \n  augment() |&gt; \n  ggplot(aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\", \n             color = \"red\", lwd = 1.5)"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#assessing-model-fit",
    "href": "slides/week-9/w9-regression.html#assessing-model-fit",
    "title": "Linear Regression",
    "section": "Assessing Model Fit",
    "text": "Assessing Model Fit\nSum of Square Errors (SSE)\n\nThis is calculated as the sum of the squared residuals.\nA small SSE means small differences between observed and fitted values.\nAlso: Sum Sq of Residuals or deviance."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#assessing-model-fit-1",
    "href": "slides/week-9/w9-regression.html#assessing-model-fit-1",
    "title": "Linear Regression",
    "section": "Assessing Model Fit",
    "text": "Assessing Model Fit\nRoot Mean Square Error (RMSE)\n\n\n\nThe standard deviation of the residuals.\nA small RMSE means small differences between observed and fitted values.\nAlso: Residual standard error or sigma.\n\n\n\nsummary(ncbirth_lm)\n\n\nCall:\nlm(formula = weight ~ gained, data = ncbirths)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4085 -0.6950  0.1643  0.9222  4.5158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.63003    0.11120  59.620  &lt; 2e-16 ***\ngained       0.01614    0.00332   4.862 1.35e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.474 on 971 degrees of freedom\n  (27 observations deleted due to missingness)\nMultiple R-squared:  0.02377,   Adjusted R-squared:  0.02276 \nF-statistic: 23.64 on 1 and 971 DF,  p-value: 1.353e-06"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#assessing-model-fit-2",
    "href": "slides/week-9/w9-regression.html#assessing-model-fit-2",
    "title": "Linear Regression",
    "section": "Assessing Model Fit",
    "text": "Assessing Model Fit\nR-squared\n\nThe proportion of variability in response accounted for by the linear model.\nA large R-squared means the explanatory variable is good at explaining the response.\nR-squared is between 0 and 1.\n\n\nbroom::glance(ncbirth_lm) |&gt; \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.0237689\n0.0227635\n1.473879\n23.6415\n1.4e-06\n1\n-1757.05\n3520.101\n3534.742\n2109.321\n971\n973"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#model-comparison",
    "href": "slides/week-9/w9-regression.html#model-comparison",
    "title": "Linear Regression",
    "section": "Model Comparison",
    "text": "Model Comparison\nRegress baby birthweight on…\n\n\n… gestation weeks.\n\nweight_weeks &lt;- lm(weight ~ weeks, \n                   data = ncbirths)\n\n\nSSE = 1246.55\nRMSE = 1.119\n\\(R^2\\) = 0.449\n\n\n… number of doctor visits.\n\nweight_visits &lt;- lm(weight ~ visits, \n                    data = ncbirths)\n\n\nSSE = 2152.74\nRMSE = 1.475\n\\(R^2\\) = 0.01819\n\n\n\nWhy does it make sense that the left model is better?"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#multiple-linear-regression",
    "href": "slides/week-9/w9-regression.html#multiple-linear-regression",
    "title": "Linear Regression",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\nWhen fitting a linear regression, you can include…\n…multiple explanatory variables.\nlm(y ~ x1 + x2 + x3 + ... + xn)\n…interaction terms.\nlm(y ~ x1 + x2 + x1:x2)\nlm(y ~ x1*x2)\n…quadratic relationships.\nlm(y ~ I(x1^2) + x1)"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#nest-and-unnest",
    "href": "slides/week-9/w9-regression.html#nest-and-unnest",
    "title": "Linear Regression",
    "section": "nest() and unnest()",
    "text": "nest() and unnest()\n\nWe can pair functions from the map() family very nicely with two tidyr functions: nest() and unnest().\nThese allow us to easily map functions onto subsets of the data."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#nest",
    "href": "slides/week-9/w9-regression.html#nest",
    "title": "Linear Regression",
    "section": "nest()",
    "text": "nest()\nNest subsets the data (as tibbles) inside a tibble.\n\nSpecify the column(s) to create subsets on.\n\n\n\n\nncbirths |&gt; \n  nest(premie_dat = -premie)\n\n# A tibble: 3 × 2\n  premie    premie_dat         \n  &lt;fct&gt;     &lt;list&gt;             \n1 full term &lt;tibble [846 × 12]&gt;\n2 premie    &lt;tibble [152 × 12]&gt;\n3 &lt;NA&gt;      &lt;tibble [2 × 12]&gt;  \n\n\n\n\nncbirths |&gt; \n  nest(ph_dat = -c(premie, habit))\n\n# A tibble: 6 × 3\n  premie    habit     ph_dat             \n  &lt;fct&gt;     &lt;fct&gt;     &lt;list&gt;             \n1 full term nonsmoker &lt;tibble [739 × 11]&gt;\n2 premie    nonsmoker &lt;tibble [133 × 11]&gt;\n3 full term smoker    &lt;tibble [107 × 11]&gt;\n4 premie    smoker    &lt;tibble [19 × 11]&gt; \n5 &lt;NA&gt;      nonsmoker &lt;tibble [1 × 11]&gt;  \n6 &lt;NA&gt;      &lt;NA&gt;      &lt;tibble [1 × 11]&gt;"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#unnest",
    "href": "slides/week-9/w9-regression.html#unnest",
    "title": "Linear Regression",
    "section": "unnest()",
    "text": "unnest()\nUn-nest the data by row binding the subsets back together.\n\nSpecify the column(s) that contains the subsets.\n\n\nncbirths |&gt; \n  nest(premie_dat = -premie) |&gt; \n  unnest(premie_dat) |&gt; \n  head()\n\n# A tibble: 6 × 13\n  premie     fage  mage mature weeks visits marital gained weight lowbirthweight\n  &lt;fct&gt;     &lt;int&gt; &lt;int&gt; &lt;fct&gt;  &lt;int&gt;  &lt;int&gt; &lt;fct&gt;    &lt;int&gt;  &lt;dbl&gt; &lt;fct&gt;         \n1 full term    NA    13 young…    39     10 not ma…     38   7.63 not low       \n2 full term    NA    14 young…    42     15 not ma…     20   7.88 not low       \n3 full term    19    15 young…    37     11 not ma…     38   6.63 not low       \n4 full term    21    15 young…    41      6 not ma…     34   8    not low       \n5 full term    NA    15 young…    39      9 not ma…     27   6.38 not low       \n6 full term    NA    15 young…    38     19 not ma…     22   5.38 low           \n# ℹ 3 more variables: gender &lt;fct&gt;, habit &lt;fct&gt;, whitemom &lt;fct&gt;"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#big-map2-example-again",
    "href": "slides/week-9/w9-regression.html#big-map2-example-again",
    "title": "Linear Regression",
    "section": "Big map2() Example (Again)",
    "text": "Big map2() Example (Again)\n\nnest()lm()predict()unnest()\n\n\n\nmtcars |&gt;\n  nest(cyl_data = -cyl)\n\n# A tibble: 3 × 2\n    cyl cyl_data          \n  &lt;dbl&gt; &lt;list&gt;            \n1     6 &lt;tibble [7 × 10]&gt; \n2     4 &lt;tibble [11 × 10]&gt;\n3     8 &lt;tibble [14 × 10]&gt;\n\n\n\n\n\nmtcars |&gt;\n  nest(cyl_data = -cyl) |&gt;\n  mutate(mod = map(cyl_data, \n                   ~ lm(mpg ~ wt, data = .x)))\n\n# A tibble: 3 × 3\n    cyl cyl_data           mod   \n  &lt;dbl&gt; &lt;list&gt;             &lt;list&gt;\n1     6 &lt;tibble [7 × 10]&gt;  &lt;lm&gt;  \n2     4 &lt;tibble [11 × 10]&gt; &lt;lm&gt;  \n3     8 &lt;tibble [14 × 10]&gt; &lt;lm&gt;  \n\n\n\n\n\nmtcars |&gt;\n  nest(cyl_data = -cyl) |&gt;\n  mutate(mod = map(cyl_data, \n                   ~ lm(mpg ~ wt, data = .x)),\n         pred_mpg = map2(.x = mod,\n                         .y = cyl_data, \n                         .f = ~ predict(object = .x, data = .y)))\n\n# A tibble: 3 × 4\n    cyl cyl_data           mod    pred_mpg  \n  &lt;dbl&gt; &lt;list&gt;             &lt;list&gt; &lt;list&gt;    \n1     6 &lt;tibble [7 × 10]&gt;  &lt;lm&gt;   &lt;dbl [7]&gt; \n2     4 &lt;tibble [11 × 10]&gt; &lt;lm&gt;   &lt;dbl [11]&gt;\n3     8 &lt;tibble [14 × 10]&gt; &lt;lm&gt;   &lt;dbl [14]&gt;\n\n\n\n\n\nmtcars |&gt;\n  nest(cyl_data = -cyl) |&gt;\n  mutate(mod = map(cyl_data, \n                   ~ lm(mpg ~ wt, data = .x)),\n         pred_mpg = map2(.x = mod,\n                         .y = cyl_data,\n                         .f = ~ predict(object = .x, data = .y))) |&gt; \n  select(-mod) |&gt; \n  unnest(cols = c(cyl_data, pred_mpg)) |&gt; \n  select(cyl, wt, mpg, pred_mpg)\n\n# A tibble: 32 × 4\n     cyl    wt   mpg pred_mpg\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1     6  2.62  21       21.1\n 2     6  2.88  21       20.4\n 3     6  3.22  21.4     19.5\n 4     6  3.46  18.1     18.8\n 5     6  3.44  19.2     18.8\n 6     6  3.44  17.8     18.8\n 7     6  2.77  19.7     20.7\n 8     4  2.32  22.8     26.5\n 9     4  3.19  24.4     21.6\n10     4  3.15  22.8     21.8\n# ℹ 22 more rows"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#pa-9.1-mystery-animal",
    "href": "slides/week-9/w9-regression.html#pa-9.1-mystery-animal",
    "title": "Linear Regression",
    "section": "PA 9.1: Mystery Animal",
    "text": "PA 9.1: Mystery Animal"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#to-do",
    "href": "slides/week-9/w9-regression.html#to-do",
    "title": "Linear Regression",
    "section": "To do…",
    "text": "To do…\n\nPA 9: Mystery Animal\n\nDue Tomorrow, Friday 5/31 at 11:59pm.\n\nPC4: Linear Regression\n\nDue Tomorrow, Friday 5/31 at 11:59pm.\n\nLab 9: Simulation Exploration\n\nDue Monday 6/2 at 11:59pm.\n\nRead Chapter 10: Model Validation + Graphics Extensions\n\nCheck-in 10 due Tuesday 6/3 before class."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#the-map2-family",
    "href": "slides/week-9/w9-regression.html#the-map2-family",
    "title": "Linear Regression",
    "section": "The map2() Family",
    "text": "The map2() Family\nThese functions allow us to iterate over two lists at the same time.\n\n\nEach function has two list arguments, denoted .x and .y, and a function argument."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#small-map2-example",
    "href": "slides/week-9/w9-regression.html#small-map2-example",
    "title": "Linear Regression",
    "section": "Small map2() Example",
    "text": "Small map2() Example\nFind the minimum.\n\na &lt;- c(1, 2, 4)\nb &lt;- c(6, 5, 3)\n\nmap2_chr(.x = a, \n         .y = b,\n         ~ str_glue(\"The minimum of {.x} and {.y} is {min(.x, .y)}.\"))\n\n[1] \"The minimum of 1 and 6 is 1.\" \"The minimum of 2 and 5 is 2.\"\n[3] \"The minimum of 4 and 3 is 3.\""
  },
  {
    "objectID": "slides/week-9/w9-regression.html#big-map2-example---regression",
    "href": "slides/week-9/w9-regression.html#big-map2-example---regression",
    "title": "Linear Regression",
    "section": "Big map2() Example - Regression",
    "text": "Big map2() Example - Regression\n\nnest()lm()predict()unnest()\n\n\n\nncbirths_clean &lt;- ncbirths |&gt; \n    filter(!if_any(.cols = c(premie, habit, weight, gained),\n                 .fns = is.na))\n\nncbirths_clean |&gt; \n  nest(ph_dat = -c(premie, habit))\n\n# A tibble: 4 × 3\n  premie    habit     ph_dat             \n  &lt;fct&gt;     &lt;fct&gt;     &lt;list&gt;             \n1 full term nonsmoker &lt;tibble [724 × 11]&gt;\n2 premie    nonsmoker &lt;tibble [126 × 11]&gt;\n3 full term smoker    &lt;tibble [103 × 11]&gt;\n4 premie    smoker    &lt;tibble [19 × 11]&gt; \n\n\n\n\n\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x)))\n\n# A tibble: 4 × 4\n  premie    habit     premie_smoke_dat    mod   \n  &lt;fct&gt;     &lt;fct&gt;     &lt;list&gt;              &lt;list&gt;\n1 full term nonsmoker &lt;tibble [724 × 11]&gt; &lt;lm&gt;  \n2 premie    nonsmoker &lt;tibble [126 × 11]&gt; &lt;lm&gt;  \n3 full term smoker    &lt;tibble [103 × 11]&gt; &lt;lm&gt;  \n4 premie    smoker    &lt;tibble [19 × 11]&gt;  &lt;lm&gt;  \n\n\n\n\n\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x)),\n         pred_weight = map2(.x = mod,\n                         .y = premie_smoke_dat, \n                         .f = ~ predict(object = .x, data = .y)))\n\n# A tibble: 4 × 5\n  premie    habit     premie_smoke_dat    mod    pred_weight\n  &lt;fct&gt;     &lt;fct&gt;     &lt;list&gt;              &lt;list&gt; &lt;list&gt;     \n1 full term nonsmoker &lt;tibble [724 × 11]&gt; &lt;lm&gt;   &lt;dbl [724]&gt;\n2 premie    nonsmoker &lt;tibble [126 × 11]&gt; &lt;lm&gt;   &lt;dbl [126]&gt;\n3 full term smoker    &lt;tibble [103 × 11]&gt; &lt;lm&gt;   &lt;dbl [103]&gt;\n4 premie    smoker    &lt;tibble [19 × 11]&gt;  &lt;lm&gt;   &lt;dbl [19]&gt; \n\n\n\n\n\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x)),\n         pred_weight = map2(.x = mod,\n                         .y = premie_smoke_dat, \n                         .f = ~ predict(object = .x, data = .y))) |&gt; \n  select(-mod) |&gt; \n  unnest(cols = c(premie_smoke_dat, pred_weight)) |&gt; \n  select(premie, habit, weight, gained, pred_weight) |&gt; \n  head()\n\n# A tibble: 6 × 5\n  premie    habit     weight gained pred_weight\n  &lt;fct&gt;     &lt;fct&gt;      &lt;dbl&gt;  &lt;int&gt;       &lt;dbl&gt;\n1 full term nonsmoker   7.63     38        7.55\n2 full term nonsmoker   7.88     20        7.43\n3 full term nonsmoker   6.63     38        7.55\n4 full term nonsmoker   8        34        7.53\n5 full term nonsmoker   6.38     27        7.48\n6 full term nonsmoker   5.38     22        7.44"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#example-cont.",
    "href": "slides/week-9/w9-regression.html#example-cont.",
    "title": "Linear Regression",
    "section": "Example Cont.",
    "text": "Example Cont.\n\nnest() + lm()Pull CoefficientsFormat Table\n\n\n\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x)),\n         coefs = map(mod,\n                      ~ broom::tidy(.x))) \n\n# A tibble: 4 × 5\n  premie    habit     premie_smoke_dat    mod    coefs           \n  &lt;fct&gt;     &lt;fct&gt;     &lt;list&gt;              &lt;list&gt; &lt;list&gt;          \n1 full term nonsmoker &lt;tibble [724 × 11]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;\n2 premie    nonsmoker &lt;tibble [126 × 11]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;\n3 full term smoker    &lt;tibble [103 × 11]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;\n4 premie    smoker    &lt;tibble [19 × 11]&gt;  &lt;lm&gt;   &lt;tibble [2 × 5]&gt;\n\n\n\n\n\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x)),\n         coefs = map(mod,\n                      ~ broom::tidy(.x))) |&gt; \n  select(premie, habit, coefs) |&gt; \n  unnest()\n\n# A tibble: 8 × 7\n  premie    habit     term        estimate std.error statistic  p.value\n  &lt;fct&gt;     &lt;fct&gt;     &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 full term nonsmoker (Intercept)  7.29      0.0965      75.5  0       \n2 full term nonsmoker gained       0.00705   0.00285      2.48 1.34e- 2\n3 premie    nonsmoker (Intercept)  4.55      0.393       11.6  1.75e-21\n4 premie    nonsmoker gained       0.0258    0.0137       1.89 6.09e- 2\n5 full term smoker    (Intercept)  6.77      0.223       30.3  1.71e-52\n6 full term smoker    gained       0.0121    0.00613      1.98 5.08e- 2\n7 premie    smoker    (Intercept)  5.75      0.880        6.54 5.04e- 6\n8 premie    smoker    gained      -0.0320    0.0293      -1.09 2.89e- 1\n\n\n\n\n\n\nCode\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x)),\n         coefs = map(mod,\n                      ~ broom::tidy(.x))) |&gt; \n  select(premie, habit, coefs) |&gt; \n  unnest() |&gt; \n  mutate(term = fct_recode(.f = term,\n                            \"Intercept\" = \"(Intercept)\",\n                            \"Mother Weight Gain (lb.)\" = \"gained\"\n                            )) |&gt; \n  select(-std.error, -statistic) |&gt; \n  mutate(p.value = case_when(p.value &lt; .0001 ~ \"&lt;.001\",\n                             TRUE ~ as.character(round(p.value, 3)))) |&gt; \n  arrange(premie, habit, term) |&gt; \n  gt() |&gt; \n  fmt_number(estimate,\n             decimals = 3) |&gt; \n  tab_row_group(\n    label = md(\"**Premature + Smoker**\"),\n    rows = premie == \"premie\" & habit == \"smoker\") |&gt; \n  tab_row_group(\n    label = md(\"**Premature + Non-Smoker**\"),\n    rows = premie == \"premie\" & habit == \"nonsmoker\") |&gt; \n  tab_row_group(\n    label = md(\"**Full Term + Smoker**\"),\n    rows = premie == \"full term\" & habit == \"smoker\") |&gt; \n  tab_row_group(\n    label = md(\"**Full Term + Non-Smoker**\"),\n    rows = premie == \"full term\" & habit == \"nonsmoker\") |&gt; \n  cols_hide(c(premie, habit)) |&gt; \n  cols_align(align = \"left\",\n             columns = term) |&gt; \n  tab_style(\n    style = cell_fill(color = \"gray85\"),\n    locations = cells_row_groups()) |&gt; \n  cols_label(\n    \"term\" = md(\"**Model & Term**\"),\n    \"estimate\" = md(\"**Est. Coef.**\"),\n    \"p.value\" = md(\"**p-value**\")\n  ) \n\n\n\n\n\n  \n    \n      Model & Term\n      Est. Coef.\n      p-value\n    \n  \n  \n    \n      Full Term + Non-Smoker\n    \n    Intercept\n7.285\n&lt;.001\n    Mother Weight Gain (lb.)\n0.007\n0.013\n    \n      Full Term + Smoker\n    \n    Intercept\n6.767\n&lt;.001\n    Mother Weight Gain (lb.)\n0.012\n0.051\n    \n      Premature + Non-Smoker\n    \n    Intercept\n4.549\n&lt;.001\n    Mother Weight Gain (lb.)\n0.026\n0.061\n    \n      Premature + Smoker\n    \n    Intercept\n5.754\n&lt;.001\n    Mother Weight Gain (lb.)\n−0.032\n0.289"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#gtsummary",
    "href": "slides/week-9/w9-regression.html#gtsummary",
    "title": "Linear Regression",
    "section": "gtsummary",
    "text": "gtsummary\n\nncbirth_lm |&gt; \n  tbl_regression(intercept = TRUE)\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI\n      p-value\n    \n  \n  \n    (Intercept)\n6.6\n6.4, 6.8\n&lt;0.001\n    gained\n0.02\n0.01, 0.02\n&lt;0.001\n  \n  \n    \n      Abbreviation: CI = Confidence Interval"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#check",
    "href": "slides/week-9/w9-regression.html#check",
    "title": "Linear Regression",
    "section": "Check",
    "text": "Check\n\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x))) |&gt; \n  pull(mod) |&gt; \n  map(.f = ~tbl_regression(.x, intercept = TRUE))\n\n[[1]]\n&lt;div id=\"agdfdbkrlr\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"&gt;\n  &lt;style&gt;#agdfdbkrlr table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#agdfdbkrlr thead, #agdfdbkrlr tbody, #agdfdbkrlr tfoot, #agdfdbkrlr tr, #agdfdbkrlr td, #agdfdbkrlr th {\n  border-style: none;\n}\n\n#agdfdbkrlr p {\n  margin: 0;\n  padding: 0;\n}\n\n#agdfdbkrlr .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#agdfdbkrlr .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#agdfdbkrlr .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#agdfdbkrlr .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#agdfdbkrlr .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#agdfdbkrlr .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#agdfdbkrlr .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#agdfdbkrlr .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#agdfdbkrlr .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#agdfdbkrlr .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#agdfdbkrlr .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#agdfdbkrlr .gt_from_md &gt; :first-child {\n  margin-top: 0;\n}\n\n#agdfdbkrlr .gt_from_md &gt; :last-child {\n  margin-bottom: 0;\n}\n\n#agdfdbkrlr .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#agdfdbkrlr .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#agdfdbkrlr .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#agdfdbkrlr .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#agdfdbkrlr .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#agdfdbkrlr .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#agdfdbkrlr .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#agdfdbkrlr .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#agdfdbkrlr .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#agdfdbkrlr .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#agdfdbkrlr .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#agdfdbkrlr .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#agdfdbkrlr .gt_left {\n  text-align: left;\n}\n\n#agdfdbkrlr .gt_center {\n  text-align: center;\n}\n\n#agdfdbkrlr .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#agdfdbkrlr .gt_font_normal {\n  font-weight: normal;\n}\n\n#agdfdbkrlr .gt_font_bold {\n  font-weight: bold;\n}\n\n#agdfdbkrlr .gt_font_italic {\n  font-style: italic;\n}\n\n#agdfdbkrlr .gt_super {\n  font-size: 65%;\n}\n\n#agdfdbkrlr .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#agdfdbkrlr .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#agdfdbkrlr .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#agdfdbkrlr .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#agdfdbkrlr .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#agdfdbkrlr .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#agdfdbkrlr .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#agdfdbkrlr .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#agdfdbkrlr div.Reactable &gt; div.rt-table &gt; div.rt-thead &gt; div.rt-tr.rt-tr-group-header &gt; div.rt-th-group:after {\n  height: 0px !important;\n}\n&lt;/style&gt;\n  &lt;table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"&gt;\n  &lt;thead&gt;\n    &lt;tr class=\"gt_col_headings\"&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"label\"&gt;&lt;span data-qmd-base64=\"KipDaGFyYWN0ZXJpc3RpYyoq\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Characteristic&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"estimate\"&gt;&lt;span data-qmd-base64=\"KipCZXRhKio=\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Beta&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.low\"&gt;&lt;span data-qmd-base64=\"Kio5NSUgQ0kqKg==\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;95% CI&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p.value\"&gt;&lt;span data-qmd-base64=\"KipwLXZhbHVlKio=\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;p-value&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody class=\"gt_table_body\"&gt;\n    &lt;tr&gt;&lt;td headers=\"label\" class=\"gt_row gt_left\"&gt;(Intercept)&lt;/td&gt;\n&lt;td headers=\"estimate\" class=\"gt_row gt_center\"&gt;7.3&lt;/td&gt;\n&lt;td headers=\"conf.low\" class=\"gt_row gt_center\"&gt;7.1, 7.5&lt;/td&gt;\n&lt;td headers=\"p.value\" class=\"gt_row gt_center\"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"label\" class=\"gt_row gt_left\"&gt;gained&lt;/td&gt;\n&lt;td headers=\"estimate\" class=\"gt_row gt_center\"&gt;0.01&lt;/td&gt;\n&lt;td headers=\"conf.low\" class=\"gt_row gt_center\"&gt;0.00, 0.01&lt;/td&gt;\n&lt;td headers=\"p.value\" class=\"gt_row gt_center\"&gt;0.013&lt;/td&gt;&lt;/tr&gt;\n  &lt;/tbody&gt;\n  &lt;tfoot class=\"gt_sourcenotes\"&gt;\n    &lt;tr&gt;\n      &lt;td class=\"gt_sourcenote\" colspan=\"4\"&gt;&lt;span data-qmd-base64=\"QWJicmV2aWF0aW9uOiBDSSA9IENvbmZpZGVuY2UgSW50ZXJ2YWw=\"&gt;&lt;span class='gt_from_md'&gt;Abbreviation: CI = Confidence Interval&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tfoot&gt;\n  \n&lt;/table&gt;\n&lt;/div&gt;\n\n[[2]]\n&lt;div id=\"akpdbapvbk\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"&gt;\n  &lt;style&gt;#akpdbapvbk table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#akpdbapvbk thead, #akpdbapvbk tbody, #akpdbapvbk tfoot, #akpdbapvbk tr, #akpdbapvbk td, #akpdbapvbk th {\n  border-style: none;\n}\n\n#akpdbapvbk p {\n  margin: 0;\n  padding: 0;\n}\n\n#akpdbapvbk .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#akpdbapvbk .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#akpdbapvbk .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#akpdbapvbk .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#akpdbapvbk .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#akpdbapvbk .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#akpdbapvbk .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#akpdbapvbk .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#akpdbapvbk .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#akpdbapvbk .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#akpdbapvbk .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#akpdbapvbk .gt_from_md &gt; :first-child {\n  margin-top: 0;\n}\n\n#akpdbapvbk .gt_from_md &gt; :last-child {\n  margin-bottom: 0;\n}\n\n#akpdbapvbk .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#akpdbapvbk .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#akpdbapvbk .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#akpdbapvbk .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#akpdbapvbk .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#akpdbapvbk .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#akpdbapvbk .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#akpdbapvbk .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#akpdbapvbk .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#akpdbapvbk .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#akpdbapvbk .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#akpdbapvbk .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#akpdbapvbk .gt_left {\n  text-align: left;\n}\n\n#akpdbapvbk .gt_center {\n  text-align: center;\n}\n\n#akpdbapvbk .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#akpdbapvbk .gt_font_normal {\n  font-weight: normal;\n}\n\n#akpdbapvbk .gt_font_bold {\n  font-weight: bold;\n}\n\n#akpdbapvbk .gt_font_italic {\n  font-style: italic;\n}\n\n#akpdbapvbk .gt_super {\n  font-size: 65%;\n}\n\n#akpdbapvbk .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#akpdbapvbk .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#akpdbapvbk .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#akpdbapvbk .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#akpdbapvbk .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#akpdbapvbk .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#akpdbapvbk .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#akpdbapvbk .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#akpdbapvbk div.Reactable &gt; div.rt-table &gt; div.rt-thead &gt; div.rt-tr.rt-tr-group-header &gt; div.rt-th-group:after {\n  height: 0px !important;\n}\n&lt;/style&gt;\n  &lt;table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"&gt;\n  &lt;thead&gt;\n    &lt;tr class=\"gt_col_headings\"&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"label\"&gt;&lt;span data-qmd-base64=\"KipDaGFyYWN0ZXJpc3RpYyoq\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Characteristic&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"estimate\"&gt;&lt;span data-qmd-base64=\"KipCZXRhKio=\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Beta&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.low\"&gt;&lt;span data-qmd-base64=\"Kio5NSUgQ0kqKg==\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;95% CI&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p.value\"&gt;&lt;span data-qmd-base64=\"KipwLXZhbHVlKio=\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;p-value&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody class=\"gt_table_body\"&gt;\n    &lt;tr&gt;&lt;td headers=\"label\" class=\"gt_row gt_left\"&gt;(Intercept)&lt;/td&gt;\n&lt;td headers=\"estimate\" class=\"gt_row gt_center\"&gt;4.5&lt;/td&gt;\n&lt;td headers=\"conf.low\" class=\"gt_row gt_center\"&gt;3.8, 5.3&lt;/td&gt;\n&lt;td headers=\"p.value\" class=\"gt_row gt_center\"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"label\" class=\"gt_row gt_left\"&gt;gained&lt;/td&gt;\n&lt;td headers=\"estimate\" class=\"gt_row gt_center\"&gt;0.03&lt;/td&gt;\n&lt;td headers=\"conf.low\" class=\"gt_row gt_center\"&gt;0.00, 0.05&lt;/td&gt;\n&lt;td headers=\"p.value\" class=\"gt_row gt_center\"&gt;0.061&lt;/td&gt;&lt;/tr&gt;\n  &lt;/tbody&gt;\n  &lt;tfoot class=\"gt_sourcenotes\"&gt;\n    &lt;tr&gt;\n      &lt;td class=\"gt_sourcenote\" colspan=\"4\"&gt;&lt;span data-qmd-base64=\"QWJicmV2aWF0aW9uOiBDSSA9IENvbmZpZGVuY2UgSW50ZXJ2YWw=\"&gt;&lt;span class='gt_from_md'&gt;Abbreviation: CI = Confidence Interval&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tfoot&gt;\n  \n&lt;/table&gt;\n&lt;/div&gt;\n\n[[3]]\n&lt;div id=\"ojbvfnomyw\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"&gt;\n  &lt;style&gt;#ojbvfnomyw table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#ojbvfnomyw thead, #ojbvfnomyw tbody, #ojbvfnomyw tfoot, #ojbvfnomyw tr, #ojbvfnomyw td, #ojbvfnomyw th {\n  border-style: none;\n}\n\n#ojbvfnomyw p {\n  margin: 0;\n  padding: 0;\n}\n\n#ojbvfnomyw .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#ojbvfnomyw .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ojbvfnomyw .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ojbvfnomyw .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ojbvfnomyw .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ojbvfnomyw .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ojbvfnomyw .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ojbvfnomyw .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ojbvfnomyw .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#ojbvfnomyw .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#ojbvfnomyw .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ojbvfnomyw .gt_from_md &gt; :first-child {\n  margin-top: 0;\n}\n\n#ojbvfnomyw .gt_from_md &gt; :last-child {\n  margin-bottom: 0;\n}\n\n#ojbvfnomyw .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ojbvfnomyw .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ojbvfnomyw .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#ojbvfnomyw .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#ojbvfnomyw .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#ojbvfnomyw .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ojbvfnomyw .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#ojbvfnomyw .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ojbvfnomyw .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ojbvfnomyw .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ojbvfnomyw .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ojbvfnomyw .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ojbvfnomyw .gt_left {\n  text-align: left;\n}\n\n#ojbvfnomyw .gt_center {\n  text-align: center;\n}\n\n#ojbvfnomyw .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ojbvfnomyw .gt_font_normal {\n  font-weight: normal;\n}\n\n#ojbvfnomyw .gt_font_bold {\n  font-weight: bold;\n}\n\n#ojbvfnomyw .gt_font_italic {\n  font-style: italic;\n}\n\n#ojbvfnomyw .gt_super {\n  font-size: 65%;\n}\n\n#ojbvfnomyw .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#ojbvfnomyw .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#ojbvfnomyw .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#ojbvfnomyw .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#ojbvfnomyw .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#ojbvfnomyw .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#ojbvfnomyw .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#ojbvfnomyw .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#ojbvfnomyw div.Reactable &gt; div.rt-table &gt; div.rt-thead &gt; div.rt-tr.rt-tr-group-header &gt; div.rt-th-group:after {\n  height: 0px !important;\n}\n&lt;/style&gt;\n  &lt;table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"&gt;\n  &lt;thead&gt;\n    &lt;tr class=\"gt_col_headings\"&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"label\"&gt;&lt;span data-qmd-base64=\"KipDaGFyYWN0ZXJpc3RpYyoq\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Characteristic&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"estimate\"&gt;&lt;span data-qmd-base64=\"KipCZXRhKio=\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Beta&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.low\"&gt;&lt;span data-qmd-base64=\"Kio5NSUgQ0kqKg==\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;95% CI&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p.value\"&gt;&lt;span data-qmd-base64=\"KipwLXZhbHVlKio=\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;p-value&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody class=\"gt_table_body\"&gt;\n    &lt;tr&gt;&lt;td headers=\"label\" class=\"gt_row gt_left\"&gt;(Intercept)&lt;/td&gt;\n&lt;td headers=\"estimate\" class=\"gt_row gt_center\"&gt;6.8&lt;/td&gt;\n&lt;td headers=\"conf.low\" class=\"gt_row gt_center\"&gt;6.3, 7.2&lt;/td&gt;\n&lt;td headers=\"p.value\" class=\"gt_row gt_center\"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"label\" class=\"gt_row gt_left\"&gt;gained&lt;/td&gt;\n&lt;td headers=\"estimate\" class=\"gt_row gt_center\"&gt;0.01&lt;/td&gt;\n&lt;td headers=\"conf.low\" class=\"gt_row gt_center\"&gt;0.00, 0.02&lt;/td&gt;\n&lt;td headers=\"p.value\" class=\"gt_row gt_center\"&gt;0.051&lt;/td&gt;&lt;/tr&gt;\n  &lt;/tbody&gt;\n  &lt;tfoot class=\"gt_sourcenotes\"&gt;\n    &lt;tr&gt;\n      &lt;td class=\"gt_sourcenote\" colspan=\"4\"&gt;&lt;span data-qmd-base64=\"QWJicmV2aWF0aW9uOiBDSSA9IENvbmZpZGVuY2UgSW50ZXJ2YWw=\"&gt;&lt;span class='gt_from_md'&gt;Abbreviation: CI = Confidence Interval&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tfoot&gt;\n  \n&lt;/table&gt;\n&lt;/div&gt;\n\n[[4]]\n&lt;div id=\"xebbzsmpry\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"&gt;\n  &lt;style&gt;#xebbzsmpry table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#xebbzsmpry thead, #xebbzsmpry tbody, #xebbzsmpry tfoot, #xebbzsmpry tr, #xebbzsmpry td, #xebbzsmpry th {\n  border-style: none;\n}\n\n#xebbzsmpry p {\n  margin: 0;\n  padding: 0;\n}\n\n#xebbzsmpry .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#xebbzsmpry .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#xebbzsmpry .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#xebbzsmpry .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#xebbzsmpry .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#xebbzsmpry .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#xebbzsmpry .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#xebbzsmpry .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#xebbzsmpry .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#xebbzsmpry .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#xebbzsmpry .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#xebbzsmpry .gt_from_md &gt; :first-child {\n  margin-top: 0;\n}\n\n#xebbzsmpry .gt_from_md &gt; :last-child {\n  margin-bottom: 0;\n}\n\n#xebbzsmpry .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#xebbzsmpry .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xebbzsmpry .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#xebbzsmpry .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#xebbzsmpry .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#xebbzsmpry .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xebbzsmpry .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#xebbzsmpry .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xebbzsmpry .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#xebbzsmpry .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xebbzsmpry .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#xebbzsmpry .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xebbzsmpry .gt_left {\n  text-align: left;\n}\n\n#xebbzsmpry .gt_center {\n  text-align: center;\n}\n\n#xebbzsmpry .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#xebbzsmpry .gt_font_normal {\n  font-weight: normal;\n}\n\n#xebbzsmpry .gt_font_bold {\n  font-weight: bold;\n}\n\n#xebbzsmpry .gt_font_italic {\n  font-style: italic;\n}\n\n#xebbzsmpry .gt_super {\n  font-size: 65%;\n}\n\n#xebbzsmpry .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#xebbzsmpry .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#xebbzsmpry .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#xebbzsmpry .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#xebbzsmpry .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#xebbzsmpry .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#xebbzsmpry .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#xebbzsmpry .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#xebbzsmpry div.Reactable &gt; div.rt-table &gt; div.rt-thead &gt; div.rt-tr.rt-tr-group-header &gt; div.rt-th-group:after {\n  height: 0px !important;\n}\n&lt;/style&gt;\n  &lt;table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"&gt;\n  &lt;thead&gt;\n    &lt;tr class=\"gt_col_headings\"&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"label\"&gt;&lt;span data-qmd-base64=\"KipDaGFyYWN0ZXJpc3RpYyoq\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Characteristic&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"estimate\"&gt;&lt;span data-qmd-base64=\"KipCZXRhKio=\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Beta&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.low\"&gt;&lt;span data-qmd-base64=\"Kio5NSUgQ0kqKg==\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;95% CI&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p.value\"&gt;&lt;span data-qmd-base64=\"KipwLXZhbHVlKio=\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;p-value&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody class=\"gt_table_body\"&gt;\n    &lt;tr&gt;&lt;td headers=\"label\" class=\"gt_row gt_left\"&gt;(Intercept)&lt;/td&gt;\n&lt;td headers=\"estimate\" class=\"gt_row gt_center\"&gt;5.8&lt;/td&gt;\n&lt;td headers=\"conf.low\" class=\"gt_row gt_center\"&gt;3.9, 7.6&lt;/td&gt;\n&lt;td headers=\"p.value\" class=\"gt_row gt_center\"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"label\" class=\"gt_row gt_left\"&gt;gained&lt;/td&gt;\n&lt;td headers=\"estimate\" class=\"gt_row gt_center\"&gt;-0.03&lt;/td&gt;\n&lt;td headers=\"conf.low\" class=\"gt_row gt_center\"&gt;-0.09, 0.03&lt;/td&gt;\n&lt;td headers=\"p.value\" class=\"gt_row gt_center\"&gt;0.3&lt;/td&gt;&lt;/tr&gt;\n  &lt;/tbody&gt;\n  &lt;tfoot class=\"gt_sourcenotes\"&gt;\n    &lt;tr&gt;\n      &lt;td class=\"gt_sourcenote\" colspan=\"4\"&gt;&lt;span data-qmd-base64=\"QWJicmV2aWF0aW9uOiBDSSA9IENvbmZpZGVuY2UgSW50ZXJ2YWw=\"&gt;&lt;span class='gt_from_md'&gt;Abbreviation: CI = Confidence Interval&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tfoot&gt;\n  \n&lt;/table&gt;\n&lt;/div&gt;"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#example-cont.---regression-coefficients",
    "href": "slides/week-9/w9-regression.html#example-cont.---regression-coefficients",
    "title": "Linear Regression",
    "section": "Example Cont. - Regression Coefficients",
    "text": "Example Cont. - Regression Coefficients\n\nnest() + lm()Pull CoefficientsFormat Table\n\n\n\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x)),\n         coefs = map(mod,\n                      ~ broom::tidy(.x))) \n\n# A tibble: 4 × 5\n  premie    habit     premie_smoke_dat    mod    coefs           \n  &lt;fct&gt;     &lt;fct&gt;     &lt;list&gt;              &lt;list&gt; &lt;list&gt;          \n1 full term nonsmoker &lt;tibble [724 × 11]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;\n2 premie    nonsmoker &lt;tibble [126 × 11]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;\n3 full term smoker    &lt;tibble [103 × 11]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;\n4 premie    smoker    &lt;tibble [19 × 11]&gt;  &lt;lm&gt;   &lt;tibble [2 × 5]&gt;\n\n\n\n\n\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x)),\n         coefs = map(mod,\n                      ~ broom::tidy(.x))) |&gt; \n  select(premie, habit, coefs) |&gt; \n  unnest(cols = coefs)\n\n# A tibble: 8 × 7\n  premie    habit     term        estimate std.error statistic  p.value\n  &lt;fct&gt;     &lt;fct&gt;     &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 full term nonsmoker (Intercept)  7.29      0.0965      75.5  0       \n2 full term nonsmoker gained       0.00705   0.00285      2.48 1.34e- 2\n3 premie    nonsmoker (Intercept)  4.55      0.393       11.6  1.75e-21\n4 premie    nonsmoker gained       0.0258    0.0137       1.89 6.09e- 2\n5 full term smoker    (Intercept)  6.77      0.223       30.3  1.71e-52\n6 full term smoker    gained       0.0121    0.00613      1.98 5.08e- 2\n7 premie    smoker    (Intercept)  5.75      0.880        6.54 5.04e- 6\n8 premie    smoker    gained      -0.0320    0.0293      -1.09 2.89e- 1\n\n\n\n\n\n\nCode\nncbirths_clean |&gt; \n  nest(premie_smoke_dat = -c(premie, habit)) |&gt; \n  mutate(mod = map(premie_smoke_dat, \n                   ~ lm(weight ~ gained, data = .x)),\n         coefs = map(mod,\n                      ~ broom::tidy(.x))) |&gt; \n  select(premie, habit, coefs) |&gt; \n  unnest(cols = coefs) |&gt; \n  mutate(term = fct_recode(.f = term,\n                            \"Intercept\" = \"(Intercept)\",\n                            \"Mother Weight Gain (lb.)\" = \"gained\"\n                            )) |&gt; \n  select(-std.error, -statistic) |&gt; \n  mutate(p.value = case_when(p.value &lt; .0001 ~ \"&lt;.001\",\n                             TRUE ~ as.character(round(p.value, 3)))) |&gt; \n  arrange(premie, habit, term) |&gt; \n  gt() |&gt; \n  fmt_number(estimate,\n             decimals = 3) |&gt; \n  tab_row_group(\n    label = md(\"**Premature + Smoker**\"),\n    rows = premie == \"premie\" & habit == \"smoker\") |&gt; \n  tab_row_group(\n    label = md(\"**Premature + Non-Smoker**\"),\n    rows = premie == \"premie\" & habit == \"nonsmoker\") |&gt; \n  tab_row_group(\n    label = md(\"**Full Term + Smoker**\"),\n    rows = premie == \"full term\" & habit == \"smoker\") |&gt; \n  tab_row_group(\n    label = md(\"**Full Term + Non-Smoker**\"),\n    rows = premie == \"full term\" & habit == \"nonsmoker\") |&gt; \n  cols_hide(c(premie, habit)) |&gt; \n  cols_align(align = \"left\",\n             columns = term) |&gt; \n  tab_style(\n    style = cell_fill(color = \"gray85\"),\n    locations = cells_row_groups()) |&gt; \n  cols_label(\n    \"term\" = md(\"**Model & Term**\"),\n    \"estimate\" = md(\"**Est. Coef.**\"),\n    \"p.value\" = md(\"**p-value**\")\n  ) \n\n\n\n\n\n  \n    \n      Model & Term\n      Est. Coef.\n      p-value\n    \n  \n  \n    \n      Full Term + Non-Smoker\n    \n    Intercept\n7.285\n&lt;.001\n    Mother Weight Gain (lb.)\n0.007\n0.013\n    \n      Full Term + Smoker\n    \n    Intercept\n6.767\n&lt;.001\n    Mother Weight Gain (lb.)\n0.012\n0.051\n    \n      Premature + Non-Smoker\n    \n    Intercept\n4.549\n&lt;.001\n    Mother Weight Gain (lb.)\n0.026\n0.061\n    \n      Premature + Smoker\n    \n    Intercept\n5.754\n&lt;.001\n    Mother Weight Gain (lb.)\n−0.032\n0.289"
  },
  {
    "objectID": "labs/lab8/lab-8-iteration.html",
    "href": "labs/lab8/lab-8-iteration.html",
    "title": "Lab 8: Searching for Efficiency",
    "section": "",
    "text": "library(tidyverse)\nDownload .qmd starter file"
  },
  {
    "objectID": "labs/lab8/lab-8-iteration.html#formatting-tables",
    "href": "labs/lab8/lab-8-iteration.html#formatting-tables",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Formatting Tables",
    "text": "Formatting Tables\nIn this lab, we will also practice making nice, report worthy, tables!\nI would recommend you think of tables no different from the visualizations you’ve been making. We want all aspects of our tables to be clear to the reader, so the comparisons we want them to make are straightforward. You should be thinking about:\n\nColumn headers\nGrouping headers\nOrder of columns\nOrder of rows\nNumber of decimals included for numeric entries\netc.\n\nTables are also a great avenue to display creativity! In fact, there is a yearly RStudio table contest, and here is a gallery of the award winning tables!\nThere are many packages for generating tables but I recommend either kable() function from the knitr package or gt() function from the gt package and their add-ons.\nFor simple tables\n\nthe kable() function from the knitr package for simple tables\nthe gt() function from the gt package\n\nFor more sophisticated tables\n\nstyling functions from the kableExtra package (e.g., kable_styling(), kable_classic())\nadd-on functions from the gt package (e.g., cols_label(), tab_header(), fmt_percent())\n\n\n\n\n\n\n\nWarning\n\n\n\nQuarto doesn’t play nice with some options for formatting HTML tables in other packages.\nTo make sure that your tables render as expected, we need to specify html-table-processing: none in the YAML header. You will notice that I already included that in this lab.\nI also recommend using the Source Editor for this lab."
  },
  {
    "objectID": "labs/lab8/lab-8-iteration.html#lab-2",
    "href": "labs/lab8/lab-8-iteration.html#lab-2",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Lab 2",
    "text": "Lab 2\nFirst up, we’re going to revisit Question 2 from Lab 2. This question asked:\n\nWhat are the data types of the variables in this dataset?\n\n1. Using map_chr(), produce a table of the data type of each variable in the surveys dataset. Specifically, the table should have two columns var_name and type with a row for each variable and be displayed using kable().\n\n\n\n\n\n\nTip\n\n\n\nYou will want to check out the enframe() function to help with this task.\n\n\n\n# Q1 code\n\n2. Format the table nicely! Think about the order of the rows to make the information easy to take in. Using either kable() and functions in the kableExtra package or gt() and functions from the gt package to make a table that includes a caption or header, and nice, bolded column names. Note that you should assign the column names when creating the table, not by renaming columns in the dataset itself because we hate variable names with spaces in them!\n\n# Q2 code"
  },
  {
    "objectID": "labs/lab8/lab-8-iteration.html#lab-3",
    "href": "labs/lab8/lab-8-iteration.html#lab-3",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Lab 3",
    "text": "Lab 3\nNow, were on to Lab 3 where we will revisit two questions.\nIn the original version of Lab 3, Question 4 asked you to:\n\nChange data types in whichever way you see fit (e.g., is the instructor ID really a numeric data type?)\n\n3. Using map_at() or map_if(), convert the course_id, weekday, academic_degree, time_of_day, and sex columns to factors. In other words, convert all character variables into factors. DO NOT PRINT OUT YOUR NEW DATA FRAME, just show the code. Hint: You will need to use bind_cols() to transform the list output back into a data frame.\n\n# Q3 code\n\nNext up, we’re going revisit Question 7 which asked:\n\nWhat are the demographics of the instructors in this study? Investigate the variables academic_degree, seniority, and sex and summarize your findings in ~3 complete sentences.\n\nMany people created multiple tables of counts for each of these demographics, but in this exercise we are going to create one table with every demographic.\n4. Recreate the (mainly unformatted) table below using one pipeline. It is okay if the rows are not in the same order in your table.\n\n\n\n\n\n\n\nNote\n\n\n\nRepeat the data cleaning steps that we did in Lab 3 before question 7 to recreate this exact table. And remember that we needed to first only keep one row per instructor.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere are two main ways (that I have thought of) to approach this efficiently:\n\nUsing the map_at() funtion. The list_rbind() function and the names_to argument in that will be helpful!\nUsing both pivot_wider() and pivot_longer().\n\nIt is easiest to start with creating a dataframe that has the variable, level, and count columns and then calculate prop, the proportion of professors that are in each group.\nFinal tip (not required) - I used the following options in kable_styling() to output this table:\n  kable_styling(full_width = F,\n                bootstrap_options = \"striped\")\n\n\n\n\n\n\n\n\nSame classification as Lab 3\n\n\n\nI’m using the sen_level classification from Lab 3\n\n\"junior\" = seniority is 4 or less (inclusive)\n\"senior\" = seniority is between 4 and 8 (inclusive)\n\"very senior\" = seniority is greater than 8.\n\n\n\n\n# Q4 code\n\n5. Now turn that into a very nice table, like one of the examples below using kable() and kableExtra or gt.\n\n\n\n\n\n\n\n\n\nExample 1\n\n\n\n\n\n\n\nExample 2\n\n\n\n\n\nYour table does not need to copy one of these exactly but it should include:\n\nSome way of clearly indicating the three variable types as row groups\nGiving nice column names\nUsing a column header that spans the count and % columns\nNicely formatting the % column\nGiving it a title or a caption\n\n\n#Q5 code"
  },
  {
    "objectID": "labs/lab8/lab-8-iteration.html#lab-5",
    "href": "labs/lab8/lab-8-iteration.html#lab-5",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Lab 5",
    "text": "Lab 5\nIn lab 5 we got to solve a mystery using a bunch of different related data sets. Remember how we got the data?\n\nThis code chunk will read in all of the tables of data for you. Don’t modify or remove this!\n\nThis was also a mystery at the time! The code chunk given loaded an .Rdata file that included all of the data frames. However, your data may not always be saved in a nice .Rdata file~ Let’s write a more general function to read in lots of datasets ourselves!\n6. Write a function whose only argument is a directory that will read in all .csv files in that directory and return a list of the data frames.\nSpecifically your function should:\n\nFind the names of all .csv files in that directory (the list.files() function will be helpful).\nUse map() to efficiently read all of the files into R and save them in a list\nRename the elements of the list with the names of each file\nReturn the list\n\nTest it on a directory that has at least two .csv files in it and show us that it works! Please do not print full datasets, just show us that the output is a list and that the names of the list are file names. Your function should be able to handle if a directory includes files that aren’t only csv’s\n\n# Q6 code\n\n\n\n\n\n\n\nNote\n\n\n\nFor example, if I have a directory data/ that has surveys.csv, teacher_evals.csv, and bCH_murder_data.Rdata in it, the function should return a list with two elements - the surveys and teacher_evals data frames. The names of the list elements should be \"surveys\" and \"teacher_evals\"."
  },
  {
    "objectID": "labs/lab8/lab-8-iteration.html#lab-7",
    "href": "labs/lab8/lab-8-iteration.html#lab-7",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Lab 7",
    "text": "Lab 7\nFor our last problem, we will revisit a question from the most recent lab. Question 1 asked you to use across() to make a table which summarized:\n\nWhat variable(s) have missing values present?\nHow many observations have missing values?\n\n7. Using map_int(), produce a nicely formatted table of the number of missing values for each variable in the fish data.\n\n#Q7 code"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html#thursday-522",
    "href": "slides/week-8/w8-simulation.html#thursday-522",
    "title": "Simulation + Nice Tables",
    "section": "Thursday, 5/22",
    "text": "Thursday, 5/22\nToday we will…\n\nDebugging Functions\nStatistical Distributions\nSimulating Data\nCommunicating Findings from Statistical Computing\n\nDescribing data\nDesigning Plots\nReport-ready tables\n\nPA 8.2: Instrument Con"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html",
    "href": "slides/week-8/w8-iteration.html",
    "title": "Iteration",
    "section": "",
    "text": "Today we will…\n\nProject Proposal + Data\nNew Material1\n\nIteration aka Performing Repeated Tasks\nVectorization\nEfficient Iteration: the map() family\n\nPA 8.1: The Twelve Days of Christmas\nLab 8: Searching for Efficiency"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#footnotes",
    "href": "slides/week-8/w8-iteration.html#footnotes",
    "title": "Iteration",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMaterial and images for today’s lecture were modified from Dr. Theobold and Hansjörg Neth’s ds4psy text↩︎"
  },
  {
    "objectID": "slides/week-7/w7-data-functions.html",
    "href": "slides/week-7/w7-data-functions.html",
    "title": "Writing Functions",
    "section": "",
    "text": "Today we will…\n\nNew Material\n\nCalling Functions on Datasets\nrlang Tidy Evaluation\nMissing Data\n\nLab 7: Functions + Fish"
  },
  {
    "objectID": "labs/lab8/lab-8-iteration.html#the-data",
    "href": "labs/lab8/lab-8-iteration.html#the-data",
    "title": "Lab 8: Searching for Efficiency",
    "section": "The Data",
    "text": "The Data\nFor this week’s lab, we will be revisiting questions from previous lab assignments, with the purpose of using functions from the map() family to iterate over certain tasks. To do this, we will need to load in the data from Lab 2, Lab 3, and Lab 7.\nEdit the code below to read in the appropriate datsets that you should have saved from the previous labs!\n\ngetwd()\n\n[1] \"/Users/czmann/Documents/teaching/stat331/stat331-calpoly-s25/labs/lab8\"\n\n# Data from Lab 2\nsurveys &lt;- read_csv(\"../lab2/surveys.csv\")\n\n# Data from Lab 3\nevals &lt;- read_csv(\"../lab3/input/teacher_evals.csv\") |&gt; \n  rename(sex = gender)\n\n# Data from Lab 7\nfish &lt;- read_csv(\"../lab7/BlackfootFish.csv\")"
  },
  {
    "objectID": "labs/lab8/lab8-iteration.html",
    "href": "labs/lab8/lab8-iteration.html",
    "title": "Lab 8: Searching for Efficiency",
    "section": "",
    "text": "library(tidyverse)\nDownload .qmd starter file"
  },
  {
    "objectID": "labs/lab8/lab8-iteration.html#the-data",
    "href": "labs/lab8/lab8-iteration.html#the-data",
    "title": "Lab 8: Searching for Efficiency",
    "section": "The Data",
    "text": "The Data\nFor this week’s lab, we will be revisiting questions from previous lab assignments, with the purpose of using functions from the map() family to iterate over certain tasks. To do this, we will need to load in the data from Lab 2, Lab 3, and Lab 7.\nEdit the code below to read in the appropriate datsets that you should have saved from the previous labs!\n\n# Data from Lab 2\nsurveys &lt;- read_csv(\"../lab2/surveys.csv\")\n\n# Data from Lab 3\nevals &lt;- read_csv(\"../lab3/input/teacher_evals.csv\") |&gt; \n  rename(sex = gender)\n\n# Data from Lab 7\nfish &lt;- read_csv(\"../lab7/BlackfootFish.csv\")"
  },
  {
    "objectID": "labs/lab8/lab8-iteration.html#formatting-tables",
    "href": "labs/lab8/lab8-iteration.html#formatting-tables",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Formatting Tables",
    "text": "Formatting Tables\nIn this lab, we will also practice making nice, report worthy, tables!\nI would recommend you think of tables no different from the visualizations you’ve been making. We want all aspects of our tables to be clear to the reader, so the comparisons we want them to make are straightforward. You should be thinking about:\n\nColumn headers\nGrouping headers\nOrder of columns\nOrder of rows\nNumber of decimals included for numeric entries\netc.\n\nTables are also a great avenue to display creativity! In fact, there is a yearly RStudio table contest, and here is a gallery of the award winning tables!\nThere are many packages for generating tables but I recommend either kable() function from the knitr package or gt() function from the gt package and their add-ons.\nFor simple tables\n\nthe kable() function from the knitr package for simple tables\nthe gt() function from the gt package\n\nFor more sophisticated tables\n\nstyling functions from the kableExtra package (e.g., kable_styling(), kable_classic())\nadd-on functions from the gt package (e.g., cols_label(), tab_header(), fmt_percent())\n\n\n\n\n\n\n\nWarning\n\n\n\nQuarto doesn’t play nice with some options for formatting HTML tables in other packages.\nTo make sure that your tables render as expected, we need to specify html-table-processing: none in the YAML header. You will notice that I already included that in this lab.\nI also recommend using the Source Editor for this lab."
  },
  {
    "objectID": "labs/lab8/lab8-iteration.html#lab-2",
    "href": "labs/lab8/lab8-iteration.html#lab-2",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Lab 2",
    "text": "Lab 2\nFirst up, we’re going to revisit Question 2 from Lab 2. This question asked:\n\nWhat are the data types of the variables in this dataset?\n\n1. Using map_chr(), produce a table of the data type of each variable in the surveys dataset. Specifically, the table should have two columns var_name and type with a row for each variable and be displayed using kable().\n\n\n\n\n\n\nTip\n\n\n\nYou will want to check out the enframe() function to help with this task.\n\n\n\n# Q1 code\n\n2. Format the table nicely! Think about the order of the rows to make the information easy to take in. Using either kable() and functions in the kableExtra package or gt() and functions from the gt package to make a table that includes a caption or header, and nice, bolded column names. Note that you should assign the column names when creating the table, not by renaming columns in the dataset itself because we hate variable names with spaces in them!\n\n# Q2 code"
  },
  {
    "objectID": "labs/lab8/lab8-iteration.html#lab-3",
    "href": "labs/lab8/lab8-iteration.html#lab-3",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Lab 3",
    "text": "Lab 3\nNow, were on to Lab 3 where we will revisit two questions.\nIn the original version of Lab 3, Question 4 asked you to:\n\nChange data types in whichever way you see fit (e.g., is the instructor ID really a numeric data type?)\n\n3. Using map_at() or map_if(), convert the course_id, weekday, academic_degree, time_of_day, and sex columns to factors. In other words, convert all character variables into factors. DO NOT PRINT OUT YOUR NEW DATA FRAME, just show the code. Hint: You will need to use bind_cols() to transform the list output back into a data frame.\n\n# Q3 code\n\nNext up, we’re going revisit Question 7 which asked:\n\nWhat are the demographics of the instructors in this study? Investigate the variables academic_degree, seniority, and sex and summarize your findings in ~3 complete sentences.\n\nMany people created multiple tables of counts for each of these demographics, but in this exercise we are going to create one table with every demographic.\n4. Recreate the (mainly unformatted) table below using one pipeline. It is okay if the rows are not in the same order in your table.\n\n\n\n\n\n\n\nNote\n\n\n\nRepeat the data cleaning steps that we did in Lab 3 before question 7 to recreate this exact table. And remember that we needed to first only keep one row per instructor.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere are two main ways (that I have thought of) to approach this efficiently:\n\nUsing the map_at() funtion. The list_rbind() function and the names_to argument in that will be helpful!\nUsing both pivot_wider() and pivot_longer().\n\nIt is easiest to start with creating a dataframe that has the variable, level, and count columns and then calculate prop, the proportion of professors that are in each group.\nFinal tip (not required) - I used the following options in kable_styling() to output this table:\n  kable_styling(full_width = F,\n                bootstrap_options = \"striped\")\n\n\n\n\n\n\n\n\nSame classification as Lab 3\n\n\n\nI’m using the sen_level classification from Lab 3\n\n\"junior\" = seniority is 4 or less (inclusive)\n\"senior\" = seniority is between 4 and 8 (inclusive)\n\"very senior\" = seniority is greater than 8.\n\n\n\n\n# Q4 code\n\n5. Now turn that into a very nice table, like one of the examples below using kable() and kableExtra or gt.\n\n\n\n\n\n\n\n\n\nExample 1\n\n\n\n\n\n\n\nExample 2\n\n\n\n\n\nYour table does not need to copy one of these exactly but it should include:\n\nSome way of clearly indicating the three variable types as row groups\nGiving nice column names\nUsing a column header that spans the count and % columns\nNicely formatting the % column\nGiving it a title or a caption\n\n\n#Q5 code"
  },
  {
    "objectID": "labs/lab8/lab8-iteration.html#lab-5",
    "href": "labs/lab8/lab8-iteration.html#lab-5",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Lab 5",
    "text": "Lab 5\nIn lab 5 we got to solve a mystery using a bunch of different related data sets. Remember how we got the data?\n\nThis code chunk will read in all of the tables of data for you. Don’t modify or remove this!\n\nThis was also a mystery at the time! The code chunk given loaded an .Rdata file that included all of the data frames. However, your data may not always be saved in a nice .Rdata file~ Let’s write a more general function to read in lots of datasets ourselves!\n6. Write a function whose only argument is a directory that will read in all .csv files in that directory and return a list of the data frames.\nSpecifically your function should:\n\nFind the names of all .csv files in that directory (the list.files() function will be helpful).\nUse map() to efficiently read all of the files into R and save them in a list\nRename the elements of the list with the names of each file\nReturn the list\n\nTest your function on a directory that has at least two .csv files in it and show us that it works! DO NOT print full datasets. Show us that the output is a list and that the names of the list are file names. Your function should be able to handle if a directory includes files that aren’t only csv’s\n\n# Q6 code\n\n\n\n\n\n\n\nNote\n\n\n\nFor example, if I have a directory data/ that has surveys.csv, teacher_evals.csv, and bCH_murder_data.Rdata in it, the function should return a list with two elements - the surveys and teacher_evals data frames. The names of the list elements should be \"surveys\" and \"teacher_evals\"."
  },
  {
    "objectID": "labs/lab8/lab8-iteration.html#lab-7",
    "href": "labs/lab8/lab8-iteration.html#lab-7",
    "title": "Lab 8: Searching for Efficiency",
    "section": "Lab 7",
    "text": "Lab 7\nFor our last problem, we will revisit a question from the most recent lab. Question 1 asked you to use across() to make a table which summarized:\n\nWhat variable(s) have missing values present?\nHow many observations have missing values?\n\n7. Using map_int(), produce a nicely formatted table of the number of missing values for each variable in the fish data.\n\n#Q7 code"
  },
  {
    "objectID": "slides/week-9/w9-regression.html",
    "href": "slides/week-9/w9-regression.html",
    "title": "Linear Regression",
    "section": "",
    "text": "Today we will…\n\nData Intro + Cleaning: Feedback\nNew Material\n\nReview of Simple Linear Regression\nAssessing Model Fit\n\nWork Time\n\nPA 9: Mystery Animal\nPC4: Linear Regression"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#thursday-may-29",
    "href": "slides/week-9/w9-regression.html#thursday-may-29",
    "title": "Linear Regression",
    "section": "Thursday, May 29",
    "text": "Thursday, May 29\nToday we will…\n\nData Intro + Cleaning: Feedback\nNew Material\n\nReview of Simple Linear Regression\nAssessing Model Fit\n\nWork Time\n\nPA 9: Mystery Animal\nPC4: Linear Regression"
  },
  {
    "objectID": "slides/week-8/w8-simulation.html",
    "href": "slides/week-8/w8-simulation.html",
    "title": "Simulation + Nice Tables",
    "section": "",
    "text": "Today we will…\n\nDebugging Functions\nStatistical Distributions\nSimulating Data\nCommunicating Findings from Statistical Computing\n\nDescribing data\nDesigning Plots\nReport-ready tables\n\nPA 8.2: Instrument Con"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#midterm-exam---what-went-well",
    "href": "slides/week-8/w8-iteration.html#midterm-exam---what-went-well",
    "title": "Iteration",
    "section": "Midterm Exam - What went well!",
    "text": "Midterm Exam - What went well!\n\nOverall, code formatting looks very nice!\nPivoting data\nData joins and cleaning on take-home\nWorking with strings (stringr)\nLot’s of interesting and well-thought out open-ended analyses"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#midterm-exam---what-we-still-are-working-on",
    "href": "slides/week-8/w8-iteration.html#midterm-exam---what-we-still-are-working-on",
    "title": "Iteration",
    "section": "Midterm Exam - What we still are working on",
    "text": "Midterm Exam - What we still are working on\n\nonly saving needed intermediate objects\nworking with logical variables\nquickly looking at variable values\nciting sources\nstatistical language"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#review-environment-junk",
    "href": "slides/week-8/w8-iteration.html#review-environment-junk",
    "title": "Iteration",
    "section": "Review: Environment Junk",
    "text": "Review: Environment Junk\n\nOnly save variables / data if you will use it again later\n\n\nNOYAY!Saving makes sense here\n\n\n\nq1 &lt;- penguins |&gt; \n  group_by(species) |&gt; \n  slice_max(bill_length_mm)\n  \nkable(q1)  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n46.0\n21.5\n194\n4200\nmale\n2007\n\n\nChinstrap\nDream\n58.0\n17.8\n181\n3700\nfemale\n2007\n\n\nGentoo\nBiscoe\n59.6\n17.0\n230\n6050\nmale\n2007\n\n\n\n\n\n\n\n\npenguins |&gt; \n  group_by(species) |&gt; \n  slice_max(bill_length_mm) |&gt; \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n46.0\n21.5\n194\n4200\nmale\n2007\n\n\nChinstrap\nDream\n58.0\n17.8\n181\n3700\nfemale\n2007\n\n\nGentoo\nBiscoe\n59.6\n17.0\n230\n6050\nmale\n2007\n\n\n\n\n\n\n\n\npenguins_long &lt;- penguins |&gt; \n  pivot_longer(cols = bill_length_mm:body_mass_g,\n               names_to = \"measure\",\n               values_to = \"value\")\n\npenguins_long |&gt; \n  slice_head(n = 3) |&gt; \n  kable()\n\n\n\n\nspecies\nisland\nsex\nyear\nmeasure\nvalue\n\n\n\n\nAdelie\nTorgersen\nmale\n2007\nbill_length_mm\n39.1\n\n\nAdelie\nTorgersen\nmale\n2007\nbill_depth_mm\n18.7\n\n\nAdelie\nTorgersen\nmale\n2007\nflipper_length_mm\n181.0"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#review-logical-variables",
    "href": "slides/week-8/w8-iteration.html#review-logical-variables",
    "title": "Iteration",
    "section": "Review: Logical Variables",
    "text": "Review: Logical Variables\n\nLogical / Boolean variables take the special values TRUE and FALSE\n\ncan be treated like a numeric vector where\n\nTRUE == 1 and FALSE == 0\n\n\n\nWhat proportion of penguins in each species have a bill length less than 45 mm?\n\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(prop_shortbeak = mean(bill_length_mm &lt; 45, na.rm = TRUE),\n            n_penguins = sum(!is.na(bill_length_mm))) |&gt; \n  kable(digits = 3)\n\n\n\n\nspecies\nprop_shortbeak\nn_penguins\n\n\n\n\nAdelie\n0.980\n151\n\n\nChinstrap\n0.088\n68\n\n\nGentoo\n0.179\n123"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#review-quickly-exploring-data",
    "href": "slides/week-8/w8-iteration.html#review-quickly-exploring-data",
    "title": "Iteration",
    "section": "Review: Quickly Exploring Data",
    "text": "Review: Quickly Exploring Data\n\nIf you want to look at all of the possible values/levels of a character/factor variable, you can use\n\n\n\ntable() (base) or\n\ntable(penguins$island)\n\n\n   Biscoe     Dream Torgersen \n      168       124        52 \n\ntable(penguins$island, penguins$species)\n\n           \n            Adelie Chinstrap Gentoo\n  Biscoe        44         0    124\n  Dream         56        68      0\n  Torgersen     52         0      0\n\n\n\ncount() (dplyr):\n\npenguins |&gt; \n  count(island)\n\n# A tibble: 3 × 2\n  island        n\n  &lt;fct&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#reminder-citing-coding-sources",
    "href": "slides/week-8/w8-iteration.html#reminder-citing-coding-sources",
    "title": "Iteration",
    "section": "Reminder: Citing Coding Sources",
    "text": "Reminder: Citing Coding Sources\n\nPart of responsible coding is giving credit to other’s work if we use it\n“Assumed knowledge:” course textbook, course slides, and course assignments / solutions.\nYou need to let me know if you use any other resources\nSee syllabus"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#review-logical-variables-1",
    "href": "slides/week-8/w8-iteration.html#review-logical-variables-1",
    "title": "Iteration",
    "section": "Review: Logical Variables",
    "text": "Review: Logical Variables\n\nUsing this logic is very useful for function / output checks!\n\n\n\nLab 5 Q0.2: Design and implement a check that you created the address_number and address_street_name columns correctly.\n\n\nperson |&gt; \n  mutate(address_check = str_c(address_number,\n                               address_street_name,\n                               sep = \" \"),\n         correct = address_check == address) |&gt; \n  pull(correct) |&gt; \n  mean()\n\n[1] 1"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#review-logical-variables-2",
    "href": "slides/week-8/w8-iteration.html#review-logical-variables-2",
    "title": "Iteration",
    "section": "Review: Logical Variables",
    "text": "Review: Logical Variables\n\nUsing this logic is very useful for function / output checks!\n\n\n\nLab 5 Q0.2: Design and implement a check that you created the address_number and address_street_name columns correctly.\n\n\nperson |&gt; \n  mutate(address_check = str_c(address_number,\n                               address_street_name,\n                               sep = \" \"),\n         correct = address_check == address) |&gt; \n  pull(correct) |&gt; \n  mean()\n\n[1] 1"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#a-note-logical-variables",
    "href": "slides/week-8/w8-iteration.html#a-note-logical-variables",
    "title": "Iteration",
    "section": "A Note: Logical Variables",
    "text": "A Note: Logical Variables\n\nWhile it works in some cases to use strings to reference the values TRUE and FALSE, it is very bad practice\n\n\nTRUE == \"TRUE\"\n\n[1] TRUE\n\nsum(c(\"TRUE\", \"FALSE\"))\n\nError in sum(c(\"TRUE\", \"FALSE\")): invalid 'type' (character) of argument\n\nsum(c(TRUE, FALSE))\n\n[1] 1"
  },
  {
    "objectID": "slides/week-8/w8-iteration.html#review-statistical-langauge",
    "href": "slides/week-8/w8-iteration.html#review-statistical-langauge",
    "title": "Iteration",
    "section": "Review: Statistical Langauge",
    "text": "Review: Statistical Langauge\nSpecific statistical vocabulary (use carefully and correctly):\n\nCorrelation: a statistic calculated between two quantitative variables\nSignificant: referring to results of statistical inference\n\n\nInstead use general vocabulary:\n\nassociation\nrelationship\nmeaningful / large\nunsubstantial / small\n“appears to be”"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#communicating-regression-model-results",
    "href": "slides/week-9/w9-regression.html#communicating-regression-model-results",
    "title": "Linear Regression",
    "section": "Communicating Regression Model Results",
    "text": "Communicating Regression Model Results\n\nYou can report the estimated linear model:\n\n\\[\\hat{y}_i = 6.6 + .016x_i\\]\nwhere \\(\\hat{y}_i\\) is the estimated birth weight in pounds and \\(x_i\\) is the weight gained during pregnancy by the birthing parent in pounds.\n\nDiscuss the slope:\n\nThink about units that are helpful for interpretation!\ne.g.: We estimate that for every 10 pounds gained during pregnancy by the birthing parent the baby will weigh around 2.5 ounces more, on average."
  },
  {
    "objectID": "slides/week-9/w9-regression.html#regression-table",
    "href": "slides/week-9/w9-regression.html#regression-table",
    "title": "Linear Regression",
    "section": "Regression Table",
    "text": "Regression Table\n\nCommonly researchers will include a table like this to report the estimated coefficients and inference:\n\n\nncbirth_lm |&gt; \n  tbl_regression(intercept = TRUE)\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI\n      p-value\n    \n  \n  \n    (Intercept)\n6.6\n6.4, 6.8\n&lt;0.001\n    gained\n0.02\n0.01, 0.02\n&lt;0.001\n  \n  \n    \n      Abbreviation: CI = Confidence Interval\n    \n  \n  \n\n\n\n\n\nThis is a nice build-it function from an extension of the gt package (gtsummary)"
  },
  {
    "objectID": "labs/lab9/lab9-simulation.html",
    "href": "labs/lab9/lab9-simulation.html",
    "title": "Lab 9: Simulation Exploration",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nDownload .qmd starter file"
  },
  {
    "objectID": "labs/lab9/lab9-simulation.html#random-babies-simulation",
    "href": "labs/lab9/lab9-simulation.html#random-babies-simulation",
    "title": "Lab 9: Simulation Exploration",
    "section": "Random Babies Simulation",
    "text": "Random Babies Simulation\nPerhaps you have seen the Random Babies applet? Suppose one night at a hospital some number of babies are born. The hospital is not very organized and looses track of which baby belongs to each parent(s), so they decide to return the babies to parents at random. Here, we are interested in the number of babies that are correctly returned to their respective parent(s).\n1. Simulate the distribution of the number of babies that are correctly returned if there were four babies born in a night at our disorganized hospital. Use 10,000 simulations. Make sure to add a line of code to make your simulation reproducible every time you run it.\n\n\n\n\n\n\nTip\n\n\n\nFirst, write a function to accomplish one simulation (i.e. one night), given a number of babies (n_babies) that were born in a hospital on a given night .\nThen use map_int() to run 10,000 simulations assuming 4 babies were born.\nKeep in mind that your function needs to output a single number (not data frame) for it to be compatible with map_int()!\n\n\n\nrandomBabies &lt;- function(n_babies){\n  ...\n}\n\n\nresults &lt;- map_int(.x = 1:10000,\n                   .f = \n                  )\n\nError in map_int(.x = 1:10000, .f = ): argument \".f\" is missing, with no default\n\n\n2. Create a table displaying the proportion of simulations where 0, 1, 2, 3, and 4 babies were given to their correct parent(s).\n\n\n\n\n\n\nTip\n\n\n\nThe output of your map_int() is a vector, but to make a nice table (and plot) you need this to be a data frame! Luckily, the enframe() function does just that–it converts a vector to a data frame.\n\n\n\n# Q2 code\n\n3. Now create a barplot showing the proportion of simulations where 0, 1, 2, 3, and 4 babies were given to their correct parent(s). Don’t forget a title and appropriate axis labels.\n\n# Q3 code"
  },
  {
    "objectID": "labs/lab9/lab9-simulation.html#simulating-coverage",
    "href": "labs/lab9/lab9-simulation.html#simulating-coverage",
    "title": "Lab 9: Simulation Exploration",
    "section": "Simulating Coverage",
    "text": "Simulating Coverage\nMany students struggle with the definition of a confidence interval when first learning the concept. The interpretation that a lot of textbooks include is somthing like “if we were to repeat the study many many times, 95% of the confidence intervals would contain the true population parameter.”\nWe are going to implement a simulation that illustrates this statistical concept using confidence intervals for the slope parameter in a linear regression model.\nLet’s break it down into a couple of steps.\nAs a reminder, the typical population model that we assume for a linear regression is:\n\\[Y = \\beta_0 + \\beta_1 X + \\varepsilon\\] Where \\(\\beta_0\\) and \\(\\beta_1\\) are the population intercept and slope parameters and and \\(\\varepsilon \\sim N(0, \\sigma^2)\\) is random noise that is normally distributed with mean 0 and variance \\(\\sigma^2\\).\nWe will design a simulation that uses this “data generating model.”\n4. Fill in the code below to generate a synthetic dataset with 100 observations. We will assume that the explanatory variable \\(X\\) is uniformly distributed from 0 to 1 and that \\(\\sigma^2\\) = 1. The synthetic data should be a dataframe with 100 rows and two columns: x and y.\n\n# define slope and intercept parameters\nintercept = 2\nslope = 1\n\n# generate x vector\n\n\n# generate noise `ep` vector\n\n\n# generate outcome from population model\ny = intercept + x*slope + ep\n\nError: object 'x' not found\n\n# create an \"observed data\" dataframe with only the x and y vectors\n\n5. Fit a simple linear regression model of the outcome y on x. Use tidy() from the broom package to extract a dataframe from the lm() output that includes the slope estimate and a 95% confidence interval for the slope estimate.\n\n# Q5 code\n\n6. Check whether the true population slope is inside of the estimated 95% confidence interval for that simulated dataset. Specifically, add a variable called cover to the dataframe of estimates you created in the last question (Q5) that is 1 if the population slope is in the interval and 0 if not.\n\n\n\n\n\n\nTip\n\n\n\nAs a reminder, we set slope = 1 in the data generation (Q4) so the true population slope is \\(\\beta_1 = 1\\).\n\n\n\n# Q6 code\n\n7. Now put this all together into a function called mycifun! Run the check provided to ensure that it works correctly\n\nThe function should have three required arguments: beta0, beta1, and n (the number of observations in the simulated data).\nThe function should complete the steps in Q4-6 given these arguments:\n\ngenerate one synthetic dataset based on the data generating model as above\nfit a linear regression model\ncheck that the population slope is contained in the estimated 95% confidence interval for the sample slope\n\nThe output of the function should be a dataframe/tibble with one row and four columns: the slope estimate, lower bound of the CI, upper bound of the CI, and whether the population slope is within the CI.\n\n\n# Q7 code\n\n\nmycifun(beta0 = 1, beta1 = 2, n = 1000)\n\nError in mycifun(beta0 = 1, beta1 = 2, n = 1000): could not find function \"mycifun\"\n\n\n8a. Now run this simulation 1,000 times using map_dfr() and the function you wrote (mycifun()). Generate data with \\(\\beta_0 = 3\\), \\(\\beta_1 = .5\\) and \\(n = 100\\). Make sure to add a line of code to make your simulation reproducible every time you run it.\n\nci_dat &lt;- map_dfr(.x = 1:1000,\n                  .f = \n                    )\n\nError in map_dfr(.x = 1:1000, .f = ): argument \".f\" is missing, with no default\n\n\n8b. What does one row in the resulting ci_dat represent?\n8c. What is your simulated coverage rate? In otherwords, for what proportion of the iterations was the population slope within the estimated 95% confidence interval? Write your answer as a sentence in Markdown using inline code!\n9. Create a visualization to illustrate the coverage rate.\nYou can create any visualization that effectively illustrates the concept. I included a plot below with my idea of an effective plot to illustrate the concept of coverage. Actually, a professor showed me a plot like this in undergrad and I have always remembered it!\n\n\n\n\n\n\nTip\n\n\n\nYou do not need to exactly copy the plot, even if you choose to do something like it. A couple of hints to get you started on making a plot like this one:\n\nCheck out geom_errorbar()\nCheck out geom_vline() for the line indicating the true population slope\nSee this slide for code from Dr. Theobold to include colors in a title rather than a legend.\nI took a random sample of 100 simulations to make it easier to look at.\n\n\n\n\n\n\nExample Plot\n\n\n\n# Q9 code"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#data-intro-cleaning-feedback",
    "href": "slides/week-9/w9-regression.html#data-intro-cleaning-feedback",
    "title": "Linear Regression",
    "section": "Data Intro + Cleaning: Feedback",
    "text": "Data Intro + Cleaning: Feedback\nGeneral:\n\nOverall these are looking good!\n\nLots of interesting topics to explore.\nNice insights and descriptions of data sources\n\nBefore the final submission, read all instructions carefully\n\nProject Details\nProject Report Writing Guide\nCitations Guide"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#data-intro-cleaning-feedback-1",
    "href": "slides/week-9/w9-regression.html#data-intro-cleaning-feedback-1",
    "title": "Linear Regression",
    "section": "Data Intro + Cleaning: Feedback",
    "text": "Data Intro + Cleaning: Feedback\nCode:\n\nAll code should be hidden – use echo: false or code-fold: true in your YAML.\nDon’t name the R functions you have used (“We used str_detect to…”.).\n\nInstead, describe what you did in plain English.\n\nDon’t use dataset or variable names in the text.\n\nSay “We removed missing values from per capita GDP.” rather than “We removed NA from per_cap_gdp.”\n\nDon’t print out the head of the data!"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#data-intro-cleaning-feedback-2",
    "href": "slides/week-9/w9-regression.html#data-intro-cleaning-feedback-2",
    "title": "Linear Regression",
    "section": "Data Intro + Cleaning: Feedback",
    "text": "Data Intro + Cleaning: Feedback\nCitations:\n\nCite your sources, including:\n\ndata sources.\ndescription of your variables that is not general knowledge.\nany other outside resources.\n\nYou should have both in-line citations and a References section at the end of your report.\n\nsee intstuctions on Canvas"
  },
  {
    "objectID": "slides/week-9/w9-regression.html#data-intro-cleaning-feedback-3",
    "href": "slides/week-9/w9-regression.html#data-intro-cleaning-feedback-3",
    "title": "Linear Regression",
    "section": "Data Intro + Cleaning: Feedback",
    "text": "Data Intro + Cleaning: Feedback\nStyle + Organization:\n\nDefine all acronyms, especially any that are related to the variables of interest.\nEverything should be in paragraph form\n\nno bullets or numbered lists unless there is a very good reason\n\nRead through your paper from top to bottom to make sure the organization makes sense.\n\nAt what point might someone get confused?"
  },
  {
    "objectID": "labs/lab7/grading.html",
    "href": "labs/lab7/grading.html",
    "title": "Lab 7: Functions + Fish",
    "section": "",
    "text": "The goal of this lab is learn more about exploring missing data and writing modular code.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(rlang)\nfish &lt;- read.csv(\"BlackfootFish.csv\")"
  },
  {
    "objectID": "labs/lab7/grading.html#the-data",
    "href": "labs/lab7/grading.html#the-data",
    "title": "Lab 7: Functions + Fish",
    "section": "The Data",
    "text": "The Data\nThis lab’s data concerns mark-recapture data on four species of trout from the Blackfoot River outside of Helena, Montana. These four species are rainbow trout (RBT), westslope cutthroat trout (WCT), bull trout, and brown trout.\nMark-recapture is a common method used by ecologists to estimate a population’s size when it is impossible to conduct a census (count every animal). This method works by tagging animals with a tracking device so that scientists can track their movement and presence."
  },
  {
    "objectID": "labs/lab7/grading.html#data-exploration",
    "href": "labs/lab7/grading.html#data-exploration",
    "title": "Lab 7: Functions + Fish",
    "section": "Data Exploration",
    "text": "Data Exploration\nThe measurements of each captured fish were taken by a biologist on a raft in the river. The lack of a laboratory setting opens the door to the possibility of measurement errors.\n1. Let’s look for missing values in the dataset. Output ONE table that answers BOTH of the following questions:\n\nHow many observations have missing values?\nWhat variable(s) have missing values present?\n\n\nfish |&gt;\n  mutate(is_missing = if_any(everything(), is.na)) |&gt;\n  summarize(\n    n_missing = sum(is_missing),\n    across(\n      trip:species,\n      ~ sum(is.na(.x))\n    )\n  )|&gt;\n  rename(\"Missing Observations\" = n_missing)|&gt;\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMissing Observations\ntrip\nmark\nlength\nweight\nyear\nsection\nspecies\n\n\n\n\n1796\n0\n0\n0\n1796\n0\n0\n0\n\n\n\n\n\n2. Create ONE thoughtful visualization that explores the frequency of missing values across the different years, sections, and trips.\n\nnagraph &lt;- fish |&gt;\n  mutate(is_missing = if_any(everything(), is.na)) |&gt;\n  select(year, section, trip, is_missing)|&gt;\n  group_by(year, section, trip)|&gt;\n  summarise(across(where(is.logical), ~ sum(. == TRUE, na.rm = TRUE)))\n\nggplot(data = nagraph, mapping = aes(x = year, y = is_missing, color = section))+\n  geom_line()+\n  facet_wrap(~ trip)+\n  labs(title = \"Missing Values Graph\", subtitle = \"Number of Missing Values by Trip\", y = \"\", color = \"Group Leader\")"
  },
  {
    "objectID": "labs/lab7/grading.html#rescaling-the-data",
    "href": "labs/lab7/grading.html#rescaling-the-data",
    "title": "Lab 7: Functions + Fish",
    "section": "Rescaling the Data",
    "text": "Rescaling the Data\nIf I wanted to rescale every quantitative variable in my dataset so that they only have values between 0 and 1, I could use this formula:\n\n\\[y_{scaled} = \\frac{y_i - min\\{y_1, y_2,..., y_n\\}}{max\\{y_1, y_2,..., y_n\\}\n- min\\{y_1, y_2,..., y_n\\}}\\]\n\nI might write the following R code to carry out the rescaling procedure for the length and weight columns of the BlackfootFish data:\n\nfish &lt;- fish |&gt; \n  mutate(length = (length - min(length, na.rm = TRUE)) / \n           (max(length, na.rm = TRUE) - min(length, na.rm = TRUE)), \n         weight = (weight - min(weight, na.rm = TRUE)) / \n           (max(weight, na.rm = TRUE) - min(length, na.rm = TRUE)))\n\nThis process of duplicating an action multiple times can make it difficult to understand the intent of the process. Additionally, it can make it very difficult to spot mistakes.\n3. What is the mistake I made in the above rescaling code?\nIn the weight rescaling calculation the minimum length was subtracted instead of the min weight.\n4. Transform the repeated process above into a rescale_01() function. Your function should…\n\n… take a single vector as input.\n… return the rescaled vector.\n\n\nrescale_01 &lt;- function(vec) {\n  stopifnot(is.numeric(vec), length(vec) &gt;= 1)\n  rescaled &lt;- (vec - min(vec, na.rm = TRUE)) / \n              (max(vec, na.rm = TRUE) - min(vec, na.rm = TRUE))\n  return(rescaled) \n  }\n\n5. Let’s incorporate some input validation into your function. Modify your previous code so that the function stops if …\n\n… the input vector is not numeric.\n… the length of the input vector is not greater than 1."
  },
  {
    "objectID": "labs/lab7/grading.html#test-your-function",
    "href": "labs/lab7/grading.html#test-your-function",
    "title": "Lab 7: Functions + Fish",
    "section": "Test Your Function",
    "text": "Test Your Function\n6. Run the code below to test your function. Verify that the maximum of your rescaled vector is 1 and the minimum is 0!\n\nx &lt;- c(1:25, NA)\n\nrescaled &lt;- rescale_01(x)\nmin(rescaled, na.rm = TRUE)\n\n[1] 0\n\nmax(rescaled, na.rm = TRUE)\n\n[1] 1\n\n\n7. The code below makes a histogram of the original values of length. Add a plot of the rescaled values of length. Output your plots side-by-side, so the reader can confirm the only aspect that has changed is the scale.\n\nSet the y-axis limits for both plots to go from 0 to 4000 to allow for direct comparison across plots.\nPay attention to binwidth! Adjust it so that the plots are comparable (they may not look exactly the same).\nLook for a Quarto code-chunk option to put the plots side-by-side.\n\nfish |&gt;  \n  ggplot(aes(x = length)) + \n  geom_histogram(binwidth = 45) +\n  labs(x = \"Original Values of Fish Length (mm)\") +\n  scale_y_continuous(limits = c(0,4000))\n# Code for Q7 plot.\nfish |&gt;\n  mutate(length = rescale_01(length))|&gt;\n  ggplot(aes(x = length)) + \n  geom_histogram(binwidth = .045) +\n  labs(x = \"Rescaled Values of Fish Length (Scale 0-1)\") +\n  scale_y_continuous(limits = c(0,4000))"
  },
  {
    "objectID": "labs/lab7/grading.html#use-variables-within-a-dataset",
    "href": "labs/lab7/grading.html#use-variables-within-a-dataset",
    "title": "Lab 7: Functions + Fish",
    "section": "Use Variables within a Dataset",
    "text": "Use Variables within a Dataset\nSuppose you would like for your rescale() function to perform operations on a variable within a dataset. Ideally, your function would take in a dataframe and a variable name as inputs and return a dataframe where the variable has been rescaled.\n8. Create a rescale_column() function that accepts two arguments: (1) a dataframe and (2) the name(s) of the variable(s) to be rescaled. The body of the function should call the original rescale_01() function you wrote previously. Your solution MUST use one of the rlang options from class.\n\nrescale_column &lt;- function(data, colnamez)\n  {\n  data &lt;- data |&gt;\n    mutate({{ colnamez }} := rescale_01({{ colnamez }}))\n  return(data)\n  \n}\n\n9. Use your rescale_column() function to rescale both the length and weight columns.\n\nfish |&gt;\n  mutate(across(length:weight, rescale_01)) |&gt;\n  head() |&gt;\n  kable()\n\n\n\n\ntrip\nmark\nlength\nweight\nyear\nsection\nspecies\n\n\n\n\n1\n0\n0.2804124\n0.0374171\n1989\nJohnsrud\nRBT\n\n\n1\n0\n0.2804124\n0.0406243\n1989\nJohnsrud\nRBT\n\n\n1\n0\n0.2773196\n0.0523840\n1989\nJohnsrud\nRBT\n\n\n1\n0\n0.3154639\n0.0587984\n1989\nJohnsrud\nRBT\n\n\n1\n0\n0.3051546\n0.0641437\n1989\nJohnsrud\nRBT\n\n\n1\n0\n0.3577320\n0.0812487\n1989\nJohnsrud\nRBT"
  },
  {
    "objectID": "labs/lab7/grading.html#condition-index",
    "href": "labs/lab7/grading.html#condition-index",
    "title": "Lab 7: Functions + Fish",
    "section": "Condition Index",
    "text": "Condition Index\nA frequently used measurement for fish health is a condition index (Wikipedia). The following equation can be used to calculate the approximate condition index of a fish:\n\\[\\text{condition index} = \\frac{weight}{length^3} \\times 100\\]\n10. When calculating the condition index, fish length must be in centimeters and fish weight must be in grams. The weight data for the Blackfoot River fish were collected in grams, but the length data were collected in millimeters. Transform the length column to the correct units.\n\nfish &lt;- fish |&gt;\n  mutate(length = length * 0.1)\n\n11. Collecting data of this sort can be very messy! Write a function that will replace unlikely length and weight measurements with NA. Your function should accept at least three inputs:\n\na vector of measurements,\nthe minimum reasonable value,\nthe maximum reasonable value.\n\n\ndemessy &lt;- function(data, column, miny, maxy) {\n  data |&gt;\n    filter({{ column }} &gt;= miny & {{ column }} &lt;= maxy)}\n\n12. After consulting the Montana Record Table for the 4 species of trout included in these data, I have conjectured that it is unlikely to have measurements for fish below 5 cm and above 80 cm in length or below 10 g and above 4,000 g in weight. Use your function to modify the length and weight columns of the fish dataset based on my cutoffs.\n\nfish &lt;- fish|&gt;\ndemessy(length, 5, 80) |&gt;\ndemessy(weight, 10, 4000) \n\nfish |&gt;\n  head() |&gt;\n  kable()\n\n\n\n\ntrip\nmark\nlength\nweight\nyear\nsection\nspecies\n\n\n\n\n1\n0\n28.8\n175\n1989\nJohnsrud\nRBT\n\n\n1\n0\n28.8\n190\n1989\nJohnsrud\nRBT\n\n\n1\n0\n28.5\n245\n1989\nJohnsrud\nRBT\n\n\n1\n0\n32.2\n275\n1989\nJohnsrud\nRBT\n\n\n1\n0\n31.2\n300\n1989\nJohnsrud\nRBT\n\n\n1\n0\n36.3\n380\n1989\nJohnsrud\nRBT\n\n\n\n\n\n13. Write a function to calculate the condition index of a fish, given inputs of weight and length. Show that it works on your modified fish dataset\n\ncondition_index &lt;- function(data, length, weight){\n  data|&gt;\n  mutate (conditionx = (({{ length }})  / ({{ weight }}) ^ 3) * 100)\n  \n}\n\n\ncondition_index(fish, length, weight) |&gt;\n  head()|&gt;\n  kable()\n\n\n\n\ntrip\nmark\nlength\nweight\nyear\nsection\nspecies\nconditionx\n\n\n\n\n1\n0\n28.8\n175\n1989\nJohnsrud\nRBT\n0.0005374\n\n\n1\n0\n28.8\n190\n1989\nJohnsrud\nRBT\n0.0004199\n\n\n1\n0\n28.5\n245\n1989\nJohnsrud\nRBT\n0.0001938\n\n\n1\n0\n32.2\n275\n1989\nJohnsrud\nRBT\n0.0001548\n\n\n1\n0\n31.2\n300\n1989\nJohnsrud\nRBT\n0.0001156\n\n\n1\n0\n36.3\n380\n1989\nJohnsrud\nRBT\n0.0000662"
  },
  {
    "objectID": "practice-activities/pa10.html",
    "href": "practice-activities/pa10.html",
    "title": "PA 10: Map it!",
    "section": "",
    "text": "Download starter .qmd template\nDownload secret_map.csv data"
  },
  {
    "objectID": "practice-activities/pa10.html#data",
    "href": "practice-activities/pa10.html#data",
    "title": "PA 10: Map it!",
    "section": "1 Data",
    "text": "1 Data\nsecret_map.csv contains a secret code for each county in the U.S. In this PA, you will figure out the code and then create a map in ggplot showing what you found.\n\n# read in and save secret_map.csv"
  },
  {
    "objectID": "practice-activities/pa10.html#simple-map-of-us-counties",
    "href": "practice-activities/pa10.html#simple-map-of-us-counties",
    "title": "PA 10: Map it!",
    "section": "2 Simple Map of US Counties",
    "text": "2 Simple Map of US Counties\nLet’s start by just creating a map of all of the counties in the continuous US.\n\nUse the map_data() function to load a dataframe of US counties with their latitudes and longitudes. Save this data as county_map.\n\n\n# code for Q1\n\n\nUsing ggplot(), generate a map of the US counties. Have the fill color for each county be white and the outline color be a dark grey. Use cartesian coordinates.\n\n\n\n\n\n\n\nTip\n\n\n\nYou will want to reference 10.3 from our “textbook” and the resources linked there to complete this task!\n\n\n\n# code for Q2-3\n\n\nIf you haven’t already, remove any axes labels and normal plot grid lines. You can remove the default grey ggplot background as well if you prefer!\nWhile cartesian coordinates are typical, they are actually somewhat visually misleading since the globe is a sphere. A recommended system for showing the US is the “Albers Equal Area Conic Projection”. Copy and paste your code from Q2-3 and change the coordinate system to this projection (or any conic projection).\n\n\n\n\n\n\n\nHint\n\n\n\nCheck out the documentation for coord_map() and the help file for map_data().\n\n\n\n# code for Q4\n\nGreat! Now you should have a nice simple map of all of the US counties. Let’s add the information from the secret_map.csv data."
  },
  {
    "objectID": "practice-activities/pa10.html#canvas-submission",
    "href": "practice-activities/pa10.html#canvas-submission",
    "title": "PA 10: Map it!",
    "section": "4 Canvas Submission:",
    "text": "4 Canvas Submission:\n\nSubmit a screenshot of your final plot. What flag is shown?"
  },
  {
    "objectID": "practice-activities/pa10.html#color-that-map",
    "href": "practice-activities/pa10.html#color-that-map",
    "title": "PA 10: Map it!",
    "section": "3 Color that Map",
    "text": "3 Color that Map\n\nFirst of all, word is just in that there are a couple of typos in the secret_code column:\n\n\nAny “g” should be replaced with “F” (case matters!)\nThe secret code should start with the hashtag character (#)\n\n\n# code for Q5\n\n\nIt turns out that the secret code gives you the colors that should be used in your final map. Save a vector called map_colors with the unique values of the secret_code column (after the cleaning in Q5).\n\n\n# code for Q6\n\n\n\n\n\n\n\nHint\n\n\n\nThere should be 3 colors.\n\n\n\nNow map it! Fill the counties as indicated in the secret map data with the appropriate color (as given by secret_code) in your US map.\n\n\n# code for Q7-8\n\n\n\n\n\n\n\nHint\n\n\n\nYou will need to join the secret_code information onto the county_map data.\nRemember the secret_code column gives both the variable to fill by in the plot and the color to use. You will want to use the map_colors vector to use the right colors.\n\n\n\nFinally, also change the outline color for counties to the appropriate color for the county based on the secret_code. Submit a screenshot of this final plot in your Canvas submission!"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#tuesday-june-3",
    "href": "slides/week-10/w10-checks.html#tuesday-june-3",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Tuesday, June 3",
    "text": "Tuesday, June 3\nToday we will…\n\nLinear Regression: Feedack\nNew Material:\n\nModel Validation\nGraphics with Geospacial Data (Maps)\n\nWork Time\n\nPA 10: Map it!\nPC5: Final Report"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#linear-regression-project-feedback",
    "href": "slides/week-10/w10-checks.html#linear-regression-project-feedback",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Linear Regression: Project Feedback",
    "text": "Linear Regression: Project Feedback\n\n\nThey are coming along very nicely!\nFinal submission should be a polished report.\n\nIntegrate writing and analysis.\n\nThink about the readability of the numbers you are presenting.\n\nDo you need 6 decimal places?\nIs scientific notation easily understood?\n\nInclude units on your plots including any transformations\nDon’t display the raw R lm() output"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#linear-regression-project-feedback-1",
    "href": "slides/week-10/w10-checks.html#linear-regression-project-feedback-1",
    "title": "Predictive Checks + Final Project",
    "section": "Linear Regression: Project Feedback",
    "text": "Linear Regression: Project Feedback\n\n\nWhen you present a plot or a table, discuss in words what it is showing and what you want the reader to take away from it.\n\nMake sure it is very clear what one point is on any plot\nDiscuss the table of variances as part of your discussion of model fit.\n\nThink about the readability of the numbers you are presenting.\n\nDo you need 6 decimal places?\nIs scientific notation easily understood?\n\nInclude units on your plots!\nDon’t display the raw R lm() output"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#pa-10-map-it",
    "href": "slides/week-10/w10-checks.html#pa-10-map-it",
    "title": "Model Validation + Geospacial Graphics",
    "section": "PA 10: Map it!",
    "text": "PA 10: Map it!\nYou are implementing CV and animated plots in your project, so we’ll take this time to practice making nice maps with ggplot!\n\n\n\nThis image has nothing to do with this PA, it used to and is to fun to remove."
  },
  {
    "objectID": "slides/week-10/w10-checks.html#to-do",
    "href": "slides/week-10/w10-checks.html#to-do",
    "title": "Model Validation + Geospacial Graphics",
    "section": "To do…",
    "text": "To do…\n\nPA 10: Map it!\n\nDue Thursday, 6/5 before class.\n\nFinal Project Report\n\nDue Friday, 6/6 at 11:59pm.\n\nCourse Evaluation\n\nCloses Friday, 6/6 at 11:59pm."
  },
  {
    "objectID": "slides/week-10/w10-checks.html#how-do-we-tell-if-a-model-is-good",
    "href": "slides/week-10/w10-checks.html#how-do-we-tell-if-a-model-is-good",
    "title": "Model Validation + Geospacial Graphics",
    "section": "How do we tell if a model is “good”?",
    "text": "How do we tell if a model is “good”?\n\nThere are lots of different metrics to measure model performance!\n\nYour choice depends on the type of model and what is “good” for the context\nDo you only care about predictions? Or more about inference?\n\n\n\nRegressionClassification (binary outcomes)\n\n\n\nSee week 9 slides\nRMSE\n\\(R^2\\)\n\n\n\n\noverall prediction success or failure rate\nsensitivity: true positive rate\nspecificity: true negative rater\nmany more…"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#section",
    "href": "slides/week-10/w10-checks.html#section",
    "title": "Model Validation + Geospacial Graphics",
    "section": "",
    "text": "Plotting geospacial data can uncover patterns that would be hard to determine through other analyses …\n\n\n\nhttps://hpcf-files.umbc.edu/research/papers/REU2015Team2.pdf"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#overfitting-underfitting",
    "href": "slides/week-10/w10-checks.html#overfitting-underfitting",
    "title": "Predictive Checks + Final Project",
    "section": "Overfitting / Underfitting",
    "text": "Overfitting / Underfitting\n\n\n\nFrom Introduction to Statistical Modeling"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#overfitting-and-underfitting",
    "href": "slides/week-10/w10-checks.html#overfitting-and-underfitting",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Overfitting and Underfitting",
    "text": "Overfitting and Underfitting\n\n\n\nFrom Introduction to Statistical Modeling"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#train-test",
    "href": "slides/week-10/w10-checks.html#train-test",
    "title": "Predictive Checks + Final Project",
    "section": "Train / Test",
    "text": "Train / Test"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#k-fold-cross-validation",
    "href": "slides/week-10/w10-checks.html#k-fold-cross-validation",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation",
    "text": "\\(k\\)-fold Cross Validation\n\n\nIterates over \\(k\\) train / test splits\nUses all of the data\nEspecially useful for model development\n\ncovariate selection\nspecifying parameters for ML models"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#k-fold-cross-validation-process",
    "href": "slides/week-10/w10-checks.html#k-fold-cross-validation-process",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process",
    "text": "\\(k\\)-fold Cross Validation Process\n\nChoose a value for \\(k\\)\nSplit data into \\(k\\) folds\nFor fold \\(i\\) from 1 … \\(k\\):\n\nFit model on observations not in fold \\(i\\)\nGenerate predictions from this model for the observations in fold \\(i\\)\nCalculate and save performance metric of interest\n\nAverage the \\(k\\) performance metrics across folds"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#k-fold-cross-validation-process-1",
    "href": "slides/week-10/w10-checks.html#k-fold-cross-validation-process-1",
    "title": "Predictive Checks + Final Project",
    "section": "\\(k\\)-fold Cross Validation Process",
    "text": "\\(k\\)-fold Cross Validation Process\n\n\n\nVisualization of 5-fold CV by Joshua Ebner"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#k-fold-cross-validation-process---details",
    "href": "slides/week-10/w10-checks.html#k-fold-cross-validation-process---details",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process - details",
    "text": "\\(k\\)-fold Cross Validation Process - details\n0.Choose a value for \\(k\\)\n\nTypical values are 5 or 10\n\n\nk &lt;- 5"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#k-fold-cross-validation-process---details-1",
    "href": "slides/week-10/w10-checks.html#k-fold-cross-validation-process---details-1",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process - details",
    "text": "\\(k\\)-fold Cross Validation Process - details\n\nSplit data into \\(k\\) folds\n\n\nShould be approximately the same size\nYou could just split the data into \\(k\\) groups based on their row number\n\n\nn &lt;- nrow(ncbirths) \n\nncbirths &lt;- ncbirths |&gt; \n  mutate(fold_cut = cut(1:n, breaks = k, labels = FALSE))\n\n\nMore typical to assign groups randomly\n\n\nncbirths &lt;- ncbirths |&gt; \n  mutate(fold_random = sample(rep_len(1:k, length.out = n),\n                       size = n))"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#k-fold-cross-validation-process---details-2",
    "href": "slides/week-10/w10-checks.html#k-fold-cross-validation-process---details-2",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process - details",
    "text": "\\(k\\)-fold Cross Validation Process - details\n\n\n\nVisualization of 5-fold CV by Joshua Ebner"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#big-question-for-model-validation",
    "href": "slides/week-10/w10-checks.html#big-question-for-model-validation",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Big Question for Model Validation",
    "text": "Big Question for Model Validation\nEven if a model is “good” according to our metric with the data we have, how do we know if it will still work well with other data?"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#k-fold-cross-validation-process---details-3",
    "href": "slides/week-10/w10-checks.html#k-fold-cross-validation-process---details-3",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process - details",
    "text": "\\(k\\)-fold Cross Validation Process - details\nWe implemented 5-fold CV for the model of birth weight on gestation weeks with the NC births data…\n\ncv_r2\n\n[1] 0.3474592 0.4493777 0.5702561 0.4499808 0.4715257\n\n\n\n\nAverage the \\(k\\) performance metrics across folds\n\n\nmean(cv_r2)\n\n[1] 0.4577199\n\n\n\n\nThe \\(R^2\\) from fitting the model on the full dataset was 0.449, so it appears the model is neither overfitting or underfitting."
  },
  {
    "objectID": "slides/week-10/w10-checks.html#arcgis-doesnt-get-to-have-all-the-fun",
    "href": "slides/week-10/w10-checks.html#arcgis-doesnt-get-to-have-all-the-fun",
    "title": "Model Validation + Geospacial Graphics",
    "section": "ArcGIS doesn’t get to have all the fun",
    "text": "ArcGIS doesn’t get to have all the fun\n\nThere are now many tools in R to plot geospacial data\nmaps / mapdata + geom_polygon()\n\npros: simplest way to map the US counties / states and world countries\ncons: doesn’t include all geospacial boundaries you might want!\n\nsf\n\npros: work with any common spacial object (like those used in ArcGIS) plus well maintained and up to date!\ncons: a bit more of a learning curve to use"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#plotting-geospacial-data-can-uncover-patterns-that-would-be-hard-to-determine-through-other-analyses",
    "href": "slides/week-10/w10-checks.html#plotting-geospacial-data-can-uncover-patterns-that-would-be-hard-to-determine-through-other-analyses",
    "title": "Predictive Checks + Final Project",
    "section": "Plotting geospacial data can uncover patterns that would be hard to determine through other analyses …",
    "text": "Plotting geospacial data can uncover patterns that would be hard to determine through other analyses …\n ## It can also help make grouping of observations in your analysis clear!\n\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC11180987/"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#section-1",
    "href": "slides/week-10/w10-checks.html#section-1",
    "title": "Model Validation + Geospacial Graphics",
    "section": "",
    "text": "… It can also help make grouping of observations in your analysis clear!\n\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC11180987/"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#graphics-with-geospacial-data-in-r",
    "href": "slides/week-10/w10-checks.html#graphics-with-geospacial-data-in-r",
    "title": "Predictive Checks + Final Project",
    "section": "Graphics with Geospacial Data in R",
    "text": "Graphics with Geospacial Data in R\n\nThere are now many tools in R to plot geospacial data\nmaps / mapdata + geom_polygon()\n\npros: simplest way to map the US counties / states and world countries\ncons: doesn’t include all geospacial boundaries you might want!\n\nsf\n\npros: work with any common spacial object (like those used in ArcGIS) plus well maintained and up to date!\ncons: a bit more of a learning curve to use"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#we-see-geospacial-graphics-all-the-time",
    "href": "slides/week-10/w10-checks.html#we-see-geospacial-graphics-all-the-time",
    "title": "Model Validation + Geospacial Graphics",
    "section": "We see geospacial graphics all the time",
    "text": "We see geospacial graphics all the time\n\n\n\nhttps://www.npr.org/sections/health-shots/2020/07/01/885263658/green-yellow-orange-or-red-this-new-tool-shows-covid-19-risk-in-your-county"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#train-test-split",
    "href": "slides/week-10/w10-checks.html#train-test-split",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Train / Test Split",
    "text": "Train / Test Split\n\n\nBig idea: Reserve part of your data for testing to get an idea of how the model would do on outside data\n\nSplit your data into a training and a testing set (typically 80%/20%)\nSet the testing set aside\nDo all the model development you want with the training data\nFit a final model with the training data\nGenerate predictions from that model with the testing data and calculate your performance metric\nCompare the testing and training metrics"
  },
  {
    "objectID": "slides/week-10/w10-checks.html#comparing-train-test-performance",
    "href": "slides/week-10/w10-checks.html#comparing-train-test-performance",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Comparing Train / Test Performance",
    "text": "Comparing Train / Test Performance\n\n\nIf the model is overfit…\n\ntest performance &lt; training performance\n\nIf the model is underfit …\n\ntest performance &gt; training performance\n\nIf the model is neither over nor underfit …\n\ntest performance \\(\\approx\\) training performance"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#tuesday-june-3",
    "href": "slides/week-10/w10-cv-maps.html#tuesday-june-3",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Tuesday, June 3",
    "text": "Tuesday, June 3\nToday we will…\n\nLinear Regression: Feedack\nNew Material:\n\nModel Validation\nGraphics with Geospacial Data (Maps)\n\nWork Time\n\nPA 10: Map it!\nPC5: Final Report"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#linear-regression-project-feedback",
    "href": "slides/week-10/w10-cv-maps.html#linear-regression-project-feedback",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Linear Regression: Project Feedback",
    "text": "Linear Regression: Project Feedback\n\n\nThey are coming along very nicely!\nFinal submission should be a polished report.\n\nIntegrate writing and analysis.\n\nThink about the readability of the numbers you are presenting.\n\nDo you need 6 decimal places?\nIs scientific notation easily understood?\n\nInclude units on your plots including any transformations\nDon’t display the raw R lm() output"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#how-do-we-tell-if-a-model-is-good",
    "href": "slides/week-10/w10-cv-maps.html#how-do-we-tell-if-a-model-is-good",
    "title": "Model Validation + Geospacial Graphics",
    "section": "How do we tell if a model is “good”?",
    "text": "How do we tell if a model is “good”?\n\nThere are lots of different metrics to measure model performance!\n\nYour choice depends on the type of model and what is “good” for the context\nDo you only care about predictions? Or more about inference?\n\n\n\nRegressionClassification (binary outcomes)\n\n\n\nSee week 9 slides\nRMSE\n\\(R^2\\)\n\n\n\n\noverall prediction success or failure rate\nsensitivity: true positive rate\nspecificity: true negative rater\nmany more…"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#overfitting-and-underfitting",
    "href": "slides/week-10/w10-cv-maps.html#overfitting-and-underfitting",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Overfitting and Underfitting",
    "text": "Overfitting and Underfitting\n\n\n\nFrom Introduction to Statistical Modeling"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#big-question-for-model-validation",
    "href": "slides/week-10/w10-cv-maps.html#big-question-for-model-validation",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Big Question for Model Validation",
    "text": "Big Question for Model Validation\nEven if a model is “good” according to our metric with the data we have, how do we know if it will still work well with other data?"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#train-test-split",
    "href": "slides/week-10/w10-cv-maps.html#train-test-split",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Train / Test Split",
    "text": "Train / Test Split\n\n\nBig idea: Reserve part of your data for testing to get an idea of how the model would do on outside data\n\nSplit your data into a training and a testing set (typically 80%/20%)\nSet the testing set aside\nDo all the model development you want with the training data\nFit a final model with the training data\nGenerate predictions from that model with the testing data and calculate your performance metric\nCompare the testing and training metrics"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#comparing-train-test-performance",
    "href": "slides/week-10/w10-cv-maps.html#comparing-train-test-performance",
    "title": "Model Validation + Geospacial Graphics",
    "section": "Comparing Train / Test Performance",
    "text": "Comparing Train / Test Performance\n\n\nIf the model is overfit…\n\ntest performance &lt; training performance\n\nIf the model is underfit …\n\ntest performance &gt; training performance\n\nIf the model is neither over nor underfit …\n\ntest performance \\(\\approx\\) training performance"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation",
    "href": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation",
    "text": "\\(k\\)-fold Cross Validation\n\n\nIterates over \\(k\\) train / test splits\nUses all of the data\nEspecially useful for model development\n\ncovariate selection\nspecifying parameters for ML models"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process",
    "href": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process",
    "text": "\\(k\\)-fold Cross Validation Process\n\nChoose a value for \\(k\\)\nSplit data into \\(k\\) folds\nFor fold \\(i\\) from 1 … \\(k\\):\n\nFit model on observations not in fold \\(i\\)\nGenerate predictions from this model for the observations in fold \\(i\\)\nCalculate and save performance metric of interest\n\nAverage the \\(k\\) performance metrics across folds"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process---details",
    "href": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process---details",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process - details",
    "text": "\\(k\\)-fold Cross Validation Process - details\n0.Choose a value for \\(k\\)\n\nTypical values are 5 or 10\n\n\nk &lt;- 5"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process---details-1",
    "href": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process---details-1",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process - details",
    "text": "\\(k\\)-fold Cross Validation Process - details\n\nSplit data into \\(k\\) folds\n\n\nShould be approximately the same size\nYou could just split the data into \\(k\\) groups based on their row number\n\n\nn &lt;- nrow(ncbirths) \n\nncbirths &lt;- ncbirths |&gt; \n  mutate(fold_cut = cut(1:n, breaks = k, labels = FALSE))\n\n\nMore typical to assign groups randomly\n\n\nncbirths &lt;- ncbirths |&gt; \n  mutate(fold_random = sample(rep_len(1:k, length.out = n),\n                       size = n))"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process---details-2",
    "href": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process---details-2",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process - details",
    "text": "\\(k\\)-fold Cross Validation Process - details\n\n\n\nVisualization of 5-fold CV by Joshua Ebner"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process---details-3",
    "href": "slides/week-10/w10-cv-maps.html#k-fold-cross-validation-process---details-3",
    "title": "Model Validation + Geospacial Graphics",
    "section": "\\(k\\)-fold Cross Validation Process - details",
    "text": "\\(k\\)-fold Cross Validation Process - details\nWe implemented 5-fold CV for the model of birth weight on gestation weeks with the NC births data…\n\ncv_r2\n\n[1] 0.4677269 0.5130754 0.4223354 0.4381092 0.3779959\n\n\n\n\nAverage the \\(k\\) performance metrics across folds\n\n\nmean(cv_r2)\n\n[1] 0.4438486\n\n\n\n\nThe \\(R^2\\) from fitting the model on the full dataset was 0.449, so it appears the model is neither overfitting or underfitting."
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#we-see-geospacial-graphics-all-the-time",
    "href": "slides/week-10/w10-cv-maps.html#we-see-geospacial-graphics-all-the-time",
    "title": "Model Validation + Geospacial Graphics",
    "section": "We see geospacial graphics all the time",
    "text": "We see geospacial graphics all the time\n\n\n\nhttps://www.npr.org/sections/health-shots/2020/07/01/885263658/green-yellow-orange-or-red-this-new-tool-shows-covid-19-risk-in-your-county"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#section",
    "href": "slides/week-10/w10-cv-maps.html#section",
    "title": "Model Validation + Geospacial Graphics",
    "section": "",
    "text": "Plotting geospacial data can uncover patterns that would be hard to determine through other analyses …\n\n\n\nhttps://hpcf-files.umbc.edu/research/papers/REU2015Team2.pdf"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#section-1",
    "href": "slides/week-10/w10-cv-maps.html#section-1",
    "title": "Model Validation + Geospacial Graphics",
    "section": "",
    "text": "… It can also help make grouping of observations in your analysis clear!\n\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC11180987/"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#arcgis-doesnt-get-to-have-all-the-fun",
    "href": "slides/week-10/w10-cv-maps.html#arcgis-doesnt-get-to-have-all-the-fun",
    "title": "Model Validation + Geospacial Graphics",
    "section": "ArcGIS doesn’t get to have all the fun",
    "text": "ArcGIS doesn’t get to have all the fun\n\nThere are now many tools in R to plot geospacial data\nmaps / mapdata + geom_polygon()\n\npros: simplest way to map the US counties / states and world countries\ncons: doesn’t include all geospacial boundaries you might want!\n\nsf\n\npros: work with any common spacial object (like those used in ArcGIS) plus well maintained and up to date!\ncons: a bit more of a learning curve to use"
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#pa-10-map-it",
    "href": "slides/week-10/w10-cv-maps.html#pa-10-map-it",
    "title": "Model Validation + Geospacial Graphics",
    "section": "PA 10: Map it!",
    "text": "PA 10: Map it!\nYou are implementing CV and animated plots in your project, so we’ll take this time to practice making nice maps with ggplot!\n\n\n\nThis image has nothing to do with this PA, it used to and is to fun to remove."
  },
  {
    "objectID": "slides/week-10/w10-cv-maps.html#to-do",
    "href": "slides/week-10/w10-cv-maps.html#to-do",
    "title": "Model Validation + Geospacial Graphics",
    "section": "To do…",
    "text": "To do…\n\nPA 10: Map it!\n\nDue Thursday, 6/5 before class.\n\nFinal Project Report\n\nDue Friday, 6/6 at 11:59pm.\n\nCourse Evaluation\n\nCloses Friday, 6/6 at 11:59pm."
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#wednesday-march-12",
    "href": "slides/week-10/w10-wrapup.html#wednesday-march-12",
    "title": "Course Review and Wrap-Up",
    "section": "Wednesday, March 12",
    "text": "Wednesday, March 12\nToday we will…\n\nCourse Review\nFinal Exam: What to Expect\nRemaining Q & A\nWork Time\n\nFinal Project\nFinal Exam Practice"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#tools-for-the-data-science-workflow",
    "href": "slides/week-10/w10-wrapup.html#tools-for-the-data-science-workflow",
    "title": "Course Review and Wrap-Up",
    "section": "Tools for the Data Science Workflow",
    "text": "Tools for the Data Science Workflow"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#guiding-principles-for-statistical-computing",
    "href": "slides/week-10/w10-wrapup.html#guiding-principles-for-statistical-computing",
    "title": "Course Review and Wrap-Up",
    "section": "Guiding Principles for Statistical Computing",
    "text": "Guiding Principles for Statistical Computing\n\nReproducibility\nEfficiency\nReadability\nCommunication\nEthics"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#reproducibility",
    "href": "slides/week-10/w10-wrapup.html#reproducibility",
    "title": "Course Review and Wrap-Up",
    "section": "Reproducibility",
    "text": "Reproducibility\nYou can to send your code to someone else, and they can jump in and start working right away.\nThis means:\n\n\nFiles are organized and well-named.\nReferences to data and code work for everyone.\nPackage dependency is clear.\nCode will run every time, even if data values change.\nAnalysis process is well-explained and easy to read."
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#tools-for-reproducibility",
    "href": "slides/week-10/w10-wrapup.html#tools-for-reproducibility",
    "title": "Course Review and Wrap-Up",
    "section": "Tools for Reproducibility",
    "text": "Tools for Reproducibility\n\nQuarto Notebooks\nRelative file paths\nset.seed() for simulations / random sampling\nCreating report-ready tables and plots using R code\nGeneralizing code as much as possible\n\ne.g. not “hard-coding” column or row indices\ne.g. regular expressions\n\nGit & GitHub"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#efficiency",
    "href": "slides/week-10/w10-wrapup.html#efficiency",
    "title": "Course Review and Wrap-Up",
    "section": "Efficiency",
    "text": "Efficiency\nWe mean a number of things by efficiency including:\n\nUsing as few steps / lines of code as possible\nNot unnecessarily saving variables or objects\nComputational efficiency"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#tools-for-efficiency",
    "href": "slides/week-10/w10-wrapup.html#tools-for-efficiency",
    "title": "Course Review and Wrap-Up",
    "section": "Tools for Efficiency",
    "text": "Tools for Efficiency\n\nPiping and pipelines |&gt;\nRecognizing when long vs. wide format will be better for a task (pivot)\nacross() and if_any()\nNO FOR-LOOPS\n\ntaking advantage of vectorization\nfunctional programming with purrr\n\nuser-written functions"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#efficiency-in-practice",
    "href": "slides/week-10/w10-wrapup.html#efficiency-in-practice",
    "title": "Course Review and Wrap-Up",
    "section": "Efficiency in Practice",
    "text": "Efficiency in Practice\n\nProgrammers will always be searching for efficiency!\nApproach a problem the way that makes the most sense for you first, then consider if you can make your approach or code more efficient.\n\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#readability",
    "href": "slides/week-10/w10-wrapup.html#readability",
    "title": "Course Review and Wrap-Up",
    "section": "Readability",
    "text": "Readability\n\nHopefully your code can read line a sentence!\nOther’s and your future self will thank you\nWith big projects you will be writing 1,000’s of lines of code – messy code gets exponentially more difficult to read"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#tools-for-readability",
    "href": "slides/week-10/w10-wrapup.html#tools-for-readability",
    "title": "Course Review and Wrap-Up",
    "section": "Tools for Readability",
    "text": "Tools for Readability\n\nPiping and pipelines |&gt;\nCoding style (spacing, new lines, etc.)\nUsing tidyverse packages / functions\nQuarto notebooks\n\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#communication",
    "href": "slides/week-10/w10-wrapup.html#communication",
    "title": "Course Review and Wrap-Up",
    "section": "Communication",
    "text": "Communication\n\nCommunication may come in many forms:\n\nemailing your boss / colleague about an analysis\npresenting to clients\nwriting a memo for your company\nwriting a news article\nwriting an academic paper\ncreating an infographic instagram post\ncreating documentation on GitHub\netc…."
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#communication-1",
    "href": "slides/week-10/w10-wrapup.html#communication-1",
    "title": "Course Review and Wrap-Up",
    "section": "Communication",
    "text": "Communication\n\n\nHow well you code doesn’t really matter unless you can effectively communicate what you did and found!\nI CANNOT STRESS THIS ENOUGH\n\n\n\n\n\nAllison Horst"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#tools-for-communication",
    "href": "slides/week-10/w10-wrapup.html#tools-for-communication",
    "title": "Course Review and Wrap-Up",
    "section": "Tools for Communication",
    "text": "Tools for Communication\n\nQuarto notebooks\nThoughtful plots and tables (ggplot and kable/gt)\nGitHub\nI yelled at you about this a bunch\nPay attention to how others communicate statistical findings"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#ethics",
    "href": "slides/week-10/w10-wrapup.html#ethics",
    "title": "Course Review and Wrap-Up",
    "section": "Ethics",
    "text": "Ethics\n\nData has context\nHow are variables defined?\nWhere / who does the data come from?\nWhat is the potential impact of your analysis?\nWhat does a plot emphasize or potentially cover-up?"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#my-two-cents",
    "href": "slides/week-10/w10-wrapup.html#my-two-cents",
    "title": "Course Review and Wrap-Up",
    "section": "My two-cents",
    "text": "My two-cents\n\n\nBe curious about your data\nTake a beat when you run into coding errors\nOrganize your &$!#% files\nFind people whose work you admire and integrate what they do into your workflow\nTake pride in your work!\n\n\n\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#course-feedback-discussion",
    "href": "slides/week-10/w10-wrapup.html#course-feedback-discussion",
    "title": "Course Review and Wrap-Up",
    "section": "Course Feedback Discussion",
    "text": "Course Feedback Discussion\nIn groups of 4 discuss…\n\nWhich activities did you find most interesting?\nWhat was the most challenging part of the course?\nIs there anything you wish you learned that we didn’t cover?\nWhat helped you when you felt stuck on a problem and/or were debugging code?\nWhat are 1 or 2 of your biggest take-aways from the course?"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#take-advanced-r",
    "href": "slides/week-10/w10-wrapup.html#take-advanced-r",
    "title": "Course Review and Wrap-Up",
    "section": "Take Advanced R!",
    "text": "Take Advanced R!\n\nSTAT 431\nTopics can include:\n\nmore advanced visualization\nwebsites & graphical user interfaces\ndata from API’s\nwebscraping\nwriting packages\nmore advanced statistical algorithms"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#final-exam-what-to-expect",
    "href": "slides/week-10/w10-wrapup.html#final-exam-what-to-expect",
    "title": "Course Review and Wrap-Up",
    "section": "Final Exam: What to Expect",
    "text": "Final Exam: What to Expect\n\nThe exam is worth a total of 100 points and has 2 parts: General Questions, and Short Answer\nYou will have 2 hours and 50 minutes for the entire exam.\nYou will complete Part 1: General Questions first.\n\nThis part is closed note and closed computer.\n\nPart 2: Short Answer.\n\nA .qmd starter file will be opened at the start of each final.\nAny non-human online resources other than ChatGPT allowed\nI will pass out paper copies of the questions."
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#final-exam-what-to-expect-1",
    "href": "slides/week-10/w10-wrapup.html#final-exam-what-to-expect-1",
    "title": "Course Review and Wrap-Up",
    "section": "Final Exam: What to Expect",
    "text": "Final Exam: What to Expect\nThe exam is cumulative so you can expect:\n\nData manipulations with dplyr and tidyr.\nData visualizations with ggplot.\nWorking with special variable types: strings, factors, and/or dates."
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#final-exam-what-to-expect-2",
    "href": "slides/week-10/w10-wrapup.html#final-exam-what-to-expect-2",
    "title": "Course Review and Wrap-Up",
    "section": "Final Exam: What to Expect",
    "text": "Final Exam: What to Expect\nThere is an emphasis on the material since the midterm:\n\nFunction writing.\nFunctional programming with map.\nStatistical modeling with lm.\nSimulation\n\nStatistical distributions (rnorm, dunif, etc.)\nSampling from a finite population (sample and slice_sample)\n\nNicely formatted tables"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#final-exam-what-to-expect-3",
    "href": "slides/week-10/w10-wrapup.html#final-exam-what-to-expect-3",
    "title": "Course Review and Wrap-Up",
    "section": "Final Exam: What to Expect",
    "text": "Final Exam: What to Expect\n\nDuring university scheduled times in our classroom:\n\nSection 70: Tuesday 10:10-1\nSection 71: Thursday 10:10-1\n\nCheck that your short answer assignment on Canvas is for the right time!\nPlan for taking the full ~3 hours\n\nbring food, water, drinks 🧋🧉 ☕️, etc.\nbring a computer charger"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#office-hours",
    "href": "slides/week-10/w10-wrapup.html#office-hours",
    "title": "Course Review and Wrap-Up",
    "section": "Office Hours",
    "text": "Office Hours\n\nFriday (tomorrow) 1 - 2:30pm\nMonday (6/9) 12 - 2pm\nAll in-person (25-201)\nAvailable to meet by appointment (schedule via email)"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#to-do",
    "href": "slides/week-10/w10-wrapup.html#to-do",
    "title": "Course Review and Wrap-Up",
    "section": "To do…",
    "text": "To do…\n\nCourse Evaluation\n\nCloses Friday, 6/6 at 11:59pm.\n\nFinal Project Report\n\nDue Friday, 6/6 at 11:59pm.\nMay use up to 4 deadline extensions on project\n\nFinal Exam\n\nUniversity scheduled time for section\nAlternative times as scheduled and confirmed."
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html#thursday-june-5",
    "href": "slides/week-10/w10-wrapup.html#thursday-june-5",
    "title": "Course Review and Wrap-Up",
    "section": "Thursday, June 5",
    "text": "Thursday, June 5\nToday we will…\n\nCourse Review\nFinal Exam: What to Expect\nRemaining Q & A\nWork Time\n\nFinal Project\nFinal Exam Practice"
  },
  {
    "objectID": "slides/week-10/w10-wrapup.html",
    "href": "slides/week-10/w10-wrapup.html",
    "title": "Course Review and Wrap-Up",
    "section": "",
    "text": "Today we will…\n\nCourse Review\nFinal Exam: What to Expect\nRemaining Q & A\nWork Time\n\nFinal Project\nFinal Exam Practice"
  }
]