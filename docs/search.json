[
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#thursday-april-17",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#thursday-april-17",
    "title": "Data Cleaning & Manipulation",
    "section": "Thursday, April 17",
    "text": "Thursday, April 17\nToday we will…\n\nNew Material\n\nExtend dplyr verbs to have more functionality.\nDiscuss data ethics.\n\nLab 3: Teacher Evaluations"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#reminder-example-data-cereal",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#reminder-example-data-cereal",
    "title": "Data Cleaning & Manipulation",
    "section": "Reminder: Example Data Cereal",
    "text": "Reminder: Example Data Cereal\n\nlibrary(liver)\ndata(cereal)\nhead(cereal, n = 5)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10\n5\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2\n8\n8\n135\n0\n3\n1\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9\n7\n5\n320\n25\n3\n1\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14\n8\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1\n14\n8\n-1\n25\n3\n1\n0.75\n34.38484"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#more-dplyr",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#more-dplyr",
    "title": "Data Cleaning & Manipulation",
    "section": "More dplyr",
    "text": "More dplyr\n\nWe have already covered a lot, but not everything you might want…\nToday we will cover functions that help with the following tasks:\n\nextract a variable as a vector\nsimple frequency table of a categorical variable\ncreating a categorical variable from levels of a quantitatie variable\napplying slice to groups and multiple variables\nmutating or summarizing many variables at once"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#pull",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#pull",
    "title": "Data Cleaning & Manipulation",
    "section": "pull()",
    "text": "pull()\nWhat is the mean potassium for cold cereals?\n\nYou can’t use the $ operator in a pipeline\npull() to the rescue!\npull() extracts a data frame column as a vector\n\n\n\ncereal |&gt; \n  filter(type == \"cold\") |&gt; \n  pull(potass) |&gt; \n  mean(na.rm = T)\n\n[1] 97.21622"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#reminder-count-with-summarize",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#reminder-count-with-summarize",
    "title": "Data Cleaning & Manipulation",
    "section": "Reminder: count with summarize()",
    "text": "Reminder: count with summarize()\nHow many cereals does each manuf have in this dataset?\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  summarize(n = n())\n\n\n\n\n\n\n\nmanuf\nn\n\n\n\n\nA\n1\n\n\nG\n22\n\n\nK\n23\n\n\nN\n6\n\n\nP\n9\n\n\nQ\n8\n\n\nR\n8"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#count-with-count",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#count-with-count",
    "title": "Data Cleaning & Manipulation",
    "section": "Count with count()",
    "text": "Count with count()\nHow many cereals does each manuf have in this dataset?\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  count()\n\n\n\n\n\n\n\nmanuf\nn\n\n\n\n\nA\n1\n\n\nG\n22\n\n\nK\n23\n\n\nN\n6\n\n\nP\n9\n\n\nQ\n8\n\n\nR\n8"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#if_else",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#if_else",
    "title": "Data Cleaning & Manipulation",
    "section": "if_else()",
    "text": "if_else()\nFor each cereal, label the potass as “high” or “low”.\n\nOne if-else statement:\n\n\nif_else(&lt;CONDITION&gt;, &lt;TRUE OUTPUT&gt;, &lt;FALSE OUTPUT&gt;)\n\n\n\n\n\ncereal |&gt; \n  mutate(po_category = if_else(potass &lt;= 100, \"low\", \"high\"),\n         .after = potass)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\npo_category\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\nhigh\n25\n3\n1.00\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\nhigh\n0\n3\n1.00\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\nhigh\n25\n3\n1.00\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\nhigh\n25\n3\n1.00\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\nlow\n25\n3\n1.00\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\nlow\n25\n1\n1.00\n0.75\n29.50954\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\nlow\n25\n2\n1.00\n1.00\n33.17409\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\nlow\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\nhigh\n25\n1\n1.00\n0.67\n49.12025\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\nhigh\n25\n3\n1.00\n0.67\n53.31381\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\nlow\n25\n2\n1.00\n0.75\n18.04285\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\nhigh\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\nlow\n25\n2\n1.00\n0.75\n19.82357\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\nhigh\n25\n3\n1.00\n0.50\n40.40021\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\nlow\n25\n2\n1.00\n1.00\n22.73645\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\nlow\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\nlow\n25\n1\n1.00\n1.00\n45.86332\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\nlow\n25\n2\n1.00\n1.00\n35.78279\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\nlow\n25\n2\n1.00\n1.00\n22.39651\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\nhigh\n25\n3\n1.00\n0.50\n40.44877\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\nlow\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\nlow\n25\n3\n1.00\n1.00\n46.89564\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\nhigh\n25\n3\n1.00\n0.75\n36.17620\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\nlow\n25\n3\n1.00\n0.75\n44.33086\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\nlow\n25\n2\n1.00\n1.00\n32.20758\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\nlow\n25\n1\n1.00\n0.75\n31.43597\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\nlow\n25\n2\n1.00\n0.80\n58.34514\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\nhigh\n25\n3\n1.25\n0.67\n40.91705\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\nhigh\n25\n3\n1.33\n0.67\n41.01549\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\nlow\n25\n2\n1.00\n0.75\n28.02576\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\nlow\n25\n1\n1.00\n0.88\n35.25244\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\nlow\n25\n2\n1.00\n0.75\n23.80404\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\nlow\n25\n3\n1.00\n0.88\n52.07690\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\nlow\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\nlow\n25\n3\n1.00\n0.33\n45.81172\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\nlow\n25\n2\n1.00\n1.00\n21.87129\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\nlow\n25\n1\n1.00\n0.75\n31.07222\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\nlow\n25\n1\n1.00\n1.33\n28.74241\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\nlow\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\nlow\n100\n3\n1.30\n0.75\n36.47151\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\nlow\n25\n2\n1.00\n1.50\n39.24111\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\nlow\n25\n2\n1.00\n0.67\n45.32807\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\nlow\n25\n2\n1.00\n1.00\n26.73451\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\nlow\n25\n2\n1.00\n1.00\n54.85092\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\nhigh\n25\n3\n1.00\n1.00\n37.13686\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\nhigh\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\nhigh\n25\n3\n1.50\n0.67\n30.31335\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\nlow\n25\n1\n1.00\n1.00\n40.10596\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\nlow\n25\n2\n1.00\n0.67\n29.92429\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\nhigh\n25\n3\n1.33\n0.67\n40.69232\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\nlow\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\nhigh\n25\n3\n1.25\n0.50\n30.45084\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\nhigh\n25\n3\n1.33\n0.67\n37.84059\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\nlow\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\nlow\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\nlow\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\nhigh\n25\n3\n1.00\n0.50\n49.51187\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\nhigh\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\nhigh\n25\n2\n1.33\n0.75\n39.25920\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\nhigh\n25\n3\n1.00\n0.50\n39.70340\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\nhigh\n25\n3\n1.00\n0.50\n55.33314\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\nlow\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\nlow\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\nlow\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\nhigh\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\nhigh\n0\n1\n1.00\n0.67\n72.80179\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\nlow\n25\n2\n1.00\n0.75\n31.23005\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\nlow\n25\n1\n1.00\n1.00\n53.13132\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\nlow\n25\n2\n1.00\n1.00\n59.36399\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\nlow\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\nhigh\n100\n3\n1.50\n1.00\n28.59278\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\nhigh\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\nlow\n25\n3\n1.00\n0.75\n39.10617\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\nlow\n25\n2\n1.00\n1.00\n27.75330\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\nhigh\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\nhigh\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\nlow\n25\n1\n1.00\n0.75\n36.18756\n\n\n\n\n\n\n\n.after – specifies the location of the newly created column"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#case_when",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#case_when",
    "title": "Data Cleaning & Manipulation",
    "section": "case_when()",
    "text": "case_when()\nFor each cereal, label the amount of sugar as “low”, “medium”, “high”, or “very high”.\n\nA series of if-else statements.\n\ncereal |&gt; \n  mutate(sugar_level = case_when(sugars == -1 ~ NA_character_,\n                                 sugars &lt; 2   ~ \"low\",\n                                 sugars &lt; 5   ~ \"medium\",\n                                 sugars &lt; 10  ~ \"high\",\n                                 TRUE         ~ \"very high\")) |&gt; \n  select(name, sugars, sugar_level)\n\n\n\n\n\n\n\nname\nsugars\nsugar_level\n\n\n\n\n100% Bran\n6\nhigh\n\n\n100% Natural Bran\n8\nhigh\n\n\nAll-Bran\n5\nmedium\n\n\nAll-Bran with Extra Fiber\n0\nlow\n\n\nAlmond Delight\n8\nhigh\n\n\nApple Cinnamon Cheerios\n10\nhigh\n\n\nApple Jacks\n14\nvery high\n\n\nBasic 4\n8\nhigh\n\n\nBran Chex\n6\nhigh\n\n\nBran Flakes\n5\nmedium\n\n\nCap'n'Crunch\n12\nvery high\n\n\nCheerios\n1\nlow\n\n\nCinnamon Toast Crunch\n9\nhigh\n\n\nClusters\n7\nhigh\n\n\nCocoa Puffs\n13\nvery high\n\n\nCorn Chex\n3\nmedium\n\n\nCorn Flakes\n2\nlow\n\n\nCorn Pops\n12\nvery high\n\n\nCount Chocula\n13\nvery high\n\n\nCracklin' Oat Bran\n7\nhigh\n\n\nCream of Wheat (Quick)\n0\nlow\n\n\nCrispix\n3\nmedium\n\n\nCrispy Wheat & Raisins\n10\nhigh\n\n\nDouble Chex\n5\nmedium\n\n\nFroot Loops\n13\nvery high\n\n\nFrosted Flakes\n11\nvery high\n\n\nFrosted Mini-Wheats\n7\nhigh\n\n\nFruit & Fibre Dates; Walnuts; and Oats\n10\nhigh\n\n\nFruitful Bran\n12\nvery high\n\n\nFruity Pebbles\n12\nvery high\n\n\nGolden Crisp\n15\nvery high\n\n\nGolden Grahams\n9\nhigh\n\n\nGrape Nuts Flakes\n5\nmedium\n\n\nGrape-Nuts\n3\nmedium\n\n\nGreat Grains Pecan\n4\nmedium\n\n\nHoney Graham Ohs\n11\nvery high\n\n\nHoney Nut Cheerios\n10\nhigh\n\n\nHoney-comb\n11\nvery high\n\n\nJust Right Crunchy Nuggets\n6\nhigh\n\n\nJust Right Fruit & Nut\n9\nhigh\n\n\nKix\n3\nmedium\n\n\nLife\n6\nhigh\n\n\nLucky Charms\n12\nvery high\n\n\nMaypo\n3\nmedium\n\n\nMuesli Raisins; Dates; & Almonds\n11\nvery high\n\n\nMuesli Raisins; Peaches; & Pecans\n11\nvery high\n\n\nMueslix Crispy Blend\n13\nvery high\n\n\nMulti-Grain Cheerios\n6\nhigh\n\n\nNut&Honey Crunch\n9\nhigh\n\n\nNutri-Grain Almond-Raisin\n7\nhigh\n\n\nNutri-grain Wheat\n2\nlow\n\n\nOatmeal Raisin Crisp\n10\nhigh\n\n\nPost Nat. Raisin Bran\n14\nvery high\n\n\nProduct 19\n3\nmedium\n\n\nPuffed Rice\n0\nlow\n\n\nPuffed Wheat\n0\nlow\n\n\nQuaker Oat Squares\n6\nhigh\n\n\nQuaker Oatmeal\n-1\nNA\n\n\nRaisin Bran\n12\nvery high\n\n\nRaisin Nut Bran\n8\nhigh\n\n\nRaisin Squares\n6\nhigh\n\n\nRice Chex\n2\nlow\n\n\nRice Krispies\n3\nmedium\n\n\nShredded Wheat\n0\nlow\n\n\nShredded Wheat 'n'Bran\n0\nlow\n\n\nShredded Wheat spoon size\n0\nlow\n\n\nSmacks\n15\nvery high\n\n\nSpecial K\n3\nmedium\n\n\nStrawberry Fruit Wheats\n5\nmedium\n\n\nTotal Corn Flakes\n3\nmedium\n\n\nTotal Raisin Bran\n14\nvery high\n\n\nTotal Whole Grain\n3\nmedium\n\n\nTriples\n3\nmedium\n\n\nTrix\n12\nvery high\n\n\nWheat Chex\n3\nmedium\n\n\nWheaties\n3\nmedium\n\n\nWheaties Honey Gold\n8\nhigh"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#group_by-slice",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#group_by-slice",
    "title": "Data Cleaning & Manipulation",
    "section": "group_by() + slice()",
    "text": "group_by() + slice()\nFor each manuf, find the cereal with the most fiber.\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  slice_max(order_by = fiber)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15\n6\n125\n25\n1\n1.00\n0.67\n49.12025"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#multiple-variables-in-slice",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#multiple-variables-in-slice",
    "title": "Data Cleaning & Manipulation",
    "section": "Multiple Variables in slice()",
    "text": "Multiple Variables in slice()\nFind the 3 cereals with the highest fiber and potass.\n\n\nIf you are ordering by multiple variables, wrap them in a data.frame!\n\n\ncereal |&gt; \n  slice_max(order_by = data.frame(fiber, potass),\n            n = 3)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14\n8\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10\n5\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9\n7\n5\n320\n25\n3\n1\n0.33\n59.42551"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns",
    "title": "Data Cleaning & Manipulation",
    "section": "Summarize multiple columns",
    "text": "Summarize multiple columns\nFor each type of cereal, calculate the mean nutrient levels.\n\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarize(mean_calories = mean(calories, na.rm = T),\n            mean_protein  = mean(protein, na.rm = T),\n            mean_fat      = mean(fat, na.rm = T),\n            mean_sodium   = mean(sodium, na.rm = T),\n            . . .,\n            mean_vitamins = mean(vitamins, na.rm = T))\n\n\n\n\n\n\n\n\n\nSO MUCH COPY-PASTE!\n\n\nThere are 9 different nutrient columns in the dataset! There has to be a better way…"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across",
    "title": "Data Cleaning & Manipulation",
    "section": "Summarize multiple columns with across()",
    "text": "Summarize multiple columns with across()\nFor each type of cereal, calculate the mean nutrient levels.\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarise(across(.cols = calories:potass, \n                   .fns = ~ mean(.x, na.rm = T)))\n\n\n\n\n\n\n\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\n\n\n\n\ncold\n107.1622\n2.486486\n1.013513\n165.06757\n2.189189\n14.7027\n7.1756757\n97.21622\n\n\nhot\n100.0000\n4.000000\n1.000000\n26.66667\n1.233333\n12.0000\n0.6666667\n68.00000\n\n\n\n\n\n\n\n\n\n\n\n\n\nSo much better!"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across-1",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Summarize multiple columns with across()",
    "text": "Summarize multiple columns with across()\nWithin the summarize() function, we use the across() function, with three arguments:\n\n.cols – to specify the columns to apply functions to.\n.fns – to specify the functions to apply.\n.x – as a placeholder for the variables being passed into the function.\n\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarise(across(.cols = calories:potass, \n                   .fns = ~ mean(.x, na.rm = T)))\n\nUse lambda functions: ~ &lt;FUN_NAME&gt;(.x, &lt;ARGS&gt;)"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across-2",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#summarize-multiple-columns-with-across-2",
    "title": "Data Cleaning & Manipulation",
    "section": "Summarize multiple columns with across()",
    "text": "Summarize multiple columns with across()\n\nTo choose columns, you can use the same options as with select()\n\n\nFor each type of cereal, calculate the means of all numeric variables.\n\n\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarise(across(.cols = where(is.numeric),\n                   .fns = ~ mean(.x, na.rm = T)))\n\n\n\n\n\n\n\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\ncold\n107.1622\n2.486486\n1.013513\n165.06757\n2.189189\n14.7027\n7.1756757\n97.21622\n29.054054\n2.229730\n1.030811\n0.8182432\n42.09522\n\n\nhot\n100.0000\n4.000000\n1.000000\n26.66667\n1.233333\n12.0000\n0.6666667\n68.00000\n8.333333\n1.666667\n1.000000\n0.8900000\n56.73771"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#if-you-are-struggling-with-across",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#if-you-are-struggling-with-across",
    "title": "Data Cleaning & Manipulation",
    "section": "If you are struggling with across()",
    "text": "If you are struggling with across()\n\nBreak it down:\n\nthink about what the code would be for one column\n\n\nsummarize(calories = mean(calories, na.rm = T))\n\n\nreplace the column name with the placeholder .x and add a ~ in front for the .fns argument. You have created a lambda function!\n\n\nsummarize(across(.cols = ,\n                 .fns  = ~mean(.x, na.rm = T)))\n\n\nthink about which columns you want to apply this to for the .cols argument\n\n\nsummarize(across(.cols = calories:potass,\n                 .fns  = ~mean(.x, na.rm = T)))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot",
    "title": "Data Cleaning & Manipulation",
    "section": "Piping into ggplot()",
    "text": "Piping into ggplot()\nPlot the mean protein per cup for each manuf.\n\n\ncereal |&gt; \n  mutate(manuf = case_when(manuf == \"A\" ~ \"American Home Food Products\", \n                           manuf == \"G\" ~ \"General Mills\", \n                           manuf == \"K\" ~ \"Kelloggs\", \n                           manuf == \"N\" ~ \"Nabisco\", \n                           manuf == \"P\" ~ \"Post\", \n                           manuf == \"Q\" ~ \"Quaker Oats\", \n                           manuf == \"R\" ~ \"Ralston Purina\"))  |&gt; \n  filter(type == \"cold\") |&gt; \n  mutate(pro_per_cup = protein / cups) |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_pro_per_cup = mean(pro_per_cup)) |&gt;  \n  ggplot(aes(x = manuf, \n             y = mean_pro_per_cup)) +\n  geom_point(size = 6) +\n  labs(x = \"Manufacturer\",\n       subtitle = \"Mean Protein per Cup\") +\n  theme_bw() +\n  theme(axis.title.y = element_blank(),\n        axis.title.x  = element_text(size = 24),\n        plot.subtitle = element_text(size = 24),\n        axis.text = element_text(size = 20),\n        axis.text.x = element_text(angle = 13)) +\n  scale_y_continuous(limits = c(0,6))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot-1",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Piping into ggplot()",
    "text": "Piping into ggplot()\nPlot the mean protein per cup for each manuf.\n\ncereal |&gt; \n  mutate(manuf = case_when(manuf == \"A\" ~ \"American Home Food Products\", \n                           manuf == \"G\" ~ \"General Mills\", \n                           manuf == \"K\" ~ \"Kelloggs\", \n                           manuf == \"N\" ~ \"Nabisco\", \n                           manuf == \"P\" ~ \"Post\", \n                           manuf == \"Q\" ~ \"Quaker Oats\", \n                           manuf == \"R\" ~ \"Ralston Purina\"))  |&gt; \n  filter(type == \"cold\") |&gt; \n  mutate(pro_per_cup = protein / cups) |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_pro_per_cup = mean(pro_per_cup)) |&gt;  \n  ggplot(aes(x = manuf, \n             y = mean_pro_per_cup)) +\n  geom_point(size = 6) +\n  labs(x = \"Manufacturer\",\n       subtitle = \"Mean Protein per Cup\") +\n  theme_bw() +\n  theme(axis.title.y = element_blank(),\n        axis.title.x  = element_text(size = 24),\n        plot.subtitle = element_text(size = 24),\n        axis.text = element_text(size = 20),\n        axis.text.x = element_text(angle = 13)) +\n  scale_y_continuous(limits = c(0,6))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot-1-output",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#piping-into-ggplot-1-output",
    "title": "Data Cleaning & Manipulation",
    "section": "Piping into ggplot()",
    "text": "Piping into ggplot()"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#putting-it-all-together---lets-practice",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#putting-it-all-together---lets-practice",
    "title": "Data Cleaning & Manipulation",
    "section": "Putting it all Together - Let’s Practice!",
    "text": "Putting it all Together - Let’s Practice!\nHow would you make this plot from the diamonds dataset in ggplot2?\n\n\nCode\ndiamonds |&gt; \n  mutate(category = case_when(price &lt; 1000 ~ \"&lt;$1k\",\n                              price &lt;= 5000 ~ \"$1k-$5k\",\n                              .default = \"&gt;$5k\")) |&gt;\n  ggplot(mapping = aes(x = cut,\n                       fill = cut)) +\n  geom_bar() +\n  facet_wrap(vars(category)) +\n  labs(subtitle = \"Number of Diamonds\",\n       x = \"Cut\",\n       y = \"\",\n       fill = \"Cut\") +\n  theme(axis.text.x = element_blank(),\n        axis.title = element_text(size = 14),\n        legend.title = element_text(size = 14),\n        legend.text = element_text(size = 14),\n        strip.text = element_text(size = 14),\n        title = element_text(size = 14))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#creating-a-game-plan-1",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#creating-a-game-plan-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Creating a Game Plan",
    "text": "Creating a Game Plan\nJust like when creating graphics with ggplot, wrangling data with dplyr involves thinking through many steps and writing many layers of code.\n\nTo help us think through a wrangling problem, we are going to create a game plan before we start writing code.\n\n\nThis might involve…\n\na sketch or flowchart.\na list of dplyr verbs and variable names.\nannotating the head of the dataframe."
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#answering-a-research-question",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#answering-a-research-question",
    "title": "Data Cleaning & Manipulation",
    "section": "Answering a Research Question",
    "text": "Answering a Research Question\n\nThe QuestionThe CodeFormatting Code Output\n\n\nWhat is the median grams of sugars per shelf and the number of cereals per shelf, when we drop the missing values (coded as sugars = -1)?\n\nThe person with the nearest birthday: explain out loud to your neighbor how you would do this manipulation.\n\n\n\ncereal |&gt; \n  select(sugars, shelf) |&gt; \n  filter(sugars != -1) |&gt; \n  group_by(shelf) |&gt; \n  summarise(med_sugars = median(sugars),\n            n_cereal = n())\n\n# A tibble: 3 × 3\n  shelf med_sugars n_cereal\n  &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;\n1     1          3       19\n2     2         12       21\n3     3          6       36\n\n\n\n\nUse kable() from the knitr package and the kableExtra package to format tables in Quarto.\n\ncereal |&gt; \n  select(sugars, shelf) |&gt; \n  filter(sugars != -1) |&gt; \n  group_by(shelf) |&gt; \n  summarise(med_sugars = median(sugars),\n            n_cereal = n()) |&gt; \n  kable()\n\n\n\n\n\n\n\nshelf\nmed_sugars\nn_cereal\n\n\n\n\n1\n3\n19\n\n\n2\n12\n21\n\n\n3\n6\n36"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#data-ethics",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#data-ethics",
    "title": "Data Cleaning & Manipulation",
    "section": "Data Ethics",
    "text": "Data Ethics\n1. What do we mean by data ethics?\n\n\n\n2. Why do we (as statisticians, data scientists, folks working with data) need to think about data ethics?"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#data-ethics-1",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#data-ethics-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Data Ethics",
    "text": "Data Ethics\n1. What do we mean by data ethics?\n\nThe process of evaluating data collection, processing, analysis, and dissemination practices for their adverse impacts on individuals, systems, and society.\n\n2. Why do we (as statisticians, data scientists, folks working with data) need to think about data ethics?\n\nWe have a lot of power to declare truth and fact, hiding behind the black box of data science methods."
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#principles-of-data-ethics",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#principles-of-data-ethics",
    "title": "Data Cleaning & Manipulation",
    "section": "Principles of Data Ethics",
    "text": "Principles of Data Ethics\n\n\nI will not be ashamed to say, “I don’t know”\nI will respect the privacy of my data subjects\nI will remember that my data are not just numbers without meaning or context, but represent real people and situations\nI will interrogate how my work may lead to unintended societal consequences or perpetuate inequity"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#asa-ethical-guidelines",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#asa-ethical-guidelines",
    "title": "Data Cleaning & Manipulation",
    "section": "ASA Ethical Guidelines",
    "text": "ASA Ethical Guidelines\n\nThe American Statistical Association’s Ethical Guidelines for Statistical Practice are intended to help statistics practitioners make decisions ethically.\nThey aim to promote accountability by informing those who rely on statistics of the standards they should expect."
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#additional-resources",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#additional-resources",
    "title": "Data Cleaning & Manipulation",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nMore Data Feminism\nCritical Quantitative Research\n\nResource 1\nResource 2\n\n\n\nI would love to discuss these with you in office hours!"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#lab-3-teacher-evaluations",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#lab-3-teacher-evaluations",
    "title": "Data Cleaning & Manipulation",
    "section": "Lab 3: Teacher Evaluations",
    "text": "Lab 3: Teacher Evaluations"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#dplyr-cheatsheet",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#dplyr-cheatsheet",
    "title": "Data Cleaning & Manipulation",
    "section": "dplyr cheatsheet",
    "text": "dplyr cheatsheet\n\nggplot2 cheatsheet"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#using-kable-for-formatting-in-labs",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#using-kable-for-formatting-in-labs",
    "title": "Data Cleaning & Manipulation",
    "section": "Using kable() for formatting in labs",
    "text": "Using kable() for formatting in labs\n\nWhen printing rows of a data frame or tibble\nneed to load the knitr package at the beginning of your file\nkable() outputs a markdown version of your data\nshould only be used to nicely format data you are printing\n\n\n\ne.g.\n\ncereal_clean &lt;- cereal |&gt; \n  mutate(ratio = sugars / potass)\n  \ncereal_clean |&gt; \n  slice_head(n = 3) |&gt; \n  kable()\n\n\nNOT\n\ncereal_clean &lt;- cereal |&gt; \n  mutate(ratio = sugars / potass) |&gt; \n  slice_head(n = 3) |&gt; \n  kable()"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#to-do",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#to-do",
    "title": "Data Cleaning & Manipulation",
    "section": "To do…",
    "text": "To do…\n\nLab 3: Teacher Evaluations\n\nDue Monday, 4/21 at 11:59pm\n\nRead Chapter 4: Data Joins and Transformations\n\nCheck-in 4.1 + 4.2 due Tuesday 4/22 before class"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#tuesday-april-8",
    "href": "slides/week-2/w2-import-ggplot.html#tuesday-april-8",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Tuesday, April 8",
    "text": "Tuesday, April 8\nToday we will…\n\nStyle Note of the Day\nNew Material\n\nWelcome to the Tidyverse\nLoad External Data\nGraphics (and ggplot2)\nGame Planning\n\nPA 2: Using Data Visualization to Find the Penguins"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#style-note-of-the-day---function-calls",
    "href": "slides/week-2/w2-import-ggplot.html#style-note-of-the-day---function-calls",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Style Note of the Day - Function Calls",
    "text": "Style Note of the Day - Function Calls\n\n\n\n\n\n\nTip\n\n\nName arguments in function calls\nOnly include necessary arguments! (If you are using any default values, no need to repeat them in your function call.)\n\n\n\nGood\n\nmean(1:10, na.rm = TRUE)\nseq(from = 1, to = 100, by = 5)\n\n\nBad\n\nmean(1:10, , TRUE)\nmean(1:10, trim = 0, na.rm = TRUE)\n\nseq(1, 100, 5)"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#tidywho",
    "href": "slides/week-2/w2-import-ggplot.html#tidywho",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Tidywho?",
    "text": "Tidywho?\n\n\n\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.1\n\n\n\n\n\n\nMost of the functionality you will need for an entire data analysis workflow with cohesive grammar\n\n\nhttps://www.tidyverse.org/"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#core-packages",
    "href": "slides/week-2/w2-import-ggplot.html#core-packages",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Core Packages",
    "text": "Core Packages\nThe tidyverse includes functions to:\n\n\n\nRead in data\nreadr\n\n\nVisualize data\nggplot2\n\n\nManipulate rectangular data\ntidyr, dplyr, tibble\n\n\nHandle special variable types\nstringr, forcats , lubridate\n\n\nSupport functional programming\npurrr"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#tidyverse-and-stat-331",
    "href": "slides/week-2/w2-import-ggplot.html#tidyverse-and-stat-331",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Tidyverse and STAT 331",
    "text": "Tidyverse and STAT 331\n\n\nThis version of the course will primarily use tidyverse packages and grammar\nReasoning:\n\nthe tidyverse is as reputable and ubiquitous as base R at this point (in my opinion)\nthe tidyverse is specifically designed to help programmers produce easy-to-read and reproducible analyses and to reduce errors\nthere is excellent documentation!\nI like it!"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#using-the-tidyverse-package",
    "href": "slides/week-2/w2-import-ggplot.html#using-the-tidyverse-package",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Using the tidyverse package",
    "text": "Using the tidyverse package\n\nInstalling/loading the tidyverse package installs/loads all of the “tidyverse” packages\nAvoid redundantly installing or loading packages!\n\n\nDo this:\n\nlibrary(tidyverse)\n\nor\n\nlibrary(readr)\n\n\n\nNot this:\n\nlibrary(tidyverse)\nlibrary(readr)"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#tidy-data",
    "href": "slides/week-2/w2-import-ggplot.html#tidy-data",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Tidy Data",
    "text": "Tidy Data\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#data-science-workflow",
    "href": "slides/week-2/w2-import-ggplot.html#data-science-workflow",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Data Science Workflow",
    "text": "Data Science Workflow"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#common-types-of-data-files",
    "href": "slides/week-2/w2-import-ggplot.html#common-types-of-data-files",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Common Types of Data Files",
    "text": "Common Types of Data Files\nLook at the file extension for the type of data file.\n\n\n\n.csv : “comma-separated values”\n\nName, Age\nBob, 49\nJoe, 40\n\n\n\n.xls, .xlsx: Microsoft Excel spreadsheet\n\nCommon approach: save as .csv\nNicer approach: use the readxl package\n\n\n\n.txt: plain text\n\nCould have any sort of delimiter…\nNeed to let R know what to look for!"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#common-types-of-data-files-1",
    "href": "slides/week-2/w2-import-ggplot.html#common-types-of-data-files-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Common Types of Data Files",
    "text": "Common Types of Data Files\n\nFile AFile BFile CSources\n\n\n\n\n\n\n\n\n\n\n\n\nFile A\nFile B\nFile C"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#loading-external-data",
    "href": "slides/week-2/w2-import-ggplot.html#loading-external-data",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Loading External Data",
    "text": "Loading External Data\nUsing base R functions:\n\nread.csv() is for reading in .csv files.\nread.table() and read.delim() are for any data with “columns” (you specify the separator)."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#loading-external-data-1",
    "href": "slides/week-2/w2-import-ggplot.html#loading-external-data-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Loading External Data",
    "text": "Loading External Data\nThe tidyverse has some cleaned-up versions in the readr and readxl packages:\n\nread_csv() is for comma-separated data.\nread_tsv() is for tab-separated data.\nread_table() is for white-space-separated data.\nread_delim() is any data with “columns” (you specify the separator). The above are special cases.\nread_excel() is specifically for dealing with Excel files.\n\nRemember to load the readr and readxl packages first!"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#take-a-look-at-the-documentation",
    "href": "slides/week-2/w2-import-ggplot.html#take-a-look-at-the-documentation",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Take a look at the documentation",
    "text": "Take a look at the documentation"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#reminder-notebooks-and-file-paths",
    "href": "slides/week-2/w2-import-ggplot.html#reminder-notebooks-and-file-paths",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Reminder: Notebooks and File Paths",
    "text": "Reminder: Notebooks and File Paths\n\nYou have to tell R where to “find” the data you want to read in using a file path.\nQuarto automatically sets the working directory to the be directory where the Quarto document is for any code within the Quarto document\nThis overrides the directory set by an .Rproj\n\n\n\n\n\nPay attention to this when setting relative filepaths\n\nTo “backout” of one directory, use \"../\"\ne.g.: \"../data/dat.csv\""
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#why-do-we-create-graphics",
    "href": "slides/week-2/w2-import-ggplot.html#why-do-we-create-graphics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Why Do We Create Graphics?",
    "text": "Why Do We Create Graphics?"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#grammar-of-graphics-1",
    "href": "slides/week-2/w2-import-ggplot.html#grammar-of-graphics-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\nThe Grammar of Graphics (GoG) is a principled way of specifying exactly how to create a particular graph from a given data set. It helps us to systematically design new graphs.\n\n\nThink of a graph or a data visualization as a mapping…\n\nFROM variables in the data set (or statistics computed from the data)…\nTO visual attributes (or “aesthetics”) of marks (or “geometric elements”) on the page/screen."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#why-grammar-of-graphics",
    "href": "slides/week-2/w2-import-ggplot.html#why-grammar-of-graphics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Why Grammar of Graphics?",
    "text": "Why Grammar of Graphics?\n\nIt’s more flexible than a “chart zoo” of named graphs.\nThe software understands the structure of your graph.\nIt easily automates graphing of data subsets."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#components-of-grammar-of-graphics",
    "href": "slides/week-2/w2-import-ggplot.html#components-of-grammar-of-graphics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Components of Grammar of Graphics",
    "text": "Components of Grammar of Graphics\n\ndata: dataframe containing variables\naes : aesthetic mappings (position, color, symbol, …)\ngeom : geometric element (point, line, bar, box, …)\nstat : statistical variable transformation (identity, count, linear model, quantile, …)\nscale : scale transformation (log scale, color mapping, axes tick breaks, …)\ncoord : Cartesian, polar, map projection, …\nfacet : divide into subplots using a categorical variable"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#how-to-build-a-graphic",
    "href": "slides/week-2/w2-import-ggplot.html#how-to-build-a-graphic",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "How to Build a Graphic",
    "text": "How to Build a Graphic\nComplete this template to build a basic graphic:\n\n\n\nWe use + to add layers to a graphic."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#section",
    "href": "slides/week-2/w2-import-ggplot.html#section",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "",
    "text": "Add dataAdd aestheticsAdd one geom per layer\n\n\nThis begins a plot that you can add layers to:\n\nggplot(data = mpg)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg, \n       aes(x = class, y = hwy))\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg, \n       aes(x = class, y = hwy)) +\n  geom_jitter()\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg, \n       aes(x = class, y = hwy)) +\n  geom_jitter() +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nHow would you make the points be on top of the boxplots?"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#aesthetics",
    "href": "slides/week-2/w2-import-ggplot.html#aesthetics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Aesthetics",
    "text": "Aesthetics\nWe map variables (columns) from the data to aesthetics on the graphic useing the aes() function.\n\nWhat aesthetics can we set (see ggplot2 cheat sheet for more)?\n\n\n\n\nx, y\ncolor, fill\nlinetype\nlineend\nsize\nshape"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#aesthetics-1",
    "href": "slides/week-2/w2-import-ggplot.html#aesthetics-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Aesthetics",
    "text": "Aesthetics\nWe map variables (columns) from the data to aesthetics on the graphic useing the aes() function.\nWhat aesthetics can we set (see ggplot2 cheat sheet for more)?\n\n\n\n\nx, y\ncolor, fill\nlinetype\nlineend\nsize\nshape"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#global-v.-local-aesthetics",
    "href": "slides/week-2/w2-import-ggplot.html#global-v.-local-aesthetics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Global v. Local Aesthetics",
    "text": "Global v. Local Aesthetics\nGlobal Aesthetics\n\nggplot(data = mpg, \n       mapping = aes(x = class, \n                     y = hwy)) +\n  geom_boxplot()\n\n\nLocal Aesthetics\n\nggplot(data = mpg) +\n  geom_boxplot(mapping = aes(x = class, \n                             y = hwy))"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#mapping-v.-setting-aesthetics",
    "href": "slides/week-2/w2-import-ggplot.html#mapping-v.-setting-aesthetics",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Mapping v. Setting Aesthetics",
    "text": "Mapping v. Setting Aesthetics\nMapping Aesthetics\n\nggplot(data = mpg) +\n  geom_jitter(mapping = aes(x = class, \n                             y = hwy,\n                             color = class))\n\n\nSetting Aesthetics\n\nggplot(data = mpg) +\n  geom_jitter(mapping = aes(x = class, \n                             y = hwy),\n               color = \"steelblue\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#geometric-objects",
    "href": "slides/week-2/w2-import-ggplot.html#geometric-objects",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Geometric Objects",
    "text": "Geometric Objects\nWe use a geom_xxx() function to represent data points.\n\n\n\none variable\n\ngeom_density()\ngeom_dotplot()\ngeom_histogram()\ngeom_boxplot()\n\n\ntwo variable\n\ngeom_point()\ngeom_line()\ngeom_density_2d()\n\n\nthree variable\n\ngeom_contour()\ngeom_raster()\n\n\n\n\nNot an exhaustive list – see ggplot2 cheat sheet."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#section-1",
    "href": "slides/week-2/w2-import-ggplot.html#section-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "",
    "text": "geom_point()geom_text()geom_line()\n\n\n\n\nCode\nggplot(data = mpg,\n       aes(x = cty,\n           y = hwy,\n           color = class)) +\n  geom_point() +\n  labs(x = \"City (mpg)\", y = \"Highway (mpg)\") +\n  theme(axis.title = element_text(size = 14),\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg,\n       aes(x = cty,\n           y = hwy,\n           color = class)) +\n  geom_text(aes(label = class)) +\n  labs(x = \"City (mpg)\", y = \"Highway (mpg)\") +\n  theme(axis.title = element_text(size = 14),\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg,\n       aes(x = cty,\n           y = hwy,\n           color = class)) +\n  geom_line() +\n  labs(x = \"City (mpg)\", y = \"Highway (mpg)\") +\n  theme(axis.title = element_text(size = 14),\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#creating-a-graphic",
    "href": "slides/week-2/w2-import-ggplot.html#creating-a-graphic",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Creating a Graphic",
    "text": "Creating a Graphic\nTo create a specific type of graphic, we will combine aesthetics and geometric objects.\n\n\nLet’s try it!"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#game-planning",
    "href": "slides/week-2/w2-import-ggplot.html#game-planning",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Game Planning",
    "text": "Game Planning\nWhat: Game Plans! are strategic guides that prompt you to map your coding strategies before implementation.\nHow: Your favorite sketch app, paper + pencil, online whiteboard (Excalidraw!).\nWhy: Tool to connect data and desired graphic before you start coding"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#section-2",
    "href": "slides/week-2/w2-import-ggplot.html#section-2",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "",
    "text": "The GoalGame Planggplot\n\n\nStart with the TX housing data.\n\nMake a plot of median house price over time (including both individual data points and a smoothed trend line), distinguishing between different cities.\n\n\n\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median, color = city)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#faceting",
    "href": "slides/week-2/w2-import-ggplot.html#faceting",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Faceting",
    "text": "Faceting\nExtracts subsets of data and places them in side-by-side plots.\n\nfacet_grid()facet_wrap()\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  facet_grid(cols = vars(city)) +\n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  facet_wrap(vars(city)) +\n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#faceting-1",
    "href": "slides/week-2/w2-import-ggplot.html#faceting-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Faceting",
    "text": "Faceting\nExtracts subsets of data and places them in side-by-side plots.\n\nOptionsScalesLabels\n\n\n\n\nfacet_grid(cols = vars(b)): facet into columns based on b\nfacet_grid(rows = vars(a)): facet into rows based on a\nfacet_grid(rows = vars(a), cols = vars(b)): facet into both rows and columns\nfacet_wrap(vars(b)): wrap facets into a rectangular layout\n\n\n\n\nYou can set scales to let axis limits vary across facets:\n\nfacet_grid(rows = vars(a),\n           cols = vars(b),\n           scales = ______)\n\n\n\n\"fixed\" – default, x- and y-axis limits are the same for each facet\n\"free\" – both x- and y-axis limits adjust to individual facets\n\"free_x\" – only x-axis limits adjust\n\"free_y\" – only y-axis limits adjust\n\n\n\n\nYou can set a labeller to adjust facet labels.\n\nInclude both the variable name and factor name in the labels:\n\nfacet_grid(cols = vars(b), labeller = label_both)\n\nDisplay math symbols in the labels:\n\nfacet_grid(cols = vars(b), labeller = label_bquote(cols = alpha ^ .(b)))\nfacet_grid(cols = vars(b), labeller = label_parsed)"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#example-facet-labels",
    "href": "slides/week-2/w2-import-ggplot.html#example-facet-labels",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Example Facet Labels",
    "text": "Example Facet Labels\n\nExample 1Example 2\n\n\nIncluding the variable and facet names using label_both:\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  facet_grid(cols = vars(city),\n             labeller = label_both) +\n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")\n\n\n\n\n\n\n\n\n\n\n\nIncluding math labels in facet names using label_bquote:\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  facet_grid(cols = vars(city),\n             labeller = label_bquote(cols = .(city)^2)) +\n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#statistical-transformation-stat",
    "href": "slides/week-2/w2-import-ggplot.html#statistical-transformation-stat",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Statistical Transformation: stat",
    "text": "Statistical Transformation: stat\nA stat transforms an existing variable into a new variable to plot.\n\nidentity leaves the data as is.\ncount counts the number of observations.\nsummary allows you to specify a desired transformation function.\n\n\nSometimes these statistical transformations happen under the hood when we call a geom."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#statistical-transformation-stat-1",
    "href": "slides/week-2/w2-import-ggplot.html#statistical-transformation-stat-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Statistical Transformation: stat",
    "text": "Statistical Transformation: stat\n\nstat_count()stat_summary()\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = class)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = class)) +\n  stat_count(geom = \"bar\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = class,\n                     y = hwy)) +\n  stat_summary(geom = \"bar\",\n               fun = \"mean\") +\n  scale_y_continuous(limits = c(0,45))\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = class,\n                     y = hwy)) +\n  stat_summary(geom = \"bar\",\n               fun = \"max\") +\n  scale_y_continuous(limits = c(0,45))"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#position-adjustements",
    "href": "slides/week-2/w2-import-ggplot.html#position-adjustements",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Position Adjustements",
    "text": "Position Adjustements\nPosition adjustments determine how to arrange geom’s that would otherwise occupy the same space.\n\n\nposition = 'dodge': Arrange elements side by side.\nposition = 'fill': Stack elements on top of one another + normalize height.\nposition = 'stack': Stack elements on top of one another.\nposition = 'jitter\": Add random noise to X & Y position of each element to avoid overplotting (see geom_jitter())."
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#position-adjustements-1",
    "href": "slides/week-2/w2-import-ggplot.html#position-adjustements-1",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Position Adjustements",
    "text": "Position Adjustements\n\nggplot(mpg, aes(x = fl, fill = drv)) + \n  geom_bar(position = \"_____\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#plot-customizations",
    "href": "slides/week-2/w2-import-ggplot.html#plot-customizations",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Plot Customizations",
    "text": "Plot Customizations\n\nLabelsThemesScales: Axes TicksScales: Color\n\n\n\n\nCode\nggplot(data = mpg) + \n  geom_jitter(mapping = aes(x = displ, y = hwy, color = cyl)) + \n  labs(x = \"Engine Displacement (liters)\", \n       y = \"Highway MPG\", \n       color = \"Number of \\nCylinders\",\n       title = \"Car Efficiency\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg) + \n  geom_jitter(mapping = aes(x = displ, y = hwy, color = cyl)) + \n  labs(xlab = \"Engine Displacement (liters)\", \n       ylab = \"Highway MPG\", \n       color = \"Number of \\nCylinders\",\n       title = \"Car Efficiency\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg) + \n  geom_jitter(mapping = aes(x = displ, y = hwy, color = cyl)) + \n  labs(x     = \"Engine Displacement (liters)\",\n       color = \"Number of \\nCylinders\",\n       title = \"Car Efficiency\") +\n  scale_y_continuous(\"Highway MPG\", \n                     limits = c(0,50),\n                     breaks = seq(0,50,5))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg) + \n  geom_jitter(mapping = aes(x = displ, y = hwy, color = cyl)) + \n  labs(x    = \"Engine Displacement (liters)\",\n       y    = \"Highway MPG\",\n       color = \"Number of \\nCylinders\",\n       title = \"Car Efficiency\") +\n  scale_color_gradient(low = \"white\", high = \"green4\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#formatting-your-plot-code",
    "href": "slides/week-2/w2-import-ggplot.html#formatting-your-plot-code",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Formatting your Plot Code",
    "text": "Formatting your Plot Code\nIt is good practice to put each geom and aes on a new line.\n\nThis makes code easier to read!\nGenerally: no line of code should be over 80 characters long.\n\n\nBad PracticeGood PracticeSomewhere In Between\n\n\n\nggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = class)) + geom_point() + theme_bw() + labs(x = \"City (mpg)\", y = \"Highway (mpg)\")\n\n\n\n\nggplot(data = mpg, \n       mapping = aes(x = cty, \n                     y = hwy, \n                     color = class)) + \n  geom_point() + \n  theme_bw() + \n  labs(x = \"City (mpg)\", \n       y = \"Highway (mpg)\")\n\n\n\n\nggplot(data = mpg, \n       mapping = aes(x = cty, y = hwy, color = class)) + \n  geom_point() + \n  theme_bw() + \n  labs(x = \"City (mpg)\", y = \"Highway (mpg)\")"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#lets-practice",
    "href": "slides/week-2/w2-import-ggplot.html#lets-practice",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Let’s Practice!",
    "text": "Let’s Practice!\nHow would you make this plot from the diamonds dataset in ggplot2?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata\naes\ngeom\nfacet"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#creating-a-game-plan",
    "href": "slides/week-2/w2-import-ggplot.html#creating-a-game-plan",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "Creating a Game Plan",
    "text": "Creating a Game Plan\nThere are a lot of pieces to put together when creating a good graphic.\n\nSo, when sitting down to create a plot, you should first create a game plan!\n\n\nThis game plan should include:\n\nWhat data are you starting from?\nWhat are your x- and y-axes?\nWhat type(s) of geom do you need?\nWhat other aes’s do you need?"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#section-3",
    "href": "slides/week-2/w2-import-ggplot.html#section-3",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "",
    "text": "Make a Game Plan!ExampleR Code - Baseline PlotR Code - Formatted Plot\n\n\nUse the mpg dataset to create two side-by-side scatterplots of city MPG vs. highway MPG where the points are colored by the drive type (drv). The two plots should be separated by year.\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg,\n       mapping = aes(x = cty,\n                     y = hwy,\n                     color = drv)) +\n  geom_point() +\n  facet_grid(cols = vars(year))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = mpg,\n       mapping = aes(x = cty,\n                     y = hwy,\n                     color = drv)) +\n  geom_point() +\n  facet_grid(cols = vars(year)) +\n  labs(x = \"city MPG\",\n       y = \"highway MPG\") +\n  scale_color_discrete(name = \"drive type\",\n                      labels = c(\"4-wheel\",\"front\",\"rear\"))"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#pa-2-using-data-visualization-to-find-the-penguins",
    "href": "slides/week-2/w2-import-ggplot.html#pa-2-using-data-visualization-to-find-the-penguins",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "PA 2: Using Data Visualization to Find the Penguins",
    "text": "PA 2: Using Data Visualization to Find the Penguins\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-2/w2-import-ggplot.html#to-do",
    "href": "slides/week-2/w2-import-ggplot.html#to-do",
    "title": "Importing Data and Graphics with ggplot2",
    "section": "To do…",
    "text": "To do…\n\nPA 2: Using Data Visualization to Find the Penguins\n\nDue Thursday (4/10) before class\n\nLab 2: Exploring Rodents with ggplot2\n\nDue Monday (4/14) at 11:59 pm"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#thursday-april-3",
    "href": "slides/week-1/w1-notebooks.html#thursday-april-3",
    "title": "Quarto & Reproducibility",
    "section": "Thursday, April 3",
    "text": "Thursday, April 3\nToday we will…\n\nAnswer Clarifying Questions:\n\nSyllabus?\nChapter 1 Reading?\nPA 1: Find the Mistakes?\n\nNew Material\n\nReproducibility\nScripts + Notebooks\n\nLab 1: Introduction to Quarto"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#reproducibility",
    "href": "slides/week-1/w1-notebooks.html#reproducibility",
    "title": "Quarto & Reproducibility",
    "section": "Reproducibility",
    "text": "Reproducibility\n\n\nIn computing: analyses can be executed again with identical results (either by you or by someone else!)\nDiscussion: Why does it matter?\n\n\n\nAbstruse Goose"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#principles-of-reproducibility",
    "href": "slides/week-1/w1-notebooks.html#principles-of-reproducibility",
    "title": "Quarto & Reproducibility",
    "section": "Principles of Reproducibility",
    "text": "Principles of Reproducibility\nYou can to send your code to someone else, and they can jump in and start working right away.\nThis means:\n\n\nFiles are organized and well-named.\nReferences to data and code work for everyone.\nPackage dependency is clear.\nCode will run the same every time, even if data values change.\nAnalysis process is well-explained and easy to read."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#principles-of-reproducibility-1",
    "href": "slides/week-1/w1-notebooks.html#principles-of-reproducibility-1",
    "title": "Quarto & Reproducibility",
    "section": "Principles of Reproducibility",
    "text": "Principles of Reproducibility\nYou can to send your code to someone else, and they can jump in and start working right away.\nThis means:\n\nFiles are organized and well-named.\nReferences to data and code work for everyone.\nPackage dependency is clear.\nCode will run the same every time, even if data values change.\nAnalysis process is well-explained and easy to read."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#paths",
    "href": "slides/week-1/w1-notebooks.html#paths",
    "title": "Quarto & Reproducibility",
    "section": "Paths",
    "text": "Paths\n\nA path describes where a certain file or directory lives.\n\n\n\n[1] \"/Users/czmann/Documents/teaching/stat331/stat331-calpoly-s25/slides/week-1\"\n\n\nThis file lives in my user files Users/…\n…on my account czmann/ …\n…in my Documents folder …\n…in a series of organized folders."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#absolute-vs.-relative-file-paths",
    "href": "slides/week-1/w1-notebooks.html#absolute-vs.-relative-file-paths",
    "title": "Quarto & Reproducibility",
    "section": "Absolute vs. Relative File Paths",
    "text": "Absolute vs. Relative File Paths\n\nabsolute file path: full path from the root directory on your computer\nrelative file path: path based on the relationship with a current working directory in terms of a hierarchichy of directories\n\n../ is the relative path to a parent directory\nexamples to folow!\n\n\n\n\n\n\n\n\n\nWarning\n\n\nAn absolute file path will only work on your computer!!\n\n\n[1] \"/Users/czmann/Documents/teaching/stat331/stat331-calpoly-s25/slides/week-1\""
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#absolute-vs.-relative-file-paths-1",
    "href": "slides/week-1/w1-notebooks.html#absolute-vs.-relative-file-paths-1",
    "title": "Quarto & Reproducibility",
    "section": "Absolute vs. Relative File Paths",
    "text": "Absolute vs. Relative File Paths"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#working-directories-in-r",
    "href": "slides/week-1/w1-notebooks.html#working-directories-in-r",
    "title": "Quarto & Reproducibility",
    "section": "Working Directories in R",
    "text": "Working Directories in R\n\nYour working directory is the folder that R “thinks it lives” in at the moment.\n\nIf you import or reference files, R will look in the working directory by default\nIf you save things you have created, they save to your working directory by default.\n\n\n\n\ngetwd()\n\n[1] \"/Users/czmann/Documents/teaching/stat331/stat331-calpoly-s25/slides/week-1\"\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nIf you are in practice of using setwd() to set a working directory in R FORGET THIS. We will be using other, better practice methods to set a working directory."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#reproducibility-pulling-it-all-together",
    "href": "slides/week-1/w1-notebooks.html#reproducibility-pulling-it-all-together",
    "title": "Quarto & Reproducibility",
    "section": "Reproducibility: Pulling it all together",
    "text": "Reproducibility: Pulling it all together\nRelative file paths allow someone else to run your code exactly (reproducibly!), as long as they\n\nhave everything organized the exact way that you do and\nthe same working directory\n\n\nEnter R Projects!"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#the-beauty-of-r-projects",
    "href": "slides/week-1/w1-notebooks.html#the-beauty-of-r-projects",
    "title": "Quarto & Reproducibility",
    "section": "The Beauty of R Projects",
    "text": "The Beauty of R Projects\n\nAn R Project is basically a “flag” planted in a certain directory.\n\n\n\nWhen you double click an .Rproj file, it:\n\n\n\n\nOpens RStudio\nSets the working directory to be wherever the .Rproj file lives.\nHas any files open or elements in your environment that you last saved.\nLinks to GitHub, if set up (more on that later!)"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#the-beauty-of-r-projects-1",
    "href": "slides/week-1/w1-notebooks.html#the-beauty-of-r-projects-1",
    "title": "Quarto & Reproducibility",
    "section": "The Beauty of R Projects",
    "text": "The Beauty of R Projects\n\n\nR Projects are great for reproducibility!\n\nYou can send anyone your folder with your .Rproj file and they will be able to run your code on their computer.\n\nR Projects are great for organization\n\nHaving a separate R project for every ..well.. project will keep your analyses separate and organized!\nWhenever you want to work on this class, double click the R Project you created to open everything up"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#scripts",
    "href": "slides/week-1/w1-notebooks.html#scripts",
    "title": "Quarto & Reproducibility",
    "section": "Scripts",
    "text": "Scripts\n\nScripts (File &gt; New File &gt; R Script) are files of code that are meant to be run on their own.\n\n\n\nScripts can be run in RStudio by clicking the Run button at the top of the editor window when the script is open.\nYou can also run code interactively in a script by:\n\nhighlighting lines of code and hitting run.\nplacing your cursor on a line of code and hitting run.\nplacing your cursor on a line of code and hitting ctrl + enter or command + enter."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#notebooks",
    "href": "slides/week-1/w1-notebooks.html#notebooks",
    "title": "Quarto & Reproducibility",
    "section": "Notebooks",
    "text": "Notebooks\nNotebooks are an implementation of literate programming.\n\nThey allow you to integrate code, output, text, images, etc. into a single document.\nE.g.,\n\nR Markdown notebook\nQuarto notebook\nJupyter notebook\n\n\nReproducibility!"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#what-is-markdown",
    "href": "slides/week-1/w1-notebooks.html#what-is-markdown",
    "title": "Quarto & Reproducibility",
    "section": "What is Markdown?",
    "text": "What is Markdown?\nMarkdown is a markup language.\n\nIt uses special symbols and formatting to make pretty documents.\nMarkdown files have the .md extension."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#what-is-quarto",
    "href": "slides/week-1/w1-notebooks.html#what-is-quarto",
    "title": "Quarto & Reproducibility",
    "section": "What is Quarto?",
    "text": "What is Quarto?\nQuarto uses regular Markdown, AND it can run and display R code.\n\n(Other languages, too!)\nQuarto files have the .qmd extension.\n\n\n\nQuarto is the next generation R Markdown"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto---rendering",
    "href": "slides/week-1/w1-notebooks.html#quarto---rendering",
    "title": "Quarto & Reproducibility",
    "section": "Quarto - Rendering",
    "text": "Quarto - Rendering\nTo take your .qmd file and make it look pretty, you have to render it."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#rendering-your-quarto-document",
    "href": "slides/week-1/w1-notebooks.html#rendering-your-quarto-document",
    "title": "Quarto & Reproducibility",
    "section": "Rendering your Quarto Document",
    "text": "Rendering your Quarto Document"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#rendering---what-happens",
    "href": "slides/week-1/w1-notebooks.html#rendering---what-happens",
    "title": "Quarto & Reproducibility",
    "section": "Rendering - What happens?",
    "text": "Rendering - What happens?\nWhen you render:\n\nYour file is saved.\nThe R code written in your .qmd file gets run in order.\n\nIt starts from scratch, even if you previously ran some of the code.\n\nA new file is created.\n\nIf your Quarto file is called “lab1.qmd”, then a file called “lab1.html” will be created.\nThis will be saved in the same folder as “lab1.qmd”."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#rendering---under-the-hood",
    "href": "slides/week-1/w1-notebooks.html#rendering---under-the-hood",
    "title": "Quarto & Reproducibility",
    "section": "Rendering - Under the hood",
    "text": "Rendering - Under the hood\nQuarto CLI (command line interface) orchestrates each step of rendering:\n\nProcess the executable code chunks with either knitr or jupyter.\nConvert the resulting Markdown file to the desired output."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto-components",
    "href": "slides/week-1/w1-notebooks.html#quarto-components",
    "title": "Quarto & Reproducibility",
    "section": "Quarto Components",
    "text": "Quarto Components"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto---front-matter",
    "href": "slides/week-1/w1-notebooks.html#quarto---front-matter",
    "title": "Quarto & Reproducibility",
    "section": "Quarto - Front Matter",
    "text": "Quarto - Front Matter\n\nConfiguration instructions: YAML\nBasic specifications like:\n\nDocument type\nTitle\nAuthor\nDate\n\nFancier specifications (you will explore this in Lab 1!)"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto---code",
    "href": "slides/week-1/w1-notebooks.html#quarto---code",
    "title": "Quarto & Reproducibility",
    "section": "Quarto - Code",
    "text": "Quarto - Code\n\n“code chunks”\noutput of code appears below the chunk\ngood practice: divide your code throughout a document into steps in different chunks\nyou specify how you want Quarto to handle code in each chunk in the final “rendered” document"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#r-code-options-in-quarto",
    "href": "slides/week-1/w1-notebooks.html#r-code-options-in-quarto",
    "title": "Quarto & Reproducibility",
    "section": "R Code Options in Quarto",
    "text": "R Code Options in Quarto\nR code chunk options are included at the top of each code chunk, prefaced with a #| (hashpipe).\n\nThese options control how the following code is run and reported in the final Quarto document.\nR code options can also be included in the front matter (YAML) and are applied globally to the document."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto---markdown",
    "href": "slides/week-1/w1-notebooks.html#quarto---markdown",
    "title": "Quarto & Reproducibility",
    "section": "Quarto - Markdown",
    "text": "Quarto - Markdown\n\nAnything other that code and output should be included as Markdown in a Quarto notebook\nSome Markdown text basics:\n\n*text* – makes italics\n**text** – makes bold text\n# – makes headers\n![ ]( ) – includes images or HTML links\n&lt; &gt; – embeds URLs\n\nFind more Markdown basics here."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#so-many-hashtags",
    "href": "slides/week-1/w1-notebooks.html#so-many-hashtags",
    "title": "Quarto & Reproducibility",
    "section": "#so many hashtags??",
    "text": "#so many hashtags??\n#’s are used in three different ways in Quarto documents…\n\n\nIn MARKDOWN, they define HEADERS\nIn YAML, they are preceded by a pipe | to define R CODE CHUNK OPTIONS\nIn R CODE, they define a COMMENT"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto-working-directory",
    "href": "slides/week-1/w1-notebooks.html#quarto-working-directory",
    "title": "Quarto & Reproducibility",
    "section": "Quarto Working Directory",
    "text": "Quarto Working Directory\n\nQuarto automatically sets the working directory to be where the notebook you are working in is located\nTHIS OVERRIDES R PROJECTS"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto-relative-file-paths",
    "href": "slides/week-1/w1-notebooks.html#quarto-relative-file-paths",
    "title": "Quarto & Reproducibility",
    "section": "Quarto & Relative File Paths",
    "text": "Quarto & Relative File Paths\n\nALWAYSNEVER 💥\n\n\n\nUse relative file paths!\nRemember that when you run code within a .qmd file or render it, the working directory is the directory where the .qmd file is saved.\n\n\n\n\nput something like this at the top of your .qmd file:\n\n\nsetwd(\"/User/chappelroan/Desktop/R_Class/Lab_1/\")\n\n\nSetting working directory by hand = ☠️\nAbsolute file paths = ☠️\nsome one else’s computer will have no idea “where” this working directory is"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#quarto-formats",
    "href": "slides/week-1/w1-notebooks.html#quarto-formats",
    "title": "Quarto & Reproducibility",
    "section": "Quarto Formats",
    "text": "Quarto Formats\nQuarto makes moving between outputs straightforward.\n\nAll that needs to change between these formats is a few lines in the front matter (YAML)!\n\n\n\nDocument\ntitle: \"Lesson 1\"\nformat: html\nPresentation\ntitle: \"Lesson 1\"\nformat: revealjs\n\nWebsite\nproject:\n  type: website\n\nwebsite: \n  navbar: \n    left:\n      - lesson-1.qmd"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#summary---highlights-of-quarto",
    "href": "slides/week-1/w1-notebooks.html#summary---highlights-of-quarto",
    "title": "Quarto & Reproducibility",
    "section": "Summary - Highlights of Quarto",
    "text": "Summary - Highlights of Quarto\n\n\nSupports reproducibility!\n\nCode, output, figures, and text all in one place\n\nConsistent implementation of pretty and handy features across different formats\n\ndocuments, presentations, websites, books, & more\n\nGuardrails that are helpful when learning:\n\nE.g., YAML completion, informative syntax errors, etc.\n\nSupport for other languages like Python, Julia, Observable, and more."
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#lab-1-introduction-to-quarto",
    "href": "slides/week-1/w1-notebooks.html#lab-1-introduction-to-quarto",
    "title": "Quarto & Reproducibility",
    "section": "Lab 1: Introduction to Quarto",
    "text": "Lab 1: Introduction to Quarto\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-1/w1-notebooks.html#to-do",
    "href": "slides/week-1/w1-notebooks.html#to-do",
    "title": "Quarto & Reproducibility",
    "section": "To do…",
    "text": "To do…\n\nLab 1: Introduction to Quarto\n\nDue Monday 4/7 at 11:59pm\n\nRead Chapter 2: Importing Data + Basics of Graphics\n\nCheck-in 2.1 + 2.2 due Tuesday (4/8) before class"
  },
  {
    "objectID": "practice-activities/pa3.html",
    "href": "practice-activities/pa3.html",
    "title": "PA 3: Identify the Mystery College 🏫",
    "section": "",
    "text": "Today you will use the dplyr package to clean some data. We will then use that cleaned data to figure out what college Margaret has been accepted to.\nDownload starter .qmd file"
  },
  {
    "objectID": "practice-activities/pa3.html#data-download-package-loading",
    "href": "practice-activities/pa3.html#data-download-package-loading",
    "title": "PA 3: Identify the Mystery College 🏫",
    "section": "Data Download & Package Loading",
    "text": "Data Download & Package Loading\nFirst, we declare our package dependencies and load the data.\n\n\n\n\n\n\nWarning\n\n\n\nThe data loading function read_csv() will give you an outpouring of helpful information about the dataset. If you do not see the word “error”, there is nothing to be concerned about.\n\n\n\nlibrary(tidyverse)\ncolleges &lt;- read_csv(\"https://www.dropbox.com/s/bt5hvctdevhbq6j/colleges.csv?dl=1\")\n\nTake a look at the variables in your downloaded data by running the following code. This code with the str (structure) function reports the data type for each column in the dataset.\n\nstr(colleges, give.attr = FALSE)\n\nspc_tbl_ [7,058 × 27] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ...1                         : num [1:7058] 1 2 3 4 5 6 7 8 9 10 ...\n $ INSTNM                       : chr [1:7058] \"Alabama A & M University\" \"University of Alabama at Birmingham\" \"Amridge University\" \"University of Alabama in Huntsville\" ...\n $ CITY                         : chr [1:7058] \"Normal\" \"Birmingham\" \"Montgomery\" \"Huntsville\" ...\n $ STABBR                       : chr [1:7058] \"AL\" \"AL\" \"AL\" \"AL\" ...\n $ ZIP                          : chr [1:7058] \"35762\" \"35294-0110\" \"36117-3553\" \"35899\" ...\n $ CONTROL                      : num [1:7058] 1 1 2 1 1 1 1 1 1 1 ...\n $ ADM_RATE                     : chr [1:7058] \"0.9027\" \"0.9181\" \"NULL\" \"0.8123\" ...\n $ SAT_AVG                      : chr [1:7058] \"929\" \"1195\" \"NULL\" \"1322\" ...\n $ TUITIONFEE_IN                : chr [1:7058] \"9857\" \"8328\" \"6900\" \"10280\" ...\n $ TUITIONFEE_OUT               : chr [1:7058] \"18236\" \"19032\" \"6900\" \"21480\" ...\n $ UGDS                         : chr [1:7058] \"4824\" \"12866\" \"322\" \"6917\" ...\n $ REGION                       : num [1:7058] 5 5 5 5 5 5 5 5 5 5 ...\n $ DEP_INC_PCT_H2               : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ MD_INC_WDRAW_2YR_TRANS_YR4_RT: chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ IND_COMP_4YR_TRANS_YR4_RT    : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ SD_EARN_WNE_P10              : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ FEMALE_WDRAW_4YR_TRANS_YR6_RT: chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ LO_INC_COMP_2YR_TRANS_YR3_RT : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ NOLOAN_COMP_ORIG_YR4_RT      : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ OPENADMP                     : chr [1:7058] \"2\" \"2\" \"1\" \"2\" ...\n $ PELL_COMP_4YR_TRANS_YR3_RT   : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ DEATH_YR2_RT                 : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ NOLOAN_UNKN_ORIG_YR2_RT      : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ NOT1STGEN_WDRAW_ORIG_YR6_RT  : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ HI_INC_YR8_N                 : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ CUML_DEBT_P90                : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ...\n $ C100_L4                      : chr [1:7058] \"NULL\" \"NULL\" \"NULL\" \"NULL\" ..."
  },
  {
    "objectID": "practice-activities/pa3.html#data-cleaning",
    "href": "practice-activities/pa3.html#data-cleaning",
    "title": "PA 3: Identify the Mystery College 🏫",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nNow we will clean the data. Alas, each of the R chunks in this section will cause an error and / or do the desired task incorrectly. Even the chunks that run without error are not correct! You will need to find the mistake and correct it to complete the intended action.\nStep 1: There are too many variables in this data set. We don’t need all of them. Narrow your data set down to only:\n\nINSTNM name of the institution\nCITY city, STABBR state, and ZIP ZIP code of the institution\nADM_RATE admissions rate\nSAT_AVG average SAT score\nUGDS number of undergraduate students\nTUITIONFEE_IN in- and TUITIONFEE_OUT out-of-state tuition\nCONTROL Whether the school is public or private\nREGION region of the school.\n\n\ncolleges_clean &lt;- colleges | &gt;  \n  select(INSTNM, CITY, STABBR, ZIP,\n         ADM_RATE, SAT_AVG, UGDS,\n         TUITIONFEE_IN, TUITIONFEE_OUT\n         CONTROL, REGION) \n\nError in parse(text = input): &lt;text&gt;:1:30: unexpected '&gt;'\n1: colleges_clean &lt;- colleges | &gt;\n                                 ^\n\n\nStep 2: Remove the schools that are for-profit (category 3), keeping public (category 1) and private schools (category 2).\n\ncolleges_clean &lt;- colleges_clean |&gt; \n  filter(CONTROL == 1, CONTROL == 2)\n\nError: object 'colleges_clean' not found\n\n\nStep 3: Adjust the appropriate variables to be numeric, using as.numeric().\n\ncolleges_clean &lt;- colleges_clean |&gt; \n  mutate(TUITIONFEE_IN  = numeric(TUITIONFEE_IN),\n         TUITIONFEE_OUT = numeric(TUITIONFEE_OUT),\n         SAT_AVG        = numeric(SAT_AVG),\n         UGDS           = numeric(UGDS),\n         ADM_RATE       = numeric(ADM_RATE)) \n\nError: object 'colleges_clean' not found\n\n\nStep 4: Adjust the appropriate variables to be factors, using as.factor().\n\n\n\n\n\n\nNote\n\n\n\nWe will talk more about special data types (including factors) in a few weeks.\n\n\n\ncolleges_clean &lt;- colleges_clean |&gt;\n  mutate(CONTROL = as.character(CONTROL),\n         REGION  = as.character(REGION))\n\nError: object 'colleges_clean' not found\n\n\nStep 5: Create a new variable called TUITION_DIFF which contains the difference between out-of-state and in-state costs.\n\ncolleges_clean |&gt; \n    TUITION_DIFF = TUITIONFEE_OUT - TUITIONFEE_IN\n\nError in TUITION_DIFF: The pipe operator requires a function call as RHS (&lt;input&gt;:2:5)\n\n\nStep 6: Create a new variable called TOTAL_IN which contains the total amount of money made from tuition per year. (Note, this is just an approximation by mutliplying the number of undergrads by the in-state tuition)\n\ncolleges_clean &lt;- colleges_clean |&gt; \n    select(TOTAL_IN = UGDS x TUITIONFEE_IN)\n\nError in parse(text = input): &lt;text&gt;:2:28: unexpected symbol\n1: colleges_clean &lt;- colleges_clean |&gt; \n2:     select(TOTAL_IN = UGDS x\n                              ^\n\n\nStep 7: Remove every row with missing data.\n\n\n\n\n\n\nWarning\n\n\n\nThis is not always a great idea! Usually, even if some of the information is missing, we don’t want to throw out the entire row. This time, however, we’ll be lazy.\n\n\n\ncolleges_clean &lt;- colleges_clean |&gt; \n  drop.na()\n\nError in drop.na(colleges_clean): could not find function \"drop.na\"\n\n\nLastly, notice that each of these steps started with\n\ncolleges_clean &lt;- colleges_clean |&gt; ...\n\nThat is pretty redundant! Instead, we could perform all these tasks as one long “pipeline.”\nStep 8: Combine your (fixed) code chunks into a single code chunk that carries out all of the steps necessary to clean the data and save it as colleges_clean.\n\n\n\n\n\n\nTip\n\n\n\nThink about coding efficiency – you should not have multiple calls to the same function!\n\n\n\n# Code combining ALL of your previous steps into ONE pipeline"
  },
  {
    "objectID": "practice-activities/pa1.html",
    "href": "practice-activities/pa1.html",
    "title": "PA 1: Find the Mistakes",
    "section": "",
    "text": "Today you will be creating and manipulating vectors, lists, and data frames to uncover a top secret message.\nSome advice:"
  },
  {
    "objectID": "practice-activities/pa1.html#access",
    "href": "practice-activities/pa1.html#access",
    "title": "PA 1: Find the Mistakes",
    "section": "Access",
    "text": "Access\nYou can access PA1: Find the Mistakes in RStudio in one of two ways:\n\nClick here to access a Posit Cloud project.\n\n\nNote: if you do not have a Posit Cloud account, you will be asked to create one.\nNote: make sure you save a permanent version!\n\n\nIf you have already installed R, RStudio, and Quarto, you can download the practice activity template here.\n\n\nMake sure to move this from your Downloads folder into your stat-331/practice-activities folder (or equivalent)!"
  },
  {
    "objectID": "practice-activities/pa1.html#part-one-setup",
    "href": "practice-activities/pa1.html#part-one-setup",
    "title": "PA 1: Find the Mistakes",
    "section": "Part One: Setup",
    "text": "Part One: Setup\nEach of the following R chunks will cause one or more errors and / or do the desired task incorrectly. Find the mistake, and correct it to complete the intended action.\n\nCreate vectors containing the upper case letters, lower case letters, and some punctuation marks.\n\n\nlower_case &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\",\n                \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\")\nupper_case &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\" \"I\", \"J\", \"K\", \"L\", \"M\",\n                \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\")\npunctuation &lt;- c(\".\", \",\", \"!\", \"?\", \"'\", '\"', \"(\", \")\", \" \", \"-\", \";\", \":\")\n\nError in parse(text = input): &lt;text&gt;:3:56: unexpected string constant\n2:                 \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\")\n3: upper_case &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\" \"I\"\n                                                          ^\n\n\n\nMake one long vector containing all the symbols.\n\n\nmy_symbols &lt;- cbind(lower_case, upper_case, punctuation)\n\nError: object 'lower_case' not found\n\n\n\nTurn the my_symbols vector into a data frame, with one column named “Symbol”.\n\n\nmy_symbols &lt;- dataframe(Symbol = my_symbols)\n\nError in dataframe(Symbol = my_symbols): could not find function \"dataframe\"\n\n\n\nFind the total number of symbols we have in our data frame.\n\n\nlen &lt;- length(my_symbols)\n\nError: object 'my_symbols' not found\n\n\n\nCreate a new variable in your dataframe that assigns a number to each symbol.\n\n\nmy_symbols%Num &lt;- 1:len\n\nError in parse(text = input): &lt;text&gt;:1:11: unexpected input\n1: my_symbols%Num &lt;- 1:len\n              ^"
  },
  {
    "objectID": "practice-activities/pa1.html#part-two-decoding-the-secret-message.",
    "href": "practice-activities/pa1.html#part-two-decoding-the-secret-message.",
    "title": "PA 1: Find the Mistakes",
    "section": "Part Two: Decoding the secret message.",
    "text": "Part Two: Decoding the secret message.\nThis chunk will load up the encoded secret message as a vector.\n\nlibrary(readr)\ntop_secret &lt;- read_csv(\"https://www.dropbox.com/s/k72h1zewk4gtqep/PA_Secret_Code?dl=1\", \n                       col_names = FALSE)$X1\n\nBy altering this top secret set of numbers, you will be able to create a message. Write your own code to complete the steps, in the order given below.\nHint: To update a vector after performing an operation, you overwrite the existing object with the updated version. This looks something like this:\nx &lt;- x + 12,\nwhere the original value(s) in x have had 12 added to them, and the resulting values are put back in to the object named x.\nBe careful not to overwrite more than you intend. If this happens, go back and re-read in the raw data and run and any subsequent code chunks to start fresh with the top_secret vector.\n\nAdd 14 to every number (completed for you!)\n\n\n## Code completed for you\ntop_secret &lt;- top_secret + 14\n\n\nMultiply every number by 18, then subtract 257 (watch your order of operations!)\n\n\n## Code to carry out step 1\n\n\nUse the exp() function to exponentiate every number.\n\n\n## Code to carry out step 2\n\n\nSquare every number.\n\n\n## Code to carry out step 3\n\nCheckpoint: Headquarters has informed you that at this stage of decoding, there should be 352 numbers in the secret message that are below 17. The code below verifies that this is true for your top_secret object!\nHint: This is what is called a “relational” comparison, where you compare an object to a number and R will give you a vector of TRUEs and FALSEs based on whether the comparison is / is not met. You can then use these TRUEs and FALSEs as numbers, since TRUE = 1 and FALSE = 0 in R land.\n\n# Write code to verify that there are 352 numbers with values **below** 17\n\nNext, carry out the following steps:\n\nTurn your vector of numbers into a matrix with 5 columns. (I would recommend naming this something different than top_secret and informative such as secret_mat.)\n\n\n## Write code to carry out step 4.\n\n\nSeparately from your top secret numbers, create a vector of all the even numbers between 1 and 382. Name it evens. That is, evens should contain 2, 4, 6, 8 …, 382.\n\n\n## Write code to carry out step 5.\n\n\nSubtract the “evens” vector from the first column of your secret message matrix.\n\n\n## Write code to carry out step 6.\n\n\nSubtract 100 from all numbers in the 18-24th rows of the 3rd column of your secret message matrix.\n\n\n## Complete the code to carry out step 7.\n\n\nMultiply all numbers in the 4th and 5th column of your secret message matrix by 2.\n\n\n## Code to carry out step 8.\n\n\nTurn your secret message matrix back into a vector.\n\n\n## Write code to carry out step 9.\n\nCheckpoint: Headquarters has informed you that at this stage of decoding, all numbers in indices 500 and beyond are below 100. The code below verifies that this is true for your top_secret object!\n\n# Write code to verify that indices 500 and beyond have values **below** 100\n\n\nTake the square root of all numbers in indices 38 to 465.\nUse the round() function to round all numbers to the nearest whole number.\nReplace all instances of the number 39 with 20.\n\n\nThis step requires another relational comparison, but this time it is equality. Equality in R is checked with a double equal sign rather than a single equal sign!\n\nCheckpoint: Headquarters has informed you that your final message should have 344 even numbers.\nHint: Checking for divisibility is an interesting operation that isn’t done much in R. Modulus is the operation you are interested in, where you are checking for whether the numbers are divisible by 2, with no remainder. See what you can find about modulus in R!\n\n# Code to verify how many even numbers are in your top_secret vector\n# Should be 344!"
  },
  {
    "objectID": "practice-activities/pa1.html#part-three-the-secret-message",
    "href": "practice-activities/pa1.html#part-three-the-secret-message",
    "title": "PA 1: Find the Mistakes",
    "section": "Part Three: The secret message!",
    "text": "Part Three: The secret message!\nUse your final vector of numbers as indices for my_symbols to discover the final message, by running the following code. Note: if your vector of numbers is not named top_secret at this point, change the code below appropriately to use your correct vector!\n\nstringr::str_c(my_symbols$Symbol[top_secret], collapse = \"\")\n\nError: object 'my_symbols' not found\n\n\nGoogle the first line of this message, if you do not recognize it, to see what poem it is.\nYou will enter your answer in the PA1 Canvas assignment."
  },
  {
    "objectID": "labs/lab2/lab2-ggplot.html",
    "href": "labs/lab2/lab2-ggplot.html",
    "title": "Lab 2: Exploring Rodents with ggplot2",
    "section": "",
    "text": "Seeking Help\n\n\n\nPart of learning to program is learning from a variety of resources. Thus, I expect you will use resources that you find on the internet. There is, however, an important balance between copying someone else’s code and using their code to learn. Therefore, if you use external resources, I want to know about it. You can “inform” me of any resources you used by pasting the link to the resource in a code comment next to where you used that resource.\nAdditionally, you are permitted and encouraged to work with your peers as you complete lab assignments, but you are expected to do your own work. Copying from each other is cheating, and letting people copy from you is also cheating. Please don’t do either of those things.\nDownload starter .qmd file here.\nDownload the data - surveys.csv - file here."
  },
  {
    "objectID": "labs/lab2/lab2-ggplot.html#scatterplot",
    "href": "labs/lab2/lab2-ggplot.html#scatterplot",
    "title": "Lab 2: Exploring Rodents with ggplot2",
    "section": "Scatterplot",
    "text": "Scatterplot\n\n# Scatterplot code for question s 4-8! \n\n4. First, let’s create a scatterplot of the relationship between weight (on the \\(x\\)-axis) and hindfoot_length (on the \\(y\\)-axis).\nWe can see there are a lot of points plotted on top of each other. Let’s try and modify this plot to extract more information from it.\n5. Let’s add transparency (alpha) to the points, to make the points more transparent and (possibly) easier to see.\nDespite our best efforts there is still a substantial amount of overplotting occurring in our scatterplot. Let’s try splitting the dataset into smaller subsets and see if that allows for us to see the trends a bit better.\n6. Facet your scatterplot by species.\n7. No plot is complete without axis labels and a title. Include reader friendly labels and a title to your plot.\nIt takes a larger cognitive load to read text that is rotated. It is common practice in many journals and media outlets to move the \\(y\\)-axis label to the top of the graph under the title.\n8. Specify your \\(y\\)-axis label to be empty and move the \\(y\\)-axis label into the subtitle. You may overwrite your code from Q7."
  },
  {
    "objectID": "labs/lab2/lab2-ggplot.html#boxplots",
    "href": "labs/lab2/lab2-ggplot.html#boxplots",
    "title": "Lab 2: Exploring Rodents with ggplot2",
    "section": "Boxplots",
    "text": "Boxplots\n9. Sketch out (by hand or using Excalidraw) a game plan for creating side-by-side boxplots to visualize the distribution of weight within each species. Include an image of your game plan. This can take on your own flavor! The ideas is that you are thinking before coding. I recommend saving this in the same folder as your .qmd file.\n \n\n# Boxplot code for question 10 - 15!\n\n10. Implement your game plan to create side-by-side boxplots to visualize the distribution of weight within each species.\nA fundamental complaint of boxplots is that they do not plot the raw data. However, with ggplot we can add the raw points on top of the boxplots!\n11. Add another layer to your previous plot that plots each observation.\nAlright, this should look less than optimal. Your points should appear rather stacked on top of each other. To make them less stacked, we need to jitter them a bit, using geom_jitter().\n12. Remove the previous layer and include a geom_jitter() layer instead. (You can overwrite your code for Q11)\nThat should look a bit better! But its really hard to see the points when everything is black.\n13. Set the color aesthetic in geom_jitter() to change the color of the points and add set the alpha aesthetic to add transparency.\n\n\n\n\n\n\nNote\n\n\n\nYou are welcome to use whatever color you wish! Some of my favorites are “orange3” and “steelblue”.\n\n\nGreat! Now that you can see the points, you should notice something odd: there are two colors of points still being plotted. Some of the observations are being plotted twice, once from geom_boxplot() as outliers and again from geom_jitter()!\n14. Inspect the help file for geom_boxplot() and see how you can remove the outliers from being plotted by geom_boxplot(). Make this change in your code!\nSome small changes can make big differences to plots. One of these changes are better labels for a plot’s axes and legend.\n15. Modify the \\(x\\)-axis and \\(y\\)-axis labels to describe what is being plotted. Be sure to include any necessary units! You might also be getting overlap in the species names – use theme(axis.text.x = ____) or theme(axis.text.y = ____) to turn the species axis labels 45 degrees. (You will need to look at the documentation or Google to find the syntax for this!)\nSome people (and journals) prefer for boxplots to be stacked with a specific orientation! Let’s practice changing the orientation of our boxplots.\n16. Copy-paste your boxplot code from above. Flip the orientation of your boxplots. If you created horizontally stacked boxplots, your boxplots should now be stacked vertically. If you had vertically stacked boxplots, you should now stack your boxplots horizontally!\n\n# Copy-paste boxplot code. Then modify for question 16!\n\nNotice how vertically stacked boxplots make the species labels more readable than horizontally stacked boxplots. This is good practice!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Computing in R",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the quarter. Note that this schedule will be updated as the quarter progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDay\nTopic / Reading\nSlides\nStarter Notes\nPractice Activity\nLab\n\n\n\n\n1\nTue, 4/1\n1: Introduction\nSyllabus & Intro to R\nWeek 1\nPA 1\n\n\n\n\nThu, 4/3\n\nIntro to Quarto\n\n\nLab 1\n\n\n2\nTue, 4/8\n2: Basics of Graphics\nImporting Data + Graphics with ggplot2\nWeek 2\nPA 2\n\n\n\n\nThu, 4/10\n\nMore Graphics!\n\n\nLab 2\n\n\n3\nTue, 4/15\n3: Data Cleaning + Manipulation\nData Cleaning with dplyr\nWeek 3\nPA 3\n\n\n\n\nThu, 4/17\nData Feminism: The Numbers Don’t Speak for Themselves\nExtending dplyr + Data Ethics\n\n\nLab 3\n\n\n4\nTue, 4/22\n4: Data Joins + Transformations\nData Joins + Pivots\nWeek 4\nPA 4\n\n\n\n\nThu, 4/24\n\nFactor Variables\n\n\nLab 4\n\n\n5\nTue, 4/29\n5: Special Data Types\nStrings\n\nPA 5.1\n\n\n\n\nThu, 5/1\n\nDates\n\nPA 5.2\nLab 5\n\n\n6\nTue, 5/6\n6: Version Control\nVersion Control\n\nPA 6\n\n\n\n\nThu, 5/8\n\nMidterm Exam\n\n\n\n\n\n7\nTue, 5/13\n7: Writing Functions\nFunctions\n\nPA 7\n\n\n\n\nThu, 5/15\n\nMore Functions\n\n\nLab 7\n\n\n8\nTue, 5/20\n8: Iteration and Simulation\nIteration\n\nPA 8.1\n\n\n\n\nThu, 5/22\n\nSimulation + Tables\n\nPA 8.2\nLab 8\n\n\n9\nTue, 5/27\n\nNO CLASS\n\n\n\n\n\n\nThu, 5/29\n9: Linear Regression\nLinear Regression\n\nPA 9\nLab 9\n\n\n10\nTue, 6/3\nTBD\nSimulation Extensions\n\nPA 10\n\n\n\n\nThu, 6/5\n\nWrap-Up",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "course-info/discord-instructions.html",
    "href": "course-info/discord-instructions.html",
    "title": "Course Discord Instructions",
    "section": "",
    "text": "We’ll be using Discord to interact with our peers and group members.\nDiscord is a platform for text chatting, voice chatting, and screen sharing."
  },
  {
    "objectID": "course-info/discord-instructions.html#join-the-server",
    "href": "course-info/discord-instructions.html#join-the-server",
    "title": "Course Discord Instructions",
    "section": "1 Join the server",
    "text": "1 Join the server\nJoin the Stat 331/531 Server to start experimenting with the interface.\nWhen you join the server, you will be given some suggestions to get started.\n\nI recommend you click through these - and in particular, it is probably a good idea to download the desktop version of Discord, and perhaps to install it on your phone if you wish."
  },
  {
    "objectID": "course-info/discord-instructions.html#set-up-your-account",
    "href": "course-info/discord-instructions.html#set-up-your-account",
    "title": "Course Discord Instructions",
    "section": "2 Set up your account",
    "text": "2 Set up your account\n\nVerify your email\nTo use this Discord server, you must have a verified email.\nNobody (including your professors) will be able to see this email, and it does not have to be your Cal Poly email. This is simply to keep the server from being overrun by temporary accounts.\n\n\nCreate your identity\nThe first thing you should do is decide what name and picture you would like to use.\n\nI would like to strongly encourage you to use your real name and picture, so that everyone can get to know you. This also helps me know who I am talking to! However, if you prefer to remain anonymous, you are free to do so.\n\n(Please do not be like Regina and use the name of another student, however!\nThis kind of impersonation will result in a permanent ban from the server.)\n\n\nDecide about privacy and notifications\nThe default settings on the channel are probably just fine for you.\nFeel free to make any changes that work for you, though.\nYou can change your message notifications:\n\nYou can edit your privacy settings, although most things are already private:"
  },
  {
    "objectID": "course-info/discord-instructions.html#using-the-channels",
    "href": "course-info/discord-instructions.html#using-the-channels",
    "title": "Course Discord Instructions",
    "section": "3 Using the Channels",
    "text": "3 Using the Channels\nThe server is made up of many channels. Some are text chatrooms, while some are “Voice Channels” that connect you via audio to everyone else in the channel.\n\nText Channels\nUse the #general channel for anything and everything:\n\nIf your question is about course logistics, rather than the material itself, consider using the #class-logistics channel:\n\nYou can use the specific weekly channels to ask questions about the material…\n\n… or the specific lab assignment.\n\nNotice that you can use tick marks (```), like in Markdown, to make your code appear in a formatted code box.\n\n\nPrivate messages\nIt is also easy to send private messages, to your professor or to each other. These private messages can also easily be used to launch a private video chat and / or screen sharing."
  },
  {
    "objectID": "course-info/discord-instructions.html#creating-your-own-server",
    "href": "course-info/discord-instructions.html#creating-your-own-server",
    "title": "Course Discord Instructions",
    "section": "4 Creating your own server",
    "text": "4 Creating your own server\nLast but not least - for the teams you are a part of, you may want to use Discord to communicate with each other about the weekly assignments. You can do this by creating your own server! You can easily hop between servers during work parties, to ask each other questions or just to take a break and chat about life."
  },
  {
    "objectID": "course-info/course-resources.html",
    "href": "course-info/course-resources.html",
    "title": "R Resources",
    "section": "",
    "text": "Tip\n\n\n\nClick on the link to access the R Cheatsheet related to a specific topic / package!\n\n\n\nWeekly R Cheatsheets\nWeek 1\n\nRStudion IDE\nQuarto\nBase R\nGit & GitHub\n\nWeek 2\n\nData Visualization with ggplot2\nData Import with readr\n\nWeek 3\n\nData Wrangling with dplyr\n\nWeek 4\n\nData Tidying with tidyr\nFactors with forcats\n\nWeek 5\n\nDates with lubridate\nStrings with stringr\nRegular Expressions\n\nWeek 7\n\nTidy Evaluation\n\nWeek 8\n\nIteration with purrr",
    "crumbs": [
      "Course information",
      "R Resources"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html",
    "href": "course-info/syllabus-w25.html",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "",
    "text": "Dr. Charlotte Zilber Mann\nYou can call me Professor, Professor/Prof. C. or Dr. C.\n Email: czmann@calpoly.edu\n Office: Building 25 Office 201\nEmail:\n\nOnly email me with your @calpoly.edu email – I cannot respond to other email addresses\nStart your email subject line with “[STAT 331]”\nI will do my best to respond within 24 hours during the week\nIf you send me an email past 7pm or on the weekend, I will likely not respond until the morning of the next working day\nYou should only email me about things that relate to you as an individual. Any other questions should be posted on the course Discord (more details below).\n\nCourse Discord Page:\nFor questions of general interest, such as course clarifications or conceptual questions, please use the course Discord page (you will join this Week 1). If you have a question – someone else in class does too! I encourage you all to respond to each other. I will do my best to check Discord at least twice each weekday during working hours (8-6) to ensure that questions are being answered accurately.\nI encourage you to give your post a concise and informative initial sentence, so that other people can find it. For example, “How do I color bars in a barplot with ggplot?” is a better opening sentence than “help with plotting”.\nYou may post snippets of your code and errors on Discord, but please do not post full solutions to lab assignments.\n While your posts are not anonymous, in this case there is no such thing as a bad question!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#communication",
    "href": "course-info/syllabus-w25.html#communication",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "",
    "text": "Dr. Charlotte Zilber Mann\nYou can call me Professor, Professor/Prof. C. or Dr. C.\n Email: czmann@calpoly.edu\n Office: Building 25 Office 201\nEmail:\n\nOnly email me with your @calpoly.edu email – I cannot respond to other email addresses\nStart your email subject line with “[STAT 331]”\nI will do my best to respond within 24 hours during the week\nIf you send me an email past 7pm or on the weekend, I will likely not respond until the morning of the next working day\nYou should only email me about things that relate to you as an individual. Any other questions should be posted on the course Discord (more details below).\n\nCourse Discord Page:\nFor questions of general interest, such as course clarifications or conceptual questions, please use the course Discord page (you will join this Week 1). If you have a question – someone else in class does too! I encourage you all to respond to each other. I will do my best to check Discord at least twice each weekday during working hours (8-6) to ensure that questions are being answered accurately.\nI encourage you to give your post a concise and informative initial sentence, so that other people can find it. For example, “How do I color bars in a barplot with ggplot?” is a better opening sentence than “help with plotting”.\nYou may post snippets of your code and errors on Discord, but please do not post full solutions to lab assignments.\n While your posts are not anonymous, in this case there is no such thing as a bad question!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-logistics",
    "href": "course-info/syllabus-w25.html#course-logistics",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Logistics",
    "text": "Course Logistics\nClass Meeting Times: Tuesdays / Thursdays\n\nSection 70: 9:10am - 11:00am\nSection 71: 12:10pm - 2:00pm\n\nRoom: - Section 70: 38-122 (Math & Science) - Section 71: 180-272 (Baker Center - Math & Science)\nOffice Hours are held in my office (25-201) during the following times:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOffice hours are for you! During this time, I am available to talk about anything related to the course.\nOffice hours are also helpful for me… This is my chance to get to know you all better and also get a good idea of what is most challenging and most interesting to you.\nFriday office hours will be remote by default, but can be in-person on request.\nSee this resource for ways that students use office hours.\nOne thing I will not do during office hours is tell you whether an answer to a problem is “correct” or not. We can talk through your thinking that led to your solution, but will leave the final assessment to once you have submitted an assignment.\nNote that office hours are not just for when you have content questions. Stop by to introduce yourself, ask questions about the broader field of statistics, or share what you are working on!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-description",
    "href": "course-info/syllabus-w25.html#course-description",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Description",
    "text": "Course Description\nStat 335/531 provides you with an introduction to programming for data and statistical analysis. The course covers basic programming concepts necessary for statistics, good computing practice, and use of built-in functions to complete basic statistical analyses.\nPrerequisites\nEntrance to STAT 331/531 requires successful completion of:\n\na Stat II qualifying course, and\nan introductory programming course.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#learning-objectives",
    "href": "course-info/syllabus-w25.html#learning-objectives",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThis course will teach you the foundations of statistical computing principles in the language of R.\nAfter taking this course, you will be able to:\n\nWork with the RStudio Integrated development environment (IDE) and quarto documents.\nImport, manage, and clean data from a wide variety of data sources.\nVisualize and summarize data for informative exploratory data analysis and presentations.\nWrite efficient, well-documented, and tidy R code.\nProgram random experiments and simulations from probability models.\n\nAdditionally, it is my hope that you will learn to:\n\nExtend your R skills independently through documentation and online resources.\nBe thoughtful, deliberate, and ethical in your use of R and similar tools.\nUse R to be playful, creative, and fun!\nContribute to and participate in the R Open Source Community.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-materials",
    "href": "course-info/syllabus-w25.html#course-materials",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Materials",
    "text": "Course Materials\nCourse Webpage (Canvas)\nAll course material will be made available on our Canvas page, including check-ins, practice activities, lab assignments, challenges, review questions, and selected solutions. Canvas will also contain detailed weekly schedules throughout the term. You are responsible for checking the Canvas page on a regular basis.\nI will also be posting material on this website for easy access to materials. Please note that this website does not include deadlines and all material will additionally be posted to Canvas. Canvas will always contain the most updated information about course deadlines and details, so always defer to these.\nTextbook\n https://manncz.github.io/stat331-calpoly-text/.\nThere is an abundance of free online resources for learning programming and R. Therefore, the primary text for this course is a compilation of various resources - it is available online for free. It is a work in progress, so expect changes and updates throughout the course.\nThis text was constructed by Dr. Emily Robinson and was modified from material by Dr. Susan VanderPlas. See Statistical Computing using R and Python for her course book with integration of content and videos from Dr. Allison Theobold and Dr. Kelly Bodwin.\nIn addition, you may find it useful to reference some of the following resources that Dr. Robinson consulted while assembling the text. Most are available online for free.\n\nR for Data Science (2nd edition)\nModern Dive\nIntroduction to Modern Statistics\nAdvanced R\n\nComputing\n Although you may always work on the computers in the classroom, I strongly recommend that you use your own personal laptop for this course if you have one.\nWe will (obviously) be using the R statistical software throughout this course. In addition, you are required to use RStudio, a companion integrated developer environment (IDE). Both R and RStudio are freely available. Download instructions are available on Canvas.\n\n\n\n\n\n\nWarning\n\n\n\nChromebooks and iPads will not be sufficient to use R. If this requirement is limiting for you, please contact me ASAP.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#class-schedule-topic-outline",
    "href": "course-info/syllabus-w25.html#class-schedule-topic-outline",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Class Schedule & Topic Outline",
    "text": "Class Schedule & Topic Outline\nThis schedule is tentative and subject to change.\n\n\n\n\n\nNote: Tuesday, May 27th will follow a Monday class schedule.\n\n\n\n\n\n\n\nTentative schedule of class topics and important due dates\n\n\nDate\nTopic\n\n\n\n\nApr 1, Apr 3\nIntroduction to R\n\n\nApr 8, Apr 10\nBasics of Graphics\n\n\nApr 15, Apr 17\nData Cleaning and Manipulation\n\n\nApr 22, Apr 24\nData Transformations + Factors\n\n\nApr 29, May 1\nSpecial Data Types\n\n\nMay 6\nVersion Control\n\n\nMay 8\nMidterm Exam\n\n\nMay 13, May 15\nFunctions\n\n\nMay 20, May 22\nFunctional Programming\n\n\nMay 29\nSimulation\n\n\nJun 3, Jun 5\nTBA\n\n\nJun 6\nProject Final Report Due\n\n\nJun 10\nFinal Exam (70)\n\n\nJun 12\nFinal Exam (71)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#assessments",
    "href": "course-info/syllabus-w25.html#assessments",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Assessments",
    "text": "Assessments\n\nGeneral Evaluation Criteria\nIn every assignment, discussion, and written component of this class, you are expected to demonstrate that you are intellectually engaging with the material. I will evaluate you based on this engagement, which means that technically correct but low effort answers which do not demonstrate engagement or understanding will receive no credit.\nWhen you answer questions in this class, your goal is to show that you either understand the material or are actively engaging with it. If you did not achieve this goal, then your answer is incomplete, regardless of whether or not it is technically correct. This is not to encourage you to add unnecessary complexity to your answer - simple, elegant solutions are always preferable to unwieldly, complex solutions that accomplish the same task.\nWhile this is not an English class, grammar and spelling are important, as is your ability to communicate technical information in writing; both of these criteria will be used in addition to assignment-specific rubrics to evaluate your work.\n\n\nFormative Assessments\n\nCheck-ins\nEach week, you will find short Check-In questions or tasks throughout the text to make sure you are prepared for class that week. Check-Ins are based on the material in each week’s reading from the textbook. Note that the Canvas Check-in quizzes can be submitted two two times and your highest score will be kept, so you should get close to 100% on this part of the course!\n\nCheck-ins are (typically) due Tuesdays before class.\n\nSection 70: 9:00am\nSection 71: 12:00pm\n\n\n\n\nPractice Activities\nMost Tuesdays’s, you will be given a Practice Activity to complete, to get the hang of the week’s necessary R skills. These activities will always result in a single, straightforward correct answer, that you will submit via Canvas (two attempts, the average score being kept).\nSince these activities are intended to be your first attempt at new skills, they are meant to be done with help from me and your peers. Therefore, you will always be given some time in class to work on them.\n\nPractice Activities are (typically) due Thursdays before class.\n\nSection 70: 9:00am\nSection 71: 12:00pm\n\n\n\n\nLab Assignments\nYour typical homework assignments will be weekly labs. You will follow each lab’s instructions to complete tasks in R and submit a rendered .html Quarto document to Canvas.\nMost weeks, there will be class time on Wednesdays dedicated to working on completing lab assignments. While you will work with peers during class time on Thursdays, you will be expected to submit your own individual work for the final submission.\n\nLabs are (typically) due on Mondays (of the following week) at 11:59pm.\n\n\n\n\nEvaluative Assessments\n\nFinal Project\nThere will be a data analysis project to be completed throughout the second half of the term. You will work in a group of 3-4 people. Each group will produce a written project report covering linear regression and model simulation. More information will follow on Canvas.\n\n\nExams\nThere will be a midterm exam and a final exam. The midterm will have both in-class and take-home portions. The final will be entirely in-class during our scheduled final exam slot. More information will follow.\n\n\n\n\n\nCourse Grade\nYour grade in STAT 331/531 will contain the following components:\n\n\n\nAssignments\nWeight\n\n\n\n\nCheck-ins\n5%\n\n\nPractice Activities\n10%\n\n\nLab Assignments\n30%\n\n\nMidterm Exam\n15%\n\n\nFinal Project\n15%\n\n\nFinal Exam\n25%\n\n\n\nLower bounds for grade cutoffs are shown in the following table. It is possible that I could lower any of the grade cutoffs. You will only have the opportunity for grade rounding if you completed all assignments in the course. \n\n\n\n\n\n\n\nLetter grade\nX +\nX\nX -\n\n\n\n\nA\n.\n93\n90\n\n\nB\n87\n83\n80\n\n\nC\n77\n73\n70\n\n\nD\n67\n63\n60\n\n\nF\n&lt;60\n\n\n\n\n\nInterpretation of this table:\n\nA grade of 85 will receive a B.\nA grade of 77 will receive a C+.\nA grade of 70 will receive a C-.\nAnything below a 60 will receive an F.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-policies",
    "href": "course-info/syllabus-w25.html#course-policies",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Policies",
    "text": "Course Policies\n\nAttendance & Participation\nI do not take formal attendance in this class. However, it is my expectation that you remain in class and on task until you have finished all your activities and assignments.\nIf you are feeling ill, please do not come to class.\nHere’s what you should do if you do miss a class:\n\nTalk to a classmate to figure out what information you missed\nCheck Canvas for any necessary handouts or changes to assignments\nPost on Discord with any questions you have after reviewing notes and handouts\n\nIf you miss a bunch of classes, please come talk to me. I’m working from the assumption that you care and are trying, but something is getting in your way (health issues? college stress? work?); let’s figure out what that is and how I can help.\n\n\nAccessibility and Accomodations\nI have taken numerous steps to ensure that all of the materials presented in this course are accessible to all participants, regardless of physical or learning disabilities. I know that everyone is unique and I may have unintentionally overlooked something that limits access to some materials or activities. Please let me know if you cannot access any content. If you find you need additional accommodations to complete the required course work, please contact me as soon as possible! I want to support your success.\nIf you wish to request disability-related accommodations such as extra exam time for this or any other course, please contact the Disability Resource Center. It’s important to do this with as much advanced notice as possible, so you have full access to your course materials and activities in a timely manner. Please also email me to let me know that I should expect an email from the DRC to get you the accommodations that you need.\n\n\nInclusive Classroom\nBecause data are collected by and about humans, data necessarily encode aspects of our proclivities and biases. As a result, this course may touch upon difficult topics related to race, gender, inequality, class, and oppression. We each come into this class with different perspectives that can be shared to enhance our understanding of these issues. I ask that you enter these conversations with respect, curiosity, and cultural humility. You should be open to alternative perspectives and be willing to revise beliefs that are based on misinformation. As a general rule, your ideas and experiences can always be shared during these conversations, but please refrain from dismissing the experiences of others. Personal attacks of any kind will not be tolerated.\n\n\nGroup Work\nThis course will rely heavily on in-class group work. You will be expected to work with classmates on in-class material. If you have concerns about random group assignment, please talk to me at the start of the term.\nYou are also encouraged to discuss your ideas for lab assignments; however, I expect that these collaborations are about ideas and no R code is shared. Each person’s lab assignment submissions are expected to reflect their own thinking, and thus copying the work of others does not provide me with any information about your learning.\nThe community standards for student-to-student and student-to-instructor interactions include the following:\n\nListen actively and attentively.\nAsk for clarification if you are confused.\nChallenge one another respectfully.\nGracefully accept constructive criticism.\nTake responsibility for the quality of the discussion and the work.\nDo not monopolize discussion.\nAcknowledge that everyone has something to offer.\nSpeak from your own experience, without generalizing.\n\n\n\nLate Policy\nEveryone will be given a “bank” of 4 deadline extensions which can be used on Check-ins, Practice Activities, and Lab Assignments at any point in the quarter. One deadline extension will get you a 24 hour extension on a given assignment. You can use all of your deadline extensions on one assignment or split them up in any way.\n\nLike how the “real world” works, you must request a deadline extension before the deadline. To use your deadline extensions, you need to email me before the assignment deadline. You don’t need to get a response from me, you just need to email me at least a minute before the deadline.\nIf you do not email me before the assignment deadline (or you run out of late days), you will be docked 20% for each day that the assignment is late. (e.g. you can get a maximum of 80% on the assignment if it is submitted within 24 hours after the original due date and time.)\n\nA note on this policy: my priority is for all of you to engage with and understand the course materials. The best way to achieve this is to complete all assignments and receive feedback on your work. At the same time, I understand that things happen outside of our control and that you are balancing many responsibilities.\n\n\n\n\n\n\nAutomatic Canvas Settings\n\n\n\nCanvas is set up to automatically input 0% for missing assignments (as an incentive to go complete the assignment) and apply the 20% grade deduction policy. I will need to manually adjust your grade when you use your “deadline extensions.” You are responsible for double checking your grade to make sure I didn’t miss anything.\n\n\nIf you find yourself with extenuating circumstances beyond the defined late policy, please email me before the due date.\n\n\nExam Conflicts\nIf you have a known conflict with an exam, please discuss it with me at least three weeks prior to the exam date. If an illness or a family emergency arises, please let me know as soon as possible, and we will work out a solution. This may involve taking the exam at a later date or replacing the missed exam score with the final exam score. If you are unable to take the final exam, you will likely receive an Incomplete in the course.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#course-expectations",
    "href": "course-info/syllabus-w25.html#course-expectations",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Course Expectations",
    "text": "Course Expectations\nFor Students, I expect:\n\nYou will ask lots of questions.\nYou will do reading and other assignments outside of class and be prepared for each class meeting.\nIf you find yourself struggling or feel that you are falling behind, please reach out to me as soon as possible so that we can develop a plan for your success together.\nYou will take advantage of the resources that I provide and to seek out additional resources if you find that you are struggling with the material. You do not need to seek out additional resources all on your own – we can figure out what additional resources you may need.\n\nYou will be doing your best to engage with what we are all doing together during class. This means that you are using technology (i.e. laptops/tablets/phones) for class activities and not in ways that distract you.\nYou will approach the course with academic integrity.\nYou will come to class on time and work on class material with your peers.\nEveryone can learn the material in this course.\n\nFor Me:\n\nI am responsible for ensuring that all students feel welcome and valued in the classroom.\nI am responsible for providing the resources necessary so that all students in the course can achieve the learning objectives.\nI am responsible for providing prompt and clear feedback on your coursework.\nI welcome and appreciate any actionable feedback regarding how the class is meeting your learning needs. We can discuss ways to adjust the course to ensure it is supporting your learning and do more of anything that is working well!\n\n\nMake Mistakes!\nProgramming is the process of making a series of silly or stupid mistakes, and then slowly fixing each mistake (while adding a few more). The only way to know how to fix these mistakes (and avoid them in the future) is to make them. (Sometimes, you have to make the same mistake a few dozen times before you can avoid it in the future). At some point during the class, you will find that you’ve spent 30 minutes staring at an error caused by a typo, a space, a parenthesis in the wrong place. You may ask for help debugging this weird error, only to have someone immediately point out the problem… it is always easier to see these things in someone else’s code. This is part of programming, it is normal, and you shouldn’t feel embarrassed or sorry (unless you put no effort into troubleshooting the problem before you asked for help)\nIf you manage to produce an error I haven’t seen before, then congratulations. You have achieved something special, and that achievement should be celebrated. Each new and bizarre error is an opportunity to learn a bit more about the programming language, the operating system, or the interaction between the two.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#academic-integrity-and-class-conduct",
    "href": "course-info/syllabus-w25.html#academic-integrity-and-class-conduct",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Academic Integrity and Class Conduct",
    "text": "Academic Integrity and Class Conduct\nOur academic community is at its best when we treat each other with fairness, honesty, respect, and trust. Unfortunately, sometimes students slip up and do something that gives themselves (or someone else) an unfair advantage over other students. Such actions will not be tolerated in this class.\nIt is most likely that a student will slip up if they are feeling overwhelmed or unsure of how to approach a problem that they are stuck on. So let’s be proactive to prevent those situations!! If you are helpless in an assignment or in studying, post on discord, come to office hours, or email me or one of your classmates! I am working hard to provide all of the resources you need to succeed\nHowever, the college doesn’t really care if you break the rules on purpose or by accident. If I suspect you have done something that violates academic integrity on any graded elements of the course (included those graded for completion), you will receive an email to tell you about my suspicion and how the situation will be handled. Typically, students earn a 0 for the assignment on which academic misconduct is found. University policy dictates that we must report every instance of suspected academic dishonesty to the Office of Student Rights and Responsibilities, no matter how small. For more information on academic misconduct and what constitutes cheating and plagiarism, please see academicprograms.calpoly.edu/content/academicpolicies/Cheating.\nIt is important to note that paraphrasing or quoting another’s work without proper citation is a form of academic misconduct. This includes the R code produced by someone else! Writing code is like writing a paper, it is obvious if you copied-and-pasted a sentence from someone else into your paper because the way each person writes is different.\nEven inadvertent or unintentional misuse or appropriation of another’s work (such as relying heavily on source material that is not expressly acknowledged) is considered plagiarism. This includes using Chat GPT, which should only be used to help you problem solve just as a tutor or peer would, and not as a substitute for your own work. If you are struggling with writing the R code for an assignment, please reach out to me. I would prefer that I get to help you rather than you spending hours Googling things and get nowhere!\n\n\n\n\n\n\nAlways Cite Outside Resources!\n\n\n\nIn this class the assumed knowledge is the course materials, including the course textbook, coursework pages, and course slides. If you use outside resources on assignments I expect that you will cite those resources. This means that\n\nIf you use any R functions or code that are not in the course materials, you must cite where you found it. e.g., if you look up the help file for mutate() and you learn about a function not covered in the course materials, you are required to cite the documentation when using that function.\nIf you use Google you are expected to “inform” me of any resources you used by pasting the link to the resource in a code comment next to where you used that resource.\nIf you use ChatGPT you are expected to “inform” me by stating that you used it in a code comment next to where you used it including the full prompt that you gave ChatGPT.\nIf you work with classmates on an assignment, you are expected to “inform” me by including a note with their names.\n\n\n\nIf you have any questions about using and citing sources, you are expected to ask for clarification.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-info/syllabus-w25.html#learning-environment-and-support",
    "href": "course-info/syllabus-w25.html#learning-environment-and-support",
    "title": "Stat 331/531: Statistical Computing with R Syllabus",
    "section": "Learning Environment and Support",
    "text": "Learning Environment and Support\nMy priority is your success in this course. I understand that things happen unexpectedly and obtaining official accommodations can be slow.\nIf you feel that any circumstances or factors beyond your control may affect your presence and work in this class, please reach out to me and we will work to accommodate your needs. You do not need to share personal information with me when you reach out, unless you would like to.\n\nMental Health\nNational surveys of college students have consistently found that stress, sleep problems, anxiety, depression, interpersonal concerns, death of a significant other and alcohol use are among the top ten health impediments to academic performance. If you are experiencing any mental health issues, I and Cal Poly are here to help you. Cal Poly’s Counseling Services (805-756-2511) is a free and confidential resource for assistance, support and advocacy https://chw.calpoly.edu/counseling.\n\n\nSupport Services\nIf you are experiencing food insecurity, housing instability, or other challenges that may impact your ability to succeed in this course, please refer to the resources listed on Canvas under “Student Support Services at Cal Poly.” These resources provide a range of essential support services, including emergency financial assistance, counseling, and academic support.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html",
    "href": "labs/lab1/lab1-quarto.html",
    "title": "Lab 1: Introduction to Quarto",
    "section": "",
    "text": "Read and follow all lab instructions carefully!"
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#setup",
    "href": "labs/lab1/lab1-quarto.html#setup",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Setup",
    "text": "Setup\n\nMake a Lab Directory\nIf you have completed Check-in 1.3, you have already completed steps 1 & 2 below.\n\nIf you have not already, create a folder on your computer called “stat-331” or similar.\nCreate an RStudio Project inside of this folder.\nInside your stat-331 folder, create another folder called either “week-1” or “labs”. Remember, we are trying to be organized and not work out of our Downloads folder!\nInside of this folder, create another folder called “lab1” or similar.\n\n\n\nCreate your Lab 1 File\nTo create a Quarto document, you first need to ensure Quarto is installed on your computer. To do this, go here. You may have already installed Quarto during Check-in 1.3.\n\nOnce you have Quarto installed, open RStudio on your computer.\nIn RStudio, go to File &gt; New File &gt; Quarto Document... and click on Create in the dialog box without changing anything.\n\n\n\n\n\n\n\nWarning\n\n\n\nFor the instructions in this lab, I am expecting that the .qmd document you just created will look exactly like the one shown in the Quarto-Rendering course slide. If your document is instead entirely blank other than a YAML header, some of these instructions will be confusing and you should talk to me!\n\n\n\nChange the title of your document to be “Lab 1: Introduction to Quarto”\nAdd additional lines to your YAML header:\n\n\nadd a line with author: and your name.\nadd a line with embed-resources: true.\nadd a line with code-tools: true.\n(optional) add a line to specify the editor as your preference for either source or visual.\n\n\nSave the Quarto file as “lab1.qmd” in your “week-1” or “labs” folder. You can change up the name of your document, but the name cannot have spaces and it should describe what the document is."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#changing-the-execution-options",
    "href": "labs/lab1/lab1-quarto.html#changing-the-execution-options",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Changing the Execution Options",
    "text": "Changing the Execution Options\nExecution options specify how the R code in your Quarto document should be displayed. This guide provides descriptions on the options you can specify in a document’s execution.\nTo start, your YAML should look something like this:\n\n---\ntitle: \"Lab 1: Introduction to Quarto\"\nauthor: \"Dr. C\"\nformat: html\nembed-resources: true\ncode-tools: true\neditor: source (or visual)\n---\n\nSimilar to how you added an author, embed-resources, (and editor) line, you will first need to add an execute line to your YAML.\nUse the guide to specify execution options so that:\n\nyour source code is always output on the page.\nyour document will render even if there are errors."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#running-the-provided-code",
    "href": "labs/lab1/lab1-quarto.html#running-the-provided-code",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Running the Provided Code",
    "text": "Running the Provided Code\nNext, click on the “Play” button on the right of the first auto-populated code chunk. Alternatively, you can highlight (or simply put your cursor on the line of) the code you want to run and hit ctrl + Enter or ⌘ + Enter.\nYou should see the code appear in the console, as well as the result of the code (2). Keep in mind the [1] before the 2 is vector notation. This means the result is a vector of length 1, whose first element is 2.\nLet’s spice this code up a bit. Delete 1 + 1 from the code chunk and write the following code:\n\n# Load a dataset into the R Environment.\ndata(ToothGrowth)\n\n# Look at the summary of the variables in the dataset.\nsummary(ToothGrowth)\n\n# Look at a frequency table of a categorical variable.\ntable(ToothGrowth$supp)\n\nNow run this code. You should see a six-number summary of the variables len and dose included in the ToothGrowth dataset, as well as the frequency of the levels contained in the supp variable. Second, there is just the frequency table for the supp variable. Further, if you inspect the Environment tab, the ToothGrowth dataset should appear. You can click on the dataset name (not the blue play button!) to look at the data."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#check-the-data-documentation",
    "href": "labs/lab1/lab1-quarto.html#check-the-data-documentation",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Check the Data Documentation",
    "text": "Check the Data Documentation\nIn your console (not in the Quarto document), type ?ToothGrowth (or alternatively help(ToothGrowth).\n\nUse the information that pops up in the Help pane in RStudio to fill in the blanks below.\nAdd the questions and your responses after the R code chunk.\nBefore the code chunk, create a section header (using #s) that describes the contents of the section (e.g., Tooth Growth Dataset).\n\nThis dataset investigates the effect of ______ ____ on tooth growth in _________ ________.\nThe two supplement delivery methods include OJ (_______ _______) and VC (_________ ______).\nIt is a data frame with ____ observations and ____ variables.\nYour Tooth Growth Dataset section should look something like this (although it will also include the table of supp):"
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#sec-creating-a-plot",
    "href": "labs/lab1/lab1-quarto.html#sec-creating-a-plot",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Creating a Plot",
    "text": "Creating a Plot\nYour second code chunk is just as boring as your first, so let’s spice it up! Replace the 2 * 2 code with the following (we will talk about graphics next week!):\n\n# make sure to load the package ggplot2\nlibrary(ggplot2)\nggplot(data = ToothGrowth, \n       aes(x = supp,\n           y = len)) +\n  geom_boxplot() +\n  labs()\n\nNow, run this code chunk! You should see side-by-side boxplots comparing tooth length between the two supplement delivery methods contained in the ToothGrowth data set.\nLook back at the help documentation for the ToothGrowth dataset to determine what len represents (i.e., “Length of xxx”).\nNext, look up the help file on the labs() ggplot2 function to find the arguments you can use to specify the \\(x\\)- and \\(y\\)-axis labels. Particularly, looking at the examples at the bottom of the help file and this site may also be helpful. Change the \\(x\\)-axis and \\(y\\)-axis labels to display reader-friendly axis labels as found in the ToothGrowth help file. For example, “Supplement Type” is better than “supp”.\nNote that #| echo: false is an output option applied only to this specific code chunk. Remove this line so the code appears in your final rendered document.\nCreate another section header (like you did before) stating what is included in this section."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#inserting-a-new-code-chunk",
    "href": "labs/lab1/lab1-quarto.html#inserting-a-new-code-chunk",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Inserting a New Code Chunk",
    "text": "Inserting a New Code Chunk\nNavigate to the last sentence of the Quarto document. We’re now going to insert a new R code chunk at the bottom of the document.\nThere are four different ways to do this:\n\ntype ctrl + alt + i on Windows, or ⌘ + ⌥ + i on macOS,\nClick on the  symbol. This should automatically default to R code, but if you have a Python compiler on your computer, you might need to select “R” from the options.\nIf you are using the Visual editor, click on the “Insert” button, then select “Code Chunk”, and finally select “R”.\nManually add the code chunk by typing ```{r}. Make sure to close your code chunk with ```."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#conducting-statistical-analyses",
    "href": "labs/lab1/lab1-quarto.html#conducting-statistical-analyses",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Conducting Statistical Analyses",
    "text": "Conducting Statistical Analyses\n\n\n\n\n\n\nRefresher on a two-sample independent t-test\n\n\n\nWhile a second course in statistics is a pre-requisite for this class, you may want to go here for a refresher on conducting two-sample independent t-tests.\n\n\nIn this section, we are going to conduct a two-sample independent t-test to compare tooth length between the two supplement methods in the ToothGrowth dataset. I have outlined the null and alternative hypotheses we will be testing:\n\n\n\n\n\n\nNull\n\n\n\nThe treatment mean tooth length for the OJ supplement delivery method is the same as the treatment mean tooth length for the VC supplement delivery method.\n\n\n\n\n\n\n\n\nAlternative\n\n\n\nThe treatment mean tooth length for the OJ supplement delivery method is different from the treatment mean tooth length for the VC supplement delivery method.\n\n\nCarry out the following steps:\n\nLook up the help documentation for t.test().\n\n\n\n\n\n\n\nHint\n\n\n\nLook at the example for a two-sample t-test comparing mpg in morning and afternoon with the mtcars data.\n\n\n\nUsing the function t.test(), write code to carry out the analysis. You can assume unequal variances and a two-sided alternative.\nRun your code chunk to obtain the output for your statistical test.\nWrite a numbered list (in Markdown) below the code chunk containing:\n\nYour conclusion (in the context of these data) based on the p-value.\nAn interpretation of the confidence interval (make sure to read what confidence level is used by default).\n\nCreate another section header, describing the contents of this section."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#render-your-document",
    "href": "labs/lab1/lab1-quarto.html#render-your-document",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Render your Document",
    "text": "Render your Document\nRender your document as an html file. Use the “Render” button (the blue arrow!) at the top of your screen.\nIf you run into trouble rendering your document, try restarting R and running your code chunks in order, and see if you can find the problem.\nAnother common issue is deleting the tick marks (```) that surround your code chunks. If you notice that the code chunks are not showing a “Play” button, or that they are not highlighted in gray, double check your tick marks!\nRecall we included error: true in our YAML execution options. This means that your document will still render even if there are errors. Make sure you are double checking your work!\nYou will notice that there is auto-generated text that is unrelated to the work that you completed. It is always a good idea to delete this extra text!"
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#include-an-image",
    "href": "labs/lab1/lab1-quarto.html#include-an-image",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Include an Image",
    "text": "Include an Image\n\nSave an image of an activity, place, book, or movie that you enjoy. Save the image somewhere that makes sense to you in your course directory.\nCheck out this documentation for how to include an image/figure in Markdown.\nInclude your image at the end of your lab, along with a brief description.\n\n\nThe Markdown code will look something like: ![Brief description](relativepath/image.png)\nYou must use a relative file path to your image!\nYou may want to adjust the image size.\n\n\nAdd a new section header before your image.\nRender your document again to make sure it worked.\n\n\n\n\nI am obsessed with this book of short stories by Ken Liu."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#styling-your-quarto-document",
    "href": "labs/lab1/lab1-quarto.html#styling-your-quarto-document",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Styling your Quarto Document",
    "text": "Styling your Quarto Document\nYou can find a list of every option you can use to format an HTML document here and here. Further, here are lists of different themes you can specify in your YAML to produce differently styled outputs.\nMake the following changes to your document:\n\nSpecify “Code Folding” in your YAML document options.\nSpecify in the code chunk options that your boxplots of tooth length by supplement delivery method should be center aligned.\nWrite and include a figure caption for the boxplots using a code-chunk option.\nClean it up - delete the any automatically included headers or text in the file that are still there.\n\nYou might have fun playing around with other themes or options!"
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#render-again",
    "href": "labs/lab1/lab1-quarto.html#render-again",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Render again!",
    "text": "Render again!\nNotice that when you render the document, all of the code reruns again, producing the same output as before, but with your changes – this is called reproducibility!\nYou should render often while completing your practice activities and lab assignments. Make small changes, then make sure the file still renders rather than making a bunch of big changes and then realizing something is wrong."
  },
  {
    "objectID": "labs/lab1/lab1-quarto.html#turn-it-in",
    "href": "labs/lab1/lab1-quarto.html#turn-it-in",
    "title": "Lab 1: Introduction to Quarto",
    "section": "Turn it in!",
    "text": "Turn it in!\nOpen the .html file on your computer to make sure it looks as you expected. Then upload the rendered (.html extension) document to Canvas!\n\n\n\n\n\n\nCaution\n\n\n\nDouble check that you have embed-resources: true in your YAML. Without this, your html will not be formatted correctly on Canvas. You may want to look at what you turn in through your Canvas portal!\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou’ll be doing this same process for all your future Lab Assignments. Each of these will involve a Quarto file. Some weeks, I may have a template for you to copy into the Quarto file just as with the first practice activity."
  },
  {
    "objectID": "labs/lab3/lab3-dplyr.html",
    "href": "labs/lab3/lab3-dplyr.html",
    "title": "Lab 3: Student Evaluations of Teaching",
    "section": "",
    "text": "In this lab, we will be using the dplyr package to explore student evaluations of teaching data. You are expected to use functions from dplyr to do your data manipulation!\nDownload starter .qmd file\nDownload teacher_evals.csv"
  },
  {
    "objectID": "labs/lab3/lab3-dplyr.html#rate-my-professor",
    "href": "labs/lab3/lab3-dplyr.html#rate-my-professor",
    "title": "Lab 3: Student Evaluations of Teaching",
    "section": "Rate my Professor",
    "text": "Rate my Professor\nFor the questions in this section (9 - 11), you don’t need to write up any answers – you only need to show the output of your code (nicely formatted with kable()) to respond to each. Your code output should clearly show the answer.\n\n\n\n\n\n\nTip\n\n\n\nHelpful functions: slice_max(), slice_min()\n\n\n9. Which instructor(s) had the lowest average rating for Question 1 (“I learnt a lot during the course.”) across all their courses (i.e. you should be looking at the mean of the SET_score_avg variable across courses for each instructor)? Include the number of courses the instructor(s) taught in your output\na. Sketch a game plan and include the image below.\n\nb. Implement/code your game plan\n\n# code chunk for Q9\n\n10. Which instructor(s), who had at least five courses reviewed in the data, had the highest average rating for Question 1 (I learnt a lot during the course.) across all their courses?\n\n# code chunk for Q10\n\n11. Which instructor(s) with either a doctorate or professor degree had the highest and lowest average percent of students responding to the evaluation across all their courses? Include how many years the instructor had worked (seniority) and their sex in your output. You can use two pipelines to answer these questions.\n\n\n\n\n\n\nTip\n\n\n\nThinking about how to include the seniority and sex of the instructor in your output may be tricky!! There are a couple of ways to approach this. One hint is to think about how many distinct seniority levels / sexes there are for each instructor.\n\n\n\n# code chunk for Q11"
  },
  {
    "objectID": "labs/lab3/lab3-dplyr.html#chi-square-test-of-independence",
    "href": "labs/lab3/lab3-dplyr.html#chi-square-test-of-independence",
    "title": "Lab 3: Student Evaluations of Teaching",
    "section": "Chi-Square Test of Independence",
    "text": "Chi-Square Test of Independence\n\n\n\n\n\n\nRefresher on Chi-square test of independence\n\n\n\nWhile a second course in statistics is a pre-requisite for this class, here is a refresher on Chi-square tests of independence.\n\n\nLet’s compare the level of SET ratings for Question 3 (The professor used activities to make the class more engaging.) between senior instructors and junior instructors.\n12. Create a new dataset teacher_evals_compare that accomplishes the following with one dplyr pipeline:\n\nincludes responses for Question 3 only,\ncreates a new variable called set_level that is “excellent” if the SET_score_avg is 4 or higher (inclusive) and “standard” otherwise,\ncreates a new variable called sen_level that is “junior” if the instructor has been teaching for 4 years or less (inclusive), “senior” if between 5-8 years (inclusive), and “very senior” if more than 8 years\ncontains only the variables we are interested in – course_id, set_level, and sen_level.\n\n\n\n\n\n\n\nTip\n\n\n\nHelpful functions: if_else(), case_when()\n\n\n\n# code chunk for Q12\n\n13. Using the new dataset and your ggplot2 skills, recreate the filled bar plot shown below.\n\n\n\n\n\n\n\nTip\n\n\n\nNote that getting the general structure and reader friendly labels is good enough. I used Cal Poly’s branded colors for fun, which use HEX codes #BD8B13 and #154734.\n\n\n\n# code chunk for Q13\n\n14. Use chisq.test() to carry out a chi-square test of independence between the SET level and instructor seniority level in your new dataset. You will want to look at the documentation and maybe Google a bit!\n\n\n\n\n\n\nTip\n\n\n\nNote that the chisq.test() function does not take a formula / data specification as we have seen before. You will either have to use with() or indicate the variables of interest using $ syntax.\n\n\n\n# code chunk for Q14\n\n15. Draw a conclusion about the independence of student evaluation of instructor’s use of activities and seniority level based on your chi-square test.\n\nStudy Critique\nPart of the impetus behind this study was to investigate characteristics of a course or an instructor that might affect student evaluations of teaching that are not explicitly related to teaching effectiveness. For instance, it has been shown that gender identity and presentation affect student evaluations of teaching (an example).\n16. If you were to conduct this study at Cal Poly, what are two other variables you would like to collect that you think might be related to student evaluations? These should be course or instructor characteristics that were not collected in this study. Explain what effects you would expect to see for each."
  },
  {
    "objectID": "practice-activities/pa2.html",
    "href": "practice-activities/pa2.html",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "",
    "text": "Download the .qmd template and save it in a reasonable location.\nToday you will be exploring different types of visualizations to uncover which species of penguins reside on different islands.\nSome advice:"
  },
  {
    "objectID": "practice-activities/pa2.html#getting-started",
    "href": "practice-activities/pa2.html#getting-started",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Getting Started",
    "text": "Getting Started\nWe will be creating visualizations using the ggplot2 package.\nFor this activity, we will be exploring the penguins data from the palmerpenguins package, which has fantastic documentation with really awesome artwork. So, you will need to install the palmerpenguins package.\ninstall.packages(\"palmerpenguins\")\n\n\n\n\n\n\ninstall.packages() in the console NOT in your .qmd file!\n\n\n\nYou should type this into your console and NOT include it in a code chunk in your .qmd file. Recall that we only have to install a package once, but load it each time we open R. Each time you render your .qmd file, ALLthe code chunks are run. Therefore, installing a package in a code chunk would cause R to unnecessarily install the package over and over again. Not good."
  },
  {
    "objectID": "practice-activities/pa2.html#creating-a-setup-code-chunk",
    "href": "practice-activities/pa2.html#creating-a-setup-code-chunk",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Creating a Setup Code Chunk",
    "text": "Creating a Setup Code Chunk\n\nInsert a code chunk at the beginning of your document (directly under the YAML).\nName the code chunk setup.\nUse the hashpipe #| to specify a code chunk option that prevents any messages (e.g., from loading in packages) from appearing.\nLoad in the tidyverse or ggplot2 package.\nLoad in the palmerpenguins package.\n\n\n\n\n\n\n\nCode chunk name: setup\n\n\n\nNaming your code chunk “setup” has special properties in a .qmd - specifically, this code chunk will run automatically when you try to run a subsequent code chunk. This ensures all packages and any other specifications for your document are loaded and will not cause you errors or messages."
  },
  {
    "objectID": "practice-activities/pa2.html#dataset-penguins",
    "href": "practice-activities/pa2.html#dataset-penguins",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Dataset: penguins",
    "text": "Dataset: penguins\nI like to start by seeing the dataset I will be working with, so I am going to pull the penguins data into my R environment. Do you see it in the top right Environment tab?\n\ndata(penguins)\n\nWarning in data(penguins): data set 'penguins' not found\n\n\nYou may notice that a dataset called penquins_raw also loaded. We will ignore this and focus on the penguins dataset.\n\nGet to know your data. What are the variables and what units are they measured in? What does each row represent?"
  },
  {
    "objectID": "practice-activities/pa2.html#graphics",
    "href": "practice-activities/pa2.html#graphics",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Graphics",
    "text": "Graphics\n\n\n\n\n\n\nNote\n\n\n\nMake sure to give your plots reader friendly axes labels!\n\n\n\n\n\n\n\n\nNote\n\n\n\nMake sure your final report does not display any warnings or messages from RStudio!\n\n\n\nUse https://excalidraw.com/ (or pen and paper, a tablet, etc.) to create a game plan for a barchart of species, where species is mapped to the fill color of the barchart. Save or take a screenshot of your game plan – you will be uploading this to Canvas with your practice activity submission.\nUse ggplot2 to create the barchart you outlined above.\n\n\nUse ggplot2 to create a scatterplot of the relationship between the bill length (bill_length_mm) and bill depth (bill_depth_mm).\n\n\nBuilding on your code from (9), add an aesthetic to differentiate the species by color.\n\n\nBuilding on your code from (10), add the location of the penguins (island) to your visualization. There us more than one way you could to address this, however, one method will make it easier to answer the questions below, so you might want to read those questions first!"
  },
  {
    "objectID": "practice-activities/pa2.html#canvas-quiz",
    "href": "practice-activities/pa2.html#canvas-quiz",
    "title": "PA 2: Using Data Visualization to Find the Penguins",
    "section": "Canvas Quiz",
    "text": "Canvas Quiz\n\n\n\n\n\n\nUse the plots you created to answer the following questions on Canvas.\n\n\n\n\nWhich species of penguins is represented least in the Palmer Penguins data set?\nWhich species of penguins are found on every island?\nWhich species of penguins are found only on Dream Island?\nWhich species of penguins are found only on Biscoe Island?"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#tuesday-april-1",
    "href": "slides/week-1/w1-intro-r.html#tuesday-april-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Tuesday, April 1",
    "text": "Tuesday, April 1\nToday we will…\n\nWelcome to Stat 331/531: Statistical Computing in R\nIntro to Me + You + the course\n“Unplugged” Warm-up\nIntro to R + RStudio\nOrganization\nR Basics & Troubleshooting\nPA 1: Find the Mistakes"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#me",
    "href": "slides/week-1/w1-intro-r.html#me",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Me!",
    "text": "Me!\n\n\nHi, I’m Dr. C!\n\n\nI am a transplant to the west coast.\nMy favorite things right now are cooking, knitting, and biking around SLO county.\nI genuinely love R."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#you",
    "href": "slides/week-1/w1-intro-r.html#you",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "You!",
    "text": "You!\nI am looking forward to reading your introductions on Discord!\n\nPlease read the intros of your classmates so you can discover who you will be learning with this quarter."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#communication",
    "href": "slides/week-1/w1-intro-r.html#communication",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Communication",
    "text": "Communication\n\n\n✉️ email\n\nwith your @calpoly.edu email address\nwith questions that relate to you as an individual\n\n💬 Discord\n\nany and all questions!!\nyou will join and introduce yourself before Thursday\n\n🏢 office hours\n\ncome and discuss anything during my scheduled hours!\nreach out to schedule other times"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#course-materials",
    "href": "slides/week-1/w1-intro-r.html#course-materials",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Course Materials",
    "text": "Course Materials\n\n\n🏫 Canvas\n\neverything will be linked or posted on Canvas!\nrefer to Canvas for current deadilnes & announcements\n\n📕 “textbook”\n\nonline course notes\nincludes videos & tutorials\n\n🖥️ materials website\n\nslides, labs, and practice activities are organized\nthis is for convenience, but everything will also be linked in Canvas"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#assessments---formative",
    "href": "slides/week-1/w1-intro-r.html#assessments---formative",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Assessments - Formative",
    "text": "Assessments - Formative\n\n\nCheck-In’s (5%)\n\n“check” that you are prepared for the week\nbased on reading from the textbook\n\nPractice Activities (10%)\n\nfirst attempt at new skills\nget the hang of the week’s R skills\n\nLab Activities (30%)\n\n“homework”\n\n\n\n\n\n\n\n\n\n\nWork with other’s!\n\n\nYou should work with other’s on all assignments! The final work you submit for a Lab should be your own."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#assessments---evaluative",
    "href": "slides/week-1/w1-intro-r.html#assessments---evaluative",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Assessments - Evaluative",
    "text": "Assessments - Evaluative\n\nExams\n\nMidterm Exam (15%)\nFinal Exam (25%)\n\nFinal project (15%)\n\ngroup project\ndue end of week 10\n\n\n\n\n\n\n\n\nExam Conflicts\n\n\nIf you have a known conflict with an exam, please discuss it with me at least three weeks prior to the exam date"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#assessments---general-criteria",
    "href": "slides/week-1/w1-intro-r.html#assessments---general-criteria",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Assessments - General Criteria",
    "text": "Assessments - General Criteria\n\n\ncorrect outputs are great, but you will also need to demonstrate that you are intellectually engaging with the material in assignments\nin addition to getting a correct output from your code, you will be assessed for efficiency and formatting\ntechnical communication will also be an important element of assessments\nI hope you will be proud of your work in this class!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#weekly-overview",
    "href": "slides/week-1/w1-intro-r.html#weekly-overview",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Weekly Overview",
    "text": "Weekly Overview"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#course-policies",
    "href": "slides/week-1/w1-intro-r.html#course-policies",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Course Policies",
    "text": "Course Policies\n\nLate Policy\n\n4 “deadline extensions”\nemail me before the deadline for a 24 hour extention\n\nAttendance\nAccessibility and Accomodations\n\nlet me know what I can do better\nemail me if you use the DRC"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#academic-integrity",
    "href": "slides/week-1/w1-intro-r.html#academic-integrity",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Academic Integrity",
    "text": "Academic Integrity\n\n\nlet’s be proactive to prevent situations where you are overwhelmed!\nuse Chat GPT as a tutor, not a substitute for your own work\ncite outside resources!\nplease review the syllabus carefully"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#my-expectations-for-you",
    "href": "slides/week-1/w1-intro-r.html#my-expectations-for-you",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "My expectations for you",
    "text": "My expectations for you\n\n\nask lots of questions\ntake advantage of resources to help you learn\n\nthis includes working with others!\n\nengage with what we are all doing together during class\nwork towards independent learning"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#my-expectations-for-me",
    "href": "slides/week-1/w1-intro-r.html#my-expectations-for-me",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "My expectations for me",
    "text": "My expectations for me\n\n\ncreating an inclusive and accessible classroom\nproviding resources needed to learn the material\nproviding prompt and clear feedback\ndoing my best to make class worth your time\nclearly communicating"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-to-expect-from-this-course",
    "href": "slides/week-1/w1-intro-r.html#what-to-expect-from-this-course",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What to expect from this course",
    "text": "What to expect from this course\n\n\neveryone comes with different knowledge and skills – figure out what helps you learn the best in this course\nindependent learning and learning from documentation is part of the course\ncoding involves unique challenges, frustrations, and satisfaction!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#statistical-computing-involves",
    "href": "slides/week-1/w1-intro-r.html#statistical-computing-involves",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Statistical computing involves…",
    "text": "Statistical computing involves…\n\n\nunderstanding data structures\n\ni.e. “what you have to work with”\n\ndeveloping an algorithm\n\ni.e. “what you want the computer to do”\n\nknowing the syntax of a specific language\n\ni.e. “how to tell the computer what to do so it will understand”\n\nimproving efficiency of your code\n\n\n\n\n\n\n\n\n\nNot just syntax\n\n\nAll of these skills improve as the others improve and we will work on all of them in this course!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#paper-planes",
    "href": "slides/week-1/w1-intro-r.html#paper-planes",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Paper Planes",
    "text": "Paper Planes\n\n\nWork with the person next to you & introduce yourself!\nWrite a set of instructions to fold a paper airplane\n\n\nvideo / picture instructions if you don’t know/remember how\n\n\nSwap the instructions with the pair next to you\nFollow their instructions as literally as possible to fold a plane"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-is-r",
    "href": "slides/week-1/w1-intro-r.html#what-is-r",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What is R?",
    "text": "What is R?\n\nR is a programming language designed originally for statistical analyses.\nR is open source"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-going-on-with-r",
    "href": "slides/week-1/w1-intro-r.html#what-going-on-with-r",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What’ going on with R?",
    "text": "What’ going on with R?\n\nStrengthsWeaknesses\n\n\nR’s strengths are…\n\n\nhandling data with lots of different types of variables.\nmaking nice and complex data visualizations.\nhaving cutting-edge statistical methods available to users.\n\n\n\n\nR’s weaknesses are…\n\n\nperforming non-analysis programming tasks, like website creation (python, ruby, …).\nhyper-efficient numerical computation (matlab, C, …).\nbeing a simple tool for all audiences (SPSS, STATA, JMP, minitab, …)."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#but-wait",
    "href": "slides/week-1/w1-intro-r.html#but-wait",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "But wait!",
    "text": "But wait!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#packages",
    "href": "slides/week-1/w1-intro-r.html#packages",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Packages",
    "text": "Packages\nThe heart and soul of R are packages.\n\n\nThese are “extra” sets of code that add new functionality to R when installed.\n“base” R refers to functions that are in the R software, and do not require a package."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#open-source",
    "href": "slides/week-1/w1-intro-r.html#open-source",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Open-Source",
    "text": "Open-Source\nImportantly, R is open-source.\n\n\nThere is no company that owns R, like there is for SAS or Matlab.\nThis means packages are created by users like you and me!\n“Official” R packages live on the Comprehensive R Archive Network, or CRAN.\nBut anyone can write and share new code in “package form”"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#open-source-1",
    "href": "slides/week-1/w1-intro-r.html#open-source-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Open-Source",
    "text": "Open-Source\nBeing a good open-source citizen means…\n\n\nsharing your code publicly when possible (later in this course, we’ll learn about GitHub!).\ncontributing to public projects and packages, as you are able.\ncreating your own packages, if you can.\nusing R for ethical and respectful projects."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-is-rstudio",
    "href": "slides/week-1/w1-intro-r.html#what-is-rstudio",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nRStudio is an IDE (Integrated Developer Environment).\n\nThis means it is an application that makes it easier for you to interact with R."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#rstudio-is-your-friend",
    "href": "slides/week-1/w1-intro-r.html#rstudio-is-your-friend",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "RStudio is Your Friend!",
    "text": "RStudio is Your Friend!\n\nYou will always interact with R through RStudio\nHelps with organization and some “point-and-click” options if desired"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#a-lot-of-pieces-go-into-a-data-analysis",
    "href": "slides/week-1/w1-intro-r.html#a-lot-of-pieces-go-into-a-data-analysis",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "A lot of pieces go into a data analysis!",
    "text": "A lot of pieces go into a data analysis!\n\n\n\nfiles with code\ndata files\ndocumentation\nimages\nreports\netc.\n\n\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#organization-is-key",
    "href": "slides/week-1/w1-intro-r.html#organization-is-key",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Organization is key!",
    "text": "Organization is key!\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-is-a-directory",
    "href": "slides/week-1/w1-intro-r.html#what-is-a-directory",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What is a directory?",
    "text": "What is a directory?\n\n\nA directory is just a fancy name for a folder.\nDirectories are your friends!\nBest practice:\n\neverything should have a place in a well-named directory\ndo not include spaces in directory names"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#project-directory-examples",
    "href": "slides/week-1/w1-intro-r.html#project-directory-examples",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Project Directory Examples",
    "text": "Project Directory Examples\n\nGOOD 😃BAD ☠️"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#class-directory-examples",
    "href": "slides/week-1/w1-intro-r.html#class-directory-examples",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Class Directory Examples",
    "text": "Class Directory Examples\n\nGOOD 😃BAD ☠️"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#manage-your-class-directory",
    "href": "slides/week-1/w1-intro-r.html#manage-your-class-directory",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Manage your Class Directory",
    "text": "Manage your Class Directory\nCreate a directory for this class!\n\n\nIs it in a place you can easily find it?\n\nNOT IN YOUR DOWNLOADS FOLDER ☠️\n\nDoes it have an informative name?\n\nlike “stat-331” or similar\n\nAre the files inside it well-organized?\n\n\n\n\n\n\n\n\n\nWarning\n\n\nI cannot stress how important this is!!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#how-do-i-run-code-in-r",
    "href": "slides/week-1/w1-intro-r.html#how-do-i-run-code-in-r",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "How do I run code in R?",
    "text": "How do I run code in R?\n\n\nYou can run any lines of code directly in the Console\n\nBut then your code isn’t saved!\nThis is best for exporatory and one-off tasks\n\nWe primarily write and run code in R scripts or notebooks in Source\n\nThese are documents where you can organize and save code!\nMore on scripts vs. notebooks tomorrow"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#packages-1",
    "href": "slides/week-1/w1-intro-r.html#packages-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Packages",
    "text": "Packages\nTo install a package use:\n\ninstall.packages(\"tibble\")\n\n\nYou should have to install a package only once.\n\n\nTo load a package use:\n\nlibrary(tibble)\n\n\nYou have to load a package each time you restart R.\nYou also should load packages at the beginning of any script.\n\n\n\n\n\n\n\n\n\nWarning\n\n\nNote that when you install packages you need to include quotation marks around the package name, but you don’t need to when loading a package!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#data-types",
    "href": "slides/week-1/w1-intro-r.html#data-types",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Data Types",
    "text": "Data Types\n\nA value is a basic unit of stuff that a program works with.\nValues have types:\n\n\n\nlogical / boolean: FALSE/TRUE or 0/1 values.\n\n\n\n\ninteger: whole numbers.\n\n\n\n\ndouble / float / numeric: decimal numbers.\n\n\n\n\ncharacter / string - holds text, usually enclosed in quotes."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#variables",
    "href": "slides/week-1/w1-intro-r.html#variables",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Variables",
    "text": "Variables\nVariables are names that refer to values.\n\nA variable is like a container that holds something - when you refer to the container, you get whatever is stored inside.\nWe assign values to variables using the syntax object_name &lt;- value.\n\nYou can read this as “object name gets value” in your head.\n\n\n\n\nmessage &lt;- \"So long and thanks for all the fish\"\nyear &lt;- 2025\nthe_answer &lt;- 42\nearth_demolished &lt;- FALSE"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#naming-conventions",
    "href": "slides/week-1/w1-intro-r.html#naming-conventions",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Naming Conventions",
    "text": "Naming Conventions\n\nsome_people_use_snake_case\nsomePeopleUseCamelCase\nsome.people.use.periods\nA few people mix conventions with variables_thatLookLike.this and they are almost universally hated.\n\n\n\n\n\n\n\nTip\n\n\nJust pick one and stick with it!"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#data-structures",
    "href": "slides/week-1/w1-intro-r.html#data-structures",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Data Structures",
    "text": "Data Structures\nHomogeneous: every element has the same data type.\n\nVector: a one-dimensional column of homogeneous data.\nMatrix: the next step after a vector - it’s a set of homogenous data arranged in a two-dimensional, rectangular format.\n\n\nHeterogeneous: the elements can be of different types.\n\nList: a one-dimensional column of heterogeneous data.\nDataframe: a two-dimensional set of heterogeneous data arranged in a rectangular format."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#indexing",
    "href": "slides/week-1/w1-intro-r.html#indexing",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Indexing",
    "text": "Indexing\nWe use square brackets ([]) to access elements within data structures.\n\nIn R, we start indexing from 1.\n\n\n\n\nVector:\n\n\nvec[4]    # 4th element\nvec[1:3]  # first 3 elements\n\n\n\n\nMatrix:\n\n\nmat[2,6]  # element in row 2, col 6\nmat[,3]   # all elements in col 3\n\n\n\n\nList:\n\n\nli[[5]]    # 5th element\n\n\n\n\nDataframe:\n\n\ndf[1,2]     # element in row 1, col 2\ndf[17,]     # all elements in row 17\ndf$calName  # all elements in the col named \"colName\"\ndf[[\"calName\"]] # all elements in the col named \"colName\""
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#logic",
    "href": "slides/week-1/w1-intro-r.html#logic",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Logic",
    "text": "Logic\nWe can combine logical statements using and, or, and not.\n\n(X AND Y) requires that both X and Y are true.\n(X OR Y) requires that one of X or Y is true.\n(NOT X) is true if X is false, and false if X is true.\n\n\n\nx &lt;- c(TRUE, FALSE, TRUE, FALSE)\ny &lt;- c(TRUE, TRUE, FALSE, FALSE)\n\nx & y   # AND\n\n[1]  TRUE FALSE FALSE FALSE\n\nx | y   # OR\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n!x & y  # NOT X AND Y\n\n[1] FALSE  TRUE FALSE FALSE"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#vectorization",
    "href": "slides/week-1/w1-intro-r.html#vectorization",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Vectorization",
    "text": "Vectorization\n\n\nR is designed to do vector and matrix math nicely\nMany operations in R are vectorized.\n\nThese functions operate on vectors of values rather than a single value.\ni.e. the function applies to every element of a vector individually.\n\n\n\n\ne.g.:\n\nx &lt;- seq(from = -2, to = 2)\nx\n\n[1] -2 -1  0  1  2\n\n\nSay we want to add 1 to every element of x…"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#vectorization-1",
    "href": "slides/week-1/w1-intro-r.html#vectorization-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Vectorization",
    "text": "Vectorization\n\n\nLoop:\n\nfor(i in 1:length(x)){\n  x[i] &lt;- x[i] + 1\n}\nx\n\n[1] -1  0  1  2  3\n\n\n\nVectorized:\n\nx &lt;- x + 1\nx\n\n[1] -1  0  1  2  3\n\n\n\n\n\nSee how leveraging vectorization in R is great?\n\n\n\n\n\n\n\nLoops be gone!\n\n\nNow forget about loops after this slide! We rarely need them in R and will avoid using them in this class"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#did-you-leave-off-a-parenthesis",
    "href": "slides/week-1/w1-intro-r.html#did-you-leave-off-a-parenthesis",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Did you leave off a parenthesis?",
    "text": "Did you leave off a parenthesis?\nseq(from = 1, to = 10, by = 1\n\nseq(from = 1, to = 10, by = 1\n\nError in parse(text = input): &lt;text&gt;:2:0: unexpected end of input\n1: seq(from = 1, to = 10, by = 1\n   ^\n\n\n\n\nseq(from = 1, to = 10, by = 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#did-you-leave-off-a-comma",
    "href": "slides/week-1/w1-intro-r.html#did-you-leave-off-a-comma",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Did you leave off a comma?",
    "text": "Did you leave off a comma?\nseq(from = 1, to = 10 by = 1)\n\nseq(from = 1, to = 10 by = 1)\n\nError in parse(text = input): &lt;text&gt;:1:23: unexpected symbol\n1: seq(from = 1, to = 10 by\n                          ^\n\n\n\n\nseq(from = 1, to = 10, by = 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#did-you-make-a-typo-are-you-using-the-right-names",
    "href": "slides/week-1/w1-intro-r.html#did-you-make-a-typo-are-you-using-the-right-names",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Did you make a typo? Are you using the right names?",
    "text": "Did you make a typo? Are you using the right names?\nsequence(from = 1, to = 10, by = 1)\n\nsequence(from = 1, to = 10, by = 1)\n\nError in sequence.default(from = 1, to = 10, by = 1): argument \"nvec\" is missing, with no default\n\n\n\n\nseq(from = 1, to = 10, by = 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#are-you-using-the-right-input-that-the-function-expects",
    "href": "slides/week-1/w1-intro-r.html#are-you-using-the-right-input-that-the-function-expects",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Are you using the right input that the function expects?",
    "text": "Are you using the right input that the function expects?\nsqrt(‘1’)\n\nsqrt('1')\n\nError in sqrt(\"1\"): non-numeric argument to mathematical function\n\n\n\n\nsqrt(1)\n\n[1] 1"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#are-you-expecting-the-right-output-of-the-function",
    "href": "slides/week-1/w1-intro-r.html#are-you-expecting-the-right-output-of-the-function",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Are you expecting the right output of the function?",
    "text": "Are you expecting the right output of the function?\n\nmy_obj &lt;- seq(from = 1, to = 10, by = 1)\n\nmy_obj(5)\n\nError in my_obj(5): could not find function \"my_obj\"\n\n\n\n\nmy_obj[5]\n\n[1] 5"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#messages",
    "href": "slides/week-1/w1-intro-r.html#messages",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Messages",
    "text": "Messages\nJust because you see scary red text, this does not mean something went wrong! This is just R communicating with you.\n\n\nFor example, you will often see:\n\n\nlibrary(lme4)\n\nLoading required package: Matrix"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#warnings",
    "href": "slides/week-1/w1-intro-r.html#warnings",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Warnings",
    "text": "Warnings\nOften, R will give you a warning.\n\nThis means that your code did run…\n…but you probably want to make sure it succeeded.\n\n\nDoes this look right?\n\nmy_vec &lt;- c(\"a\", \"b\", \"c\")\n\nmy_new_vec &lt;- as.numeric(my_vec)\n\nWarning: NAs introduced by coercion\n\n\n\n\n\nmy_new_vec\n\n[1] NA NA NA"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#errors",
    "href": "slides/week-1/w1-intro-r.html#errors",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Errors",
    "text": "Errors\nIf the word Error appears in your message from R, then you have a problem.\n\nThis means your code could not run!\n\n\n\nmy_vec &lt;- c(\"a\", \"b\", \"c\")\n\nmy_new_vec &lt;- my_vec + 1\n\nError in my_vec + 1: non-numeric argument to binary operator"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#r-says",
    "href": "slides/week-1/w1-intro-r.html#r-says",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "R says…",
    "text": "R says…\n\nError in ggplot() : could not find function “ggplot”\n\n\nIt probably means…\n\nYou haven’t installed/loaded the package that includes the ggplot() function OR you mispelled the function name\n\nYou should:\n\ncheck if the package is installed\nload the package (library())"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#r-says-1",
    "href": "slides/week-1/w1-intro-r.html#r-says-1",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "R says…",
    "text": "R says…\n\nError: Object some_obj not found.\n\n\nIt probably means…\n\nYou haven’t run the code to create some_obj OR you have a typo in the name!\n\n\nsome_ojb &lt;- 1:10\n\nmean(some_obj)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'mean': object 'some_obj' not found"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#r-says-2",
    "href": "slides/week-1/w1-intro-r.html#r-says-2",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "R says…",
    "text": "R says…\n\nError: Object of type ‘closure’ is not subsettable.\n\n\nIt probably means…\n\nOops, you tried to use square brackets on a function\n\n\nmean[1, 2]\n\nError in mean[1, 2]: object of type 'closure' is not subsettable"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#r-says-3",
    "href": "slides/week-1/w1-intro-r.html#r-says-3",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "R says…",
    "text": "R says…\n\nError: Non-numeric argument to binary operator.\n\n\nIt probably means…\n\nYou tried to do math on data that isn’t numeric.\n\n\n\"a\" + 2\n\nError in \"a\" + 2: non-numeric argument to binary operator"
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#what-if-none-of-these-solved-my-error",
    "href": "slides/week-1/w1-intro-r.html#what-if-none-of-these-solved-my-error",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "What if none of these solved my error?",
    "text": "What if none of these solved my error?\n\nLook at the help file for the function!\nBreak what you are doing down into smaller pieces and look at whether or not each step gives you what you expect\nWhen all else fails, Google your error message.\n\nInclude the function you are using."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#try-it",
    "href": "slides/week-1/w1-intro-r.html#try-it",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "Try it…",
    "text": "Try it…\nWhat’s wrong here?\n\nmatrix(c(\"a\", \"b\", \"c\", \"d\"), num_row = 2)\n\nError in matrix(c(\"a\", \"b\", \"c\", \"d\"), num_row = 2): unused argument (num_row = 2)\n\n\n\n\n\n\n\n\n\nTip\n\n\nLook up the help file for the function matrix by running ?matrix in the Console."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#pa-1-find-the-mistakes",
    "href": "slides/week-1/w1-intro-r.html#pa-1-find-the-mistakes",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "PA 1: Find the Mistakes",
    "text": "PA 1: Find the Mistakes\nPart One:\nThis file has many mistakes in the code. Some are errors that will prevent the file from knitting; some are mistakes that do NOT result in an error.\nFix all the problems in the code chunks.\nPart Two:\nFollow the instructions in the file to uncover a secret message.\nSubmit the name of the poem as the answer to the Canvas Quiz question."
  },
  {
    "objectID": "slides/week-1/w1-intro-r.html#to-do",
    "href": "slides/week-1/w1-intro-r.html#to-do",
    "title": "Intro to STAT 331/531 + Intro to R",
    "section": "To do…",
    "text": "To do…\n\nRead Chapter 1: Introduction\nCheck-ins 1.1 - 1.4\n\nDue Thursday (4/3) before class\n\nPA 1: Find the Mistakes\n\nDue Friday (4/4) at 11:59 pm"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#thursday-april-10",
    "href": "slides/week-2/w2-graphics.html#thursday-april-10",
    "title": "Basics of Graphics",
    "section": "Thursday, April 10",
    "text": "Thursday, April 10\nToday we will…\n\nNew Material\n\nWhat makes a good graphic?\nColor\n\nLab 2: Exploring Rodents with ggplot2"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#lab-1-notes",
    "href": "slides/week-2/w2-graphics.html#lab-1-notes",
    "title": "Basics of Graphics",
    "section": "Lab 1 Notes",
    "text": "Lab 1 Notes\n\nOverall looking nice!\nmake sure your code is visible: echo: true\nsee what your rendered document looks like before you submit it\nif you have questions about statistical interpretations, just ask!"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#graphics",
    "href": "slides/week-2/w2-graphics.html#graphics",
    "title": "Basics of Graphics",
    "section": "Graphics",
    "text": "Graphics\nGraphics consist of:\n\nStructure: boxplot, scatterplot, etc.\nAesthetics: features such as color, shape, and size that map other variables to structural features.\n\nBoth the structure and aesthetics should help viewers interpret the information."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#what-makes-bad-graphics-bad",
    "href": "slides/week-2/w2-graphics.html#what-makes-bad-graphics-bad",
    "title": "Basics of Graphics",
    "section": "What makes bad graphics bad?",
    "text": "What makes bad graphics bad?\n\nBAD DATA.\nToo much “chartjunk” – superfluous details (Tufte).\nDesign choices that are difficult for the human brain to process, including:\n\n\n\n\n\n\nColors\nOrientation\nOrganization"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#what-makes-good-graphics-good",
    "href": "slides/week-2/w2-graphics.html#what-makes-good-graphics-good",
    "title": "Basics of Graphics",
    "section": "What makes good graphics good?",
    "text": "What makes good graphics good?\nEdward R. Tufte is a well-known critic of visualizations, and his definition of graphical excellence consists of:\n\n\ncommunicating complex ideas with clarity, precision, and efficiency.\nmaximizing the data-to-ink ratio.\nusing multivariate displays.\ntelling the truth about the data."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#graphics-1",
    "href": "slides/week-2/w2-graphics.html#graphics-1",
    "title": "Basics of Graphics",
    "section": "Graphics",
    "text": "Graphics\n\nWhen creating graphics, we need to think carefully about how we make structural and aesthetic decisions.\nThis takes iteration and practice!"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#gestalt-principles",
    "href": "slides/week-2/w2-graphics.html#gestalt-principles",
    "title": "Basics of Graphics",
    "section": "Gestalt Principles",
    "text": "Gestalt Principles\nOur brains have an amazing ability to create and perceive structure among visual objects.\n\n“Gestalt principles of visual perception”\nThis framework can help us think about how to create the most expressive and effective data visualizations"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#gestalt-principles-1",
    "href": "slides/week-2/w2-graphics.html#gestalt-principles-1",
    "title": "Basics of Graphics",
    "section": "Gestalt Principles",
    "text": "Gestalt Principles\n\n\n\nGestalt Hierarchy\nGraphical Feature\n\n\n\n\n1. Enclosure\nFacets\n\n\n2. Connection\nLines\n\n\n3. Proximitiy\nWhite Space\n\n\n4. Similarity\nColor/Shape\n\n\n\n\nImplications for practice:\n\nKnow that we perceive some groups before others.\nDesign to facilitate and emphasize the most important comparisons."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pre-attentive-features",
    "href": "slides/week-2/w2-graphics.html#pre-attentive-features",
    "title": "Basics of Graphics",
    "section": "Pre-attentive Features",
    "text": "Pre-attentive Features\n\nThe next slide will have one point that is not like the others.\n\nRaise your hand when you notice it."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pre-attentive-features-1",
    "href": "slides/week-2/w2-graphics.html#pre-attentive-features-1",
    "title": "Basics of Graphics",
    "section": "Pre-attentive Features",
    "text": "Pre-attentive Features"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pre-attentive-features-2",
    "href": "slides/week-2/w2-graphics.html#pre-attentive-features-2",
    "title": "Basics of Graphics",
    "section": "Pre-attentive Features",
    "text": "Pre-attentive Features"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pre-attentive-features-3",
    "href": "slides/week-2/w2-graphics.html#pre-attentive-features-3",
    "title": "Basics of Graphics",
    "section": "Pre-attentive Features",
    "text": "Pre-attentive Features\nPre-attentive features are features that we see and perceive before we even think about it.\n\nThey will jump out at us in less than 250 ms.\nE.g., color, form, movement, spatial location.\n\n\nThere is a hierarchy of features:\n\nColor is stronger than shape.\nCombinations of pre-attentive features may not be pre-attentive due to interference."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#double-encoding",
    "href": "slides/week-2/w2-graphics.html#double-encoding",
    "title": "Basics of Graphics",
    "section": "Double Encoding",
    "text": "Double Encoding"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#no-double-encoding",
    "href": "slides/week-2/w2-graphics.html#no-double-encoding",
    "title": "Basics of Graphics",
    "section": "No Double Encoding",
    "text": "No Double Encoding"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-1",
    "href": "slides/week-2/w2-graphics.html#color-1",
    "title": "Basics of Graphics",
    "section": "Color",
    "text": "Color\n\nColor, hue, and intensity are pre-attentive features, and bigger contrasts lead to faster detection.\n\nHue: main color family (red, orange, yellow…)\nIntensity: amount of color"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines",
    "href": "slides/week-2/w2-graphics.html#color-guidelines",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\n\nDo not use rainbow color gradients!\nBe conscious of what certain colors “mean”.\n\nGood idea to use red for “good” and green for “bad”?"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-1",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-1",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\n\nFor categorical data, try not to use more than 7 colors:\n\n\n\n\n\n\n\n\n\n\nCan use colorRampPalette() from the RColorBrewer package to produce larger palettes:"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-2",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-2",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\n\nFor quantitative data, use mappings from data to color that are numerically and perceptually uniform.\n\nRelative discriminability of two colors should be proportional to the difference between the corresponding data values."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-3",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-3",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\nTo colorblind-proof a graphic…\n\nuse double encoding - when you use color, also use another aesthetic (line type, shape, etc.)."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-4",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-4",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\nTo colorblind-proof a graphic…\n\nwith a unidirectional scale (e.g., all + values), use a monochromatic color gradient.\n\n\n\n\n\n\n\n\n\n\n\nwith a bidirectional scale (e.g., + and - values), use a purple-white-orange color gradient. Transition through white!"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-guidelines-5",
    "href": "slides/week-2/w2-graphics.html#color-guidelines-5",
    "title": "Basics of Graphics",
    "section": "Color Guidelines",
    "text": "Color Guidelines\nTo colorblind-proof a graphic…\n\nprint your chart out in black and white – if you can still read it, it will be safe for all users."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#color-in-ggplot2",
    "href": "slides/week-2/w2-graphics.html#color-in-ggplot2",
    "title": "Basics of Graphics",
    "section": "Color in ggplot2",
    "text": "Color in ggplot2\nThere are several packages with color scheme options:\n\nRcolorbrewer\nggsci\nviridis\nwesanderson\n\nThese packages have color palettes that are aesthetically pleasing and, in many cases, colorblind friendly.\nYou can also take a look at other ways to find nice color palettes. ColorBrewer is my personal favorite."
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#penguins---flipper-length-by-species",
    "href": "slides/week-2/w2-graphics.html#penguins---flipper-length-by-species",
    "title": "Basics of Graphics",
    "section": "Penguins - Flipper Length by Species",
    "text": "Penguins - Flipper Length by Species\n\nSpecies X-AxisSpecies Facets\n\n\n\n\nCode\nggplot(data = penguins,\n       mapping = aes(y = flipper_length_mm, \n                              x = species)) +\n    geom_boxplot() + \n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         x = \"Species\" , \n         y = \"Flipper Length (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = penguins,\n       mapping = aes(y = flipper_length_mm)) +\n    geom_boxplot() + \n    facet_grid(cols = vars(species)) +\n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         y = \"Flipper Length (mm)\")"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#penguins---flipper-length-by-species-sex",
    "href": "slides/week-2/w2-graphics.html#penguins---flipper-length-by-species-sex",
    "title": "Basics of Graphics",
    "section": "Penguins - Flipper Length by Species & Sex",
    "text": "Penguins - Flipper Length by Species & Sex\n\nOption 1Option 2Option 3\n\n\n\n\nCode\nggplot(data = penguins) +\n    geom_boxplot(mapping = aes(y = flipper_length_mm, \n                             x = species,\n                             color = sex)) + \n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         x = \"Species\" , \n         y = \"Flipper Length (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = penguins) +\n    geom_boxplot(mapping = aes(y = flipper_length_mm,\n                               x = sex)) + \n    facet_grid(cols = vars(species)) +\n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         y = \"Flipper Length (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = penguins) +\n    geom_boxplot(mapping = aes(y = flipper_length_mm,\n                               x = species)) + \n    facet_grid(cols = vars(sex)) +\n    labs(title = \"Distribution of Flipper Lengths for Penguin Species\", \n         y = \"Flipper Length (mm)\")"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#pa-2-example---two-categorical-variables",
    "href": "slides/week-2/w2-graphics.html#pa-2-example---two-categorical-variables",
    "title": "Basics of Graphics",
    "section": "PA 2 Example - Two Categorical Variables",
    "text": "PA 2 Example - Two Categorical Variables\n\nColors & ShapesColors & Facets\n\n\n\n\nCode\nggplot(data = penguins) +\n    geom_point(mapping = aes(x = bill_length_mm, \n                             y = bill_depth_mm, \n                             color = species, \n                             shape = island )) + \n    labs(title = \"Relationship Between Bill Length and Bill Depth\", \n         x = \"Bill Length (mm)\" , \n         y = \"Bill Depth (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = penguins,\n       mapping = aes(x = bill_length_mm, \n                     y = bill_depth_mm, \n                     color = species)) +\n  geom_point() + \n  facet_wrap(~island) +\n  labs(x = \"Bill Length (mm)\",\n       y = \"Bill Depth (mm)\", \n       title = \"Relationship Between Bill Length and Bill Depth\")"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#lecture-example---texas-housing-data",
    "href": "slides/week-2/w2-graphics.html#lecture-example---texas-housing-data",
    "title": "Basics of Graphics",
    "section": "Lecture Example - Texas Housing Data",
    "text": "Lecture Example - Texas Housing Data\n\nColorFacet\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median, color = city)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") + \n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices over Time for Select Cities\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = sm_tx,\n       aes(x = date, y = median)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") + \n  facet_wrap(vars(city)) +\n  labs(x = \"Date\",\n       y = \"Median Home Price\",\n       title = \"Texas Housing Prices over Time for Select Cities\")"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#example-1",
    "href": "slides/week-2/w2-graphics.html#example-1",
    "title": "Basics of Graphics",
    "section": "Example 1",
    "text": "Example 1"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#example-2",
    "href": "slides/week-2/w2-graphics.html#example-2",
    "title": "Basics of Graphics",
    "section": "Example 2",
    "text": "Example 2\n\nhttps://www.data-to-viz.com/graph/area.html"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#example-3",
    "href": "slides/week-2/w2-graphics.html#example-3",
    "title": "Basics of Graphics",
    "section": "Example 3",
    "text": "Example 3\n\nhttps://r-graph-gallery.com/web-vertical-line-chart-with-ggplot2.html"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#example-4",
    "href": "slides/week-2/w2-graphics.html#example-4",
    "title": "Basics of Graphics",
    "section": "Example 4",
    "text": "Example 4\n\nhttps://r-graph-gallery.com/web-line-chart-with-labels-at-end-of-line.html"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#lab-2-exploring-rodents-with-ggplot2",
    "href": "slides/week-2/w2-graphics.html#lab-2-exploring-rodents-with-ggplot2",
    "title": "Basics of Graphics",
    "section": "Lab 2: Exploring Rodents with ggplot2",
    "text": "Lab 2: Exploring Rodents with ggplot2"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#lab-formatting",
    "href": "slides/week-2/w2-graphics.html#lab-formatting",
    "title": "Basics of Graphics",
    "section": "Lab Formatting",
    "text": "Lab Formatting\n\nStarting with Lab 2, your labs will be graded more strictly on appearance and code format.\nReview the lab formatting guidelines on Canvas before you submit your lab!\nBig points:\n\nuse relative file paths\nmake sure all markdown renders as expected\nNEVER PRINT OUT FULL DATASETS\nno long code lines - use line breaks liberally\n“clean up” the lab before submitting"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#ggplot2-cheatsheet",
    "href": "slides/week-2/w2-graphics.html#ggplot2-cheatsheet",
    "title": "Basics of Graphics",
    "section": "ggplot2 cheatsheet",
    "text": "ggplot2 cheatsheet\n\nggplot2 cheatsheet"
  },
  {
    "objectID": "slides/week-2/w2-graphics.html#to-do",
    "href": "slides/week-2/w2-graphics.html#to-do",
    "title": "Basics of Graphics",
    "section": "To do…",
    "text": "To do…\n\nLab 2: Exploring Rodents with ggplot2\n\ndue Monday 4/14 at 11:59pm\n\nRead Chapter 3: Data Cleaning and Manipulation\n\nCheck-in 3.1 due Tuesday 4/15 before class"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#tuesday-april-15",
    "href": "slides/week-3/w3-dplyr.html#tuesday-april-15",
    "title": "Data Cleaning & Manipulation",
    "section": "Tuesday, April 15",
    "text": "Tuesday, April 15\nToday we will…\n\nComments from Week 2\nNew Material\n\nData wrangling\nIntroduce the dplyr package.\nUse dplyr verbs to manipulate data.\n\nPA 3: Identify the Mystery College\n\n\n\n\n\n\n\nFollow along\n\n\nRemember to download, save, and open up the starter notes for this week!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#syle-note-of-the-day---spacing",
    "href": "slides/week-3/w3-dplyr.html#syle-note-of-the-day---spacing",
    "title": "Data Cleaning & Manipulation",
    "section": "Syle Note of the Day - Spacing",
    "text": "Syle Note of the Day - Spacing\n\n\nAlways put a space after a comma, but never before\nSurround = with spaces when naming arguments\nSurround many mathematical operators (+, -, *) with spaces (but not all!)\nDon’t include spaces around parentheses for function calls (although you may include a new-line)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#syle-note-of-the-day---spacing-1",
    "href": "slides/week-3/w3-dplyr.html#syle-note-of-the-day---spacing-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Syle Note of the Day - Spacing",
    "text": "Syle Note of the Day - Spacing\nNice:\n\nmean(x, na.rm = TRUE)\n\nheight &lt;- (feet * 12) + inches\n\n2^2\n\nNo thank you:\n\nmean(x,na.rm=TRUE)\nmean( x , na.rm = TRUE )\nmean (x, na.rm = TRUE)\n\nheight&lt;-(feet*12)+inches\n\n2 ^ 2"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#demonstration-data-cereal",
    "href": "slides/week-3/w3-dplyr.html#demonstration-data-cereal",
    "title": "Data Cleaning & Manipulation",
    "section": "Demonstration Data – Cereal",
    "text": "Demonstration Data – Cereal\n\nlibrary(liver)\ndata(cereal)\n\n\n\nData StructureHead of the DataData Summary\n\n\n\nstr(cereal, give.attr = FALSE)\n\n'data.frame':   77 obs. of  16 variables:\n $ name    : Factor w/ 77 levels \"100% Bran\",\"100% Natural Bran\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ manuf   : Factor w/ 7 levels \"A\",\"G\",\"K\",\"N\",..: 4 6 3 3 7 2 3 2 7 5 ...\n $ type    : Factor w/ 2 levels \"cold\",\"hot\": 1 1 1 1 1 1 1 1 1 1 ...\n $ calories: int  70 120 70 50 110 110 110 130 90 90 ...\n $ protein : int  4 3 4 4 2 2 2 3 2 3 ...\n $ fat     : int  1 5 1 0 2 2 0 2 1 0 ...\n $ sodium  : int  130 15 260 140 200 180 125 210 200 210 ...\n $ fiber   : num  10 2 9 14 1 1.5 1 2 4 5 ...\n $ carbo   : num  5 8 7 8 14 10.5 11 18 15 13 ...\n $ sugars  : int  6 8 5 0 8 10 14 8 6 5 ...\n $ potass  : int  280 135 320 330 -1 70 30 100 125 190 ...\n $ vitamins: int  25 0 25 25 25 25 25 25 25 25 ...\n $ shelf   : int  3 3 3 3 3 1 2 3 1 3 ...\n $ weight  : num  1 1 1 1 1 1 1 1.33 1 1 ...\n $ cups    : num  0.33 1 0.33 0.5 0.75 0.75 1 0.75 0.67 0.67 ...\n $ rating  : num  68.4 34 59.4 93.7 34.4 ...\n\n\n\n\n\nhead(cereal) \n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1\n0.75\n29.50954\n\n\n\n\n\n\n\n\n\n\nsummary(cereal)\n\n                        name    manuf    type       calories    \n 100% Bran                : 1   A: 1   cold:74   Min.   : 50.0  \n 100% Natural Bran        : 1   G:22   hot : 3   1st Qu.:100.0  \n All-Bran                 : 1   K:23             Median :110.0  \n All-Bran with Extra Fiber: 1   N: 6             Mean   :106.9  \n Almond Delight           : 1   P: 9             3rd Qu.:110.0  \n Apple Cinnamon Cheerios  : 1   Q: 8             Max.   :160.0  \n (Other)                  :71   R: 8                            \n    protein           fat            sodium          fiber       \n Min.   :1.000   Min.   :0.000   Min.   :  0.0   Min.   : 0.000  \n 1st Qu.:2.000   1st Qu.:0.000   1st Qu.:130.0   1st Qu.: 1.000  \n Median :3.000   Median :1.000   Median :180.0   Median : 2.000  \n Mean   :2.545   Mean   :1.013   Mean   :159.7   Mean   : 2.152  \n 3rd Qu.:3.000   3rd Qu.:2.000   3rd Qu.:210.0   3rd Qu.: 3.000  \n Max.   :6.000   Max.   :5.000   Max.   :320.0   Max.   :14.000  \n                                                                 \n     carbo          sugars           potass          vitamins     \n Min.   :-1.0   Min.   :-1.000   Min.   : -1.00   Min.   :  0.00  \n 1st Qu.:12.0   1st Qu.: 3.000   1st Qu.: 40.00   1st Qu.: 25.00  \n Median :14.0   Median : 7.000   Median : 90.00   Median : 25.00  \n Mean   :14.6   Mean   : 6.922   Mean   : 96.08   Mean   : 28.25  \n 3rd Qu.:17.0   3rd Qu.:11.000   3rd Qu.:120.00   3rd Qu.: 25.00  \n Max.   :23.0   Max.   :15.000   Max.   :330.00   Max.   :100.00  \n                                                                  \n     shelf           weight          cups           rating     \n Min.   :1.000   Min.   :0.50   Min.   :0.250   Min.   :18.04  \n 1st Qu.:1.000   1st Qu.:1.00   1st Qu.:0.670   1st Qu.:33.17  \n Median :2.000   Median :1.00   Median :0.750   Median :40.40  \n Mean   :2.208   Mean   :1.03   Mean   :0.821   Mean   :42.67  \n 3rd Qu.:3.000   3rd Qu.:1.00   3rd Qu.:1.000   3rd Qu.:50.83  \n Max.   :3.000   Max.   :1.50   Max.   :1.500   Max.   :93.70"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#before-jumping-in-to-code",
    "href": "slides/week-3/w3-dplyr.html#before-jumping-in-to-code",
    "title": "Data Cleaning & Manipulation",
    "section": "Before jumping in to code…",
    "text": "Before jumping in to code…\nIn groups, write a game plan or describe in words steps you would take from cereal data to get the output for each of the following:\n\nWhat is the ratio of fiber to sugars in each cereal?\nCreate a new dataset that only has Nabisco cereals and displays the protein, fat, and sodium in each.\nCreate a table that shows, for each manufacturer the average and standard deviation of the grams of sugar in their cereals, along with how many cereals are in the data for each manufacturer. Order the table from most sugar (on average) to least."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#dplyr",
    "href": "slides/week-3/w3-dplyr.html#dplyr",
    "title": "Data Cleaning & Manipulation",
    "section": "dplyr",
    "text": "dplyr\ndplyr is part of the tidyverse that provides us with the Grammar of Data Manipulation.\n\nThis package gives us the tools to wrangle, manipulate, and tidy our data with ease.\nCheck out the dplyr cheatsheet."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#dplyr-verbs",
    "href": "slides/week-3/w3-dplyr.html#dplyr-verbs",
    "title": "Data Cleaning & Manipulation",
    "section": "dplyr verbs",
    "text": "dplyr verbs\n\nfilter() – select rows based on their values\narrange() – sort rows based on their values\nselect() – select columns\nmutate() – add new columns by transforming other columns\nsummarize() – perform summary operations on columns\ngroup_by() – facilitate group-wise operations\n\n\nUse the pipe operator (|&gt; or %&gt;%) to chain together data wrangling operations."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#match-the-dplyr-verb",
    "href": "slides/week-3/w3-dplyr.html#match-the-dplyr-verb",
    "title": "Data Cleaning & Manipulation",
    "section": "Match the dplyr verb",
    "text": "Match the dplyr verb\nIn groups match the dplyr verbs to your suggested steps:\n\nWhat is the ratio of fiber to sugars in each cereal?\nCreate a new dataset that only has Nabisco cereals and displays the protein, fat, and sodium in each.\nCreate a table that shows, for each manufacturer the average and standard deviation of the grams of sugar in their cereals, along with how many cereals are in the data for each manufacturer. Order the table from most sugar (on average) to least."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#the-pipe-operator-1",
    "href": "slides/week-3/w3-dplyr.html#the-pipe-operator-1",
    "title": "Data Cleaning & Manipulation",
    "section": "The Pipe Operator",
    "text": "The Pipe Operator\n\nThe pipe specifies a sequence of operations.\nThe output from one operation is passed (piped) into the first argument of the next operation.\n\n\nThese are equivalent:\n\n\n\nsummary(cereal)\n\n\n\ncereal |&gt; \n  summary()"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#the-pipe-operator-2",
    "href": "slides/week-3/w3-dplyr.html#the-pipe-operator-2",
    "title": "Data Cleaning & Manipulation",
    "section": "The Pipe Operator",
    "text": "The Pipe Operator\n\n\nThe “original” pipe: %&gt;%\n\nLoaded with tidyverse package (part of magrittr).\n\nThe “native” pipe: |&gt;\n\nCreated in R version 4.1.0.\nTools &gt; Global Options... &gt; Code &gt; check Use native pipe operator box to use keyboard shortcut:\n\nctrl/cmd + shift + m"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#the-pipe-operator-3",
    "href": "slides/week-3/w3-dplyr.html#the-pipe-operator-3",
    "title": "Data Cleaning & Manipulation",
    "section": "The Pipe Operator",
    "text": "The Pipe Operator\n\nWith dplyr, your code should read like a sentence.\nThe data is the primary object in your sentence, so it should come first in your code.\nThe pipe operator is an important part of that readability.\n\n\n\ndr_c |&gt;\n  bake_a_dessert()\n\n\n\n\ndr_c |&gt;\n  put_on(\"apron\") |&gt;\n  bake_a_dessert(type = \"cake\")\n\n\n\nSO MUCH better than:\n\n  bake_a_dessert(put_on(dr_c, \"apron\"), type = \"cake\")"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#data-comes-first",
    "href": "slides/week-3/w3-dplyr.html#data-comes-first",
    "title": "Data Cleaning & Manipulation",
    "section": "Data Comes First!",
    "text": "Data Comes First!\ndplyr verbs are designed for piping!\n\nfilter(.data = cereal, ...)\nselect(.data = cereal, ...)\nmutate(.data = cereal, ...)\n\n\n\nThe pipe operator is your friend!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-1",
    "href": "slides/week-3/w3-dplyr.html#filter-1",
    "title": "Data Cleaning & Manipulation",
    "section": "filter()",
    "text": "filter()\nWe filter to the rows (observations) we would like to keep in the data.\n\n\ncereal |&gt; \n  filter(sugars &lt; 5)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17\n3\n110\n25\n1\n1.00\n1.00\n51.59219"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-2",
    "href": "slides/week-3/w3-dplyr.html#filter-2",
    "title": "Data Cleaning & Manipulation",
    "section": "filter()",
    "text": "filter()\nWe can add multiple filters to our data, to get a more specific subset.\n\ncereal |&gt; \n  filter(sugars &lt; 5,\n         type == \"hot\")\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21\n0\n-1\n0\n2\n1\n1.00\n64.53382\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1\n1.00\n54.85092\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1\n0.67\n50.82839"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-handy-helpers",
    "href": "slides/week-3/w3-dplyr.html#filter-handy-helpers",
    "title": "Data Cleaning & Manipulation",
    "section": "filter(): Handy Helpers!",
    "text": "filter(): Handy Helpers!\n\n&gt; – greater than\n&lt; – less than\n== – equal to\n! – not\n%in% – checks if an element belongs to a vector\nis.na() – binary evaluation of missing values\n\n\n\n& and , – and\n| – or"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-3",
    "href": "slides/week-3/w3-dplyr.html#filter-3",
    "title": "Data Cleaning & Manipulation",
    "section": "filter(): |",
    "text": "filter(): |\n\ncereal |&gt; \n  filter(sugars &lt; 5,\n         type == \"hot\")\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21\n0\n-1\n0\n2\n1\n1.00\n64.53382\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1\n1.00\n54.85092\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1\n0.67\n50.82839\n\n\n\n\n\n\n\n\nWhat if I wanted either non-sugary cereals or hot cereals…\n\n\nCode\ncereal |&gt; \n  filter(sugars &lt; 5 |\n           type == \"hot\")"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-in",
    "href": "slides/week-3/w3-dplyr.html#filter-in",
    "title": "Data Cleaning & Manipulation",
    "section": "filter(): %in%",
    "text": "filter(): %in%\nAre you interested in observations with values in multiple levels?\n\n\ncereal |&gt; \n  filter(name %in% c(\"Cheerios\", \"Cinnamon Toast Crunch\", \"Raisin Bran\", \"Cracklin' Oat Bran\"))\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2\n17\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0\n13\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4\n10\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5\n14\n12\n240\n25\n2\n1.33\n0.75\n39.25920"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#filter-related-functions",
    "href": "slides/week-3/w3-dplyr.html#filter-related-functions",
    "title": "Data Cleaning & Manipulation",
    "section": "filter(): Related Functions",
    "text": "filter(): Related Functions\nThese functions select rows by row number.\n\nslice() – select rows with the specified indicies\nslice_head() – select the first n rows\nslice_tail() – select the last n rows\nslice_sample() – randomly select n rows"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#arrange-1",
    "href": "slides/week-3/w3-dplyr.html#arrange-1",
    "title": "Data Cleaning & Manipulation",
    "section": "arrange()",
    "text": "arrange()\nWe arrange the rows of the data in order of a particular variable.\n\n\n\ncereal |&gt; \n  arrange(sodium)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#arrange-2",
    "href": "slides/week-3/w3-dplyr.html#arrange-2",
    "title": "Data Cleaning & Manipulation",
    "section": "arrange()",
    "text": "arrange()\nWe can arrange by multiple variables.\n\n\n\ncereal |&gt; \n  arrange(sodium, sugars) |&gt;\n  select(name:type, sodium, sugars)\n\n\n\n\n\n\n\nname\nmanuf\ntype\nsodium\nsugars\n\n\n\n\nQuaker Oatmeal\nQ\nhot\n0\n-1\n\n\nPuffed Rice\nQ\ncold\n0\n0\n\n\nPuffed Wheat\nQ\ncold\n0\n0\n\n\nShredded Wheat\nN\ncold\n0\n0\n\n\nShredded Wheat 'n'Bran\nN\ncold\n0\n0\n\n\nShredded Wheat spoon size\nN\ncold\n0\n0\n\n\nMaypo\nA\nhot\n0\n3\n\n\nRaisin Squares\nK\ncold\n0\n6\n\n\nFrosted Mini-Wheats\nK\ncold\n0\n7\n\n\nStrawberry Fruit Wheats\nN\ncold\n15\n5\n\n\n100% Natural Bran\nQ\ncold\n15\n8\n\n\nGolden Crisp\nP\ncold\n45\n15\n\n\nSmacks\nK\ncold\n70\n15\n\n\nGreat Grains Pecan\nP\ncold\n75\n4\n\n\nCream of Wheat (Quick)\nN\nhot\n80\n0\n\n\nCorn Pops\nK\ncold\n90\n12\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n95\n11\n\n\nFroot Loops\nK\ncold\n125\n13\n\n\nApple Jacks\nK\ncold\n125\n14\n\n\n100% Bran\nN\ncold\n130\n6\n\n\nQuaker Oat Squares\nQ\ncold\n135\n6\n\n\nFruity Pebbles\nP\ncold\n135\n12\n\n\nAll-Bran with Extra Fiber\nK\ncold\n140\n0\n\n\nGrape Nuts Flakes\nP\ncold\n140\n5\n\n\nClusters\nG\ncold\n140\n7\n\n\nCracklin' Oat Bran\nK\ncold\n140\n7\n\n\nRaisin Nut Bran\nG\ncold\n140\n8\n\n\nCrispy Wheat & Raisins\nG\ncold\n140\n10\n\n\nTrix\nG\ncold\n140\n12\n\n\nLife\nQ\ncold\n150\n6\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n11\n\n\nMueslix Crispy Blend\nK\ncold\n150\n13\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n160\n10\n\n\nNutri-grain Wheat\nK\ncold\n170\n2\n\n\nGrape-Nuts\nP\ncold\n170\n3\n\n\nJust Right Crunchy Nuggets\nK\ncold\n170\n6\n\n\nJust Right Fruit & Nut\nK\ncold\n170\n9\n\n\nOatmeal Raisin Crisp\nG\ncold\n170\n10\n\n\nApple Cinnamon Cheerios\nG\ncold\n180\n10\n\n\nHoney-comb\nP\ncold\n180\n11\n\n\nLucky Charms\nG\ncold\n180\n12\n\n\nCocoa Puffs\nG\ncold\n180\n13\n\n\nCount Chocula\nG\ncold\n180\n13\n\n\nDouble Chex\nR\ncold\n190\n5\n\n\nNut&Honey Crunch\nK\ncold\n190\n9\n\n\nTotal Raisin Bran\nG\ncold\n190\n14\n\n\nTotal Corn Flakes\nG\ncold\n200\n3\n\n\nTotal Whole Grain\nG\ncold\n200\n3\n\n\nWheaties\nG\ncold\n200\n3\n\n\nBran Chex\nR\ncold\n200\n6\n\n\nAlmond Delight\nR\ncold\n200\n8\n\n\nWheaties Honey Gold\nG\ncold\n200\n8\n\n\nFrosted Flakes\nK\ncold\n200\n11\n\n\nPost Nat. Raisin Bran\nP\ncold\n200\n14\n\n\nBran Flakes\nP\ncold\n210\n5\n\n\nBasic 4\nG\ncold\n210\n8\n\n\nCinnamon Toast Crunch\nG\ncold\n210\n9\n\n\nRaisin Bran\nK\ncold\n210\n12\n\n\nCrispix\nK\ncold\n220\n3\n\n\nMulti-Grain Cheerios\nG\ncold\n220\n6\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n220\n7\n\n\nHoney Graham Ohs\nQ\ncold\n220\n11\n\n\nCap'n'Crunch\nQ\ncold\n220\n12\n\n\nSpecial K\nK\ncold\n230\n3\n\n\nWheat Chex\nR\ncold\n230\n3\n\n\nRice Chex\nR\ncold\n240\n2\n\n\nFruitful Bran\nK\ncold\n240\n12\n\n\nTriples\nG\ncold\n250\n3\n\n\nHoney Nut Cheerios\nG\ncold\n250\n10\n\n\nKix\nG\ncold\n260\n3\n\n\nAll-Bran\nK\ncold\n260\n5\n\n\nCorn Chex\nR\ncold\n280\n3\n\n\nGolden Grahams\nG\ncold\n280\n9\n\n\nCheerios\nG\ncold\n290\n1\n\n\nCorn Flakes\nK\ncold\n290\n2\n\n\nRice Krispies\nK\ncold\n290\n3\n\n\nProduct 19\nK\ncold\n320\n3"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#arrange-descending-order",
    "href": "slides/week-3/w3-dplyr.html#arrange-descending-order",
    "title": "Data Cleaning & Manipulation",
    "section": "arrange(): Descending Order",
    "text": "arrange(): Descending Order\nDefault is ascending order…\n\ncereal |&gt; \n  arrange(sodium)\n\n\n…but can add desc() to get descending order!\n\ncereal |&gt; \n  arrange(desc(sodium))"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#arrange-related-functions",
    "href": "slides/week-3/w3-dplyr.html#arrange-related-functions",
    "title": "Data Cleaning & Manipulation",
    "section": "arrange(): Related Functions",
    "text": "arrange(): Related Functions\nThese functions implicitly arrange the data before slicing it (selecting rows).\n\nslice_min() – select rows with the lowest value(s) of a variable\nslice_max() – select rows with the highest value(s) of a variable"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#slice_max",
    "href": "slides/week-3/w3-dplyr.html#slice_max",
    "title": "Data Cleaning & Manipulation",
    "section": "slice_max()",
    "text": "slice_max()\nSelects the n rows with the maximum values of the specified variable.\n\ncereal |&gt; \n  slice_max(order_by = sugars, n = 3)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0\n11\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1\n9\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1\n11\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6\n11\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4\n15\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\n\n\n\n\n\n\n\ncereal |&gt; \n  slice_max(order_by = sugars, n = 3, with_ties = FALSE)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#efficiency-note",
    "href": "slides/week-3/w3-dplyr.html#efficiency-note",
    "title": "Data Cleaning & Manipulation",
    "section": "Efficiency note",
    "text": "Efficiency note\nUse slice_max()/slice_min():\n\ncereal |&gt; \n  slice_max(order_by = sugars, n = 3)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0\n11\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1\n9\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1\n11\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6\n11\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4\n15\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\n\n\n\n\n\nNot arrange() and slice_head():\n\ncereal |&gt; \n  arrange(desc(sugars)) |&gt; \n  slice_head(n = 3)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0\n11\n15\n40\n25\n1\n1\n0.88\n35.25244\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1\n9\n15\n40\n25\n2\n1\n0.75\n31.23005\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1\n11\n14\n30\n25\n2\n1\n1.00\n33.17409"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#select-1",
    "href": "slides/week-3/w3-dplyr.html#select-1",
    "title": "Data Cleaning & Manipulation",
    "section": "select()",
    "text": "select()\nWe select which variables we would like to remain in the data.\n\n\ncereal |&gt; \n  select(name, manuf, calories, cups)\n\n\n\n\n\n\n\nname\nmanuf\ncalories\ncups\n\n\n\n\n100% Bran\nN\n70\n0.33\n\n\n100% Natural Bran\nQ\n120\n1.00\n\n\nAll-Bran\nK\n70\n0.33\n\n\nAll-Bran with Extra Fiber\nK\n50\n0.50\n\n\nAlmond Delight\nR\n110\n0.75\n\n\nApple Cinnamon Cheerios\nG\n110\n0.75\n\n\nApple Jacks\nK\n110\n1.00\n\n\nBasic 4\nG\n130\n0.75\n\n\nBran Chex\nR\n90\n0.67\n\n\nBran Flakes\nP\n90\n0.67\n\n\nCap'n'Crunch\nQ\n120\n0.75\n\n\nCheerios\nG\n110\n1.25\n\n\nCinnamon Toast Crunch\nG\n120\n0.75\n\n\nClusters\nG\n110\n0.50\n\n\nCocoa Puffs\nG\n110\n1.00\n\n\nCorn Chex\nR\n110\n1.00\n\n\nCorn Flakes\nK\n100\n1.00\n\n\nCorn Pops\nK\n110\n1.00\n\n\nCount Chocula\nG\n110\n1.00\n\n\nCracklin' Oat Bran\nK\n110\n0.50\n\n\nCream of Wheat (Quick)\nN\n100\n1.00\n\n\nCrispix\nK\n110\n1.00\n\n\nCrispy Wheat & Raisins\nG\n100\n0.75\n\n\nDouble Chex\nR\n100\n0.75\n\n\nFroot Loops\nK\n110\n1.00\n\n\nFrosted Flakes\nK\n110\n0.75\n\n\nFrosted Mini-Wheats\nK\n100\n0.80\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\n120\n0.67\n\n\nFruitful Bran\nK\n120\n0.67\n\n\nFruity Pebbles\nP\n110\n0.75\n\n\nGolden Crisp\nP\n100\n0.88\n\n\nGolden Grahams\nG\n110\n0.75\n\n\nGrape Nuts Flakes\nP\n100\n0.88\n\n\nGrape-Nuts\nP\n110\n0.25\n\n\nGreat Grains Pecan\nP\n120\n0.33\n\n\nHoney Graham Ohs\nQ\n120\n1.00\n\n\nHoney Nut Cheerios\nG\n110\n0.75\n\n\nHoney-comb\nP\n110\n1.33\n\n\nJust Right Crunchy Nuggets\nK\n110\n1.00\n\n\nJust Right Fruit & Nut\nK\n140\n0.75\n\n\nKix\nG\n110\n1.50\n\n\nLife\nQ\n100\n0.67\n\n\nLucky Charms\nG\n110\n1.00\n\n\nMaypo\nA\n100\n1.00\n\n\nMuesli Raisins; Dates; & Almonds\nR\n150\n1.00\n\n\nMuesli Raisins; Peaches; & Pecans\nR\n150\n1.00\n\n\nMueslix Crispy Blend\nK\n160\n0.67\n\n\nMulti-Grain Cheerios\nG\n100\n1.00\n\n\nNut&Honey Crunch\nK\n120\n0.67\n\n\nNutri-Grain Almond-Raisin\nK\n140\n0.67\n\n\nNutri-grain Wheat\nK\n90\n1.00\n\n\nOatmeal Raisin Crisp\nG\n130\n0.50\n\n\nPost Nat. Raisin Bran\nP\n120\n0.67\n\n\nProduct 19\nK\n100\n1.00\n\n\nPuffed Rice\nQ\n50\n1.00\n\n\nPuffed Wheat\nQ\n50\n1.00\n\n\nQuaker Oat Squares\nQ\n100\n0.50\n\n\nQuaker Oatmeal\nQ\n100\n0.67\n\n\nRaisin Bran\nK\n120\n0.75\n\n\nRaisin Nut Bran\nG\n100\n0.50\n\n\nRaisin Squares\nK\n90\n0.50\n\n\nRice Chex\nR\n110\n1.13\n\n\nRice Krispies\nK\n110\n1.00\n\n\nShredded Wheat\nN\n80\n1.00\n\n\nShredded Wheat 'n'Bran\nN\n90\n0.67\n\n\nShredded Wheat spoon size\nN\n90\n0.67\n\n\nSmacks\nK\n110\n0.75\n\n\nSpecial K\nK\n110\n1.00\n\n\nStrawberry Fruit Wheats\nN\n90\n1.00\n\n\nTotal Corn Flakes\nG\n110\n1.00\n\n\nTotal Raisin Bran\nG\n140\n1.00\n\n\nTotal Whole Grain\nG\n100\n1.00\n\n\nTriples\nG\n110\n0.75\n\n\nTrix\nG\n110\n1.00\n\n\nWheat Chex\nR\n100\n0.67\n\n\nWheaties\nG\n100\n1.00\n\n\nWheaties Honey Gold\nG\n110\n0.75"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#select-2",
    "href": "slides/week-3/w3-dplyr.html#select-2",
    "title": "Data Cleaning & Manipulation",
    "section": "select()",
    "text": "select()\nYou can use : to select a sequence of columns.\n\ncereal |&gt; \n  select(name:calories)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\n\n\n\n\n100% Bran\nN\ncold\n70\n\n\n100% Natural Bran\nQ\ncold\n120\n\n\nAll-Bran\nK\ncold\n70\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n\n\nAlmond Delight\nR\ncold\n110\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n\n\nApple Jacks\nK\ncold\n110\n\n\nBasic 4\nG\ncold\n130\n\n\nBran Chex\nR\ncold\n90\n\n\nBran Flakes\nP\ncold\n90\n\n\nCap'n'Crunch\nQ\ncold\n120\n\n\nCheerios\nG\ncold\n110\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n\n\nClusters\nG\ncold\n110\n\n\nCocoa Puffs\nG\ncold\n110\n\n\nCorn Chex\nR\ncold\n110\n\n\nCorn Flakes\nK\ncold\n100\n\n\nCorn Pops\nK\ncold\n110\n\n\nCount Chocula\nG\ncold\n110\n\n\nCracklin' Oat Bran\nK\ncold\n110\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n\n\nCrispix\nK\ncold\n110\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n\n\nDouble Chex\nR\ncold\n100\n\n\nFroot Loops\nK\ncold\n110\n\n\nFrosted Flakes\nK\ncold\n110\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n\n\nFruitful Bran\nK\ncold\n120\n\n\nFruity Pebbles\nP\ncold\n110\n\n\nGolden Crisp\nP\ncold\n100\n\n\nGolden Grahams\nG\ncold\n110\n\n\nGrape Nuts Flakes\nP\ncold\n100\n\n\nGrape-Nuts\nP\ncold\n110\n\n\nGreat Grains Pecan\nP\ncold\n120\n\n\nHoney Graham Ohs\nQ\ncold\n120\n\n\nHoney Nut Cheerios\nG\ncold\n110\n\n\nHoney-comb\nP\ncold\n110\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n\n\nKix\nG\ncold\n110\n\n\nLife\nQ\ncold\n100\n\n\nLucky Charms\nG\ncold\n110\n\n\nMaypo\nA\nhot\n100\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n\n\nMueslix Crispy Blend\nK\ncold\n160\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n\n\nNut&Honey Crunch\nK\ncold\n120\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n\n\nNutri-grain Wheat\nK\ncold\n90\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n\n\nProduct 19\nK\ncold\n100\n\n\nPuffed Rice\nQ\ncold\n50\n\n\nPuffed Wheat\nQ\ncold\n50\n\n\nQuaker Oat Squares\nQ\ncold\n100\n\n\nQuaker Oatmeal\nQ\nhot\n100\n\n\nRaisin Bran\nK\ncold\n120\n\n\nRaisin Nut Bran\nG\ncold\n100\n\n\nRaisin Squares\nK\ncold\n90\n\n\nRice Chex\nR\ncold\n110\n\n\nRice Krispies\nK\ncold\n110\n\n\nShredded Wheat\nN\ncold\n80\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n\n\nShredded Wheat spoon size\nN\ncold\n90\n\n\nSmacks\nK\ncold\n110\n\n\nSpecial K\nK\ncold\n110\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n\n\nTotal Corn Flakes\nG\ncold\n110\n\n\nTotal Raisin Bran\nG\ncold\n140\n\n\nTotal Whole Grain\nG\ncold\n100\n\n\nTriples\nG\ncold\n110\n\n\nTrix\nG\ncold\n110\n\n\nWheat Chex\nR\ncold\n100\n\n\nWheaties\nG\ncold\n100\n\n\nWheaties Honey Gold\nG\ncold\n110\n\n\n\n\n\n\n\n\nYou can remove columns from the dataset using a -.\n\ncereal |&gt; \n  select(-rating)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#select-reordering",
    "href": "slides/week-3/w3-dplyr.html#select-reordering",
    "title": "Data Cleaning & Manipulation",
    "section": "select(): Reordering",
    "text": "select(): Reordering\nYou can reorder columns inside of select().\n\ncereal |&gt; \n  select(name, rating, manuf, type, calories, cups, weight,\n         everything())\n\n\n\n\n\n\n\nname\nrating\nmanuf\ntype\ncalories\ncups\nweight\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\n\n\n\n\n100% Bran\n68.40297\nN\ncold\n70\n0.33\n1.00\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n\n\n100% Natural Bran\n33.98368\nQ\ncold\n120\n1.00\n1.00\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n\n\nAll-Bran\n59.42551\nK\ncold\n70\n0.33\n1.00\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n\n\nAll-Bran with Extra Fiber\n93.70491\nK\ncold\n50\n0.50\n1.00\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n\n\nAlmond Delight\n34.38484\nR\ncold\n110\n0.75\n1.00\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n\n\nApple Cinnamon Cheerios\n29.50954\nG\ncold\n110\n0.75\n1.00\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n\n\nApple Jacks\n33.17409\nK\ncold\n110\n1.00\n1.00\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n\n\nBasic 4\n37.03856\nG\ncold\n130\n0.75\n1.33\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n\n\nBran Chex\n49.12025\nR\ncold\n90\n0.67\n1.00\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n\n\nBran Flakes\n53.31381\nP\ncold\n90\n0.67\n1.00\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n\n\nCap'n'Crunch\n18.04285\nQ\ncold\n120\n0.75\n1.00\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n\n\nCheerios\n50.76500\nG\ncold\n110\n1.25\n1.00\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n\n\nCinnamon Toast Crunch\n19.82357\nG\ncold\n120\n0.75\n1.00\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n\n\nClusters\n40.40021\nG\ncold\n110\n0.50\n1.00\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n\n\nCocoa Puffs\n22.73645\nG\ncold\n110\n1.00\n1.00\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n\n\nCorn Chex\n41.44502\nR\ncold\n110\n1.00\n1.00\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n\n\nCorn Flakes\n45.86332\nK\ncold\n100\n1.00\n1.00\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n\n\nCorn Pops\n35.78279\nK\ncold\n110\n1.00\n1.00\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n\n\nCount Chocula\n22.39651\nG\ncold\n110\n1.00\n1.00\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n\n\nCracklin' Oat Bran\n40.44877\nK\ncold\n110\n0.50\n1.00\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n\n\nCream of Wheat (Quick)\n64.53382\nN\nhot\n100\n1.00\n1.00\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n\n\nCrispix\n46.89564\nK\ncold\n110\n1.00\n1.00\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n\n\nCrispy Wheat & Raisins\n36.17620\nG\ncold\n100\n0.75\n1.00\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n\n\nDouble Chex\n44.33086\nR\ncold\n100\n0.75\n1.00\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n\n\nFroot Loops\n32.20758\nK\ncold\n110\n1.00\n1.00\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n\n\nFrosted Flakes\n31.43597\nK\ncold\n110\n0.75\n1.00\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n\n\nFrosted Mini-Wheats\n58.34514\nK\ncold\n100\n0.80\n1.00\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n\n\nFruit & Fibre Dates; Walnuts; and Oats\n40.91705\nP\ncold\n120\n0.67\n1.25\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n\n\nFruitful Bran\n41.01549\nK\ncold\n120\n0.67\n1.33\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n\n\nFruity Pebbles\n28.02576\nP\ncold\n110\n0.75\n1.00\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n\n\nGolden Crisp\n35.25244\nP\ncold\n100\n0.88\n1.00\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n\n\nGolden Grahams\n23.80404\nG\ncold\n110\n0.75\n1.00\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n\n\nGrape Nuts Flakes\n52.07690\nP\ncold\n100\n0.88\n1.00\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n\n\nGrape-Nuts\n53.37101\nP\ncold\n110\n0.25\n1.00\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n\n\nGreat Grains Pecan\n45.81172\nP\ncold\n120\n0.33\n1.00\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n\n\nHoney Graham Ohs\n21.87129\nQ\ncold\n120\n1.00\n1.00\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n\n\nHoney Nut Cheerios\n31.07222\nG\ncold\n110\n0.75\n1.00\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n\n\nHoney-comb\n28.74241\nP\ncold\n110\n1.33\n1.00\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n\n\nJust Right Crunchy Nuggets\n36.52368\nK\ncold\n110\n1.00\n1.00\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n\n\nJust Right Fruit & Nut\n36.47151\nK\ncold\n140\n0.75\n1.30\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n\n\nKix\n39.24111\nG\ncold\n110\n1.50\n1.00\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n\n\nLife\n45.32807\nQ\ncold\n100\n0.67\n1.00\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n\n\nLucky Charms\n26.73451\nG\ncold\n110\n1.00\n1.00\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n\n\nMaypo\n54.85092\nA\nhot\n100\n1.00\n1.00\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n\n\nMuesli Raisins; Dates; & Almonds\n37.13686\nR\ncold\n150\n1.00\n1.00\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n\n\nMuesli Raisins; Peaches; & Pecans\n34.13976\nR\ncold\n150\n1.00\n1.00\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n\n\nMueslix Crispy Blend\n30.31335\nK\ncold\n160\n0.67\n1.50\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n\n\nMulti-Grain Cheerios\n40.10596\nG\ncold\n100\n1.00\n1.00\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n\n\nNut&Honey Crunch\n29.92429\nK\ncold\n120\n0.67\n1.00\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n\n\nNutri-Grain Almond-Raisin\n40.69232\nK\ncold\n140\n0.67\n1.33\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n\n\nNutri-grain Wheat\n59.64284\nK\ncold\n90\n1.00\n1.00\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n\n\nOatmeal Raisin Crisp\n30.45084\nG\ncold\n130\n0.50\n1.25\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n\n\nPost Nat. Raisin Bran\n37.84059\nP\ncold\n120\n0.67\n1.33\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n\n\nProduct 19\n41.50354\nK\ncold\n100\n1.00\n1.00\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n\n\nPuffed Rice\n60.75611\nQ\ncold\n50\n1.00\n0.50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n\n\nPuffed Wheat\n63.00565\nQ\ncold\n50\n1.00\n0.50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n\n\nQuaker Oat Squares\n49.51187\nQ\ncold\n100\n0.50\n1.00\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n\n\nQuaker Oatmeal\n50.82839\nQ\nhot\n100\n0.67\n1.00\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n\n\nRaisin Bran\n39.25920\nK\ncold\n120\n0.75\n1.33\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n\n\nRaisin Nut Bran\n39.70340\nG\ncold\n100\n0.50\n1.00\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n\n\nRaisin Squares\n55.33314\nK\ncold\n90\n0.50\n1.00\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n\n\nRice Chex\n41.99893\nR\ncold\n110\n1.13\n1.00\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n\n\nRice Krispies\n40.56016\nK\ncold\n110\n1.00\n1.00\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n\n\nShredded Wheat\n68.23588\nN\ncold\n80\n1.00\n0.83\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n\n\nShredded Wheat 'n'Bran\n74.47295\nN\ncold\n90\n0.67\n1.00\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n\n\nShredded Wheat spoon size\n72.80179\nN\ncold\n90\n0.67\n1.00\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n\n\nSmacks\n31.23005\nK\ncold\n110\n0.75\n1.00\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n\n\nSpecial K\n53.13132\nK\ncold\n110\n1.00\n1.00\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n\n\nStrawberry Fruit Wheats\n59.36399\nN\ncold\n90\n1.00\n1.00\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n\n\nTotal Corn Flakes\n38.83975\nG\ncold\n110\n1.00\n1.00\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n\n\nTotal Raisin Bran\n28.59278\nG\ncold\n140\n1.00\n1.50\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n\n\nTotal Whole Grain\n46.65884\nG\ncold\n100\n1.00\n1.00\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n\n\nTriples\n39.10617\nG\ncold\n110\n0.75\n1.00\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n\n\nTrix\n27.75330\nG\ncold\n110\n1.00\n1.00\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n\n\nWheat Chex\n49.78744\nR\ncold\n100\n0.67\n1.00\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n\n\nWheaties\n51.59219\nG\ncold\n100\n1.00\n1.00\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n\n\nWheaties Honey Gold\n36.18756\nG\ncold\n110\n0.75\n1.00\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#select-handy-helpers",
    "href": "slides/week-3/w3-dplyr.html#select-handy-helpers",
    "title": "Data Cleaning & Manipulation",
    "section": "select(): Handy Helpers!",
    "text": "select(): Handy Helpers!\n\neverything() – selects all columns that you have not already specified\nstarts_with() – selects columns with names that start with the specified string\nends_with() – selects columns with names that end with the specified string\ncontains() – selects columns with names that contain the specified string\nwhere() – applies a function to all variables and selects those for which the function returns TRUE\n\nSee the help file for select()!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#rename",
    "href": "slides/week-3/w3-dplyr.html#rename",
    "title": "Data Cleaning & Manipulation",
    "section": "rename()",
    "text": "rename()\n\nYou can rename columns with select(), but all columns not specified will be dropped.\n\nUsing the rename() function is easier!\n\n\n\ncereal |&gt; \n  rename(temp = type)\n\n\n\n\n\n\n\nname\nmanuf\ntemp\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#mutate-1",
    "href": "slides/week-3/w3-dplyr.html#mutate-1",
    "title": "Data Cleaning & Manipulation",
    "section": "mutate()",
    "text": "mutate()\nThe dataset gets mutated to either include a new variable…\n\ncereal |&gt; \n  mutate(potass_per_cup = potass / cups)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\npotass_per_cup\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n848.484848\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n135.000000\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n969.696970\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n660.000000\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n-1.333333\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n93.333333\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n30.000000\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n133.333333\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n186.567164\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n283.582090\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n46.666667\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n84.000000\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n60.000000\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n210.000000\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n55.000000\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n25.000000\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n35.000000\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n20.000000\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n65.000000\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n320.000000\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n-1.000000\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n30.000000\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n160.000000\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n106.666667\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n30.000000\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n33.333333\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n125.000000\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n298.507463\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n283.582090\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n33.333333\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n45.454546\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n60.000000\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n96.590909\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n360.000000\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n303.030303\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n45.000000\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n120.000000\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n26.315790\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n60.000000\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n126.666667\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n26.666667\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n141.791045\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n55.000000\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n95.000000\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n170.000000\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n170.000000\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n238.805970\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n90.000000\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n59.701493\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n194.029851\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n90.000000\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n240.000000\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n388.059702\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n45.000000\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n15.000000\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n50.000000\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n220.000000\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n164.179104\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n320.000000\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n280.000000\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n220.000000\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n26.548673\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n35.000000\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n95.000000\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n208.955224\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n179.104478\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n53.333333\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n55.000000\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n90.000000\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n35.000000\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n230.000000\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n110.000000\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n80.000000\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n25.000000\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n171.641791\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n110.000000\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n80.000000\n\n\n\n\n\n\n\n\n…OR revise an existing variable.\n\ncereal |&gt; \n  mutate(shelf = as.factor(shelf))"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#mutate-handy-helpers",
    "href": "slides/week-3/w3-dplyr.html#mutate-handy-helpers",
    "title": "Data Cleaning & Manipulation",
    "section": "mutate(): Handy Helpers!",
    "text": "mutate(): Handy Helpers!\n\nif_else() or case_when() – shortcut for if-else loop\nas.factor(), as.numeric(), etc. – change variable type\n+, -, *, / – basic mathematical operations\n%% – modulo (returns the remainder when doing division)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#summarize-1",
    "href": "slides/week-3/w3-dplyr.html#summarize-1",
    "title": "Data Cleaning & Manipulation",
    "section": "summarize()",
    "text": "summarize()\nWe can calculate summaries of variables in the data.\n\n\ncereal |&gt; \n  summarise(mean_fiber = mean(fiber))\n\n  mean_fiber\n1   2.151948\n\n\n\n\nOr multiple summaries at the same time.\n\ncereal |&gt; \nsummarise(mean_fiber = mean(fiber),\n          num_cereals = n(),\n          mean_sugar = mean(sugars))\n\n  mean_fiber num_cereals mean_sugar\n1   2.151948          77   6.922078\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nsummarize() and summarise() are synonyms!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#summarize-handy-helpers",
    "href": "slides/week-3/w3-dplyr.html#summarize-handy-helpers",
    "title": "Data Cleaning & Manipulation",
    "section": "summarize(): Handy Helpers!",
    "text": "summarize(): Handy Helpers!\n\nmean(), median(), sd(), sum()\nmin(), max()\nn(), n_distinct() – counts the number of (distinct) elements\nfirst(), last(), nth() – extract the first, last, or nth element\nacross() – apply a function across columns"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#group_by-1",
    "href": "slides/week-3/w3-dplyr.html#group_by-1",
    "title": "Data Cleaning & Manipulation",
    "section": "group_by()",
    "text": "group_by()\nSeparate the data into different groups based on a categorical variable.\n\n\nThe data gets grouped, but nothing happens externally if used on its own.\n\n\ncereal |&gt; \n  group_by(type)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#group_by-summarize",
    "href": "slides/week-3/w3-dplyr.html#group_by-summarize",
    "title": "Data Cleaning & Manipulation",
    "section": "group_by() + summarize()!",
    "text": "group_by() + summarize()!\n\ngroup_by a variable (or multiple variables)\nsummarize a variable (or multiple variables) within the groups\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_sugar = mean(sugars))\n\n\n\n\n\n\n\nmanuf\nmean_sugar\n\n\n\n\nA\n3.000000\n\n\nG\n7.954546\n\n\nK\n7.565217\n\n\nN\n1.833333\n\n\nP\n8.777778\n\n\nQ\n5.250000\n\n\nR\n6.125000"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#group_by-mutate",
    "href": "slides/week-3/w3-dplyr.html#group_by-mutate",
    "title": "Data Cleaning & Manipulation",
    "section": "group_by() + mutate()!",
    "text": "group_by() + mutate()!\n\ngroup_by a variable (or multiple variables)\nmutate a variable (or multiple variables) within the groups\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  mutate(mean_sugar = mean(sugars))\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\nmean_sugar\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n1.833333\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n5.250000\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n7.565217\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n7.565217\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n6.125000\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n7.954546\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n7.565217\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n7.954546\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n6.125000\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n8.777778\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n5.250000\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n7.954546\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n7.954546\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n7.954546\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n7.954546\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n6.125000\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n7.565217\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n7.565217\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n7.954546\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n7.565217\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n1.833333\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n7.565217\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n7.954546\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n6.125000\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n7.565217\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n7.565217\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n7.565217\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n8.777778\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n7.565217\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n8.777778\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n8.777778\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n7.954546\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n8.777778\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n8.777778\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n8.777778\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n5.250000\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n7.954546\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n8.777778\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n7.565217\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n7.565217\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n7.954546\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n5.250000\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n7.954546\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n3.000000\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n6.125000\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n6.125000\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n7.565217\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n7.954546\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n7.565217\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n7.565217\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n7.565217\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n7.954546\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n8.777778\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n7.565217\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n5.250000\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n5.250000\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n5.250000\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n5.250000\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n7.565217\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n7.954546\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n7.565217\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n6.125000\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n7.565217\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n1.833333\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n1.833333\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n1.833333\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n7.565217\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n7.565217\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n1.833333\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n7.954546\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n7.954546\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n7.954546\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n7.954546\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n7.954546\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n6.125000\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n7.954546\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n7.954546"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#mutate-vs-summarise",
    "href": "slides/week-3/w3-dplyr.html#mutate-vs-summarise",
    "title": "Data Cleaning & Manipulation",
    "section": "mutate() vs summarise()",
    "text": "mutate() vs summarise()\n\ngroup_by() + summarize() collapses the data.\n\nYou will only have one row per group remaining.\nYou will only have one column for each grouping variable, plus each variable that you specified in summarize.\n\n\ngroup_by() + mutate() does not.\n\nYou will have the full number of rows remaining.\nYou will have the full number of columns remaining, plus additional columns you created."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#mutate-vs-summarise-1",
    "href": "slides/week-3/w3-dplyr.html#mutate-vs-summarise-1",
    "title": "Data Cleaning & Manipulation",
    "section": "mutate() vs summarise()",
    "text": "mutate() vs summarise()\n\nsummarise()mutate()"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#quick-check",
    "href": "slides/week-3/w3-dplyr.html#quick-check",
    "title": "Data Cleaning & Manipulation",
    "section": "Quick check",
    "text": "Quick check\nHow many rows and columns will each of these data frames have?\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  mutate(fiber_carb_rat = mean(fiber / carbo))\n\n\n\ncereal |&gt; \n  group_by(manuf) |&gt; \n  summarize(fiber_carb_rat = mean(fiber / carbo))\n\n\n\n\n\n\n\n\nTip\n\n\nThe cereal data starts with 77 rows and 16 columns. There are 7 manufacturers in the data."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#ungroup",
    "href": "slides/week-3/w3-dplyr.html#ungroup",
    "title": "Data Cleaning & Manipulation",
    "section": "ungroup()",
    "text": "ungroup()\nThe ungroup() function will remove the internal grouping in your data.\n\n\nUseful if you want to create a different grouping\nThis is not something that you always need to do.\nTip: if you are getting unexpected output downstream from a group_by() statement, try ungrouping your data!"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#glue-it-all-together",
    "href": "slides/week-3/w3-dplyr.html#glue-it-all-together",
    "title": "Data Cleaning & Manipulation",
    "section": "Glue it all together!",
    "text": "Glue it all together!\n\ncereal |&gt; \n  filter(type == \"cold\") |&gt; \n  mutate(potass_per_cup = potass / cups) |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_potass_per_cup = mean(potass_per_cup))\n\n\n\n\n\n\n\nmanuf\nmean_potass_per_cup\n\n\n\n\nG\n109.1970\n\n\nK\n175.3978\n\n\nN\n284.3089\n\n\nP\n203.8749\n\n\nQ\n93.3511\n\n\nR\n106.8864"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#save-your-changes",
    "href": "slides/week-3/w3-dplyr.html#save-your-changes",
    "title": "Data Cleaning & Manipulation",
    "section": "Save your changes!",
    "text": "Save your changes!\nWhen you manipulate your data, make sure you assign your new dataset to a variable.\n\ncereal_summary &lt;- cereal |&gt; \n  filter(type == \"cold\") |&gt; \n  mutate(potass_per_cup = potas / cups) |&gt; \n  group_by(manuf) |&gt; \n  summarise(mean_potass_per_cup = mean(potass_per_cup))"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#code-formatting",
    "href": "slides/week-3/w3-dplyr.html#code-formatting",
    "title": "Data Cleaning & Manipulation",
    "section": "Code Formatting",
    "text": "Code Formatting\nSimilar to the + formatting in ggplot, do not continue a line after writing a |&gt;!\n\nBad PracticeGood Practice\n\n\n\ncereal |&gt; group_by(type) |&gt; summarise(mean_fiber = mean(fiber), num_cereals = n(), mean_sugar = mean(sugars))\n\n\n\n\ncereal |&gt; \n  group_by(type) |&gt; \n  summarise(mean_fiber = mean(fiber), \n            num_cereals = n(),\n            mean_sugar = mean(sugars))"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#now-you",
    "href": "slides/week-3/w3-dplyr.html#now-you",
    "title": "Data Cleaning & Manipulation",
    "section": "Now you!",
    "text": "Now you!\nIn your group implement the dplyr pipelines to address the three questions from the beginning of class:\n\nWhat is the ratio of fiber to sugars in each cereal?\nCreate a new dataset that only has Nabisco cereals and displays the protein, fat, and sodium in each.\nCreate a table that shows, for each manufacturer the average and standard deviation of the grams of sugar in their cereals, along with how many cereals are in the data for each manufacturer. Order the table from most sugar (on average) to least."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#pa-3-identify-the-mystery-college",
    "href": "slides/week-3/w3-dplyr.html#pa-3-identify-the-mystery-college",
    "title": "Data Cleaning & Manipulation",
    "section": "PA 3: Identify the Mystery College",
    "text": "PA 3: Identify the Mystery College\nToday you will use the dplyr package to clean some data and then use that cleaned data to figure out what college Margaret has been accepted to.\n\nSubmit the full name of the college Margaret will attend to the Canvas Quiz."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#to-do",
    "href": "slides/week-3/w3-dplyr.html#to-do",
    "title": "Data Cleaning & Manipulation",
    "section": "To do…",
    "text": "To do…\n\nPA 3: Identify the Mystery College\n\nDue Thursday 4/17 before class\n\nExtra Data Ethics Reading\n\nData Feminism: The Numbers Don’t Speak for Themselves\nRead before class on Thursday\n\nLab 3: Teacher Evaluations\n\nDue Monday 4/21 at 11:59 pm"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-filter-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-filter-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “filter” in base R?",
    "text": "How do we “filter” in base R?\nYou can use the subset() function!\n\ncereal |&gt; \n  subset(name %in% c(\"Cheerios\", \"Cinnamon Toast Crunch\", \"Raisin Bran\", \"Cracklin' Oat Bran\"))\n\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n12\nCheerios\nG\ncold\n110\n6\n2\n290\n2\n17\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\n13\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0\n13\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\n20\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4\n10\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\n59\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5\n14\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\n\n\n\n\n\n\n\ncereal |&gt; \n  subset(sugars &lt; 5 & type == \"hot\")\n\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n21\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21\n0\n-1\n0\n2\n1\n1.00\n64.53382\n\n\n44\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16\n3\n95\n25\n2\n1\n1.00\n54.85092\n\n\n58\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1\n-1\n110\n0\n1\n1\n0.67\n50.82839"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-arrange-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-arrange-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “arrange” in base R?",
    "text": "How do we “arrange” in base R?\nYou can use the order() function!\n\ncereal[order(cereal$sodium),]\n\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n27\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\n44\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\n55\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\n56\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\n58\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\n61\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\n64\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\n65\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\n66\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\n2\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\n69\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\n31\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\n67\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\n35\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\n21\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\n18\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\n45\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\n7\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\n25\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\n1\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n30\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\n57\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\n4\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\n14\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\n20\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\n23\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\n33\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\n60\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\n74\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\n42\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\n46\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\n47\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\n28\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\n34\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\n39\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\n40\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\n51\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\n52\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\n6\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\n15\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\n19\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\n38\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\n43\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\n24\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\n49\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\n71\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\n5\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\n9\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\n26\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\n53\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\n70\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\n72\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\n76\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\n77\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n\n\n8\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\n10\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\n13\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\n59\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\n11\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\n22\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\n36\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\n48\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\n50\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\n68\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\n75\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\n29\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\n62\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\n37\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\n73\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\n3\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\n41\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\n16\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\n32\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\n12\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\n17\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\n63\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\n54\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\n\n\n\n\n\n\n\ncereal[order(cereal$sodium, cereal$sugars),]\n\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n58\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\n55\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\n56\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\n64\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\n65\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\n66\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\n44\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\n61\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\n27\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\n69\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\n2\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\n31\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\n67\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\n35\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\n21\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\n18\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\n45\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\n25\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\n7\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\n1\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n57\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\n30\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\n4\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\n33\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\n14\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\n20\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\n60\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\n23\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\n74\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\n42\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\n46\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\n47\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\n28\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\n51\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\n34\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\n39\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\n40\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\n52\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\n6\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\n38\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\n43\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\n15\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\n19\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\n24\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\n49\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\n71\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\n70\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\n72\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\n76\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\n9\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\n5\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\n77\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n\n\n26\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\n53\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\n10\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\n8\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\n13\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\n59\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\n22\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\n48\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\n50\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\n36\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\n11\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\n68\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\n75\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\n62\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\n29\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\n73\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\n37\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\n41\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\n3\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\n16\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\n32\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\n12\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\n17\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\n63\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\n54\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-select-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-select-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “select” in base R?",
    "text": "How do we “select” in base R?\nYou don’t really use a specific function!\n\ncereal[,c(\"name\", \"manuf\", \"calories\", \"cups\")]\n\n\n\n\n\n\n\nname\nmanuf\ncalories\ncups\n\n\n\n\n100% Bran\nN\n70\n0.33\n\n\n100% Natural Bran\nQ\n120\n1.00\n\n\nAll-Bran\nK\n70\n0.33\n\n\nAll-Bran with Extra Fiber\nK\n50\n0.50\n\n\nAlmond Delight\nR\n110\n0.75\n\n\nApple Cinnamon Cheerios\nG\n110\n0.75\n\n\nApple Jacks\nK\n110\n1.00\n\n\nBasic 4\nG\n130\n0.75\n\n\nBran Chex\nR\n90\n0.67\n\n\nBran Flakes\nP\n90\n0.67\n\n\nCap'n'Crunch\nQ\n120\n0.75\n\n\nCheerios\nG\n110\n1.25\n\n\nCinnamon Toast Crunch\nG\n120\n0.75\n\n\nClusters\nG\n110\n0.50\n\n\nCocoa Puffs\nG\n110\n1.00\n\n\nCorn Chex\nR\n110\n1.00\n\n\nCorn Flakes\nK\n100\n1.00\n\n\nCorn Pops\nK\n110\n1.00\n\n\nCount Chocula\nG\n110\n1.00\n\n\nCracklin' Oat Bran\nK\n110\n0.50\n\n\nCream of Wheat (Quick)\nN\n100\n1.00\n\n\nCrispix\nK\n110\n1.00\n\n\nCrispy Wheat & Raisins\nG\n100\n0.75\n\n\nDouble Chex\nR\n100\n0.75\n\n\nFroot Loops\nK\n110\n1.00\n\n\nFrosted Flakes\nK\n110\n0.75\n\n\nFrosted Mini-Wheats\nK\n100\n0.80\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\n120\n0.67\n\n\nFruitful Bran\nK\n120\n0.67\n\n\nFruity Pebbles\nP\n110\n0.75\n\n\nGolden Crisp\nP\n100\n0.88\n\n\nGolden Grahams\nG\n110\n0.75\n\n\nGrape Nuts Flakes\nP\n100\n0.88\n\n\nGrape-Nuts\nP\n110\n0.25\n\n\nGreat Grains Pecan\nP\n120\n0.33\n\n\nHoney Graham Ohs\nQ\n120\n1.00\n\n\nHoney Nut Cheerios\nG\n110\n0.75\n\n\nHoney-comb\nP\n110\n1.33\n\n\nJust Right Crunchy Nuggets\nK\n110\n1.00\n\n\nJust Right Fruit & Nut\nK\n140\n0.75\n\n\nKix\nG\n110\n1.50\n\n\nLife\nQ\n100\n0.67\n\n\nLucky Charms\nG\n110\n1.00\n\n\nMaypo\nA\n100\n1.00\n\n\nMuesli Raisins; Dates; & Almonds\nR\n150\n1.00\n\n\nMuesli Raisins; Peaches; & Pecans\nR\n150\n1.00\n\n\nMueslix Crispy Blend\nK\n160\n0.67\n\n\nMulti-Grain Cheerios\nG\n100\n1.00\n\n\nNut&Honey Crunch\nK\n120\n0.67\n\n\nNutri-Grain Almond-Raisin\nK\n140\n0.67\n\n\nNutri-grain Wheat\nK\n90\n1.00\n\n\nOatmeal Raisin Crisp\nG\n130\n0.50\n\n\nPost Nat. Raisin Bran\nP\n120\n0.67\n\n\nProduct 19\nK\n100\n1.00\n\n\nPuffed Rice\nQ\n50\n1.00\n\n\nPuffed Wheat\nQ\n50\n1.00\n\n\nQuaker Oat Squares\nQ\n100\n0.50\n\n\nQuaker Oatmeal\nQ\n100\n0.67\n\n\nRaisin Bran\nK\n120\n0.75\n\n\nRaisin Nut Bran\nG\n100\n0.50\n\n\nRaisin Squares\nK\n90\n0.50\n\n\nRice Chex\nR\n110\n1.13\n\n\nRice Krispies\nK\n110\n1.00\n\n\nShredded Wheat\nN\n80\n1.00\n\n\nShredded Wheat 'n'Bran\nN\n90\n0.67\n\n\nShredded Wheat spoon size\nN\n90\n0.67\n\n\nSmacks\nK\n110\n0.75\n\n\nSpecial K\nK\n110\n1.00\n\n\nStrawberry Fruit Wheats\nN\n90\n1.00\n\n\nTotal Corn Flakes\nG\n110\n1.00\n\n\nTotal Raisin Bran\nG\n140\n1.00\n\n\nTotal Whole Grain\nG\n100\n1.00\n\n\nTriples\nG\n110\n0.75\n\n\nTrix\nG\n110\n1.00\n\n\nWheat Chex\nR\n100\n0.67\n\n\nWheaties\nG\n100\n1.00\n\n\nWheaties Honey Gold\nG\n110\n0.75\n\n\n\n\n\n\n\n\n\ncereal |&gt; \n  subset(select = -c(rating))\n\n\n\n\n\ncolnames(cereal)[2:4] &lt;- c(\"maker\",\"temp\",\"cals\")"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-mutate-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-mutate-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “mutate” in base R?",
    "text": "How do we “mutate” in base R?\nYou can define new columns…\n\ncereal$potass_per_cup &lt;- cereal$potass / cereal$cups\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\npotass_per_cup\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n848.484848\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n135.000000\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n969.696970\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n660.000000\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n-1.333333\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n93.333333\n\n\nApple Jacks\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n30.000000\n\n\nBasic 4\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n133.333333\n\n\nBran Chex\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n186.567164\n\n\nBran Flakes\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n283.582090\n\n\nCap'n'Crunch\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n46.666667\n\n\nCheerios\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n84.000000\n\n\nCinnamon Toast Crunch\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n60.000000\n\n\nClusters\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n210.000000\n\n\nCocoa Puffs\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n55.000000\n\n\nCorn Chex\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n25.000000\n\n\nCorn Flakes\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n35.000000\n\n\nCorn Pops\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n20.000000\n\n\nCount Chocula\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n65.000000\n\n\nCracklin' Oat Bran\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n320.000000\n\n\nCream of Wheat (Quick)\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n-1.000000\n\n\nCrispix\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n30.000000\n\n\nCrispy Wheat & Raisins\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n160.000000\n\n\nDouble Chex\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n106.666667\n\n\nFroot Loops\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n30.000000\n\n\nFrosted Flakes\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n33.333333\n\n\nFrosted Mini-Wheats\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n125.000000\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n298.507463\n\n\nFruitful Bran\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n283.582090\n\n\nFruity Pebbles\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n33.333333\n\n\nGolden Crisp\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n45.454546\n\n\nGolden Grahams\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n60.000000\n\n\nGrape Nuts Flakes\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n96.590909\n\n\nGrape-Nuts\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n360.000000\n\n\nGreat Grains Pecan\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n303.030303\n\n\nHoney Graham Ohs\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n45.000000\n\n\nHoney Nut Cheerios\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n120.000000\n\n\nHoney-comb\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n26.315790\n\n\nJust Right Crunchy Nuggets\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n60.000000\n\n\nJust Right Fruit & Nut\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n126.666667\n\n\nKix\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n26.666667\n\n\nLife\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n141.791045\n\n\nLucky Charms\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n55.000000\n\n\nMaypo\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n95.000000\n\n\nMuesli Raisins; Dates; & Almonds\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n170.000000\n\n\nMuesli Raisins; Peaches; & Pecans\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n170.000000\n\n\nMueslix Crispy Blend\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n238.805970\n\n\nMulti-Grain Cheerios\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n90.000000\n\n\nNut&Honey Crunch\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n59.701493\n\n\nNutri-Grain Almond-Raisin\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n194.029851\n\n\nNutri-grain Wheat\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n90.000000\n\n\nOatmeal Raisin Crisp\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n240.000000\n\n\nPost Nat. Raisin Bran\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n388.059702\n\n\nProduct 19\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n45.000000\n\n\nPuffed Rice\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n15.000000\n\n\nPuffed Wheat\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n50.000000\n\n\nQuaker Oat Squares\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n220.000000\n\n\nQuaker Oatmeal\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n164.179104\n\n\nRaisin Bran\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n320.000000\n\n\nRaisin Nut Bran\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n280.000000\n\n\nRaisin Squares\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n220.000000\n\n\nRice Chex\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n26.548673\n\n\nRice Krispies\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n35.000000\n\n\nShredded Wheat\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n95.000000\n\n\nShredded Wheat 'n'Bran\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n208.955224\n\n\nShredded Wheat spoon size\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n179.104478\n\n\nSmacks\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n53.333333\n\n\nSpecial K\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n55.000000\n\n\nStrawberry Fruit Wheats\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n90.000000\n\n\nTotal Corn Flakes\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n35.000000\n\n\nTotal Raisin Bran\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n230.000000\n\n\nTotal Whole Grain\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n110.000000\n\n\nTriples\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n80.000000\n\n\nTrix\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n25.000000\n\n\nWheat Chex\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n171.641791\n\n\nWheaties\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n110.000000\n\n\nWheaties Honey Gold\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756\n80.000000\n\n\n\n\n\n\n\n\n…OR overwrite old ones!\n\ncereal$shelf &lt;- as.factor(cereal$shelf)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#how-do-we-group-and-summarize-in-base-r",
    "href": "slides/week-3/w3-dplyr.html#how-do-we-group-and-summarize-in-base-r",
    "title": "Data Cleaning & Manipulation",
    "section": "How do we “group” and “summarize” in base R?",
    "text": "How do we “group” and “summarize” in base R?\nYou can use the aggregate() function.\n\ncereal |&gt; \n  aggregate(sugars ~ manuf, FUN = mean)\n\n\n\n\n\n\n\nmanuf\nsugars\n\n\n\n\nA\n3.000000\n\n\nG\n7.954546\n\n\nK\n7.565217\n\n\nN\n1.833333\n\n\nP\n8.777778\n\n\nQ\n5.250000\n\n\nR\n6.125000"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#questions-from-week-2",
    "href": "slides/week-3/w3-dplyr.html#questions-from-week-2",
    "title": "Data Cleaning & Manipulation",
    "section": "Questions from Week 2?",
    "text": "Questions from Week 2?\n\nStat departmnet joke of the week by Syliva Du. Image created with AI."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#check-in-3.1-question-8",
    "href": "slides/week-3/w3-dplyr.html#check-in-3.1-question-8",
    "title": "Data Cleaning & Manipulation",
    "section": "Check-in 3.1 Question 8",
    "text": "Check-in 3.1 Question 8\n\nWhile the following code runs it does not do what we want:\n\n\npenguins |&gt; \n  filter(species == \"Adelie\") |&gt; \n  select(body_mass_g) |&gt; \n  mean(na.rm = T)\n\nWarning in mean.default(select(filter(penguins, species == \"Adelie\"),\nbody_mass_g), : argument is not numeric or logical: returning NA\n\n\n[1] NA\n\n\n\nWe will learn how to fix this code on Thursday\nI will go back and fix grades. Either choosing “Line 4” or “No error” will be considered correct."
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#style-note-of-the-day---spacing",
    "href": "slides/week-3/w3-dplyr.html#style-note-of-the-day---spacing",
    "title": "Data Cleaning & Manipulation",
    "section": "Style Note of the Day - Spacing",
    "text": "Style Note of the Day - Spacing\n\n\nAlways put a space after a comma, but never before\nSurround = with spaces when naming arguments\nSurround many mathematical operators (+, -, *) with spaces (but not all!)\nDon’t include spaces around parentheses for function calls (although you may include a new-line)"
  },
  {
    "objectID": "slides/week-3/w3-dplyr.html#style-note-of-the-day---spacing-1",
    "href": "slides/week-3/w3-dplyr.html#style-note-of-the-day---spacing-1",
    "title": "Data Cleaning & Manipulation",
    "section": "Style Note of the Day - Spacing",
    "text": "Style Note of the Day - Spacing\nNice:\n\nmean(x, na.rm = TRUE)\n\nheight &lt;- (feet * 12) + inches\n\n2^2\n\nNo thank you:\n\nmean(x,na.rm=TRUE)\nmean( x , na.rm = TRUE )\nmean (x, na.rm = TRUE)\n\nheight&lt;-(feet*12)+inches\n\n2 ^ 2"
  },
  {
    "objectID": "project/proj-citations.html",
    "href": "project/proj-citations.html",
    "title": "Project Citations",
    "section": "",
    "text": "If you are just letting me know how you found any functions that we have not discussed in class - please include this as a comment in your code chunk. Remember, the text of your report should be discussing your analysis and findings, NOT your code.\nFor example:\n\n# basenames() function found in stackoverflow discussion\n# https://stackoverflow.com/questions/29113973/get-filename-without-extension-in-r\n\ncsv_files &lt;- list.files(path = \"../\", pattern = \".csv\", \n                          full.names = TRUE)\n\nnames &lt;- basename(csv_files)"
  },
  {
    "objectID": "project/proj-citations.html#citing-small-coding-sources",
    "href": "project/proj-citations.html#citing-small-coding-sources",
    "title": "Project Citations",
    "section": "",
    "text": "If you are just letting me know how you found any functions that we have not discussed in class - please include this as a comment in your code chunk. Remember, the text of your report should be discussing your analysis and findings, NOT your code.\nFor example:\n\n# basenames() function found in stackoverflow discussion\n# https://stackoverflow.com/questions/29113973/get-filename-without-extension-in-r\n\ncsv_files &lt;- list.files(path = \"../\", pattern = \".csv\", \n                          full.names = TRUE)\n\nnames &lt;- basename(csv_files)"
  },
  {
    "objectID": "project/proj-citations.html#citing-data-and-other-sources",
    "href": "project/proj-citations.html#citing-data-and-other-sources",
    "title": "Project Citations",
    "section": "Citing Data and Other Sources",
    "text": "Citing Data and Other Sources\nAll other sources should be cited both in-text and in a “References” section at the end of your report.\nIn-text citations should include the author name and year of publication (if relevant) like:\n\n(Wilkinson 2005)\n\n\n(Wilkinson, 2005)\n\n\nWilkinson (2005)\n\nIf there is no author or year of publication (like for many websites) a hyperlink to the website is acceptable in-text and do your best to create a full citation in the References section citation.\nYou may use any citation style for References as long as it is consistent.\nYou can do all of this manually, but you may also want to use citation tools in Quarto, which I explain in the next section."
  },
  {
    "objectID": "project/proj-citations.html#citing-automatically-in-quarto",
    "href": "project/proj-citations.html#citing-automatically-in-quarto",
    "title": "Project Citations",
    "section": "Citing Automatically in Quarto",
    "text": "Citing Automatically in Quarto\n\n\n\n\n\n\nOptional but NICE!\n\n\n\nYou are not required to do this for the project, but using automatic citations is VERY nice and a good practice to start.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nYou will want to download the .qmd for this document to see exactly how everything works.\n\n\n\n\n\n\n\n\nMake sure bibtex is installed on your computer\n\n\n\nJust once, you will need to install the bibtex package if you don’t already have bibtex installed on your computer.\n\n\nQuarto supports automatic citations using BibTex. You can find detailed information at (Posit 2025), but I will also summarize some of the big points and give some tips.\nStep 1: Create a .bib document and save it in the same directory as your report .qmd. You can download the references.bib file that I created for this example as a starting point.\nStep 2: Tell Quarto to that you have a references document. Include the following in your YAML (changin the name of the .bib document appropriately:\nbibliography: references.bib\nStep 3: Add citations to your .bib! BibTex has a special way that you need to include the citations.\n\nYou can find some examples in the references.bib file.\nThere are many websites that you can find that help you generate a BibTex citation such as this one.\nOften journals also provide a way to download a BibTex citation for a given paper.\n\nCitations look something like this:\n@book{wickham2016r,\n    title = {R for data science: {Import}, tidy, transform, visualize, and model data},\n    url = {https://books.google.com/books?id=vfi3DQAAQBAJ},\n    publisher = {O'Reilly Media},\n    author = {Wickham, H. and Grolemund, G.},\n    year = {2016},\n    note = {tex.lccn: 2017300238},\n}\nThe first entry wickham2016r gives a “nickname” for the citation that you can then use to reference it in your main document.\nStep 4: Cite!\nIn Quarto you can include in text citations by refrencing that nickname with an @ in front (e.g. @wickham2016r). You can chose one of two formats for in-text citation depending on the context:\n\n(Wickham and Grolemund 2016) or\nWickham and Grolemund (2016)\n\nThis will make a nicely formatted in-text citation as well as automatically creating a “References” section at the end of your document with the full citations like you can see here!"
  },
  {
    "objectID": "practice-activities/pa4.html",
    "href": "practice-activities/pa4.html",
    "title": "PA 4: Military Spending",
    "section": "",
    "text": "# load packages\nlibrary(readxl) \nlibrary(tidyverse)\nToday you will be tidying messy data to explore the relationship between countries of the world and military spending.\nDownload starter .qmd file\nDownload data – SPIRI-Milex-data-1949-2024.xlsx"
  },
  {
    "objectID": "practice-activities/pa4.html#data-description",
    "href": "practice-activities/pa4.html#data-description",
    "title": "PA 4: Military Spending",
    "section": "Data Description",
    "text": "Data Description\nWe will be using data from the Stockholm International Peace Research Institute (SIPRI). The SIPRI Military Expenditure Database is an open source data set containing time series on the military spending of countries from 1949–2023. The database is updated annually, which may include updates to data from previous years.\nMilitary expenditure is presented in many ways:\n\nin local currency and in US $ (both from 2022 and current);\nin terms of financial years and calendar years;\nas a share of GDP and per capita.\n\nThe availability of data varies considerably by country, but we note that data is available from at least the late 1950s for a majority of countries that were independent at the time. Estimates for regional military expenditure have been extended backwards depending on availability of data, but no estimates for total world military expenditure are available before 1988 due to the lack of data from the Soviet Union.\nSIPRI military expenditure data is based on open sources only."
  },
  {
    "objectID": "practice-activities/pa4.html#data-import",
    "href": "practice-activities/pa4.html#data-import",
    "title": "PA 4: Military Spending",
    "section": "Data Import",
    "text": "Data Import\nFirst, you should notice that there are ten different sheets included in the dataset. We are interested in the sheet labeled “Share of Govt. spending”, which contains information about the share of all government spending that is allocated to the military.\nNext, you’ll notice that there are notes about the data in the first six rows. Ugh!\nRather than copying this one sheet into a new Excel file and deleting the first few rows, let’s learn something new about the read_xlsx() function!\n\n\n\n\n\n\nWarning\n\n\n\nAs much as you can, always try to keep your raw data raw! Rather than changing anything about the raw data file by hand - figure out different ways to import the data to fit your needs.\n\n\n\n\n\n\n\n\nData Import with read_xlsx()\n\n\n\nThe read_xlsx() function has several useful arguments:\n\nsheet: specify the name of the sheet that you want to use. The name must be passed in as a string (in quotations)!\nskip: specify the number of rows you want to skip before reading in the data.\n\n\n\n1. Modify the code below (potentially including the file path) to read the military expenditures data into your workspace.\n\nmilitary &lt;- read_xlsx(\"SIPRI-Milex-data-1949-2024.xlsx\", \n                      sheet = , \n                      skip  = )\n\nError: `path` does not exist: 'SIPRI-Milex-data-1949-2024.xlsx'\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you have the Excel file open on your computer while trying to import the data, you may get an error. If you do, close the Excel file and try running your code again."
  },
  {
    "objectID": "practice-activities/pa4.html#data-cleaning",
    "href": "practice-activities/pa4.html#data-cleaning",
    "title": "PA 4: Military Spending",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nYou will notice that there are a couple of columns that don’t include spending data or are all missing (Notes and Reporting year). There is also an extra row that doesn’t include information on a country.\n2. In one pipeline, drop those columns and that row. Save this dataset as a new object named military_clean.\n\n# code for Q2\n\nIn addition to NAs, missing values were coded in two other ways.\n3. Find these two methods and write code to replace these values with NAs. Save these changes into an updated version of military_clean.\n\n\n\n\n\n\nTip\n\n\n\nThe information in the top 6 rows of the excel sheet will help you answer this question.\nHelpful functions: mutate(), across() – you will need two of these, na_if()\nNote: When referring to one of the year variable names that start with a number must put tick marks (above the tab key) around the name. Starting the name of a variable with a number is not commonly read as a variable name. E.g., to read the 1988 column through the 2019 column, use `1988.0`:`2019.0`. However, you don’t have to refer to the variable names to complete this task - it might be most efficient to specify columns you don’t want to mutate.\n\n\n\n# code for Q3\n\nBecause characters were used to indicate missing values, all of the columns 1988 through 2023 were read in as characters.\n4. Change these columns to a numeric data type. Save these changes into an updated version of military_clean.\n\n# code for Q4\n\nIf you give the Country column a look, you’ll see there are names of continents and regions included. These names are only included to make it simpler to find countries, as they contain no data.\nLuckily for us, these region names were also stored in the “Regional totals” sheet. We can use the Region column of this dataset to filter out the names we don’t want.\nRun the code below to read in the “Regional totals” dat, making any necessary modifications to the file path.\n\ncont_region &lt;- read_xlsx(\"SIPRI-Milex-data-1949-2024.xlsx\", \n                      sheet = \"Regional totals\", \n                      skip = 13) |&gt; \n  filter(Region != \"World total (including Iraq)\", \n         Region != \"World total (excluding Iraq)\") |&gt; \n  select(Region)\n\nError: `path` does not exist: 'SIPRI-Milex-data-1949-2024.xlsx'\n\n\nA clever way to filter out observations you don’t want is with a join. A tool tailored just for this scenario is the anti_join() function. This function will return all of the rows of one dataset without a match in another dataset.\n5. Use the anti_join() function to filter out the Country values we don’t want in the military_clean data. The by argument needs to be filled with the name(s) of the variables that the two datasets should be joined with.\n\n\n\n\n\n\nTip\n\n\n\nJoin by different variables in dataX and dataY: join_by(a == b) will match dataX$a to dataY$b.\n\n\n\n# code for Q5\n\n\n\n\n\n\n\nCanvas Q1 & Q2\n\n\n\n6. How many countries have no spending information in this dataset? What are some of these countries (a list to choose from will be given in Canvas)?\n\n\n\n\n\n\n\n\nTip\n\n\n\nUseful functions: filter(), if_all(), is.na(). You will also want to double check that any observations that are missing information aren’t just a region that we missed excluding!\n\n\n\n# code for Q6"
  },
  {
    "objectID": "practice-activities/pa4.html#data-organization",
    "href": "practice-activities/pa4.html#data-organization",
    "title": "PA 4: Military Spending",
    "section": "Data Organization",
    "text": "Data Organization\nWe are interested in comparing the military expenditures of countries in Eastern Europe. We want to look at trends over time and to visualize variability in expenditures within and between countries, like the following two plots:\n\n\n\n\n\nDesired boxplot: Countries from Central Asia used for demonstration – your plot will have different countries and spending values.\n\n\n\n\n\n\n\n\n\nDesired line plot: Countries from North Africa used for demonstration – your plot will have different countries and spending values.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nUnfortunately, if we want a point in the graph representing the spending for every country and year (without some SERIOUS headache), we need every year to be a single column!\n\n\nTo tidy a dataset like this, we need to pivot the columns of years from wide format to long format. To do this process we need three arguments:\n\ncols: The set of columns that represent values, not variables. In these data, those are all the columns from 1988.0 to 2023.0.\nnames_to: The name of the variable that should be created to move these columns into. In these data, this could be \"year\".\nvalues_to: The name of the variable that should be created to move these column’s values into. In these data, this could be labeled \"spending\".\n\nThese form the three required arguments for the pivot_longer() function.\n7. Pivot the cleaned up military data set to a “longer” orientation. Save this new “long” version as a new variable called military_long.\n\n\n\n\n\n\nCaution\n\n\n\nDo not overwrite your cleaned up dataset!\n\n\n\n# code for Q7\n\n8. Notice that when you pivoted the data, the year variable is a character data type. Convert this to numeric.\n\nsummary(military_long)\n\nError: object 'military_long' not found\n\n\n\n# code for Q8"
  },
  {
    "objectID": "practice-activities/pa4.html#data-visualization",
    "href": "practice-activities/pa4.html#data-visualization",
    "title": "PA 4: Military Spending",
    "section": "Data Visualization",
    "text": "Data Visualization\nNow that we’ve transformed the data, let’s create a plot to explore military spending across Eastern European countries.\n9. Create side-by-side boxplots to explore the military spending between Eastern European countries.\n\n\n\n\n\n\nTip\n\n\n\nMake sure you change the plot title and axis labels to accurately represent the plot.\nYou might also want to change the x-axis limits and the color of your plots.\nPlace the Country variable on an axis that makes it easier to read the labels!\n\n\n\n# I have provided a list of Eastern European countries (in these data) for you to use.\neastern_europe &lt;- c(\"Armenia\", \"Azerbaijan\", \"Belarus\", \n                    \"Georgia\", \"Moldova\", \"Russia\", \"Ukraine\")\n\n# code for Q9\n\n10. Create a line plot to explore the military spending of Eastern European countries over time.\n\n# code for Q10\n\n\n\n\n\n\n\nCanvas Q3 + Q4\n\n\n\n11. Looking at the plots you created above, which Eastern European country had the smallest variability in military expenditures over time? Consider a measure of variability that is robust to outliers (like IQR).\n12. Looking at the plots you created above, you can see that for one Eastern European country, their miliary spending (%) over doubled and then returned to previous levels by around 2015. What is the name of the war that would explain this trend?."
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html",
    "href": "labs/lab4/lab4-childcare.html",
    "title": "Lab 4: Childcare Costs in California",
    "section": "",
    "text": "Tip\n\n\n\n\n\nI advise you to focus particularly on:\n\nSetting chunk options carefully.\nMaking sure you don’t print out more output than you need.\nMaking sure you don’t assign more objects than necessary. Avoid “object junk” in your environment.\nMaking your code readable and nicely formatted.\nThinking through your desired result before writing any code.\nDownload starter .qmd file"
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html#the-data",
    "href": "labs/lab4/lab4-childcare.html#the-data",
    "title": "Lab 4: Childcare Costs in California",
    "section": "The Data",
    "text": "The Data\nIn this lab we’re going look at the median weekly cost of childcare in California. The data come to us from TidyTuesday. A detailed description of the data can be found here. You will need to use this data dictionary to complete the lab!\nWe also have information from the California State Controller on tax revenue for california counties from 2005 - 2018. I compiled the data from this website for you. Note that there is no data for San Franscisco County. The variables included in the ca_tax_revenue.csv data file (loaded below) include:\n\nentity_name: County name\nyear: fiscal year\ntotal_property_taxes: total revenue in $ from property taxes\nsales_and_use_taxes: total revenue in $ from sales and use taxes\n\n0. Load the appropriate libraries and the data.\n\n# load libraries\n\n\n# load data\nchildcare_costs &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/childcare_costs.csv')\n\nError in read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/childcare_costs.csv\"): could not find function \"read_csv\"\n\ncounties &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/counties.csv')\n\nError in read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/counties.csv\"): could not find function \"read_csv\"\n\ntax_rev &lt;- read_csv('https://raw.githubusercontent.com/manncz/stat-331-s25/main/labs/lab4/data/ca_tax_revenue.csv')\n\nError in read_csv(\"https://raw.githubusercontent.com/manncz/stat-331-s25/main/labs/lab4/data/ca_tax_revenue.csv\"): could not find function \"read_csv\"\n\n\n1. Briefly describe the data (~ 4 sentences). What information does it contain?"
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html#california-childcare-costs",
    "href": "labs/lab4/lab4-childcare.html#california-childcare-costs",
    "title": "Lab 4: Childcare Costs in California",
    "section": "California Childcare Costs",
    "text": "California Childcare Costs\n2. Let’s focus only on California. Create a ca_childcare dataset containing (1) county information and (2) all information from the childcare_costs dataset.\na. Sketch a game plan for completing this task. You should do all of this within one pipeline\n\nb. Implement/code your game plan to create the dataset of childcare costs in California. Checkpoint: There are 58 counties in CA and 11 years in the dataset. Therefore, your new dataset should have 638 observations.\n\n# code for Q2\n\n3. Now, lets add the tax revenue information to the ca_childcare dataset. Add the data from tax_rev for the counties and years that are already in the ca_childcare data. Overwrite the old ca_childcare data with this dataset. Checkpoint: you are just adding columns here, so your new dataset should still have 638 observations\n\n# code for Q3\n\n4. Using a function from the forcats package, complete the code below to create a new variable where each county is categorized into one of the 10 Census regions in California. Use the Region description (from the plot), not the Region number. The code below will help you get started.\n\n\nCode\n# defining 10 census regions\n\nsuperior_counties &lt;- c(\"Butte\",\"Colusa\",\"El Dorado\",\n                       \"Glenn\",\"Lassen\",\"Modoc\",\n                       \"Nevada\",\"Placer\",\"Plumas\",\n                       \"Sacramento\",\"Shasta\",\"Sierra\",\"Siskiyou\",\n                       \"Sutter\",\"Tehama\",\"Yolo\",\"Yuba\")\n\nnorth_coast_counties &lt;- c(\"Del Norte\",\"Humboldt\",\"Lake\",\n                          \"Mendocino\",\"Napa\",\"Sonoma\",\"Trinity\")\n\nsan_fran_counties &lt;- c(\"Alameda\",\"Contra Costa\",\"Marin\",\n                       \"San Francisco\",\"San Mateo\",\"Santa Clara\",\n                       \"Solano\")\n\nn_san_joaquin_counties &lt;- c(\"Alpine\",\"Amador\",\"Calaveras\",\"Madera\",\n                            \"Mariposa\",\"Merced\",\"Mono\",\"San Joaquin\",\n                            \"Stanislaus\",\"Tuolumne\")\n\ncentral_coast_counties &lt;- c(\"Monterey\",\"San Benito\",\"San Luis Obispo\",\n                            \"Santa Barbara\",\"Santa Cruz\",\"Ventura\")\n\ns_san_joaquin_counties &lt;- c(\"Fresno\",\"Inyo\",\"Kern\",\"Kings\",\"Tulare\")\n\ninland_counties &lt;- c(\"Riverside\",\"San Bernardino\")\n\nla_county &lt;- \"Los Angeles\"\n\norange_county  &lt;- \"Orange\"\n\nsan_diego_imperial_counties &lt;- c(\"Imperial\",\"San Diego\")\n\n\n\n# finish this code for Q4\n\nca_childcare &lt;- ca_childcare |&gt; \n  mutate(county_name = str_remove(county_name, \" County\"))\n\nError in mutate(ca_childcare, county_name = str_remove(county_name, \" County\")): could not find function \"mutate\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nI have provided you with code that eliminates the word “County” from each of the county names in your ca_childcare dataset. You should keep this line of code and pipe into the rest of your data manipulations.\nYou will learn about the str_remove() function from the stringr package next week!\n\n\n5. Let’s consider the median household income of each region, and how that income has changed over time. Create a table with ten rows, one for each region, and two columns, one for 2008 and one for 2018 (plus a column for region). The cells should contain the median() of the median household income (expressed in 2018 dollars) of the region and the study_year. Order the rows by 2018 values from highest income to lowest income.\n\n\n\n\n\n\nTip\n\n\n\nThis will require transforming your data! Sketch out what you want the data to look like before you begin to code. You should be starting with your California dataset that contains the regions.\n\n\n\n# code for Q5\n\n6. Which California region had the lowest median full-time median weekly price for center-based childcare for infants in 2018? Does this region correspond to the region with the lowest median income in 2018 that you found in Q4?\n\n\n\n\n\n\nWarning\n\n\n\nThe code for the first question should give me the EXACT answer. This means having the code output the exact row(s) and variable(s) necessary for providing the solution. To answer the second question, compare this output with the output from Q4.\n\n\n\n# code for Q6\n\n7. The following plot shows, for all ten regions, the change over time of the full-time median price for center-based childcare for infants, toddlers, and preschoolers. Recreate the plot. You do not have to replicate the exact colors or theme, but your plot should have the same content, including the order of the facets and legend, reader-friendly labels, axes breaks, and a loess smoother.\n\n\n\n\n\n\nHints\n\n\n\nThis will require transforming your data! Sketch out what you want the data to look like before you begin to code. You should be starting with your California dataset that contains the regions.\nA point on the plot represents one county and year.\nYou should use a forcats function to reorder the legend automatically\nTry setting aspect.ratio = 1 in theme() if your plot is squished\nAgain, your plot does not need to look exactly like this one!!\nRemember to avoid “object junk” in your environment!\n\n\n\n\n\nPlot to recreate\n\n\n\n# code for Q7"
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html#median-household-income-vs.-childcare-costs-for-infants",
    "href": "labs/lab4/lab4-childcare.html#median-household-income-vs.-childcare-costs-for-infants",
    "title": "Lab 4: Childcare Costs in California",
    "section": "Median Household Income vs. Childcare Costs for Infants",
    "text": "Median Household Income vs. Childcare Costs for Infants\n\n\n\n\n\n\nRefresher on Linear Regression\n\n\n\nWhile a second course in statistics is a pre-requisite for this class, here is a refresher on simple linear regression with a single predictor.\n\n\n8. Create a scatterplot showing the relationship between median household income (expressed in 2018 dollars) and the full-time median weekly price charged for center-based childcare for an infant in California. Overlay a linear regression line (lm) to show the trend.\n\n# plot for scatterplot\n\n9. Look up the documentation for lm() and fit a linear regression model to the relationship shown in your plot above (recall: \\(y = mx+b\\)). Identify the coefficient estimates from the model.\n\n# complete the code provided\nreg_mod1 &lt;- lm()\n\nError in terms.formula(formula, data = data): argument is not a valid model\n\nsummary(reg_mod1)\n\nError: object 'reg_mod1' not found\n\n\n10. Do you have evidence to conclude there is a relationship between the median household income and the median weekly cost of center-based childcare for infants in California? Cite values from your output for support."
  },
  {
    "objectID": "labs/lab4/lab4-childcare.html#open-ended-analysis",
    "href": "labs/lab4/lab4-childcare.html#open-ended-analysis",
    "title": "Lab 4: Childcare Costs in California",
    "section": "Open-Ended Analysis",
    "text": "Open-Ended Analysis\nLet’s give you a taste of what to expect for the take-home portion of the midterm exam.\n11. Investigate the full-time median price for childcare in a center-based setting versus the full-time median price for childcare in a family (in-home) setting in California. Posit a research question. This could include any other variables in the dataset as well. Present one table of summary statistics and one plot that helps to address your research question.\nThis write-up should include:\n\nA description of the data you are using\nYour research question\nOne well-designed table of summary statistics\n\nNote, this should not be inference (results from a statistical test)\nThis should be a summary table of the data itself, like Q5\n\nOne well-designed plot\nDescriptions of the table and plot that both:\n\nExplain what the table/plot is literally showing (e.g. the median cost by year)\nAnalyze what you learn from the table/plot about your research question\n\n\nThe table and plot should not show reduntant information, they should be used to gain more insight on your question.\nDr. C will be reading through these and providing some feedback!"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#across-related-functions",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#across-related-functions",
    "title": "Data Cleaning & Manipulation",
    "section": "across(): Related Functions",
    "text": "across(): Related Functions\nThese functions are used with filter() to select rows based on a logical statement applied to multiple columns\n\nif_any() – returns a logical vector (one element for each row) that is TRUE if the logical statement is true for any column in the supplied columns\nif_all() – returns a logical vector (one element for each row) that is TRUE if the logical statement is true for all columns in the supplied columns"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#if_any-example",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#if_any-example",
    "title": "Data Cleaning & Manipulation",
    "section": "if_any() Example",
    "text": "if_any() Example\nRemember, you got warnings in PA3 when converting some columns to numeric? If you look at the original data, you can see this is because missing values were indicated with the string \"NULL\".\n\n\n\n\n\n\nINSTNM\nCITY\nSTABBR\nZIP\nADM_RATE\nSAT_AVG\nUGDS\nTUITIONFEE_IN\nTUITIONFEE_OUT\nCONTROL\nREGION\n\n\n\n\nAlabama A & M University\nNormal\nAL\n35762\n0.9027\n929\n4824\n9857\n18236\n1\n5\n\n\nUniversity of Alabama at Birmingham\nBirmingham\nAL\n35294-0110\n0.9181\n1195\n12866\n8328\n19032\n1\n5\n\n\nAmridge University\nMontgomery\nAL\n36117-3553\nNULL\nNULL\n322\n6900\n6900\n2\n5\n\n\n\n\n\n\n\n\nWe could drop these rows before converting the columns to numeric if desired, using if_any():\n\ncolleges_clean &lt;- colleges_clean |&gt; \n  filter(!if_any(.cols = ADM_RATE:TUITIONFEE_OUT, \n                 .fns = ~ .x == \"NULL\"))"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#the-numbers-dont-speak-for-themselves",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#the-numbers-dont-speak-for-themselves",
    "title": "Data Cleaning & Manipulation",
    "section": "The Numbers Don’t Speak for Themselves",
    "text": "The Numbers Don’t Speak for Themselves\nWith the people next to you discuss:\n\nWhat was the main take-away for you?\nWhat points stood out to you?\nWhat was something that suprised you?\nIs there anything you didn’t agree with?\nWhat questions do you have after reading?\n\n\nSource: Data Feminism by by Catherine D’Ignazio and Lauren Klein (2020)"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#tuesday-april-22",
    "href": "slides/week-4/w4-joins-pivots.html#tuesday-april-22",
    "title": "Data Joins + Pivots",
    "section": "Tuesday, April 22",
    "text": "Tuesday, April 22\nToday we will…\n\nBig Picture\nNew Material\n\nJoining data with dplyr\nPivoting data with tidyr\n\nPA 4: Military Spending\n\n\n\n\n\n\n\nFollow along\n\n\nRemember to download, save, and open up the starter notes for this week! This week you need to download and save some data as well."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#comments-from-week-3",
    "href": "slides/week-4/w4-joins-pivots.html#comments-from-week-3",
    "title": "Data Joins + Pivots",
    "section": "Comments from Week 3",
    "text": "Comments from Week 3\n\nVery nice work overall!!\nWork on the lab early!\n\nGet an idea of how long it may take and what any big challenges are\n\nBe thoughtful about use of color in plots\nOnly save variables / intermediate objects when needed\nAvoid long lines of code"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#data-science-process",
    "href": "slides/week-4/w4-joins-pivots.html#data-science-process",
    "title": "Data Joins + Pivots",
    "section": "Data Science Process",
    "text": "Data Science Process\n\nAdapted from r4ds"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#we-have-covered",
    "href": "slides/week-4/w4-joins-pivots.html#we-have-covered",
    "title": "Data Joins + Pivots",
    "section": "We have covered…",
    "text": "We have covered…"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#today",
    "href": "slides/week-4/w4-joins-pivots.html#today",
    "title": "Data Joins + Pivots",
    "section": "Today",
    "text": "Today"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#getting-data",
    "href": "slides/week-4/w4-joins-pivots.html#getting-data",
    "title": "Data Joins + Pivots",
    "section": "Getting Data",
    "text": "Getting Data\n\nSo far, we have simply needed to import one nice rectangular data set in a typical file type\nReal life often gets a bit more complicated!!"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#motivating-real-example1",
    "href": "slides/week-4/w4-joins-pivots.html#motivating-real-example1",
    "title": "Data Joins + Pivots",
    "section": "Motivating (Real) Example1",
    "text": "Motivating (Real) Example1\n\n\nTexas Education Data (AEIS): K-12 student performance data provided by the Texas Education Agency\nProvides A LOT of information … in many separate files:\n\nby year\nfor State, Regions, Districts, or Schools\nfor different sets of variables\n\n\n\n\n🧐 need to get this #%$ together before we can analyze it\n\nI worked with this data for a project. See the paper and Github repo if you are interested!"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#relational-data",
    "href": "slides/week-4/w4-joins-pivots.html#relational-data",
    "title": "Data Joins + Pivots",
    "section": "Relational Data",
    "text": "Relational Data\n\n\nMultiple, interconnected tables of data are called relational.\nIndividual datsets may not provide exactly what we need - but we can use the relation between datasets to get the information we want.\n\n\n\n\n\n\nIMDb movie relational data"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#example---imdb-movie-data",
    "href": "slides/week-4/w4-joins-pivots.html#example---imdb-movie-data",
    "title": "Data Joins + Pivots",
    "section": "Example - IMDb Movie Data",
    "text": "Example - IMDb Movie Data\n\n\n\n\n\n\nDiscussion\n\n\nWhat if we want to know which actor has worked with the most directors in the dataset?\nWhat analytical dataset would we need to answer this question? What are the rows, and variables needed?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#example---imdb-movie-data-1",
    "href": "slides/week-4/w4-joins-pivots.html#example---imdb-movie-data-1",
    "title": "Data Joins + Pivots",
    "section": "Example - IMDb Movie Data",
    "text": "Example - IMDb Movie Data\n\n\n\n\n\n\nDiscussion\n\n\nWhat if we want to know which actor has worked with the most directors in the dataset?\nWhat analytical dataset would we need to answer this question? What are the rows, and variables needed?\n\n\n\n\n\n💡 In order to answer our question, we need to combine some of the individual datasets into one big dataset\nJoins!"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#data-joins-1",
    "href": "slides/week-4/w4-joins-pivots.html#data-joins-1",
    "title": "Data Joins + Pivots",
    "section": "Data Joins",
    "text": "Data Joins\nWe can combine (join) data tables based on their relations.\n\n\nMutating joins\nAdd variables from a new dataframe to observations in an existing dataframe.\nfull_join(), left_join(), right_join(), inner_join()\n\nFiltering Joins\nFilter observations based on values in new dataframe.\nsemi_join(), anti_join()"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#keys",
    "href": "slides/week-4/w4-joins-pivots.html#keys",
    "title": "Data Joins + Pivots",
    "section": "Keys",
    "text": "Keys\nSome combination of variables (should) uniquely identify an observation in a data set.\n\nTo combine (join) two datasets, a key needs to be present in both."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#general-structure-of-a-join",
    "href": "slides/week-4/w4-joins-pivots.html#general-structure-of-a-join",
    "title": "Data Joins + Pivots",
    "section": "General Structure of a Join",
    "text": "General Structure of a Join\n\n\n\n\nChoose a left and a right dataset\nAdd or remove rows based on the type of join and the structure of the left vs. right data\nAdd columns (or not) based on the type of join and the and the structure of the left vs. right data"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#inner_join",
    "href": "slides/week-4/w4-joins-pivots.html#inner_join",
    "title": "Data Joins + Pivots",
    "section": "inner_join()",
    "text": "inner_join()\nKeeps observations when their keys are present in both datasets.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\n\nWhen would you want to use inner_join()?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#inner_join-imdb-example",
    "href": "slides/week-4/w4-joins-pivots.html#inner_join-imdb-example",
    "title": "Data Joins + Pivots",
    "section": "inner_join(): IMDb Example",
    "text": "inner_join(): IMDb Example\n\n\n\ndirectors_genres\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n429\nAdventure\n0.750000\n\n\n429\nFantasy\n0.750000\n\n\n2931\nDrama\n0.714286\n\n\n2931\nAction\n0.428571\n\n\n11652\nSci-Fi\n0.500000\n\n\n11652\nAction\n0.500000\n\n\n14927\nAnimation\n1.000000\n\n\n14927\nFamily\n1.000000\n\n\n15092\nComedy\n0.545455\n\n\n15092\nCrime\n0.545455\n\n\n\n\n\n\n\n\n\nmovies_directors\n\n\n\n\n\n\n\ndirector_id\nmovie_id\n\n\n\n\n429\n300229\n\n\n9247\n124110\n\n\n11652\n10920\n\n\n11652\n333856\n\n\n14927\n192017\n\n\n15092\n109093\n\n\n15092\n237431\n\n\n\n\n\n\n\n\n\nID: 429, 2931, 11652, 14927, 15092       ID: 429, 9247, 11652, 14927, 15092\n\n\n\ninner_join(directors_genres, movies_directors, \n           by = \"director_id\")\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\nmovie_id\n\n\n\n\n429\nAdventure\n0.750000\n300229\n\n\n429\nFantasy\n0.750000\n300229\n\n\n11652\nSci-Fi\n0.500000\n10920\n\n\n11652\nSci-Fi\n0.500000\n333856\n\n\n11652\nAction\n0.500000\n10920\n\n\n11652\nAction\n0.500000\n333856\n\n\n14927\nAnimation\n1.000000\n192017\n\n\n14927\nFamily\n1.000000\n192017\n\n\n15092\nComedy\n0.545455\n109093\n\n\n15092\nComedy\n0.545455\n237431\n\n\n15092\nCrime\n0.545455\n109093\n\n\n15092\nCrime\n0.545455\n237431\n\n\n\n\n\n\n\n\nID: 429, 2931, 9247, 11652, 14927, 15092"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#inner_join-imdb-example-1",
    "href": "slides/week-4/w4-joins-pivots.html#inner_join-imdb-example-1",
    "title": "Data Joins + Pivots",
    "section": "inner_join(): IMDb Example",
    "text": "inner_join(): IMDb Example\nWhat if our key does not have the same name?\n\n\n\ndirectors_genres\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n429\nAdventure\n0.750000\n\n\n429\nFantasy\n0.750000\n\n\n2931\nDrama\n0.714286\n\n\n2931\nAction\n0.428571\n\n\n11652\nSci-Fi\n0.500000\n\n\n11652\nAction\n0.500000\n\n\n14927\nAnimation\n1.000000\n\n\n14927\nFamily\n1.000000\n\n\n15092\nComedy\n0.545455\n\n\n15092\nCrime\n0.545455\n\n\n\n\n\n\n\n\n\ndirectors\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\n\n\n\n\n429\nAndrew\nAdamson\n\n\n9247\nZach\nBraff\n\n\n11652\nJames (I)\nCameron\n\n\n14927\nRon\nClements\n\n\n15092\nEthan\nCoen\n\n\n\n\n\n\n\n\n\n\ninner_join(directors_genres, \n           directors, \n           by = join_by(director_id == id))\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\ngenre\nprob\n\n\n\n\n429\nAndrew\nAdamson\nAdventure\n0.750000\n\n\n429\nAndrew\nAdamson\nFantasy\n0.750000\n\n\n11652\nJames (I)\nCameron\nSci-Fi\n0.500000\n\n\n11652\nJames (I)\nCameron\nAction\n0.500000\n\n\n14927\nRon\nClements\nAnimation\n1.000000\n\n\n14927\nRon\nClements\nFamily\n1.000000\n\n\n15092\nEthan\nCoen\nComedy\n0.545455\n\n\n15092\nEthan\nCoen\nCrime\n0.545455\n\n\n\n\n\n\n\n Join by different variables on dataX and dataY: join_by(a == b) will match dataX$a to dataY$b."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#piping-joins",
    "href": "slides/week-4/w4-joins-pivots.html#piping-joins",
    "title": "Data Joins + Pivots",
    "section": "Piping Joins",
    "text": "Piping Joins\nRemember: the dataset you pipe in becomes the first argument of the function you are piping into!\n\nIf you are using a pipe,\n\nthe piped in data is the left dataset\nspecify the right dataset inside the join function.\n\n\n\n\ninner_join(directors_genres, movies_directors)\n\n…is equivalent to…\n\ndirectors_genres |&gt; \n  inner_join(movies_directors, by = \"director_id\")"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#more-mutating-joins",
    "href": "slides/week-4/w4-joins-pivots.html#more-mutating-joins",
    "title": "Data Joins + Pivots",
    "section": "More Mutating Joins",
    "text": "More Mutating Joins\n\nleft_join() – keep only (and all) observations present in the left data set\nright_join() – keep only (and all) observations present in the right data set\nfull_join() – keep only (and all) observations present in both data sets"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#why-use-a-certain-mutating-join",
    "href": "slides/week-4/w4-joins-pivots.html#why-use-a-certain-mutating-join",
    "title": "Data Joins + Pivots",
    "section": "Why Use a Certain Mutating Join?",
    "text": "Why Use a Certain Mutating Join?\n\n\n\ninner_join()\n\nYou want all of the columns from both left and right data and only to include the observations that have information in both\n\nleft_join()\n\nThe left dataset is your “main” data and you just want to add information (columns) from the right dataset\n\nright_join()\n\nThe right data is your “main data” and you just want to add columns from the left dataset\n\nfull_join()\n\nYou want all of the columns from both left and right data for all of the observations possible"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#which-join",
    "href": "slides/week-4/w4-joins-pivots.html#which-join",
    "title": "Data Joins + Pivots",
    "section": "Which Join?",
    "text": "Which Join?\n\n\n\n\n\n\nDiscussion\n\n\nHow many movies are there in the data for each director (by name), including if any directors don’t have any movies in the data? Which join should I use??\n\n\n\ndirectors |&gt; \n  ??_join(movies_directors, \n          by = join_by(\"id\" == \"director_id\"))\n\n\n\n\ndirectors |&gt; \n  slice_head(n = 5)\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\n\n\n\n\n429\nAndrew\nAdamson\n\n\n2931\nDarren\nAronofsky\n\n\n9247\nZach\nBraff\n\n\n11652\nJames (I)\nCameron\n\n\n14927\nRon\nClements\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  slice_head(n = 5)\n\n\n\n\n\n\n\ndirector_id\nmovie_id\n\n\n\n\n429\n300229\n\n\n2931\n254943\n\n\n9247\n124110\n\n\n11652\n10920\n\n\n11652\n333856"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#which-join-1",
    "href": "slides/week-4/w4-joins-pivots.html#which-join-1",
    "title": "Data Joins + Pivots",
    "section": "Which Join?",
    "text": "Which Join?\n\n\n\n\n\n\nDiscussion\n\n\nWhat is the complete set movies and actors included in the data? Which join should I use??\n\n\n\nroles |&gt; \n  ??_join(actors, \n          by = join_by(\"actor_id\" == \"id\"))\n\n\n\n\nroles |&gt; \n  slice_head(n = 5)\n\n\n\n\n\n\n\nactor_id\nmovie_id\nrole\n\n\n\n\n933\n333856\nLewis Bodine\n\n\n2547\n300229\nDuloc Mascot\n\n\n2700\n306032\nTyrone\n\n\n2898\n333856\nSlovakian three-year-old boy\n\n\n2925\n192017\nAdditional Voices\n\n\n\n\n\n\n\n\n\nactors |&gt; \n  slice_head(n = 5)\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\ngender\nfilm_count\n\n\n\n\n933\nLewis\nAbernathy\nM\n1\n\n\n2547\nAndrew\nAdamson\nM\n1\n\n\n2700\nWilliam\nAddy\nM\n1\n\n\n2898\nSeth (I)\nAdkins\nM\n1\n\n\n2925\nCharles (I)\nAdler\nM\n1"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#filtering-joins-semi_join",
    "href": "slides/week-4/w4-joins-pivots.html#filtering-joins-semi_join",
    "title": "Data Joins + Pivots",
    "section": "Filtering Joins: semi_join()",
    "text": "Filtering Joins: semi_join()\nKeeps observations when their keys are present in both datasets, but only keeps variables from the left dataset.\n\n\n\n\n\n\n→"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#imdb-data-example",
    "href": "slides/week-4/w4-joins-pivots.html#imdb-data-example",
    "title": "Data Joins + Pivots",
    "section": "IMDb Data Example",
    "text": "IMDb Data Example\n\n\n\ndirectors_genres |&gt; \n  distinct(director_id)\n\n\n\n\n\n\n\ndirector_id\n\n\n\n\n429\n\n\n2931\n\n\n11652\n\n\n14927\n\n\n15092\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  distinct(director_id)\n\n\n\n\n\n\n\ndirector_id\n\n\n\n\n429\n\n\n9247\n\n\n11652\n\n\n14927\n\n\n15092"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#filtering-joins-semi_join-1",
    "href": "slides/week-4/w4-joins-pivots.html#filtering-joins-semi_join-1",
    "title": "Data Joins + Pivots",
    "section": "Filtering Joins: semi_join()",
    "text": "Filtering Joins: semi_join()\n\nsemi_join()Connection to filter()\n\n\n\ndirectors_genres |&gt; \n  semi_join(movies_directors)\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n429\nAdventure\n0.750000\n\n\n429\nFantasy\n0.750000\n\n\n11652\nSci-Fi\n0.500000\n\n\n11652\nAction\n0.500000\n\n\n14927\nAnimation\n1.000000\n\n\n14927\nFamily\n1.000000\n\n\n15092\nComedy\n0.545455\n\n\n15092\nCrime\n0.545455\n\n\n\n\n\n\n\nMovie Directors: 429, 2931, 11652, 14927, 15092\n\n\n\ndirectors_genres |&gt;\n  filter(director_id %in% movies_directors$director_id)\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n429\nAdventure\n0.750000\n\n\n429\nFantasy\n0.750000\n\n\n11652\nSci-Fi\n0.500000\n\n\n11652\nAction\n0.500000\n\n\n14927\nAnimation\n1.000000\n\n\n14927\nFamily\n1.000000\n\n\n15092\nComedy\n0.545455\n\n\n15092\nCrime\n0.545455"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#filtering-joins-anti_join",
    "href": "slides/week-4/w4-joins-pivots.html#filtering-joins-anti_join",
    "title": "Data Joins + Pivots",
    "section": "Filtering Joins: anti_join()",
    "text": "Filtering Joins: anti_join()\nRemoves observations when their keys are present in both datasets, and only keeps variables from the left dataset.\n\n\n\n\n\n\n→"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#filtering-joins-anti_join-1",
    "href": "slides/week-4/w4-joins-pivots.html#filtering-joins-anti_join-1",
    "title": "Data Joins + Pivots",
    "section": "Filtering Joins: anti_join()",
    "text": "Filtering Joins: anti_join()\n\nanti_join()Connection to filter()\n\n\n\ndirectors_genres |&gt; \n  anti_join(movies_directors)\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n2931\nDrama\n0.714286\n\n\n2931\nAction\n0.428571\n\n\n\n\n\n\n\nMovie Directors: 429, 2931, 11652, 14927, 15092\n\n\n\ndirectors_genres |&gt;\n  filter(!director_id %in% movies_directors$director_id)\n\n\n\n\n\n\n\ndirector_id\ngenre\nprob\n\n\n\n\n2931\nDrama\n0.714286\n\n\n2931\nAction\n0.428571"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#building-an-analytical-dataset-1",
    "href": "slides/week-4/w4-joins-pivots.html#building-an-analytical-dataset-1",
    "title": "Data Joins + Pivots",
    "section": "Building an Analytical Dataset",
    "text": "Building an Analytical Dataset\nNow we have tools to:\n\nCombine multiple data sets (xx_join())\nSubset to certain observations (filter() and xx_join())\nCreate new variables (mutate())\nSelect columns of interest (select())\n\n\nWe are well on our way to building and cleaning up a nice dataset! 🥳"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#transform-and-tidy",
    "href": "slides/week-4/w4-joins-pivots.html#transform-and-tidy",
    "title": "Data Joins + Pivots",
    "section": "Transform and Tidy",
    "text": "Transform and Tidy\nWhat’s next?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#transform-and-tidy-1",
    "href": "slides/week-4/w4-joins-pivots.html#transform-and-tidy-1",
    "title": "Data Joins + Pivots",
    "section": "Transform and Tidy",
    "text": "Transform and Tidy\nWhat’s next?\nWe may need to transform our data to turn it into the version of tidy that is best for a task at hand.\n\nAllison Horst"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#creating-tidy-data",
    "href": "slides/week-4/w4-joins-pivots.html#creating-tidy-data",
    "title": "Data Joins + Pivots",
    "section": "Creating Tidy Data",
    "text": "Creating Tidy Data\nLet’s say we want to look at mean cereal nutrients based on shelf.\n\n\nThe data are in a wide format – a separate column for each nutrient.\n\n\nlibrary(liver)\ndata(cereal)\nhead(cereal)\n\n\n\n\n\n\n\nname\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\n100% Natural Bran\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1\n1.00\n33.98368\n\n\nAll-Bran\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\nAlmond Delight\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1\n0.75\n29.50954"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#creating-tidy-data-1",
    "href": "slides/week-4/w4-joins-pivots.html#creating-tidy-data-1",
    "title": "Data Joins + Pivots",
    "section": "Creating Tidy Data",
    "text": "Creating Tidy Data\n\n\n\n\n\n\nDiscussion\n\n\nHow would we plot the mean cereal nutrients by shelf (as shown below) with the wide data using ggplot2?\n\n\n\n\n\nTransforming the data will make plotting much easier"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#creating-tidy-data-2",
    "href": "slides/week-4/w4-joins-pivots.html#creating-tidy-data-2",
    "title": "Data Joins + Pivots",
    "section": "Creating Tidy Data",
    "text": "Creating Tidy Data\n\nWideWide PlotLongLong Plot\n\n\n\n\nCode\ncereal_wide &lt;- cereal |&gt; \n  group_by(shelf) |&gt; \n  summarise(across(calories:vitamins, mean))\n\n\n\n\n\n\n\n\nshelf\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\n\n\n\n\n1\n102.5000\n2.650000\n0.60\n176.2500\n1.6850000\n15.80000\n4.800000\n75.50000\n20.00000\n\n\n2\n109.5238\n1.904762\n1.00\n145.7143\n0.9047619\n13.61905\n9.619048\n57.80952\n23.80952\n\n\n3\n107.7778\n2.861111\n1.25\n158.6111\n3.1388889\n14.50000\n6.527778\n129.83333\n35.41667\n\n\n\n\n\n\n\n\n\n\n\nCode\nmy_colors &lt;- c(\"calories_col\" = \"steelblue\", \"sugars_col\" = \"orange3\")\n\ncereal_wide |&gt; \n  ggplot() +\n  geom_point(aes(x = shelf, y = calories, color = \"calories_col\")) +\n  geom_line(aes(x = shelf, y = calories, color = \"calories_col\")) + \n  geom_point(aes(x = shelf, y = sugars, color = \"sugars_col\")) +\n  geom_line(aes(x = shelf, y = sugars, color = \"sugars_col\")) +\n  scale_color_manual(values = my_colors, labels = names(my_colors)) +\n  labs(x = \"Shelf\", y = \"\", subtitle = \"Mean Amount\", color = \"Nutrient\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncereal_long&lt;- cereal |&gt; \n  pivot_longer(cols = calories:vitamins,\n               names_to = \"Nutrient\",\n               values_to = \"Amount\") |&gt; \n  group_by(shelf, Nutrient) |&gt; \n  summarise(mean_amount = mean(Amount))\n\n\n\n\n\n\n\n\nshelf\nNutrient\nmean_amount\n\n\n\n\n1\ncalories\n102.5000000\n\n\n1\ncarbo\n15.8000000\n\n\n1\nfat\n0.6000000\n\n\n1\nfiber\n1.6850000\n\n\n1\npotass\n75.5000000\n\n\n1\nprotein\n2.6500000\n\n\n1\nsodium\n176.2500000\n\n\n1\nsugars\n4.8000000\n\n\n1\nvitamins\n20.0000000\n\n\n2\ncalories\n109.5238095\n\n\n2\ncarbo\n13.6190476\n\n\n2\nfat\n1.0000000\n\n\n2\nfiber\n0.9047619\n\n\n2\npotass\n57.8095238\n\n\n2\nprotein\n1.9047619\n\n\n2\nsodium\n145.7142857\n\n\n2\nsugars\n9.6190476\n\n\n2\nvitamins\n23.8095238\n\n\n3\ncalories\n107.7777778\n\n\n3\ncarbo\n14.5000000\n\n\n3\nfat\n1.2500000\n\n\n3\nfiber\n3.1388889\n\n\n3\npotass\n129.8333333\n\n\n3\nprotein\n2.8611111\n\n\n3\nsodium\n158.6111111\n\n\n3\nsugars\n6.5277778\n\n\n3\nvitamins\n35.4166667\n\n\n\n\n\n\n\n\n\n\n\nCode\ncereal_long |&gt; \n  ggplot(aes(x = shelf, \n             y = mean_amount, \n             color = Nutrient)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Shelf\", y = \"\", subtitle = \"Mean Amount\")"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#data-layouts",
    "href": "slides/week-4/w4-joins-pivots.html#data-layouts",
    "title": "Data Joins + Pivots",
    "section": "Data Layouts",
    "text": "Data Layouts\n\nKelsey Gonzalez"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#manual-method",
    "href": "slides/week-4/w4-joins-pivots.html#manual-method",
    "title": "Data Joins + Pivots",
    "section": "Manual Method",
    "text": "Manual Method\nConsider daily rainfall observed in SLO in January 2023.\n\nThe data is in a human-friendly form (like a calendar).\nEach week has a row, and each day has a column.\n\n\nData source\n\n\n\n\n\nDiscussion\n\n\nHow would you manually convert this to long format?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#manual-method-steps",
    "href": "slides/week-4/w4-joins-pivots.html#manual-method-steps",
    "title": "Data Joins + Pivots",
    "section": "Manual Method: Steps",
    "text": "Manual Method: Steps\n\nKeep the column Week.\nCreate a new column Day_of_Week.\nCreate a new column Rainfall (hold daily rainfall values).\nNow we have three columns – move Sunday values over.\nDuplicate Week 1-5 and copy Monday values over.\n\n\n\n\n\nRepeat …"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#computational-approach",
    "href": "slides/week-4/w4-joins-pivots.html#computational-approach",
    "title": "Data Joins + Pivots",
    "section": "Computational Approach",
    "text": "Computational Approach\n\nWe can use pivot_longer() to turn a wide dataset into a long(er) dataset."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pivot_longer",
    "href": "slides/week-4/w4-joins-pivots.html#pivot_longer",
    "title": "Data Joins + Pivots",
    "section": "pivot_longer()",
    "text": "pivot_longer()\nTake a wide dataset and turn it into a long dataset.\n\ncols – specify the columns that should be pivoted.\n\nDo not include the names of ID columns (columns to not be pivoted).\n\nnames_to – the name of the new column containing the old column names.\nvalues_to – the name of the new column containing the old column values."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pivot_longer-1",
    "href": "slides/week-4/w4-joins-pivots.html#pivot_longer-1",
    "title": "Data Joins + Pivots",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nslo_rainfall |&gt; \n  pivot_longer(cols      = Sunday:Saturday,\n               names_to  = \"Day_of_Week\",\n               values_to = \"Daily_Rainfall\")\n\n\n\n\n\n\n\nWeek\nDay_of_Week\nDaily_Rainfall\n\n\n\n\n1\nSunday\n0.00\n\n\n1\nMonday\n0.12\n\n\n1\nTuesday\n0.00\n\n\n1\nWednesday\n1.58\n\n\n1\nThursday\n0.91\n\n\n1\nFriday\n0.00\n\n\n1\nSaturday\n0.05\n\n\n2\nSunday\n0.27\n\n\n2\nMonday\n4.26\n\n\n2\nTuesday\n0.43\n\n\n2\nWednesday\n0.00\n\n\n2\nThursday\n0.00\n\n\n2\nFriday\n0.16\n\n\n2\nSaturday\n1.41\n\n\n3\nSunday\n0.34\n\n\n3\nMonday\n0.33\n\n\n3\nTuesday\n0.00\n\n\n3\nWednesday\n0.00\n\n\n3\nThursday\n0.13\n\n\n3\nFriday\n0.00\n\n\n3\nSaturday\n0.00\n\n\n4\nSunday\n0.00\n\n\n4\nMonday\n0.00\n\n\n4\nTuesday\n0.00\n\n\n4\nWednesday\n0.00\n\n\n4\nThursday\n0.00\n\n\n4\nFriday\n0.00\n\n\n4\nSaturday\nNA\n\n\n5\nSunday\nNA\n\n\n5\nMonday\nNA\n\n\n5\nTuesday\nNA\n\n\n5\nWednesday\nNA\n\n\n5\nThursday\nNA\n\n\n5\nFriday\nNA\n\n\n5\nSaturday\nNA"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#long-to-wide",
    "href": "slides/week-4/w4-joins-pivots.html#long-to-wide",
    "title": "Data Joins + Pivots",
    "section": "Long to Wide",
    "text": "Long to Wide\nWhat are the mean amount of protein for cereals on each shelf and for each manuf?\n\nmean_protein &lt;- cereal |&gt; \n  group_by(manuf, shelf) |&gt; \n  summarize(mean_protein = mean(protein))\n\n\n\n\n\n\n\nmanuf\nshelf\nmean_protein\n\n\n\n\nA\n2\n4.000000\n\n\nG\n1\n3.000000\n\n\nG\n2\n1.285714\n\n\nG\n3\n2.666667\n\n\nK\n1\n2.750000\n\n\nK\n2\n2.142857\n\n\nK\n3\n2.916667\n\n\nN\n1\n2.666667\n\n\nN\n2\n2.500000\n\n\nN\n3\n4.000000\n\n\nP\n1\n1.500000\n\n\nP\n2\n1.000000\n\n\nP\n3\n3.000000\n\n\nQ\n1\n5.000000\n\n\nQ\n2\n2.000000\n\n\nQ\n3\n2.500000\n\n\nR\n1\n2.000000\n\n\nR\n3\n3.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\n\nWhat could we do to make this table easier to understand?"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pivot_wider",
    "href": "slides/week-4/w4-joins-pivots.html#pivot_wider",
    "title": "Data Joins + Pivots",
    "section": "pivot_wider()",
    "text": "pivot_wider()\nTake a long dataset and turn it into a wide dataset.\n\nid_cols – specify the column(s) that contain the ID for unique rows in the wide dataset.\nnames_from – the name of the column containing the new column names.\nvalues_from – the name of the column containing the new column values."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pivot_wider-1",
    "href": "slides/week-4/w4-joins-pivots.html#pivot_wider-1",
    "title": "Data Joins + Pivots",
    "section": "pivot_wider()",
    "text": "pivot_wider()\nMuch easier to read!\n\nmean_protein |&gt; \n  arrange(shelf) |&gt; \n  pivot_wider(id_cols = manuf,\n              names_from = shelf,\n              values_from = mean_protein)\n\n\n\n\n\n\n\nmanuf\n1\n2\n3\n\n\n\n\nG\n3.000000\n1.285714\n2.666667\n\n\nK\n2.750000\n2.142857\n2.916667\n\n\nN\n2.666667\n2.500000\n4.000000\n\n\nP\n1.500000\n1.000000\n3.000000\n\n\nQ\n5.000000\n2.000000\n2.500000\n\n\nR\n2.000000\nNA\n3.000000\n\n\nA\nNA\n4.000000\nNA"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#better-names-in-pivot_wider",
    "href": "slides/week-4/w4-joins-pivots.html#better-names-in-pivot_wider",
    "title": "Data Joins + Pivots",
    "section": "Better names in pivot_wider()",
    "text": "Better names in pivot_wider()\nEven better!\n\nmean_protein |&gt; \n  arrange(shelf) |&gt; \n  pivot_wider(id_cols = manuf,\n              names_from = shelf,\n              values_from = mean_protein,\n              names_prefix = \"Shelf_\")\n\n\n\n\n\n\n\nmanuf\nShelf_1\nShelf_2\nShelf_3\n\n\n\n\nG\n3.000000\n1.285714\n2.666667\n\n\nK\n2.750000\n2.142857\n2.916667\n\n\nN\n2.666667\n2.500000\n4.000000\n\n\nP\n1.500000\n1.000000\n3.000000\n\n\nQ\n5.000000\n2.000000\n2.500000\n\n\nR\n2.000000\nNA\n3.000000\n\n\nA\nNA\n4.000000\nNA"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#pa-4-military-spending",
    "href": "slides/week-4/w4-joins-pivots.html#pa-4-military-spending",
    "title": "Data Joins + Pivots",
    "section": "PA 4: Military Spending",
    "text": "PA 4: Military Spending\nToday you will be tidying messy data to explore the relationship between countries of the world and military spending."
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#resources---use-them-all",
    "href": "slides/week-4/w4-joins-pivots.html#resources---use-them-all",
    "title": "Data Joins + Pivots",
    "section": "Resources - use them all!",
    "text": "Resources - use them all!\n\n\n\ndplyr and tidyr cheatsheets\nslides and textbook\nhelp files\n\n\n\n⭐️️ each other⭐️\nand me 😎\n\n\n\nDon’t struggle individually for too long!"
  },
  {
    "objectID": "slides/week-4/w4-joins-pivots.html#to-do",
    "href": "slides/week-4/w4-joins-pivots.html#to-do",
    "title": "Data Joins + Pivots",
    "section": "To do…",
    "text": "To do…\n\nPA 4: Military Spending\n\nDue Thursday, 4/24 before class"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html",
    "href": "labs/lab5/lab5-murder.html",
    "title": "Lab 5: Murder in SQL City",
    "section": "",
    "text": "Download starter .qmd file\nFor this lab, you will be joining and filtering related datasets to solve a murder mystery!"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#instructions",
    "href": "labs/lab5/lab5-murder.html#instructions",
    "title": "Lab 5: Murder in SQL City",
    "section": "Instructions",
    "text": "Instructions\nNorthwestern University’s Knight Lab wanted to help sharpen users’ database skills, so they created a murder mystery. Can you solve this crime in SQL City??\nThe relational data you will be working with contains tables with different pieces of information pertinent to the crime - people, social media check-ins, driver’s licenses, crime scene reports, police interviews, and more!\n\n\n\nDatabase schema"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#access-the-data",
    "href": "labs/lab5/lab5-murder.html#access-the-data",
    "title": "Lab 5: Murder in SQL City",
    "section": "Access the Data",
    "text": "Access the Data\nThis code chunk will read in all of the tables of data for you. Don’t modify or remove this!\n\nlibrary(tidyverse)\n\nurl(\"https://raw.githubusercontent.com/manncz/stat-331-s25/main/labs/lab5/data/bCH_murder_data.Rdata\") |&gt; \n  load()\n\n\n\n\n\n\n\nTip\n\n\n\nIf the code above does not work for you for some reason, you can download the special data file here and use the load() function to read it in."
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#solve-the-crime",
    "href": "labs/lab5/lab5-murder.html#solve-the-crime",
    "title": "Lab 5: Murder in SQL City",
    "section": "Solve the Crime",
    "text": "Solve the Crime\n\nCrime Scene Report\nDetective Wickham reaches out to you…\n\nA crime has taken place and I need your help! There was a murder in SQL City sometime on Jan.15, 2018. Could you retrieve the crime scene report from the police department’s database and follow the clues to find the person responsible for the murder?!\n\nSolve the murder mystery, showing all of your work in this document. Your document and code must be well organized, easy to follow, and reproducible.\n\nUse headers and written descriptions to indicate what you are doing.\nYou must use dplyr verbs and join functions rather than just looking through the tables manually.\nYou should never filter on a specific person id – rather use join functions\nYou should have a final output that just includes the murder’s name as well as their interview transcript (which is missing!).\nUse the data frames you just created when helpful!\nUse good code formatting practices.\nComment your code.\nCite any external sources you use to solve the mystery.\n\n\n\n\n\n\n\nTip\n\n\n\nUse kable() to nicely output clues!\n\n\nFollow the evidence to the person responsible for the murder, building a report as you go.\n\n# code for looking at the relevant crime scene report.\n\n# you will want to use multiple chunks!\n\n\n\n\n\n\n\nCaution\n\n\n\nMake sure you check for interviews with any suspects and anyone mentioned!\nThe murderer will have no interview - don’t stop until you find them!\n\n\n\n\n\n\n\n\nAnd the final suspect is…\n\n\n\nput the name of the person responsible for the murder here."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#thursday-april-24",
    "href": "slides/week-4/w4-factors.html#thursday-april-24",
    "title": "Extending Data Joins + Factors",
    "section": "Thursday, April 24",
    "text": "Thursday, April 24\nToday we will…\n\nNotes on Lab 3\nProject Info\nNew Material\n\nExtensions to Data Joins\nFactors with forcats\nClean Variable Names\nLifecycle Stages\n\nLab 4: Childcare Costs in California"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#notes-on-lab-3",
    "href": "slides/week-4/w4-factors.html#notes-on-lab-3",
    "title": "Data Joins + Pivots + Factors",
    "section": "Notes on Lab 3",
    "text": "Notes on Lab 3\n\n\nOnly include output that (exactly) answers a specific question\n\nIf you find yourself outputting a datatable with more than 20 rows, think again!\n\nBe mindful of “environment junk”\nIf we have cleaned up a dataset, you can assume that will be used for the remainder of the lab, unless otherwise specified\nPlease look at the solutions for efficient code and statistical interpretations"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#where-is-my-file",
    "href": "slides/week-4/w4-factors.html#where-is-my-file",
    "title": "Data Joins + Pivots + Factors",
    "section": "Where is my file?",
    "text": "Where is my file?\n\nRemember: I will smash 💥 your computer if you:\n\nSet a working directory in a Quarto file setwd() OR\nUse an aboslute file path that would only work on your computer\n\n\n\n\nUSE RELATIVE FILE PATHS I BEG OF YOU"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#lab-3-question-11",
    "href": "slides/week-4/w4-factors.html#lab-3-question-11",
    "title": "Data Joins + Pivots + Factors",
    "section": "Lab 3 Question 11",
    "text": "Lab 3 Question 11\n Which instructor(s) with either a doctorate or professor degree had the highest and lowest average percent of students responding to the evaluation across all their courses? Include how many years the professor had worked (seniority) and their sex in your output \n\nThe trick: group_by() instructor_id, seniority, and sex\n\nteacher_evals_clean |&gt; \n  filter(academic_degree %in% c(\"dr\", \"prof\")) |&gt; \n  group_by(teacher_id, seniority, sex) |&gt; \n  summarize(avg_response = mean(resp_share)) |&gt; \n  ungroup() |&gt; \n  slice_max(order_by = avg_response) |&gt; \n  kable()\n\n\nIf you find yourself using mutate() and then distinct(), you should probably be using summarize()"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#relational-data-reminder---keys",
    "href": "slides/week-4/w4-factors.html#relational-data-reminder---keys",
    "title": "Extending Data Joins + Factors",
    "section": "Relational Data Reminder - Keys",
    "text": "Relational Data Reminder - Keys\nWhen we work with relational data, we rely on keys.\n\nA key uniquely identifies an observation in a dataset.\nA key allows us to relate datasets to each other"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#imdb-movies-data",
    "href": "slides/week-4/w4-factors.html#imdb-movies-data",
    "title": "Extending Data Joins + Factors",
    "section": "IMDb Movies Data",
    "text": "IMDb Movies Data\n\nWhat were the active years of each director?\n\n\n\n\n\n\nDiscussion\n\n\nWhich datasets do we need to use to answer this question?"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#joining-multiple-data-sets",
    "href": "slides/week-4/w4-factors.html#joining-multiple-data-sets",
    "title": "Extending Data Joins + Factors",
    "section": "Joining Multiple Data Sets",
    "text": "Joining Multiple Data Sets\n\nDataSketch1st + 2nd+ 3rdAnalysis\n\n\n\n\n\nmovies_directors |&gt; \n  slice_head(n = 4)\n\n\n\n\n\n\n\ndirector_id\nmovie_id\n\n\n\n\n429\n300229\n\n\n2931\n254943\n\n\n9247\n124110\n\n\n11652\n10920\n\n\n\n\n\n\n\n\n\ndirectors |&gt; \n  slice_head(n = 4)\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\n\n\n\n\n429\nAndrew\nAdamson\n\n\n2931\nDarren\nAronofsky\n\n\n9247\nZach\nBraff\n\n\n11652\nJames (I)\nCameron\n\n\n\n\n\n\n\n\n\n\n\n\n\nmovies |&gt; \n  slice_head(n = 4)\n\n\n\n\n\n\n\nid\nname\nyear\nrank\n\n\n\n\n10920\nAliens\n1986\n8.2\n\n\n17173\nAnimal House\n1978\n7.5\n\n\n18979\nApollo 13\n1995\n7.5\n\n\n30959\nBatman Begins\n2005\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  inner_join(directors, \n             join_by(director_id == id))\n\n\n\n\n\n\n\ndirector_id\nmovie_id\nfirst_name\nlast_name\n\n\n\n\n429\n300229\nAndrew\nAdamson\n\n\n2931\n254943\nDarren\nAronofsky\n\n\n9247\n124110\nZach\nBraff\n\n\n11652\n10920\nJames (I)\nCameron\n\n\n11652\n333856\nJames (I)\nCameron\n\n\n14927\n192017\nRon\nClements\n\n\n15092\n109093\nEthan\nCoen\n\n\n15092\n237431\nEthan\nCoen\n\n\n15093\n109093\nJoel\nCoen\n\n\n15093\n237431\nJoel\nCoen\n\n\n15901\n130128\nFrancis Ford\nCoppola\n\n\n15906\n194874\nSofia\nCoppola\n\n\n16816\n350424\nCameron\nCrowe\n\n\n17810\n297838\nFrank\nDarabont\n\n\n22104\n224842\nClint\nEastwood\n\n\n24758\n112290\nDavid\nFincher\n\n\n28395\n46169\nMel (I)\nGibson\n\n\n35573\n18979\nRon\nHoward\n\n\n35838\n257264\nJohn (I)\nHughes\n\n\n37872\n300229\nVicky\nJenson\n\n\n38746\n238695\nMike (I)\nJudge\n\n\n41975\n314965\nDavid\nKoepp\n\n\n44291\n17173\nJohn (I)\nLandis\n\n\n46315\n344203\nJay\nLevey\n\n\n48115\n313459\nGeorge\nLucas\n\n\n56332\n192017\nJohn\nMusker\n\n\n58201\n30959\nChristopher\nNolan\n\n\n58201\n210511\nChristopher\nNolan\n\n\n65940\n111813\nRob\nReiner\n\n\n66849\n306032\nGuy\nRitchie\n\n\n68161\n116907\nHerbert (I)\nRoss\n\n\n74758\n238072\nSteven\nSoderbergh\n\n\n76524\n167324\nOliver (I)\nStone\n\n\n78273\n176711\nQuentin\nTarantino\n\n\n78273\n176712\nQuentin\nTarantino\n\n\n78273\n267038\nQuentin\nTarantino\n\n\n78273\n276217\nQuentin\nTarantino\n\n\n82525\n147603\nPaul (I)\nVerhoeven\n\n\n83616\n207992\nAndy\nWachowski\n\n\n83617\n207992\nLarry\nWachowski\n\n\n88802\n256630\nUnknown\nDirector\n\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  inner_join(directors, \n             join_by(director_id == id)) |&gt; \n  inner_join(movies,\n             join_by(movie_id == id))\n\n\n\n\n\n\n\ndirector_id\nmovie_id\nfirst_name\nlast_name\nname\nyear\nrank\n\n\n\n\n429\n300229\nAndrew\nAdamson\nShrek\n2001\n8.1\n\n\n2931\n254943\nDarren\nAronofsky\nPi\n1998\n7.5\n\n\n9247\n124110\nZach\nBraff\nGarden State\n2004\n8.3\n\n\n11652\n10920\nJames (I)\nCameron\nAliens\n1986\n8.2\n\n\n11652\n333856\nJames (I)\nCameron\nTitanic\n1997\n6.9\n\n\n14927\n192017\nRon\nClements\nLittle Mermaid, The\n1989\n7.3\n\n\n15092\n109093\nEthan\nCoen\nFargo\n1996\n8.2\n\n\n15092\n237431\nEthan\nCoen\nO Brother, Where Art Thou?\n2000\n7.8\n\n\n15093\n109093\nJoel\nCoen\nFargo\n1996\n8.2\n\n\n15093\n237431\nJoel\nCoen\nO Brother, Where Art Thou?\n2000\n7.8\n\n\n15901\n130128\nFrancis Ford\nCoppola\nGodfather, The\n1972\n9.0\n\n\n15906\n194874\nSofia\nCoppola\nLost in Translation\n2003\n8.0\n\n\n16816\n350424\nCameron\nCrowe\nVanilla Sky\n2001\n6.9\n\n\n17810\n297838\nFrank\nDarabont\nShawshank Redemption, The\n1994\n9.0\n\n\n22104\n224842\nClint\nEastwood\nMystic River\n2003\n8.1\n\n\n24758\n112290\nDavid\nFincher\nFight Club\n1999\n8.5\n\n\n28395\n46169\nMel (I)\nGibson\nBraveheart\n1995\n8.3\n\n\n35573\n18979\nRon\nHoward\nApollo 13\n1995\n7.5\n\n\n35838\n257264\nJohn (I)\nHughes\nPlanes, Trains & Automobiles\n1987\n7.2\n\n\n37872\n300229\nVicky\nJenson\nShrek\n2001\n8.1\n\n\n38746\n238695\nMike (I)\nJudge\nOffice Space\n1999\n7.6\n\n\n41975\n314965\nDavid\nKoepp\nStir of Echoes\n1999\n7.0\n\n\n44291\n17173\nJohn (I)\nLandis\nAnimal House\n1978\n7.5\n\n\n46315\n344203\nJay\nLevey\nUHF\n1989\n6.6\n\n\n48115\n313459\nGeorge\nLucas\nStar Wars\n1977\n8.8\n\n\n56332\n192017\nJohn\nMusker\nLittle Mermaid, The\n1989\n7.3\n\n\n58201\n30959\nChristopher\nNolan\nBatman Begins\n2005\nNA\n\n\n58201\n210511\nChristopher\nNolan\nMemento\n2000\n8.7\n\n\n65940\n111813\nRob\nReiner\nFew Good Men, A\n1992\n7.5\n\n\n66849\n306032\nGuy\nRitchie\nSnatch.\n2000\n7.9\n\n\n68161\n116907\nHerbert (I)\nRoss\nFootloose\n1984\n5.8\n\n\n74758\n238072\nSteven\nSoderbergh\nOcean's Eleven\n2001\n7.5\n\n\n76524\n167324\nOliver (I)\nStone\nJFK\n1991\n7.8\n\n\n78273\n176711\nQuentin\nTarantino\nKill Bill: Vol. 1\n2003\n8.4\n\n\n78273\n176712\nQuentin\nTarantino\nKill Bill: Vol. 2\n2004\n8.2\n\n\n78273\n267038\nQuentin\nTarantino\nPulp Fiction\n1994\n8.7\n\n\n78273\n276217\nQuentin\nTarantino\nReservoir Dogs\n1992\n8.3\n\n\n82525\n147603\nPaul (I)\nVerhoeven\nHollow Man\n2000\n5.3\n\n\n83616\n207992\nAndy\nWachowski\nMatrix, The\n1999\n8.5\n\n\n83617\n207992\nLarry\nWachowski\nMatrix, The\n1999\n8.5\n\n\n88802\n256630\nUnknown\nDirector\nPirates of the Caribbean\n2003\nNA\n\n\n\n\n\n\n\n\n\n\nmovies_directors |&gt; \n  inner_join(directors, \n             join_by(director_id == id)) |&gt; \n  inner_join(movies,\n             join_by(movie_id == id)) |&gt; \n  group_by(first_name, last_name) |&gt;\n  summarize(start_year = min(year),\n            end_year = max(year)) |&gt; \n  mutate(n_years_active = end_year - start_year) |&gt; \n  arrange(desc(n_years_active))\n\n\n\n\n\n\n\nfirst_name\nlast_name\nstart_year\nend_year\nn_years_active\n\n\n\n\nQuentin\nTarantino\n1992\n2004\n12\n\n\nJames (I)\nCameron\n1986\n1997\n11\n\n\nChristopher\nNolan\n2000\n2005\n5\n\n\nEthan\nCoen\n1996\n2000\n4\n\n\nJoel\nCoen\n1996\n2000\n4\n\n\nAndrew\nAdamson\n2001\n2001\n0\n\n\nAndy\nWachowski\n1999\n1999\n0\n\n\nCameron\nCrowe\n2001\n2001\n0\n\n\nClint\nEastwood\n2003\n2003\n0\n\n\nDarren\nAronofsky\n1998\n1998\n0\n\n\nDavid\nFincher\n1999\n1999\n0\n\n\nDavid\nKoepp\n1999\n1999\n0\n\n\nFrancis Ford\nCoppola\n1972\n1972\n0\n\n\nFrank\nDarabont\n1994\n1994\n0\n\n\nGeorge\nLucas\n1977\n1977\n0\n\n\nGuy\nRitchie\n2000\n2000\n0\n\n\nHerbert (I)\nRoss\n1984\n1984\n0\n\n\nJay\nLevey\n1989\n1989\n0\n\n\nJohn\nMusker\n1989\n1989\n0\n\n\nJohn (I)\nHughes\n1987\n1987\n0\n\n\nJohn (I)\nLandis\n1978\n1978\n0\n\n\nLarry\nWachowski\n1999\n1999\n0\n\n\nMel (I)\nGibson\n1995\n1995\n0\n\n\nMike (I)\nJudge\n1999\n1999\n0\n\n\nOliver (I)\nStone\n1991\n1991\n0\n\n\nPaul (I)\nVerhoeven\n2000\n2000\n0\n\n\nRob\nReiner\n1992\n1992\n0\n\n\nRon\nClements\n1989\n1989\n0\n\n\nRon\nHoward\n1995\n1995\n0\n\n\nSofia\nCoppola\n2003\n2003\n0\n\n\nSteven\nSoderbergh\n2001\n2001\n0\n\n\nUnknown\nDirector\n2003\n2003\n0\n\n\nVicky\nJenson\n2001\n2001\n0\n\n\nZach\nBraff\n2004\n2004\n0"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#know-your-unique-observations",
    "href": "slides/week-4/w4-factors.html#know-your-unique-observations",
    "title": "Extending Data Joins + Factors",
    "section": "Know Your Unique Observations!",
    "text": "Know Your Unique Observations!\n\n\n\n\n\n\nDiscussion\n\n\nWhat is the observational unit after joining the directors and movies_directors by the director_id key? What happens for directors that have multiple movies in the movies_directors data?\n\n\n\n\n\ndirectors |&gt; \n  inner_join(movies_directors, \n             join_by(id == director_id))\n\n\n\n\n\n\n\nid\nfirst_name\nlast_name\nmovie_id\n\n\n\n\n429\nAndrew\nAdamson\n300229\n\n\n2931\nDarren\nAronofsky\n254943\n\n\n9247\nZach\nBraff\n124110\n\n\n11652\nJames (I)\nCameron\n10920\n\n\n11652\nJames (I)\nCameron\n333856\n\n\n14927\nRon\nClements\n192017\n\n\n15092\nEthan\nCoen\n109093\n\n\n15092\nEthan\nCoen\n237431\n\n\n15093\nJoel\nCoen\n109093\n\n\n15093\nJoel\nCoen\n237431\n\n\n15901\nFrancis Ford\nCoppola\n130128\n\n\n15906\nSofia\nCoppola\n194874\n\n\n16816\nCameron\nCrowe\n350424\n\n\n17810\nFrank\nDarabont\n297838\n\n\n22104\nClint\nEastwood\n224842\n\n\n24758\nDavid\nFincher\n112290\n\n\n28395\nMel (I)\nGibson\n46169\n\n\n35573\nRon\nHoward\n18979\n\n\n35838\nJohn (I)\nHughes\n257264\n\n\n37872\nVicky\nJenson\n300229\n\n\n38746\nMike (I)\nJudge\n238695\n\n\n41975\nDavid\nKoepp\n314965\n\n\n44291\nJohn (I)\nLandis\n17173\n\n\n46315\nJay\nLevey\n344203\n\n\n48115\nGeorge\nLucas\n313459\n\n\n56332\nJohn\nMusker\n192017\n\n\n58201\nChristopher\nNolan\n30959\n\n\n58201\nChristopher\nNolan\n210511\n\n\n65940\nRob\nReiner\n111813\n\n\n66849\nGuy\nRitchie\n306032\n\n\n68161\nHerbert (I)\nRoss\n116907\n\n\n74758\nSteven\nSoderbergh\n238072\n\n\n76524\nOliver (I)\nStone\n167324\n\n\n78273\nQuentin\nTarantino\n176711\n\n\n78273\nQuentin\nTarantino\n176712\n\n\n78273\nQuentin\nTarantino\n267038\n\n\n78273\nQuentin\nTarantino\n276217\n\n\n82525\nPaul (I)\nVerhoeven\n147603\n\n\n83616\nAndy\nWachowski\n207992\n\n\n83617\nLarry\nWachowski\n207992\n\n\n88802\nUnknown\nDirector\n256630"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#know-your-unique-observations-1",
    "href": "slides/week-4/w4-factors.html#know-your-unique-observations-1",
    "title": "Extending Data Joins + Factors",
    "section": "Know Your Unique Observations!",
    "text": "Know Your Unique Observations!\nRemember the rodent data from Lab 2. Say we had separate datsets for measurements and species information:\n\nSpeciesMeasurements\n\n\n\nspecies\n\n\n\n\n\n\n\ngenus\nspecies\ntaxa\nspecies_id\n\n\n\n\nDipodomys\nmerriami\nRodent\nDM\n\n\nDipodomys\nordii\nRodent\nDO\n\n\nPerognathus\nflavus\nRodent\nPF\n\n\nChaetodipus\npenicillatus\nRodent\nPP\n\n\nPeromyscus\neremicus\nRodent\nPE\n\n\nOnychomys\nleucogaster\nRodent\nOL\n\n\nReithrodontomys\nmegalotis\nRodent\nRM\n\n\nDipodomys\nspectabilis\nRodent\nDS\n\n\nOnychomys\ntorridus\nRodent\nOT\n\n\nNeotoma\nalbigula\nRodent\nNL\n\n\nPeromyscus\nmaniculatus\nRodent\nPM\n\n\nSigmodon\nhispidus\nRodent\nSH\n\n\nReithrodontomys\nfulvescens\nRodent\nRF\n\n\nChaetodipus\nbaileyi\nRodent\nPB\n\n\n\n\n\n\n\n\n\n\nmeasurements\n\n\n\n\n\n\n\ngenus_name\nspecies\nsex\nhindfoot_length\nweight\n\n\n\n\nDipodomys\nmerriami\nM\n35\n40\n\n\nDipodomys\nmerriami\nM\n37\n48\n\n\nDipodomys\nmerriami\nF\n34\n29\n\n\nDipodomys\nmerriami\nF\n35\n46\n\n\nDipodomys\nmerriami\nM\n35\n36\n\n\nDipodomys\nordii\nF\n32\n52\n\n\nPerognathus\nflavus\nM\n15\n8\n\n\nDipodomys\nmerriami\nF\n36\n35\n\n\nPerognathus\nflavus\nM\n12\n7\n\n\nDipodomys\nmerriami\nF\n32\n22\n\n\nPerognathus\nflavus\nM\n16\n9\n\n\nDipodomys\nmerriami\nF\n34\n42\n\n\nPerognathus\nflavus\nF\n14\n8\n\n\nDipodomys\nmerriami\nF\n35\n41\n\n\nDipodomys\nmerriami\nF\n37\n37\n\n\nDipodomys\nmerriami\nF\n35\n43\n\n\nDipodomys\nmerriami\nF\n35\n41\n\n\nDipodomys\nmerriami\nF\n33\n40\n\n\nPerognathus\nflavus\nF\n11\n9\n\n\nDipodomys\nmerriami\nF\n35\n45\n\n\nChaetodipus\npenicillatus\nF\n20\n15\n\n\nDipodomys\nmerriami\nM\n35\n29\n\n\nDipodomys\nmerriami\nM\n35\n39\n\n\nDipodomys\nmerriami\nF\n36\n43\n\n\nDipodomys\nmerriami\nM\n38\n46\n\n\nDipodomys\nmerriami\nM\n36\n41\n\n\nDipodomys\nmerriami\nM\n36\n41\n\n\nDipodomys\nmerriami\nM\n38\n40\n\n\nDipodomys\nmerriami\nM\n37\n45\n\n\nDipodomys\nmerriami\nF\n35\n46\n\n\nDipodomys\nmerriami\nF\n35\n40\n\n\nDipodomys\nmerriami\nF\n35\n30\n\n\nDipodomys\nmerriami\nM\n35\n39\n\n\nDipodomys\nmerriami\nM\n35\n34\n\n\nDipodomys\nmerriami\nF\n37\n42\n\n\nDipodomys\nmerriami\nM\n37\n42\n\n\nPerognathus\nflavus\nF\n13\n8\n\n\nDipodomys\nmerriami\nF\n37\n31\n\n\nDipodomys\nmerriami\nF\n36\n40\n\n\nDipodomys\nmerriami\nM\n36\n37\n\n\nDipodomys\nmerriami\nM\n36\n48\n\n\nDipodomys\nmerriami\nM\n37\n42\n\n\nDipodomys\nmerriami\nF\n39\n45\n\n\nChaetodipus\npenicillatus\nF\n21\n16\n\n\nDipodomys\nmerriami\nF\n36\n36\n\n\nDipodomys\nmerriami\nM\n36\n42\n\n\nDipodomys\nmerriami\nM\n36\n44\n\n\nDipodomys\nmerriami\nF\n36\n41\n\n\nDipodomys\nmerriami\nF\n36\n40\n\n\nDipodomys\nmerriami\nM\n37\n34\n\n\nDipodomys\nmerriami\nM\n33\n40\n\n\nDipodomys\nmerriami\nM\n33\n44\n\n\nDipodomys\nmerriami\nM\n37\n44\n\n\nDipodomys\nmerriami\nM\n34\n36\n\n\nDipodomys\nmerriami\nM\n35\n33\n\n\nDipodomys\nmerriami\nF\n37\n46\n\n\nDipodomys\nmerriami\nF\n34\n35\n\n\nDipodomys\nmerriami\nM\n36\n46\n\n\nDipodomys\nmerriami\nF\n33\n37\n\n\nDipodomys\nmerriami\nM\n36\n34\n\n\nDipodomys\nmerriami\nF\n36\n45\n\n\nPerognathus\nflavus\nF\n15\n7\n\n\nDipodomys\nmerriami\nM\n37\n51\n\n\nDipodomys\nmerriami\nM\n35\n39\n\n\nDipodomys\nmerriami\nM\n36\n29\n\n\nDipodomys\nmerriami\nF\n32\n48\n\n\nDipodomys\nmerriami\nM\n38\n46\n\n\nDipodomys\nmerriami\nF\n37\n41\n\n\nDipodomys\nmerriami\nM\n37\n45\n\n\nDipodomys\nmerriami\nF\n35\n42\n\n\nDipodomys\nmerriami\nF\n36\n53\n\n\nDipodomys\nmerriami\nF\n35\n49\n\n\nDipodomys\nmerriami\nF\n36\n46\n\n\nPerognathus\nflavus\nF\n13\n9\n\n\nChaetodipus\npenicillatus\nF\n19\n15\n\n\nPerognathus\nflavus\nM\n13\n4\n\n\nDipodomys\nmerriami\nM\n36\n48\n\n\nDipodomys\nmerriami\nM\n37\n51\n\n\nDipodomys\nmerriami\nM\n38\n50\n\n\nDipodomys\nmerriami\nM\n35\n44\n\n\nDipodomys\nmerriami\nM\n25\n44\n\n\nDipodomys\nmerriami\nM\n35\n45\n\n\nDipodomys\nmerriami\nF\n37\n45\n\n\nPeromyscus\neremicus\nM\n20\n19\n\n\nDipodomys\nmerriami\nF\n38\n44\n\n\nDipodomys\nmerriami\nF\n36\n42\n\n\nDipodomys\nmerriami\nM\n37\n39\n\n\nDipodomys\nmerriami\nM\n37\n47\n\n\nDipodomys\nmerriami\nM\n36\n42\n\n\nDipodomys\nmerriami\nM\n36\n49\n\n\nDipodomys\nmerriami\nM\n38\n39\n\n\nDipodomys\nmerriami\nF\n36\n43\n\n\nDipodomys\nmerriami\nM\n35\n50\n\n\nDipodomys\nmerriami\nM\n36\n41\n\n\nDipodomys\nmerriami\nM\n37\n47\n\n\nDipodomys\nmerriami\nF\n36\n37\n\n\nDipodomys\nmerriami\nM\n36\n41\n\n\nDipodomys\nmerriami\nF\n36\n36\n\n\nDipodomys\nmerriami\nM\n36\n45\n\n\nPeromyscus\neremicus\nM\n19\n20"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#know-your-unique-observations-2",
    "href": "slides/week-4/w4-factors.html#know-your-unique-observations-2",
    "title": "Extending Data Joins + Factors",
    "section": "Know Your Unique Observations!",
    "text": "Know Your Unique Observations!\n\n\n\n\n\n\nDiscussion\n\n\nWhat happens if we join species and measurements by the genus only?\n\n\n\n\nmeasurements |&gt; \n  inner_join(species, \n             by = join_by(genus_name == genus))\n\n\n\n\n\n\n\ngenus_name\nspecies.x\nsex\nhindfoot_length\nweight\nspecies.y\ntaxa\nspecies_id\n\n\n\n\nDipodomys\nmerriami\nM\n35\n40\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n40\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n40\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n37\n48\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n37\n48\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n37\n48\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n34\n29\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n34\n29\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n34\n29\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n46\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n46\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n46\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n35\n36\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n36\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n36\nspectabilis\nRodent\nDS\n\n\nDipodomys\nordii\nF\n32\n52\nmerriami\nRodent\nDM\n\n\nDipodomys\nordii\nF\n32\n52\nordii\nRodent\nDO\n\n\nDipodomys\nordii\nF\n32\n52\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nM\n15\n8\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n36\n35\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n36\n35\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n36\n35\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nM\n12\n7\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n32\n22\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n32\n22\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n32\n22\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nM\n16\n9\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n34\n42\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n34\n42\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n34\n42\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nF\n14\n8\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n35\n41\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n41\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n41\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n37\n37\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n37\n37\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n37\n37\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n43\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n43\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n43\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n41\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n41\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n41\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n33\n40\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n33\n40\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n33\n40\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nF\n11\n9\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n35\n45\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n45\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n45\nspectabilis\nRodent\nDS\n\n\nChaetodipus\npenicillatus\nF\n20\n15\npenicillatus\nRodent\nPP\n\n\nChaetodipus\npenicillatus\nF\n20\n15\nbaileyi\nRodent\nPB\n\n\nDipodomys\nmerriami\nM\n35\n29\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n29\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n29\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n35\n39\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n39\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n39\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n36\n43\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n36\n43\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n36\n43\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n38\n46\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n38\n46\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n38\n46\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n36\n41\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n36\n41\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n36\n41\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n36\n41\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n36\n41\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n36\n41\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n38\n40\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n38\n40\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n38\n40\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n37\n45\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n37\n45\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n37\n45\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n46\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n46\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n46\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n40\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n40\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n40\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n35\n30\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n35\n30\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n35\n30\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n35\n39\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n39\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n39\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n35\n34\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n35\n34\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n35\n34\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nF\n37\n42\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n37\n42\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nF\n37\n42\nspectabilis\nRodent\nDS\n\n\nDipodomys\nmerriami\nM\n37\n42\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nM\n37\n42\nordii\nRodent\nDO\n\n\nDipodomys\nmerriami\nM\n37\n42\nspectabilis\nRodent\nDS\n\n\nPerognathus\nflavus\nF\n13\n8\nflavus\nRodent\nPF\n\n\nDipodomys\nmerriami\nF\n37\n31\nmerriami\nRodent\nDM\n\n\nDipodomys\nmerriami\nF\n37\n31\nordii\nRodent\nDO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDANGER : MANY-TO-MANY JOIN!\n\n\nOur observations exploded and the species_id isn’t even right for some observations! We also now have a species.x and species.y variable since the variable was present in both the left and right data."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#joining-on-multiple-variables",
    "href": "slides/week-4/w4-factors.html#joining-on-multiple-variables",
    "title": "Extending Data Joins + Factors",
    "section": "Joining on Multiple Variables",
    "text": "Joining on Multiple Variables\nTo fix this, we need to join on multiple variables (a compound key):\n\nspecies |&gt; \n  full_join(measurements,\n            join_by(species == species, \n                    genus == genus_name))\n\n\n\n\n\n\n\ngenus\nspecies\ntaxa\nspecies_id\nsex\nhindfoot_length\nweight\n\n\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n34\n29\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n35\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n32\n22\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n34\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n37\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n43\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n33\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n29\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n43\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n30\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n34\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n31\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n37\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n39\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n34\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n33\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n33\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n34\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n33\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n34\n35\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n33\n37\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n34\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n51\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n29\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n32\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n53\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n35\n49\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n51\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n50\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n25\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n37\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n38\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n47\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n42\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n49\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n39\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n43\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n35\n50\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n47\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n37\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n45\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n40\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n49\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n55\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n38\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n46\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n34\n36\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n44\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n36\n53\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n41\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n37\n48\n\n\nDipodomys\nmerriami\nRodent\nDM\nM\n38\n47\n\n\nDipodomys\nmerriami\nRodent\nDM\nF\n36\n42"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#what-is-a-factor-variable",
    "href": "slides/week-4/w4-factors.html#what-is-a-factor-variable",
    "title": "Extending Data Joins + Factors",
    "section": "What is a factor variable?",
    "text": "What is a factor variable?\nFactors are used for\n\ncategorical variables with a fixed and known set of possible values.\n\n\nE.g., day_born = Sunday, Monday, Tuesday, …, Saturday\n\n\ndisplaying character vectors in non-alphabetical order.\n\n\nuseful for nice tables and plots!"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#eras-tour",
    "href": "slides/week-4/w4-factors.html#eras-tour",
    "title": "Extending Data Joins + Factors",
    "section": "Eras Tour",
    "text": "Eras Tour\nLet’s consider songs that Taylor Swift played on her Eras Tour.\nI have randomly selected 25 songs (and their albums) to demonstrate.\n\neras_data |&gt; \n  slice_head(n = 10)\n\n\n\n\n\n\n\nSong\nAlbum\n\n\n\n\n22\nRed\n\n\n...Ready for It?\nReputation\n\n\nThe Archer\nLover\n\n\nBejeweled\nMidnights\n\n\nStyle\n1989\n\n\nYou Belong With Me\nFearless\n\n\nDon't Blame Me\nReputation\n\n\nillicit affairs\nFolklore\n\n\nLavender Haze\nMidnights\n\n\nmarjorie\nEvermore"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-base-r",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-base-r",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – Base R",
    "text": "Creating a Factor – Base R\nA character vector:\n\neras_data |&gt; \n  pull(Album)\n\n [1] \"Red\"        \"Reputation\" \"Lover\"      \"Midnights\"  \"1989\"      \n [6] \"Fearless\"   \"Reputation\" \"Folklore\"   \"Midnights\"  \"Evermore\"  \n[11] \"Evermore\"   \"Lover\"      \"Lover\"      \"Red\"        \"Reputation\"\n[16] \"Reputation\" \"Speak Now\"  \"Red\"        \"Midnights\"  \"Fearless\"  \n[21] \"1989\"       \"Midnights\"  \"Fearless\"   \"Folklore\"   \"Lover\"     \n\n\n\nA factor vector:\n\neras_data |&gt; \n  pull(Album) |&gt; \n  factor()\n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: 1989 Evermore Fearless Folklore Lover Midnights Red ... Speak Now"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-base-r-1",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-base-r-1",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – Base R",
    "text": "Creating a Factor – Base R\nWhen you create a factor variable from a vector…\n\nEvery unique element in the vector becomes a level.\nThe levels are ordered alphabetically.\nThe elements are no longer displayed in quotes."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-base-r-2",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-base-r-2",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – Base R",
    "text": "Creating a Factor – Base R\nYou can specify the order of the levels with the level argument.\n\neras_data |&gt; \n  pull(Album) |&gt; \n  factor(levels = c(\"Fearless\",\"Speak Now\",\"Red\",\"1989\",\n                    \"Reputation\",\"Lover\",\"Folklore\",\n                    \"Evermore\",\"Midnights\"))\n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Fearless Speak Now Red 1989 Reputation Lover Folklore ... Midnights"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#forcats",
    "href": "slides/week-4/w4-factors.html#forcats",
    "title": "Extending Data Joins + Factors",
    "section": "forcats",
    "text": "forcats\n\n\nWe use this package to…\n\nturn character variables into factors.\nmake factors by discretizing numeric variables.\nrename or reorder the levels of an existing factor.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe packages forcats (“for categoricals”) helps wrangle categorical variables.\n\nforcats loads with tidyverse!"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-fct",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-fct",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – fct",
    "text": "Creating a Factor – fct\nWith fct(), the levels are automatically ordered in the order of first appearance.\n\neras_data |&gt; \n  mutate(Album = fct(Album)) |&gt; \n  pull(Album)\n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Red Reputation Lover Midnights 1989 Fearless Folklore ... Speak Now"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-fct-1",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-fct-1",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – fct",
    "text": "Creating a Factor – fct\nYou can still specify the order of the levels with level.\n\neras_data |&gt; \n  mutate(Album = fct(Album,\n                     levels = c(\"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\", \"Reputation\",\"Lover\",\n                                \"Folklore\", \"Evermore\",\"Midnights\"))) |&gt; \n  pull(Album) \n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Fearless Speak Now Red 1989 Reputation Lover Folklore ... Midnights"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#creating-a-factor-fct-2",
    "href": "slides/week-4/w4-factors.html#creating-a-factor-fct-2",
    "title": "Extending Data Joins + Factors",
    "section": "Creating a Factor – fct",
    "text": "Creating a Factor – fct\nYou can also specify non-present levels.\n\neras_data |&gt; \n  mutate(Album = fct(Album, \n                     levels = c(\"Taylor Swift\",\n                                \"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\", \"Reputation\",\"Lover\",\n                                \"Folklore\", \"Evermore\",\"Midnights\",\n                                \"The Tortured Poets Department\"))) |&gt; \n  pull(Album) \n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n11 Levels: Taylor Swift Fearless Speak Now Red 1989 Reputation ... The Tortured Poets Department"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-coding-a-factor-fct_recode",
    "href": "slides/week-4/w4-factors.html#re-coding-a-factor-fct_recode",
    "title": "Extending Data Joins + Factors",
    "section": "Re-coding a Factor – fct_recode",
    "text": "Re-coding a Factor – fct_recode\nOops, we have a typo in some of our levels! We change existing levels with the syntax &lt;new level&gt; = &lt;old level&gt;.\n\n\neras_data |&gt;\n  mutate(Album = fct_recode(.f = Album,\n                            \"folklore\" = \"Folklore\",\n                            \"evermore\" = \"Evermore\",\n                            \"reputation\" = \"Reputation\")) |&gt;\n  pull(Album) \n\n [1] Red        reputation Lover      Midnights  1989       Fearless  \n [7] reputation folklore   Midnights  evermore   evermore   Lover     \n[13] Lover      Red        reputation reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   folklore  \n[25] Lover     \n11 Levels: Taylor Swift Fearless Speak Now Red 1989 reputation ... The Tortured Poets Department\n\n\n\n\nNon-specified levels are not re-coded."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-coding-a-factor-case_when",
    "href": "slides/week-4/w4-factors.html#re-coding-a-factor-case_when",
    "title": "Extending Data Joins + Factors",
    "section": "Re-coding a Factor – case_when",
    "text": "Re-coding a Factor – case_when\nWe have similar functionality with the case_when() function…\n\n\neras_data |&gt;\n  mutate(Album = case_when(Album == \"Folklore\" ~ \"folklore\",\n                           Album == \"Evermore\" ~ \"evermore\",\n                           Album == \"Reputation\" ~ \"reputation\",\n                           .default = Album),\n         Album = fct(Album)) |&gt; \n  pull(Album)\n\n [1] Red        reputation Lover      Midnights  1989       Fearless  \n [7] reputation folklore   Midnights  evermore   evermore   Lover     \n[13] Lover      Red        reputation reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   folklore  \n[25] Lover     \n9 Levels: Red reputation Lover Midnights 1989 Fearless folklore ... Speak Now"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#collapsing-a-factor-fct_collapse",
    "href": "slides/week-4/w4-factors.html#collapsing-a-factor-fct_collapse",
    "title": "Extending Data Joins + Factors",
    "section": "Collapsing a Factor –fct_collapse",
    "text": "Collapsing a Factor –fct_collapse\nCollapse multiple existing levels of a factor with the syntax &lt;new level&gt; = c(&lt;old levels&gt;).\n\n\neras_data |&gt; \n  mutate(Genre = fct_collapse(.f= Album,\n                       \"country pop\" = c(\"Taylor Swift\", \"Fearless\"),\n                       \"pop rock\" = c(\"Speak Now\",\"Red\"),\n                       \"electropop\" = c(\"1989\",\"reputation\",\"Lover\"),\n                       \"folk pop\" = c(\"folklore\",\"evermore\"),\n                       \"alt-pop\" = \"Midnights\")) |&gt; \n  slice_sample(n = 6)\n\n\n\n\n\n\n\nSong\nAlbum\nGenre\n\n\n\n\nwillow\nevermore\nfolk pop\n\n\nYou Belong With Me\nFearless\ncountry pop\n\n\nLavender Haze\nMidnights\nalt-pop\n\n\nWe Are Never Ever Getting Back Together\nRed\npop rock\n\n\nillicit affairs\nfolklore\nfolk pop\n\n\nLook What You Made Me Do\nreputation\nelectropop"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-leveling-a-factor-fct_relevel",
    "href": "slides/week-4/w4-factors.html#re-leveling-a-factor-fct_relevel",
    "title": "Extending Data Joins + Factors",
    "section": "Re-leveling a Factor –fct_relevel",
    "text": "Re-leveling a Factor –fct_relevel\nChange the order of the levels of an existing factor.\n\nOriginalOrdered by Copies Sold\n\n\n\neras_data |&gt;\n  pull(Album) |&gt; \n  levels()\n\n [1] \"Taylor Swift\"                  \"Fearless\"                     \n [3] \"Speak Now\"                     \"Red\"                          \n [5] \"1989\"                          \"reputation\"                   \n [7] \"Lover\"                         \"folklore\"                     \n [9] \"evermore\"                      \"Midnights\"                    \n[11] \"The Tortured Poets Department\"\n\n\n\n\n\neras_data |&gt; \n  mutate(Album = fct_relevel(.f = Album, \n                             c(\"Fearless\",\"1989\",\"Taylor Swift\",\n                               \"Speak Now\",\"Red\",\"Midnights\",\"reputation\",\n                               \"folklore\",\"Lover\",\"evermore\"))) |&gt;\n  pull(Album) |&gt;\n  levels()\n\n [1] \"Fearless\"                      \"1989\"                         \n [3] \"Taylor Swift\"                  \"Speak Now\"                    \n [5] \"Red\"                           \"Midnights\"                    \n [7] \"reputation\"                    \"folklore\"                     \n [9] \"Lover\"                         \"evermore\"                     \n[11] \"The Tortured Poets Department\"\n\n\nUnspecified levels remain in the same order at the end."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2",
    "href": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2",
    "title": "Extending Data Joins + Factors",
    "section": "Re-ordering Factors in ggplot2",
    "text": "Re-ordering Factors in ggplot2\n\nOriginalPlotSpecify LevelsPlot\n\n\nThe bars follow the default factor levels.\n\nfull_eras |&gt; \n  mutate(Album = fct(Album)) |&gt; \n  ggplot() +\n  geom_bar(aes(y = Album), fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can order factor levels to order the bar plot.\n\nfull_eras |&gt; \n  mutate(Album = fct(Album,\n                     levels = c(\"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\",\"Reputation\",\"Lover\",\n                                \"Folklore\",\"Evermore\",\n                                \"Midnights\"))) |&gt; \n  ggplot() +\n  geom_bar(aes(y = Album), fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-1",
    "href": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-1",
    "title": "Extending Data Joins + Factors",
    "section": "Re-ordering Factors in ggplot2",
    "text": "Re-ordering Factors in ggplot2\n\nOriginalPlotReorder by ValuePlot\n\n\nThe bars follow the default factor levels.\n\nfull_eras |&gt; \n  mutate(Album = fct(Album)) |&gt; \n  ggplot() +\n  geom_bar(aes(y = Album), fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can order factor levels to order the bar plot by the count using fct_infreq()\n\nfull_eras |&gt; \n  ggplot() +\n  geom_bar(aes(y = fct_infreq(Album)), \n           fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-2",
    "href": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-2",
    "title": "Extending Data Joins + Factors",
    "section": "Re-ordering Factors in ggplot2",
    "text": "Re-ordering Factors in ggplot2\n\nOriginalPlotfct_reorder()Plot\n\n\nThe ridge plots follow the order of the factor levels.\n\nfull_eras |&gt; \n  ggplot(aes(x = Length, \n             y = Album, \n             fill = Album)) +\n  geom_density_ridges() +\n  theme_minimal() +\n  theme(legend.position = \"none\")+\n  labs(x = \"Song Length (mins)\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInside ggplot(), we can order factor levels by a summary value.\n\nfull_eras |&gt; \n  ggplot(aes(x = Length, \n             y = fct_reorder(.f = Album,\n                             .x = Length,\n                             .fun = mean), \n             fill = Album)) +\n  geom_density_ridges() +\n  theme_minimal() +\n  theme(legend.position = \"none\")+\n  labs(x = \"Song Length (mins)\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-3",
    "href": "slides/week-4/w4-factors.html#re-ordering-factors-in-ggplot2-3",
    "title": "Extending Data Joins + Factors",
    "section": "Re-ordering Factors in ggplot2",
    "text": "Re-ordering Factors in ggplot2\n\nOriginalPlotfct_reorder2()Plot\n\n\nRemember the miliary data from the practice activity?\nThe legend follows the order of the factor levels.\n\nmilitary_long |&gt; \n  filter(Country %in% central.asia,\n         !is.na(spending)) |&gt; \n  ggplot(aes(x = year,\n             y = spending,\n             color = Country)) +\n  geom_line() +\n  labs(x = \"Year\",\n       y = \"\",\n       subtitle = \"Spending (as % of Government Spending)\",\n       title = \"Military Expenditures in Central Asia\") +\n  scale_color_manual(values = brewer.pal(3, \"Dark2\")) +\n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = seq(1990, 2023, 5)) +\n  theme_bw() +\n  theme(panel.grid.minor.x = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInside ggplot(), we can order factor levels by the \\(y\\) values associated with the largest \\(x\\) values.\n\nmilitary_long |&gt; \n  filter(Country %in% central.asia,\n         !is.na(spending)) |&gt; \n  ggplot(aes(x = year,\n             y = spending,\n             color = fct_reorder2(.x = year,\n                                  .y = spending,\n                                  .f = Country))) +\n  geom_line() +\n  labs(x = \"Year\",\n       y = \"\",\n       color = \"Country\",\n       subtitle = \"Spending (as % of Government Spending)\",\n       title = \"Military Expenditures in Central Asia\") +\n  scale_color_manual(values = brewer.pal(3, \"Dark2\")) +\n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = seq(1990, 2023, 5)) +\n  theme_bw() +\n  theme(panel.grid.minor.x = element_blank())"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#why-mess-with-factors",
    "href": "slides/week-4/w4-factors.html#why-mess-with-factors",
    "title": "Extending Data Joins + Factors",
    "section": "Why Mess with Factors?",
    "text": "Why Mess with Factors?\n\n\n\n\n\n\nDiscussion\n\n\nWhat are some of the benefits to re-ordering or re-leveling factors variables?"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#variable-names-in-r",
    "href": "slides/week-4/w4-factors.html#variable-names-in-r",
    "title": "Extending Data Joins + Factors",
    "section": "Variable Names in R",
    "text": "Variable Names in R\nData from external sources likely has variable names not ideally formatted for R.\nNames may…\n\ncontain spaces.\nstart with numbers.\nstart with a mix of capital and lower case letters.\n\n\n\nnames(military)[1:12]\n\n [1] \"Country\"        \"Notes\"          \"Reporting year\" \"1988.0\"        \n [5] \"1989.0\"         \"1990.0\"         \"1991.0\"         \"1992.0\"        \n [9] \"1993.0\"         \"1994.0\"         \"1995.0\"         \"1996.0\""
  },
  {
    "objectID": "slides/week-4/w4-factors.html#messy-variable-names-are-a-pain",
    "href": "slides/week-4/w4-factors.html#messy-variable-names-are-a-pain",
    "title": "Extending Data Joins + Factors",
    "section": "Messy Variable Names are a Pain",
    "text": "Messy Variable Names are a Pain\n\nYou should have noticed this in Practice Activity 4 working with the SIPRI data\nYou have to use back tick marks around variables that start with numbers or have spaces:\n\n\nmilitary |&gt; \n  select(`Reporting year`,\n          `1988.0`)\n\n\nI personally find capitilization in variable names is very annoying and slows me down"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#janitor-to-the-rescue",
    "href": "slides/week-4/w4-factors.html#janitor-to-the-rescue",
    "title": "Extending Data Joins + Factors",
    "section": "janitor to the rescue!",
    "text": "janitor to the rescue!\n\nMr. Johnson from Abbot Elementary (https://giphy.com/abcnetwork)"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#clean-variable-names-with-janitor",
    "href": "slides/week-4/w4-factors.html#clean-variable-names-with-janitor",
    "title": "Extending Data Joins + Factors",
    "section": "Clean Variable Names with janitor",
    "text": "Clean Variable Names with janitor\nThe janitor package converts all variable names in a dataset to snake_case.\n\nNames will…\n\nstart with a lower case letter.\nhave spaces and special characters filled in with _.\n\n\nlibrary(janitor)\nmilitary_clean_names &lt;- military |&gt; \n  clean_names()\n\nnames(military_clean_names)[1:12]\n\n [1] \"country\"        \"notes\"          \"reporting_year\" \"x1988_0\"       \n [5] \"x1989_0\"        \"x1990_0\"        \"x1991_0\"        \"x1992_0\"       \n [9] \"x1993_0\"        \"x1994_0\"        \"x1995_0\"        \"x1996_0\""
  },
  {
    "objectID": "slides/week-4/w4-factors.html#r-is-always-evolving",
    "href": "slides/week-4/w4-factors.html#r-is-always-evolving",
    "title": "Extending Data Joins + Factors",
    "section": "R Is Always Evolving",
    "text": "R Is Always Evolving\n\nRemember: R is open source so folks are always adding and updating packages and functions\n\n\n\n\n\n\n\nDiscussion\n\n\nWhat benefits and drawbacks of R’s ever-evolving nature have you noticed?\n\n\n\n\n\nthe good 🥳the annoying\n\n\n\nalways (aiming) to get better!\nresponsive to user input\nnew functionality for new statistical methods\n\n\n\n\ncode may no longer run after an update 😭\nneed to learn new syntax\nhave to keep track of it all 🫠"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#lifceycle-stages",
    "href": "slides/week-4/w4-factors.html#lifceycle-stages",
    "title": "Extending Data Joins + Factors",
    "section": "Lifceycle Stages",
    "text": "Lifceycle Stages\nAs packages get updated, the functions and function arguments included in those packages will change.\n\nThe accepted syntax for a function may change.\nA function/functionality may disappear.\n\n\nLearn more about lifecycle stages of packages, functions, function arguments in R."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#lifceycle-stages-1",
    "href": "slides/week-4/w4-factors.html#lifceycle-stages-1",
    "title": "Extending Data Joins + Factors",
    "section": "Lifceycle Stages",
    "text": "Lifceycle Stages"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#deprecated-functions",
    "href": "slides/week-4/w4-factors.html#deprecated-functions",
    "title": "Extending Data Joins + Factors",
    "section": "Deprecated Functions",
    "text": "Deprecated Functions\nA deprecated functionality has a better alternative available and is scheduled for removal.\n\nYou get a warning telling you what to use instead.\n\n\n\nmilitary_clean |&gt; \n  filter(across(!Country, is.na)) |&gt; \n  slice_head(n = 3) |&gt; \n  select(1:8)\n\nWarning: Using `across()` in `filter()` was deprecated in dplyr 1.0.8.\nℹ Please use `if_any()` or `if_all()` instead.\n\n\n# A tibble: 3 × 8\n  Country         `1988.0` `1989.0` `1990.0` `1991.0` `1992.0` `1993.0` `1994.0`\n  &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 Africa          &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n2 North Africa    &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n3 sub-Saharan Af… &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#deprecated-functions-1",
    "href": "slides/week-4/w4-factors.html#deprecated-functions-1",
    "title": "Extending Data Joins + Factors",
    "section": "Deprecated Functions",
    "text": "Deprecated Functions\nYou should not use deprecated functions!\nInstead, we use…\n\nmilitary_clean |&gt;\n  filter(if_all(!Country, ~ is.na(.x))) |&gt; \n  slice_head(n = 3) |&gt; \n  select(1:8)\n\n# A tibble: 3 × 8\n  Country         `1988.0` `1989.0` `1990.0` `1991.0` `1992.0` `1993.0` `1994.0`\n  &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 Africa          &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n2 North Africa    &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n3 sub-Saharan Af… &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#superceded-functions",
    "href": "slides/week-4/w4-factors.html#superceded-functions",
    "title": "Extending Data Joins + Factors",
    "section": "Superceded Functions",
    "text": "Superceded Functions\nA superseded functionality has a better alternative, but is not going away.\n\nThis is a softer alternative to deprecation.\nA superseded function will not give a warning (since there’s no risk if you keep using it), but the documentation will give you a recommendation."
  },
  {
    "objectID": "slides/week-4/w4-factors.html#lab-4-childcare-costs-in-california",
    "href": "slides/week-4/w4-factors.html#lab-4-childcare-costs-in-california",
    "title": "Extending Data Joins + Factors",
    "section": "Lab 4: Childcare Costs in California",
    "text": "Lab 4: Childcare Costs in California"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#to-do",
    "href": "slides/week-4/w4-factors.html#to-do",
    "title": "Extending Data Joins + Factors",
    "section": "To do…",
    "text": "To do…\n\nLab 4: Childcare Costs in California\n\nDue Monday 4/28 at 11:59pm\n\nRead Chapter 5: Strings + Dates\n\nCheck-in 5.1 - 5.2 due Tuesday (4/29) before class"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#combine-the-data",
    "href": "labs/lab5/lab5-murder.html#combine-the-data",
    "title": "Lab 5: Murder in SQL City",
    "section": "Combine the Data",
    "text": "Combine the Data\nLet’s set ourselves up to solve this crime lickity-split!\nCreate two new datasets:\n\nget_fit_now_full\n\nevery row represents one visit to the “Get Fit” gym.\nall member information is included (e.g. check in times, names, and membership information)\nshould have 2,703 rows and 8 columns\n\nsuspects_all\n\neach row represents one person\nincludes their address, driver’s licence information, income, and interview with the police, if they have one\nshould have 10,011 rows and 16 columns\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t worry about missing values! We are just gathering all of the information that we have about everyone.\n\n\n\n# code to create get_fit_now_full\n\n\n# code to create suspects_all"
  },
  {
    "objectID": "labs/lab4/data/prepare-data.html",
    "href": "labs/lab4/data/prepare-data.html",
    "title": "Prepare County Data Lab 4",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(janitor)"
  },
  {
    "objectID": "labs/lab4/data/prepare-data.html#county-revenue-data",
    "href": "labs/lab4/data/prepare-data.html#county-revenue-data",
    "title": "Prepare County Data Lab 4",
    "section": "County Revenue Data",
    "text": "County Revenue Data\nData collected from the California State Controller. San Franscisco County is excluded.\n\n2003 - 2016 data\n\ndat_03_16 &lt;- read_excel(\"CountiesRawData_20180613.xlsx\",\n                        sheet = \"CO_REV_PROP_OTHR_TAXES\") |&gt; \n  clean_names() |&gt; \n  select(entity_name, year = fiscal_year,\n         total_property_taxes, sales_and_use_taxes)\n\n\n\n2017 data\n\ndat_17 &lt;- read_excel(\"CountiesRawData_20181228.xlsx\",\n                        sheet = \"CO_REV_PROP_OTHR_TAX\",\n                     na = c(\"\", \"NULL\")) |&gt; \n  clean_names() |&gt; \n  select(entity_name, year = fiscal_year,\n         sales_and_use_taxes = sales_and_use_taxes_total_governmental_funds_taxes_other,\n         total_property_taxes = total_property_taxes_total_governmental_funds_property_taxes) \n\n\n\n2018 data\n\ndat_18 &lt;- read_excel(\"CountiesRawData_FY2018-2020_20210926_V4.xlsx\",\n                        sheet = \"CO_REV_PROP_OTHR_TAXES\") |&gt; \n  clean_names() |&gt; \n  select(entity_name, year = fiscal_year,\n         sales_and_use_taxes = sales_and_use_taxes_total_governmental_funds_taxes_other,\n         total_property_taxes = total_property_taxes_total_governmental_funds)\n\n\n\nAppend and clean\n\ntax_dat &lt;- dat_03_16 |&gt; \n  rows_append(dat_17) |&gt; \n  rows_append(dat_18) |&gt; \n  arrange(entity_name, year) |&gt; \n  filter(year %in% 2005:2018) |&gt; \n  mutate(entity_name = str_c(entity_name, \" County\"))"
  },
  {
    "objectID": "labs/lab4/data/prepare-data.html#check-that-county-names-align-with-other-lab-data",
    "href": "labs/lab4/data/prepare-data.html#check-that-county-names-align-with-other-lab-data",
    "title": "Prepare County Data Lab 4",
    "section": "Check that county names align with other lab data",
    "text": "Check that county names align with other lab data\n\ncounties &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/counties.csv')\n\n\ntax_counties &lt;- tax_dat |&gt; \n  group_by(entity_name) |&gt; \n  summarize(mean_tax = mean(total_property_taxes))\n\n\nca_counties &lt;- counties |&gt; \n  filter(state_abbreviation == \"CA\") |&gt; \n  left_join(tax_counties, by = join_by(county_name == entity_name))"
  },
  {
    "objectID": "labs/lab4/data/prepare-data.html#save-data",
    "href": "labs/lab4/data/prepare-data.html#save-data",
    "title": "Prepare County Data Lab 4",
    "section": "Save data",
    "text": "Save data\n\nwrite_csv(tax_dat, \n          file = \"ca_tax_revenue.csv\")"
  },
  {
    "objectID": "slides/week-3/w3-more-dplyr-ethics.html#data-biography",
    "href": "slides/week-3/w3-more-dplyr-ethics.html#data-biography",
    "title": "Data Cleaning & Manipulation",
    "section": "Data Biography",
    "text": "Data Biography\nHeather Kraus suggests asking 5 questions of your data:\n\nWhere did it come from?\nWho collected it?\nWhen?\nHow was it collected?\nWhy was it collected?"
  },
  {
    "objectID": "labs/lab5/data/bCH_murder_setup.html",
    "href": "labs/lab5/data/bCH_murder_setup.html",
    "title": "Setup Up Murder Data for Lab 5",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n# clear global environment\n\nrm(list = ls())\n\n\ntable_names &lt;- c(\"crime_scene_report\",\"drivers_license\",\n                 \"facebook_event_checkin\",\n                 \"get_fit_now_check_in\",\"get_fit_now_member\",\n                 \"income\", \"interview\",\"person\")\n\n# For each name, read in the table and store it as the name.\npurrr::walk(table_names, function(x) {\n  assign(x, readr::read_csv(paste0(\"../bCH_murder_data/\", x, \".csv\")), envir = .GlobalEnv)\n})\n\nRows: 1228 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): type, description, city\ndbl (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 10007 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): eye_color, hair_color, gender, plate_number, car_make, car_model\ndbl (3): id, age, height\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 20011 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): event_name\ndbl (3): person_id, event_id, date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 2703 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): membership_id\ndbl (3): check_in_date, check_in_time, check_out_time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 184 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, name, membership_status\ndbl (2): person_id, membership_start_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 7514 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): ssn, annual_income\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 4991 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): transcript\ndbl (1): person_id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 10011 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): name, address_street_name\ndbl (4): id, license_id, address_number, ssn\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# remove vector from global environment\n\nrm(table_names)\n\nTo add some extra practice with regular expressions, I am going to edit the person data.\n\nperson &lt;- person |&gt; \n  mutate(address = str_c(address_number, \n                         address_street_name,\n                         sep = \" \"),\n         .before = address_number) |&gt; \n  select(-address_number,\n         -address_street_name)\n\n\n# save all data frames in global environment to an .Rdata file\n# when loaded, will open up all data frames\n\nsave.image(file = \"bCH_murder_data.Rdata\")"
  },
  {
    "objectID": "slides/week-4/w4-notes.html",
    "href": "slides/week-4/w4-notes.html",
    "title": "Week 4 Starter Notes",
    "section": "",
    "text": "Download .qmd\n\n\n\n\n\n\nWarning\n\n\n\nDownload the data that we will be using this week at the followings links and add them to a data/ directory\nIMDb data\nRainfall data\nEras Tour data\n\n\n\nData\n\n\n\n\n\n\n.Rdata Files\n\n\n\n\n\nOnce in R, data frames can be saves as .Rdata files using the syntax:\nsave(data_frame1, data_frame2, ..., file = \"path/file-name.Rdata\")\nand then loaded into R using the syntax:\nload(\"path/file-name.Rdata\")\nThis can be preferable when saving intermediate datasets in an analysis because .Rdata files are much smaller and more memory efficient than .csv files. Additionally, you can save and load multiple data frames at once!\nYou can see that this is useful here, where we have 7 related data frames saved in imdb_data.Rdata, which are then loaded in one line below.\n\n\n\nWe will use 7 datasets that describe movies from IMDb.\n\n\n\n\n\nRelationship between data sets in IMDb movie data.\n\n\n\n\n\nload(file = \"data/imdb_data.Rdata\")\n\nOn Thursday will also look at joining datasets created from the Lab 2 Rodent data. Note that you will need to change the file path to be appropriate for your directory strucure!\n\nrodent &lt;- read_csv(\"../../labs/lab2/surveys.csv\")\n\nspecies &lt;- rodent |&gt; \n  select(genus:taxa, species_id) |&gt; \n  distinct()\n\nmeasurements &lt;- rodent |&gt; \n  select(genus, species, sex:weight) |&gt; \n  rename(genus_name = genus)\n\n… and daily rainfall observed in SLO in January 2023. Data source\n\nslo_rainfall &lt;- read_excel(\"data/2023-rainfall-slo.xlsx\")\n\nslo_rainfall &lt;- slo_rainfall |&gt; \n  mutate(across(Sunday:Saturday, as.numeric))"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#data-joins",
    "href": "slides/week-4/w4-notes.html#data-joins",
    "title": "Week 4 Starter Notes",
    "section": "Data Joins",
    "text": "Data Joins\n\ninner_join(directors_genres, \n           movies_directors, \n           by = \"director_id\")\n\n# A tibble: 344 × 4\n   director_id genre      prob movie_id\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1         429 Adventure 0.75    300229\n 2         429 Music     0.25    300229\n 3         429 Fantasy   0.75    300229\n 4         429 Romance   0.5     300229\n 5         429 Family    0.75    300229\n 6         429 Comedy    0.75    300229\n 7         429 Short     0.25    300229\n 8         429 Animation 0.75    300229\n 9        2931 Action    0.429   254943\n10        2931 Horror    0.143   254943\n# ℹ 334 more rows\n\n\n\ninner_join(directors_genres, \n           directors, \n           by = join_by(director_id == id))\n\n# A tibble: 285 × 5\n   director_id genre      prob first_name last_name\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;    \n 1         429 Adventure 0.75  Andrew     Adamson  \n 2         429 Music     0.25  Andrew     Adamson  \n 3         429 Fantasy   0.75  Andrew     Adamson  \n 4         429 Romance   0.5   Andrew     Adamson  \n 5         429 Family    0.75  Andrew     Adamson  \n 6         429 Comedy    0.75  Andrew     Adamson  \n 7         429 Short     0.25  Andrew     Adamson  \n 8         429 Animation 0.75  Andrew     Adamson  \n 9        2931 Action    0.429 Darren     Aronofsky\n10        2931 Horror    0.143 Darren     Aronofsky\n# ℹ 275 more rows\n\n\n\ndirectors_genres |&gt; \n  inner_join(movies_directors, \n             by = \"director_id\")\n\n# A tibble: 344 × 4\n   director_id genre      prob movie_id\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1         429 Adventure 0.75    300229\n 2         429 Music     0.25    300229\n 3         429 Fantasy   0.75    300229\n 4         429 Romance   0.5     300229\n 5         429 Family    0.75    300229\n 6         429 Comedy    0.75    300229\n 7         429 Short     0.25    300229\n 8         429 Animation 0.75    300229\n 9        2931 Action    0.429   254943\n10        2931 Horror    0.143   254943\n# ℹ 334 more rows"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#which-join",
    "href": "slides/week-4/w4-notes.html#which-join",
    "title": "Week 4 Starter Notes",
    "section": "Which Join?",
    "text": "Which Join?\nHow many movies are there in the data for each director (by name), including if any directors don’t have any movies in the data?\n\ndirectors |&gt; \n  ??_join(movies_directors, \n          by = join_by(id == director_id))\n\nWhat is the complete set of movies and actors included in the data?\n\nroles |&gt; \n  ??_join(actors, \n          by = join_by(actor_id == id))"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#filtering-joins",
    "href": "slides/week-4/w4-notes.html#filtering-joins",
    "title": "Week 4 Starter Notes",
    "section": "Filtering Joins",
    "text": "Filtering Joins\n\ndirectors_genres |&gt; \n  semi_join(movies_directors)\n\n# A tibble: 285 × 3\n   director_id genre      prob\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1         429 Adventure 0.75 \n 2         429 Music     0.25 \n 3         429 Fantasy   0.75 \n 4         429 Romance   0.5  \n 5         429 Family    0.75 \n 6         429 Comedy    0.75 \n 7         429 Short     0.25 \n 8         429 Animation 0.75 \n 9        2931 Action    0.429\n10        2931 Horror    0.143\n# ℹ 275 more rows\n\n\n\ndirectors_genres |&gt;\n  filter(director_id %in% movies_directors$director_id)\n\n# A tibble: 285 × 3\n   director_id genre      prob\n         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1         429 Adventure 0.75 \n 2         429 Music     0.25 \n 3         429 Fantasy   0.75 \n 4         429 Romance   0.5  \n 5         429 Family    0.75 \n 6         429 Comedy    0.75 \n 7         429 Short     0.25 \n 8         429 Animation 0.75 \n 9        2931 Action    0.429\n10        2931 Horror    0.143\n# ℹ 275 more rows\n\n\n\ndirectors_genres |&gt; \n  anti_join(movies_directors)\n\n# A tibble: 0 × 3\n# ℹ 3 variables: director_id &lt;dbl&gt;, genre &lt;chr&gt;, prob &lt;dbl&gt;\n\n\n\ndirectors_genres |&gt;\n  filter(!director_id %in% movies_directors$director_id)\n\n# A tibble: 0 × 3\n# ℹ 3 variables: director_id &lt;dbl&gt;, genre &lt;chr&gt;, prob &lt;dbl&gt;"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#data-pivots",
    "href": "slides/week-4/w4-notes.html#data-pivots",
    "title": "Week 4 Starter Notes",
    "section": "Data Pivots",
    "text": "Data Pivots\nExample data includes the cereal dataset from the liver package (which we saw last week)…\n\ndata(cereal)\n\nHow would we plot the mean cereal nutrients by shelf (as shown below) with the wide data?\n\nmy_colors &lt;- c(\"calories_col\" = \"steelblue\", \"sugars_col\" = \"orange3\")\n\ncereal |&gt; \n  group_by(shelf) |&gt; \n  summarise(across(calories:vitamins, mean)) |&gt; \n  ggplot() +\n  geom_point(aes(x = shelf, y = calories, color = \"calories_col\")) +\n  geom_line(aes(x = shelf, y = calories, color = \"calories_col\")) + \n  geom_point(aes(x = shelf, y = sugars, color = \"sugars_col\")) +\n  geom_line(aes(x = shelf, y = sugars, color = \"sugars_col\")) +\n  scale_color_manual(values = my_colors, labels = names(my_colors)) +\n  labs(x = \"Shelf\", y = \"\", subtitle = \"Mean Amount\", color = \"Nutrient\")\n\n\n\n\n\n\n\n\n\ncereal_long &lt;- cereal |&gt; \n  pivot_longer(cols = calories:vitamins,\n               names_to = \"Nutrient\",\n               values_to = \"Amount\") |&gt; \n  group_by(shelf, Nutrient) |&gt; \n  summarise(mean_amount = mean(Amount))\n\n\ncereal_long |&gt; \n  ggplot(aes(x = shelf, \n             y = mean_amount, \n             color = Nutrient)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Shelf\", y = \"\", subtitle = \"Mean Amount\")\n\n\n\n\n\n\n\n\n\nslo_rainfall |&gt; \n  pivot_longer(cols      = Sunday:Saturday,\n               names_to  = \"Day_of_Week\",\n               values_to = \"Daily_Rainfall\")\n\n# A tibble: 35 × 3\n    Week Day_of_Week Daily_Rainfall\n   &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt;\n 1     1 Sunday                0   \n 2     1 Monday                0.12\n 3     1 Tuesday               0   \n 4     1 Wednesday             1.58\n 5     1 Thursday              0.91\n 6     1 Friday                0   \n 7     1 Saturday              0.05\n 8     2 Sunday                0.27\n 9     2 Monday                4.26\n10     2 Tuesday               0.43\n# ℹ 25 more rows\n\n\n\nmean_protein &lt;- cereal |&gt; \n  group_by(manuf, shelf) |&gt; \n  summarize(mean_protein = mean(protein))\n\n\nmean_protein |&gt; \n  pivot_wider(id_cols = manuf,\n              names_from = shelf,\n              values_from = mean_protein)\n\n# A tibble: 7 × 4\n# Groups:   manuf [7]\n  manuf   `2`   `1`   `3`\n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A      4    NA    NA   \n2 G      1.29  3     2.67\n3 K      2.14  2.75  2.92\n4 N      2.5   2.67  4   \n5 P      1     1.5   3   \n6 Q      2     5     2.5 \n7 R     NA     2     3"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#extending-joins",
    "href": "slides/week-4/w4-notes.html#extending-joins",
    "title": "Week 4 Starter Notes",
    "section": "Extending Joins",
    "text": "Extending Joins\n\nmovies_directors |&gt; \n  inner_join(directors, \n             join_by(director_id == id)) |&gt; \n  inner_join(movies,\n             join_by(movie_id == id)) |&gt; \n  group_by(first_name, last_name) |&gt;\n  summarize(start_year = min(year),\n            end_year = max(year)) |&gt; \n  mutate(n_years_active = end_year - start_year) |&gt; \n  arrange(desc(n_years_active))\n\n# A tibble: 34 × 5\n# Groups:   first_name [31]\n   first_name  last_name start_year end_year n_years_active\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1 Quentin     Tarantino       1992     2004             12\n 2 James (I)   Cameron         1986     1997             11\n 3 Christopher Nolan           2000     2005              5\n 4 Ethan       Coen            1996     2000              4\n 5 Joel        Coen            1996     2000              4\n 6 Andrew      Adamson         2001     2001              0\n 7 Andy        Wachowski       1999     1999              0\n 8 Cameron     Crowe           2001     2001              0\n 9 Clint       Eastwood        2003     2003              0\n10 Darren      Aronofsky       1998     1998              0\n# ℹ 24 more rows\n\n\n\ndirectors |&gt; \n  inner_join(movies_directors, \n             join_by(id == director_id))\n\n# A tibble: 41 × 4\n      id first_name last_name movie_id\n   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;\n 1   429 Andrew     Adamson     300229\n 2  2931 Darren     Aronofsky   254943\n 3  9247 Zach       Braff       124110\n 4 11652 James (I)  Cameron      10920\n 5 11652 James (I)  Cameron     333856\n 6 14927 Ron        Clements    192017\n 7 15092 Ethan      Coen        109093\n 8 15092 Ethan      Coen        237431\n 9 15093 Joel       Coen        109093\n10 15093 Joel       Coen        237431\n# ℹ 31 more rows\n\n\n\nhead(species)\n\n# A tibble: 6 × 4\n  genus       species      taxa   species_id\n  &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;     \n1 Dipodomys   merriami     Rodent DM        \n2 Dipodomys   ordii        Rodent DO        \n3 Perognathus flavus       Rodent PF        \n4 Chaetodipus penicillatus Rodent PP        \n5 Peromyscus  eremicus     Rodent PE        \n6 Onychomys   leucogaster  Rodent OL        \n\nhead(measurements)\n\n# A tibble: 6 × 5\n  genus_name species  sex   hindfoot_length weight\n  &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1 Dipodomys  merriami M                  35     40\n2 Dipodomys  merriami M                  37     48\n3 Dipodomys  merriami F                  34     29\n4 Dipodomys  merriami F                  35     46\n5 Dipodomys  merriami M                  35     36\n6 Dipodomys  ordii    F                  32     52\n\n\n\nmeasurements |&gt; \n  inner_join(species, \n             by = join_by(genus_name == genus))\n\nWarning in inner_join(measurements, species, by = join_by(genus_name == : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 72,824 × 8\n   genus_name species.x sex   hindfoot_length weight species.y  taxa  species_id\n   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     \n 1 Dipodomys  merriami  M                  35     40 merriami   Rode… DM        \n 2 Dipodomys  merriami  M                  35     40 ordii      Rode… DO        \n 3 Dipodomys  merriami  M                  35     40 spectabil… Rode… DS        \n 4 Dipodomys  merriami  M                  37     48 merriami   Rode… DM        \n 5 Dipodomys  merriami  M                  37     48 ordii      Rode… DO        \n 6 Dipodomys  merriami  M                  37     48 spectabil… Rode… DS        \n 7 Dipodomys  merriami  F                  34     29 merriami   Rode… DM        \n 8 Dipodomys  merriami  F                  34     29 ordii      Rode… DO        \n 9 Dipodomys  merriami  F                  34     29 spectabil… Rode… DS        \n10 Dipodomys  merriami  F                  35     46 merriami   Rode… DM        \n# ℹ 72,814 more rows\n\n\n\nspecies |&gt; \n  full_join(measurements,\n            join_by(species == species, \n                    genus == genus_name))\n\n# A tibble: 30,463 × 7\n   genus     species  taxa   species_id sex   hindfoot_length weight\n   &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Dipodomys merriami Rodent DM         M                  35     40\n 2 Dipodomys merriami Rodent DM         M                  37     48\n 3 Dipodomys merriami Rodent DM         F                  34     29\n 4 Dipodomys merriami Rodent DM         F                  35     46\n 5 Dipodomys merriami Rodent DM         M                  35     36\n 6 Dipodomys merriami Rodent DM         F                  36     35\n 7 Dipodomys merriami Rodent DM         F                  32     22\n 8 Dipodomys merriami Rodent DM         F                  34     42\n 9 Dipodomys merriami Rodent DM         F                  35     41\n10 Dipodomys merriami Rodent DM         F                  37     37\n# ℹ 30,453 more rows"
  },
  {
    "objectID": "slides/week-4/w4-notes.html#factors-with-forcats",
    "href": "slides/week-4/w4-notes.html#factors-with-forcats",
    "title": "Week 4 Starter Notes",
    "section": "Factors with forcats",
    "text": "Factors with forcats\nTo practice working with factor variables, we will use data on songs that Taylor Swift included in the Era’s Tour.\n\nfull_eras &lt;- read_excel(\"data/TS_data.xlsx\", sheet = \"full\")\n\nset.seed(2)\neras_data &lt;- full_eras |&gt; \n  slice_sample(n = 25) |&gt; \n  select(Song, Album)\n\n\neras_data |&gt; \n  mutate(Album = fct(Album)) |&gt; \n  pull(Album)\n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Red Reputation Lover Midnights 1989 Fearless Folklore ... Speak Now\n\n\n\neras_data |&gt; \n  mutate(Album = fct(Album,\n                     levels = c(\"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\", \"Reputation\",\"Lover\",\n                                \"Folklore\", \"Evermore\",\"Midnights\"))) |&gt; \n  pull(Album) \n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n9 Levels: Fearless Speak Now Red 1989 Reputation Lover Folklore ... Midnights\n\n\n\neras_data |&gt; \n  mutate(Album = fct(Album, \n                     levels = c(\"Taylor Swift\",\n                                \"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\", \"Reputation\",\"Lover\",\n                                \"Folklore\", \"Evermore\",\"Midnights\",\n                                \"The Tortured Poets Department\"))) |&gt; \n  pull(Album) \n\n [1] Red        Reputation Lover      Midnights  1989       Fearless  \n [7] Reputation Folklore   Midnights  Evermore   Evermore   Lover     \n[13] Lover      Red        Reputation Reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   Folklore  \n[25] Lover     \n11 Levels: Taylor Swift Fearless Speak Now Red 1989 Reputation ... The Tortured Poets Department\n\n\n\neras_data |&gt;\n  mutate(Album = fct_recode(.f = Album,\n                            \"folklore\" = \"Folklore\",\n                            \"evermore\" = \"Evermore\",\n                            \"reputation\" = \"Reputation\")) |&gt;\n  pull(Album) \n\n [1] Red        reputation Lover      Midnights  1989       Fearless  \n [7] reputation folklore   Midnights  evermore   evermore   Lover     \n[13] Lover      Red        reputation reputation Speak Now  Red       \n[19] Midnights  Fearless   1989       Midnights  Fearless   folklore  \n[25] Lover     \n9 Levels: 1989 evermore Fearless folklore Lover Midnights Red ... Speak Now\n\n\n\neras_data |&gt; \n  mutate(Genre = fct_collapse(.f= Album,\n                       \"country pop\" = c(\"Taylor Swift\", \"Fearless\"),\n                       \"pop rock\" = c(\"Speak Now\",\"Red\"),\n                       \"electropop\" = c(\"1989\",\"reputation\",\"Lover\"),\n                       \"folk pop\" = c(\"folklore\",\"evermore\"),\n                       \"alt-pop\" = \"Midnights\")) |&gt; \n  slice_sample(n = 6)\n\n# A tibble: 6 × 3\n  Song                                    Album      Genre      \n  &lt;chr&gt;                                   &lt;chr&gt;      &lt;fct&gt;      \n1 willow                                  Evermore   Evermore   \n2 You Belong With Me                      Fearless   country pop\n3 Lavender Haze                           Midnights  alt-pop    \n4 We Are Never Ever Getting Back Together Red        pop rock   \n5 illicit affairs                         Folklore   Folklore   \n6 Look What You Made Me Do                Reputation Reputation \n\n\n\neras_data |&gt; \n  mutate(Album = fct_relevel(.f = Album, \n                             c(\"Fearless\",\"1989\",\"Taylor Swift\",\n                               \"Speak Now\",\"Red\",\"Midnights\",\"reputation\",\n                               \"folklore\",\"Lover\",\"evermore\"))) |&gt;\n  pull(Album) |&gt;\n  levels()\n\n[1] \"Fearless\"   \"1989\"       \"Speak Now\"  \"Red\"        \"Midnights\" \n[6] \"Lover\"      \"Evermore\"   \"Folklore\"   \"Reputation\""
  },
  {
    "objectID": "slides/week-4/w4-notes.html#re-order-factors-for-plots",
    "href": "slides/week-4/w4-notes.html#re-order-factors-for-plots",
    "title": "Week 4 Starter Notes",
    "section": "Re-order Factors for Plots",
    "text": "Re-order Factors for Plots\n\nfull_eras |&gt; \n  mutate(Album = fct(Album,\n                     levels = c(\"Fearless\",\"Speak Now\",\"Red\",\n                                \"1989\",\"Reputation\",\"Lover\",\n                                \"Folklore\",\"Evermore\",\n                                \"Midnights\"))) |&gt; \n  ggplot() +\n  geom_bar(aes(y = Album), fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\nfull_eras |&gt; \n  ggplot() +\n  geom_bar(aes(y = fct_infreq(Album)), \n           fill = \"#A5C9A5\") +\n  theme_minimal() +\n  labs(x = \"Number of Songs\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\nfull_eras |&gt; \n  ggplot(aes(x = Length, \n             y = fct_reorder(.f = Album,\n                             .x = Length,\n                             .fun = mean), \n             fill = Album)) +\n  geom_density_ridges() +\n  theme_minimal() +\n  theme(legend.position = \"none\")+\n  labs(x = \"Song Length (mins)\",\n       y = \"\",\n       subtitle = \"Album\",\n       title = \"Songs Played on the Eras Tour\")\n\n\n\n\n\n\n\n\n\ncereal_long |&gt; \n  ggplot(aes(x = shelf, \n             y = mean_amount, \n             color = fct_reorder2(.x = shelf,\n                                  .y = mean_amount,\n                                  .f = Nutrient))) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Shelf\", y = \"\", \n       subtitle = \"Mean Amount\",\n       color = \"Nutrient\")"
  },
  {
    "objectID": "practice-activities/pa5-1.html",
    "href": "practice-activities/pa5-1.html",
    "title": "PA 5.1: Scrambled Message",
    "section": "",
    "text": "Download starter qmd file\nlibrary(tidyverse)"
  },
  {
    "objectID": "practice-activities/pa5-1.html#pick-your-poison",
    "href": "practice-activities/pa5-1.html#pick-your-poison",
    "title": "PA 5.1: Scrambled Message",
    "section": "Pick your poison!",
    "text": "Pick your poison!\nYou may choose to work through Q1 - Q6 using a data.frame message_data and follow the dplyr pipeline syntax…\n\nmessage_data &lt;- read_csv(\"https://github.com/earobinson95/stat331-calpoly/raw/master/practice-activities/data/scrambled_message.txt\")\n\nclass(message_data)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\n…or you might prefer to work with the character vector message and use indexing – e.g. message[1] gives you the first element.\n\nmessage &lt;- message_data |&gt; \n  pull(Word)\n\nclass(message)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn this activity, a “word” is a set of characters with no white space. That is, even though many of elements of the scrambled mess vector are nonsense, and some have punctuation, you can consider each element to be a “word”."
  },
  {
    "objectID": "practice-activities/pa5-1.html#warm-up-exercises",
    "href": "practice-activities/pa5-1.html#warm-up-exercises",
    "title": "PA 5.1: Scrambled Message",
    "section": "Warm-up exercises",
    "text": "Warm-up exercises\n\nHow many characters are in the scrambled message?\nHow many words are in the scrambled message?\nPrint out every word in the scrambled message that starts with the letter “m”.\nPrint out every word in the scrambled message that ends with a punctuation mark.\nPrint out the longest word in the scrambled message.\nPrint out the punctuation symbols that are present in the scrambled message. (This one is the trickiest! You will need to use a number of steps and stringr functions.)"
  },
  {
    "objectID": "practice-activities/pa5-1.html#decode-the-message",
    "href": "practice-activities/pa5-1.html#decode-the-message",
    "title": "PA 5.1: Scrambled Message",
    "section": "Decode the Message",
    "text": "Decode the Message\n\n\n\n\n\n\nCaution\n\n\n\nYou likely want to work with the message character vector for decoding. You should still use piping to chain the steps together!\n\n\nComplete the following steps to decode the message.\n\nRemove any spaces before or after each word.\nNo word should be longer than 16 characters. Drop all extra characters off the end of each word.\nEvery time you see the word “ugh”, with any number of h’s, followed by a punctuation mark, delete this.\nReplace all instances of exactly 2 a’s with exactly 2 e’s.\nReplace all z’s with t’s.\nEvery word that ends in b, change that to a y.\nEvery word that starts with k (or K), change that to a v.\nRecombine all your words into a message with a stringr function.\nFind the movie this quote is from.\n\n\n\n\n\n\n\nCanvas Quiz Submission\n\n\n\nWhat is the name of the movie the quote is from?"
  },
  {
    "objectID": "practice-activities/pa5-2.html",
    "href": "practice-activities/pa5-2.html",
    "title": "PA 5.2: Jewel Heist",
    "section": "",
    "text": "Download starter qmd file\nlibrary(tidyverse)"
  },
  {
    "objectID": "practice-activities/pa5-2.html#solve-the-mystery",
    "href": "practice-activities/pa5-2.html#solve-the-mystery",
    "title": "PA 5.2: Jewel Heist",
    "section": "Solve the Mystery",
    "text": "Solve the Mystery\nJust down the road in Montecito, CA several rare jewels went missing. The jewels were stolen and replaced with fakes, but detectives have not been able to solve the case. They are now calling in a data scientist to help parse their clues.\nA camera was located near the building where the jewels went missing, so the detectives have provided you with a list of people who may have entered the building. This list includes the date and time they were spotted on the camera, in Pacific Standard Time (PST).\nUnfortunately, the date and time of the jewel heist is not known. You have been hired to crack the case. Use the clues below to discover the thief’s identity.\n\n# 214 total suspects\nsuspects &lt;- read_csv(\"https://raw.githubusercontent.com/zoerehnberg/STAT331-S23/main/practice_activities/suspects.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nTime Zones will be very important to find the right suspect!\n\n\n\nWhen data is read into R, dates are automatically read in as the UTC time zone. The first thing that we need to do is tell R that the times listed are actually in PST. Fill in the code below to do this.\n\n\nsuspects &lt;- suspects |&gt; \n  mutate(Time.Spotted = )\n\nError in quo_as_label(quo): argument \"expr\" is missing, with no default\n\n\n\nBased on the cleaning schedule for the room where the jewels are held, the heist was not committed in the morning (i.e. at 12:00pm PCT or later).\n\n\n# end with 112 suspects left\n\n\nThe room where the heist was committed is closed on Tuesdays and Thursdays (and there were no signs of forced entry), so the heist did not happen on those days.\n\n\n# end with 78 suspects left\n\n\nIt is believed that the heist was committed within 5 weeks (35 days) of Thanksgiving 2022 (before or after).\n\n\n\n\n\n\n\nHints\n\n\n\nPay attention to time zones!\nYou will want to look up the date of Thanksgiving 2022.\nI would recommend using an interval\n\n\n\n# end with 11 suspects left\n\n\nThe detectives partially decoded a message from the thief to a notorious fence in Iceland. In it, the thief said the job would be done “after the sun sets for you, but before midnight.”\n\n\n\n\n\n\n\nHints\n\n\n\nIn November, the sun sets at 4:00pm in Iceland.\nPay attention to time zones!\n\n\n\n# end with 4 suspects left\n\n\nThe thief left behind a receipt at the scene of the crime. The receipt is smudged, but the day of the month is shown to be 22. It is thought that the heist took place no more than three days after the receipt was issued.\n\n\n# end with 2 suspects left\n\n\nThe thief is amused by your efforts and has sent you a cryptic clue:\n\n\n“The exact number of seconds between midnight on Jan 1, 1970 and the time I arrived on the scene is divisible by 6.”\n\n\n\n\n\n\n\nHint\n\n\n\nCheck out how date-time objects are stored on the lubridate cheatsheet.\n\n\n\n# end with 1 suspect left\n\n\n\n\n\n\n\nCanvas Quiz Submission\n\n\n\nWho is the thief? Only one name should remain. Remember that you can check with classmates and me about the answer!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#tuesday-april-29",
    "href": "slides/week-5/week-5-strings.html#tuesday-april-29",
    "title": "Using stringr to Work with Strings",
    "section": "Tuesday, April 29",
    "text": "Tuesday, April 29\nToday we will…\n\nDifferent schedule this week & next\nNew material\n\nString variables\nFunctions for working with strings\nRegular expressions\n\nPA 5.1: Scrambled Message\n\n\n\n\n\n\n\nFollow along\n\n\nRemember to download, save, and open up the starter notes for this week!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#week-5-layout",
    "href": "slides/week-5/week-5-strings.html#week-5-layout",
    "title": "Using stringr to Work with Strings",
    "section": "Week 5 Layout",
    "text": "Week 5 Layout\n\nToday: Strings with stringr\n\nPractice Activity: Decoding a Message\n\n\n\n\nThursday: Dates with lubridate\n\nPractice Activity: Jewel Heist\nDiscuss midterm exam and project\n\n\n\n\n\nLab Assignment Solving a Murder Mystery\n\nUsing dplyr + stringr + ludridate\nDue (next) Monday\nMay only use 1 late day so that I can post solutions before the exam"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#week-6-layout",
    "href": "slides/week-5/week-5-strings.html#week-6-layout",
    "title": "Using stringr to Work with Strings",
    "section": "Week 6 Layout",
    "text": "Week 6 Layout\n\nTuesday: Version control with git\n\nPractice Activity - done in groups in class\nLast day to submit Lab 5\n\n\n\n\nThursday: Midterm Exam"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#what-is-a-string",
    "href": "slides/week-5/week-5-strings.html#what-is-a-string",
    "title": "Using stringr to Work with Strings",
    "section": "What is a string?",
    "text": "What is a string?\nA string is a bunch of characters.\n\nThere is a difference between…\n\n…a string (many characters, one object)…\nand\n…a character vector (vector of strings).\n\n\n\n\nmy_string &lt;- \"Hi, my name is Bond!\"\nmy_string\n\n[1] \"Hi, my name is Bond!\"\n\n\n\n\n\nmy_vector &lt;- c(\"Hi\", \"my\", \"name\", \"is\", \"Bond\")\nmy_vector\n\n[1] \"Hi\"   \"my\"   \"name\" \"is\"   \"Bond\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#stringr",
    "href": "slides/week-5/week-5-strings.html#stringr",
    "title": "Using stringr to Work with Strings",
    "section": "stringr",
    "text": "stringr\n\n\nCommon tasks\n\nIdentify strings containing a particular pattern.\nRemove or replace a pattern.\nEdit a string (e.g., make it lowercase).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe stringr package loads with tidyverse.\nAll functions are of the form str_xxx()."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#pattern",
    "href": "slides/week-5/week-5-strings.html#pattern",
    "title": "Using stringr to Work with Strings",
    "section": "pattern =",
    "text": "pattern =\nThe pattern argument appears in many stringr functions.\n\nThe pattern must be supplied inside quotes.\n\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_detect(my_vector, pattern = \"Bond\")\nstr_locate(my_vector, pattern = \"James Bond\")\nstr_match(my_vector, pattern = \"[bB]ond\")\nstr_extract(my_vector, pattern = \"[jJ]ames [bB]ond\")\n\n\n\n\nLet’s explore these functions!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_detect",
    "href": "slides/week-5/week-5-strings.html#str_detect",
    "title": "Using stringr to Work with Strings",
    "section": "str_detect()",
    "text": "str_detect()\nReturns a logical vector indicating whether the pattern was found in each element of the supplied vector.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\nstr_detect(my_vector, pattern = \"Bond\")\n\n[1] FALSE FALSE  TRUE  TRUE\n\n\n\n\n\n\nPairs well with filter().\nWorks with summarise() + sum (to get total matches) or mean (to get proportion of matches).\n\n\n\n\n\n\n\n\n\n\n\nRelated Function\n\n\nstr_which() returns the indexes of the strings that contain a match."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_match",
    "href": "slides/week-5/week-5-strings.html#str_match",
    "title": "Using stringr to Work with Strings",
    "section": "str_match()",
    "text": "str_match()\nReturns a character matrix containing either NA or the pattern, depending on if the pattern was found.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_match(my_vector, pattern = \"Bond\")\n\n     [,1]  \n[1,] NA    \n[2,] NA    \n[3,] \"Bond\"\n[4,] \"Bond\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_extract",
    "href": "slides/week-5/week-5-strings.html#str_extract",
    "title": "Using stringr to Work with Strings",
    "section": "str_extract()",
    "text": "str_extract()\nReturns a character vector with either NA or the pattern, depending on if the pattern was found.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_extract(my_vector, pattern = \"Bond\")\n\n[1] NA     NA     \"Bond\" \"Bond\"\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nstr_extract() only returns the first pattern match.\nUse str_extract_all() to return every pattern match."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#what-do-you-mean-by-the-first-match",
    "href": "slides/week-5/week-5-strings.html#what-do-you-mean-by-the-first-match",
    "title": "Using stringr to Work with Strings",
    "section": "What do you mean by the first match?",
    "text": "What do you mean by the first match?\nSuppose we had a slightly different vector…\n\nalt_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond, James Bond\")\n\n\nIf we were to extract every instance of \"Bond\" from the vector…\n\n\n\n\nstr_extract(alt_vector, \n            pattern = \"Bond\")\n\n[1] NA     NA     \"Bond\"\n\n\n\n\n\n\n\n\n\nstr_extract_all(alt_vector, \n                pattern = \"Bond\")\n\n[[1]]\ncharacter(0)\n\n[[2]]\ncharacter(0)\n\n[[3]]\n[1] \"Bond\" \"Bond\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_locate",
    "href": "slides/week-5/week-5-strings.html#str_locate",
    "title": "Using stringr to Work with Strings",
    "section": "str_locate()",
    "text": "str_locate()\nReturns a dateframe with two numeric variables – the starting and ending location of the pattern. The values are NA if the pattern is not found.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_locate(my_vector, pattern = \"Bond\")\n\n     start end\n[1,]    NA  NA\n[2,]    NA  NA\n[3,]     1   4\n[4,]     7  10\n\n\n\n\n\n\n\n\n\n\n\nRelated Function\n\n\nstr_sub() extracts values based on a starting and ending location."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#str_subset",
    "href": "slides/week-5/week-5-strings.html#str_subset",
    "title": "Using stringr to Work with Strings",
    "section": "str_subset()",
    "text": "str_subset()\nReturns a character vector containing a subset of the original character vector consisting of the elements where the pattern was found anywhere in the element.\n\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_subset(my_vector, pattern = \"Bond\")\n\n[1] \"Bond\"       \"James Bond\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#try-it-out",
    "href": "slides/week-5/week-5-strings.html#try-it-out",
    "title": "Using stringr to Work with Strings",
    "section": "Try it out!",
    "text": "Try it out!\n\n\nmy_vector &lt;- c(\"I scream,\", \n               \"you scream\", \n               \"we all\",\n               \"scream\",\n               \"for\",\n               \"ice cream\")\n\nstr_detect(my_vector, pattern = \"cream\")\nstr_locate(my_vector, pattern = \"cream\")\nstr_match(my_vector, pattern = \"cream\")\nstr_extract(my_vector, pattern = \"cream\")\nstr_subset(my_vector, pattern = \"cream\")\n\n\n\n\n\n\n\nNote\n\n\nFor each of these functions, write down:\n\nthe object structure of the output.\nthe data type of the output.\na brief explanation of what they do."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#replace-remove-patterns",
    "href": "slides/week-5/week-5-strings.html#replace-remove-patterns",
    "title": "Using stringr to Work with Strings",
    "section": "Replace / Remove Patterns",
    "text": "Replace / Remove Patterns\n\nstr_replace()str_remove()\n\n\n\nReplace the first matched pattern in each string.\n\nPairs well with mutate().\n\n\nstr_replace(my_vector, \n            pattern = \"Bond\", \n            replace = \"Franco\")\n\n[1] \"Hello,\"       \"my name is\"   \"Franco\"       \"James Franco\"\n\n\n\n\n\n\n\n\n\n\n\nRelated Function\n\n\nstr_replace_all() replaces all matched patterns in each string.\n\n\n\n\n\n\n\nRemove the first matched pattern in each string.\n\nstr_remove(my_vector, \n           pattern = \"Bond\")\n\n[1] \"Hello,\"     \"my name is\" \"\"           \"James \"    \n\n\n\n\n\n\n\n\n\n\n\nRelated Functions\n\n\nThis is a special case of str_replace(x, pattern, replacement = \"\").\nstr_remove_all() removes all matched patterns in each string."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#edit-strings",
    "href": "slides/week-5/week-5-strings.html#edit-strings",
    "title": "Using stringr to Work with Strings",
    "section": "Edit Strings",
    "text": "Edit Strings\nConvert letters in a string to a specific capitalization format.\n\nlowerUPPERTitle\n\n\nstr_to_lower() converts all letters in a string to lowercase.\n\n\nstr_to_lower(my_vector)\n\n[1] \"hello,\"     \"my name is\" \"bond\"       \"james bond\"\n\n\n\n\nstr_to_upper() converts all letters in a string to uppercase.\n\n\nstr_to_upper(my_vector)\n\n[1] \"HELLO,\"     \"MY NAME IS\" \"BOND\"       \"JAMES BOND\"\n\n\n\n\nstr_to_title() converts the first letter of each word to uppercase.\n\n\nstr_to_title(my_vector)\n\n[1] \"Hello,\"     \"My Name Is\" \"Bond\"       \"James Bond\"\n\n\n\n\n\n\n\n\nThis is handy for axis labels!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#combine-strings",
    "href": "slides/week-5/week-5-strings.html#combine-strings",
    "title": "Using stringr to Work with Strings",
    "section": "Combine Strings",
    "text": "Combine Strings\n\nstr_c()str_flatten()str_glue()\n\n\nJoin multiple strings into a single character vector.\n\nprompt &lt;- \"Hello, my name is\"\nfirst  &lt;- \"James\"\nlast   &lt;- \"Bond\"\nstr_c(prompt, last, \",\", first, last, sep = \" \")\n\n[1] \"Hello, my name is Bond , James Bond\"\n\n\n\n\n\n\n\n\nNote\n\n\nSimilar to paste() and paste0().\n\n\n\n\n\nCombine a vector of strings into a single string.\n\nmy_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond\", \n               \"James Bond\")\n\nstr_flatten(my_vector, collapse = \" \")\n\n[1] \"Hello, my name is Bond James Bond\"\n\n\n\n\nUse variables in the environment to create a string based on {expressions}.\n\nfirst &lt;- \"James\"\nlast &lt;- \"Bond\"\nstr_glue(\"My name is {last}, {first} {last}\")\n\nMy name is Bond, James Bond\n\n\n\n\n\n\n\n\nTip\n\n\nFor more details, I would recommend looking up the glue R package!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#tips-for-string-success",
    "href": "slides/week-5/week-5-strings.html#tips-for-string-success",
    "title": "Using stringr to Work with Strings",
    "section": "Tips for String Success",
    "text": "Tips for String Success\n\nRefer to the stringr cheatsheet\nRemember that str_xxx functions need the first argument to be a vector of strings, not a dataset!\n\nYou will use these functions inside dplyr verbs like filter() or mutate().\n\n\n\ncereal |&gt; \n  mutate(is_bran = str_detect(name, \"Bran\"), \n         .after = name)\n\n\n\n\n\n\n\nname\nis_bran\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nTRUE\nN\ncold\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.00\n0.33\n68.40297\n\n\n100% Natural Bran\nTRUE\nQ\ncold\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.00\n1.00\n33.98368\n\n\nAll-Bran\nTRUE\nK\ncold\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.00\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nTRUE\nK\ncold\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.00\n0.50\n93.70491\n\n\nAlmond Delight\nFALSE\nR\ncold\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.00\n0.75\n34.38484\n\n\nApple Cinnamon Cheerios\nFALSE\nG\ncold\n110\n2\n2\n180\n1.5\n10.5\n10\n70\n25\n1\n1.00\n0.75\n29.50954\n\n\nApple Jacks\nFALSE\nK\ncold\n110\n2\n0\n125\n1.0\n11.0\n14\n30\n25\n2\n1.00\n1.00\n33.17409\n\n\nBasic 4\nFALSE\nG\ncold\n130\n3\n2\n210\n2.0\n18.0\n8\n100\n25\n3\n1.33\n0.75\n37.03856\n\n\nBran Chex\nTRUE\nR\ncold\n90\n2\n1\n200\n4.0\n15.0\n6\n125\n25\n1\n1.00\n0.67\n49.12025\n\n\nBran Flakes\nTRUE\nP\ncold\n90\n3\n0\n210\n5.0\n13.0\n5\n190\n25\n3\n1.00\n0.67\n53.31381\n\n\nCap'n'Crunch\nFALSE\nQ\ncold\n120\n1\n2\n220\n0.0\n12.0\n12\n35\n25\n2\n1.00\n0.75\n18.04285\n\n\nCheerios\nFALSE\nG\ncold\n110\n6\n2\n290\n2.0\n17.0\n1\n105\n25\n1\n1.00\n1.25\n50.76500\n\n\nCinnamon Toast Crunch\nFALSE\nG\ncold\n120\n1\n3\n210\n0.0\n13.0\n9\n45\n25\n2\n1.00\n0.75\n19.82357\n\n\nClusters\nFALSE\nG\ncold\n110\n3\n2\n140\n2.0\n13.0\n7\n105\n25\n3\n1.00\n0.50\n40.40021\n\n\nCocoa Puffs\nFALSE\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n55\n25\n2\n1.00\n1.00\n22.73645\n\n\nCorn Chex\nFALSE\nR\ncold\n110\n2\n0\n280\n0.0\n22.0\n3\n25\n25\n1\n1.00\n1.00\n41.44502\n\n\nCorn Flakes\nFALSE\nK\ncold\n100\n2\n0\n290\n1.0\n21.0\n2\n35\n25\n1\n1.00\n1.00\n45.86332\n\n\nCorn Pops\nFALSE\nK\ncold\n110\n1\n0\n90\n1.0\n13.0\n12\n20\n25\n2\n1.00\n1.00\n35.78279\n\n\nCount Chocula\nFALSE\nG\ncold\n110\n1\n1\n180\n0.0\n12.0\n13\n65\n25\n2\n1.00\n1.00\n22.39651\n\n\nCracklin' Oat Bran\nTRUE\nK\ncold\n110\n3\n3\n140\n4.0\n10.0\n7\n160\n25\n3\n1.00\n0.50\n40.44877\n\n\nCream of Wheat (Quick)\nFALSE\nN\nhot\n100\n3\n0\n80\n1.0\n21.0\n0\n-1\n0\n2\n1.00\n1.00\n64.53382\n\n\nCrispix\nFALSE\nK\ncold\n110\n2\n0\n220\n1.0\n21.0\n3\n30\n25\n3\n1.00\n1.00\n46.89564\n\n\nCrispy Wheat & Raisins\nFALSE\nG\ncold\n100\n2\n1\n140\n2.0\n11.0\n10\n120\n25\n3\n1.00\n0.75\n36.17620\n\n\nDouble Chex\nFALSE\nR\ncold\n100\n2\n0\n190\n1.0\n18.0\n5\n80\n25\n3\n1.00\n0.75\n44.33086\n\n\nFroot Loops\nFALSE\nK\ncold\n110\n2\n1\n125\n1.0\n11.0\n13\n30\n25\n2\n1.00\n1.00\n32.20758\n\n\nFrosted Flakes\nFALSE\nK\ncold\n110\n1\n0\n200\n1.0\n14.0\n11\n25\n25\n1\n1.00\n0.75\n31.43597\n\n\nFrosted Mini-Wheats\nFALSE\nK\ncold\n100\n3\n0\n0\n3.0\n14.0\n7\n100\n25\n2\n1.00\n0.80\n58.34514\n\n\nFruit & Fibre Dates; Walnuts; and Oats\nFALSE\nP\ncold\n120\n3\n2\n160\n5.0\n12.0\n10\n200\n25\n3\n1.25\n0.67\n40.91705\n\n\nFruitful Bran\nTRUE\nK\ncold\n120\n3\n0\n240\n5.0\n14.0\n12\n190\n25\n3\n1.33\n0.67\n41.01549\n\n\nFruity Pebbles\nFALSE\nP\ncold\n110\n1\n1\n135\n0.0\n13.0\n12\n25\n25\n2\n1.00\n0.75\n28.02576\n\n\nGolden Crisp\nFALSE\nP\ncold\n100\n2\n0\n45\n0.0\n11.0\n15\n40\n25\n1\n1.00\n0.88\n35.25244\n\n\nGolden Grahams\nFALSE\nG\ncold\n110\n1\n1\n280\n0.0\n15.0\n9\n45\n25\n2\n1.00\n0.75\n23.80404\n\n\nGrape Nuts Flakes\nFALSE\nP\ncold\n100\n3\n1\n140\n3.0\n15.0\n5\n85\n25\n3\n1.00\n0.88\n52.07690\n\n\nGrape-Nuts\nFALSE\nP\ncold\n110\n3\n0\n170\n3.0\n17.0\n3\n90\n25\n3\n1.00\n0.25\n53.37101\n\n\nGreat Grains Pecan\nFALSE\nP\ncold\n120\n3\n3\n75\n3.0\n13.0\n4\n100\n25\n3\n1.00\n0.33\n45.81172\n\n\nHoney Graham Ohs\nFALSE\nQ\ncold\n120\n1\n2\n220\n1.0\n12.0\n11\n45\n25\n2\n1.00\n1.00\n21.87129\n\n\nHoney Nut Cheerios\nFALSE\nG\ncold\n110\n3\n1\n250\n1.5\n11.5\n10\n90\n25\n1\n1.00\n0.75\n31.07222\n\n\nHoney-comb\nFALSE\nP\ncold\n110\n1\n0\n180\n0.0\n14.0\n11\n35\n25\n1\n1.00\n1.33\n28.74241\n\n\nJust Right Crunchy Nuggets\nFALSE\nK\ncold\n110\n2\n1\n170\n1.0\n17.0\n6\n60\n100\n3\n1.00\n1.00\n36.52368\n\n\nJust Right Fruit & Nut\nFALSE\nK\ncold\n140\n3\n1\n170\n2.0\n20.0\n9\n95\n100\n3\n1.30\n0.75\n36.47151\n\n\nKix\nFALSE\nG\ncold\n110\n2\n1\n260\n0.0\n21.0\n3\n40\n25\n2\n1.00\n1.50\n39.24111\n\n\nLife\nFALSE\nQ\ncold\n100\n4\n2\n150\n2.0\n12.0\n6\n95\n25\n2\n1.00\n0.67\n45.32807\n\n\nLucky Charms\nFALSE\nG\ncold\n110\n2\n1\n180\n0.0\n12.0\n12\n55\n25\n2\n1.00\n1.00\n26.73451\n\n\nMaypo\nFALSE\nA\nhot\n100\n4\n1\n0\n0.0\n16.0\n3\n95\n25\n2\n1.00\n1.00\n54.85092\n\n\nMuesli Raisins; Dates; & Almonds\nFALSE\nR\ncold\n150\n4\n3\n95\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n37.13686\n\n\nMuesli Raisins; Peaches; & Pecans\nFALSE\nR\ncold\n150\n4\n3\n150\n3.0\n16.0\n11\n170\n25\n3\n1.00\n1.00\n34.13976\n\n\nMueslix Crispy Blend\nFALSE\nK\ncold\n160\n3\n2\n150\n3.0\n17.0\n13\n160\n25\n3\n1.50\n0.67\n30.31335\n\n\nMulti-Grain Cheerios\nFALSE\nG\ncold\n100\n2\n1\n220\n2.0\n15.0\n6\n90\n25\n1\n1.00\n1.00\n40.10596\n\n\nNut&Honey Crunch\nFALSE\nK\ncold\n120\n2\n1\n190\n0.0\n15.0\n9\n40\n25\n2\n1.00\n0.67\n29.92429\n\n\nNutri-Grain Almond-Raisin\nFALSE\nK\ncold\n140\n3\n2\n220\n3.0\n21.0\n7\n130\n25\n3\n1.33\n0.67\n40.69232\n\n\nNutri-grain Wheat\nFALSE\nK\ncold\n90\n3\n0\n170\n3.0\n18.0\n2\n90\n25\n3\n1.00\n1.00\n59.64284\n\n\nOatmeal Raisin Crisp\nFALSE\nG\ncold\n130\n3\n2\n170\n1.5\n13.5\n10\n120\n25\n3\n1.25\n0.50\n30.45084\n\n\nPost Nat. Raisin Bran\nTRUE\nP\ncold\n120\n3\n1\n200\n6.0\n11.0\n14\n260\n25\n3\n1.33\n0.67\n37.84059\n\n\nProduct 19\nFALSE\nK\ncold\n100\n3\n0\n320\n1.0\n20.0\n3\n45\n100\n3\n1.00\n1.00\n41.50354\n\n\nPuffed Rice\nFALSE\nQ\ncold\n50\n1\n0\n0\n0.0\n13.0\n0\n15\n0\n3\n0.50\n1.00\n60.75611\n\n\nPuffed Wheat\nFALSE\nQ\ncold\n50\n2\n0\n0\n1.0\n10.0\n0\n50\n0\n3\n0.50\n1.00\n63.00565\n\n\nQuaker Oat Squares\nFALSE\nQ\ncold\n100\n4\n1\n135\n2.0\n14.0\n6\n110\n25\n3\n1.00\n0.50\n49.51187\n\n\nQuaker Oatmeal\nFALSE\nQ\nhot\n100\n5\n2\n0\n2.7\n-1.0\n-1\n110\n0\n1\n1.00\n0.67\n50.82839\n\n\nRaisin Bran\nTRUE\nK\ncold\n120\n3\n1\n210\n5.0\n14.0\n12\n240\n25\n2\n1.33\n0.75\n39.25920\n\n\nRaisin Nut Bran\nTRUE\nG\ncold\n100\n3\n2\n140\n2.5\n10.5\n8\n140\n25\n3\n1.00\n0.50\n39.70340\n\n\nRaisin Squares\nFALSE\nK\ncold\n90\n2\n0\n0\n2.0\n15.0\n6\n110\n25\n3\n1.00\n0.50\n55.33314\n\n\nRice Chex\nFALSE\nR\ncold\n110\n1\n0\n240\n0.0\n23.0\n2\n30\n25\n1\n1.00\n1.13\n41.99893\n\n\nRice Krispies\nFALSE\nK\ncold\n110\n2\n0\n290\n0.0\n22.0\n3\n35\n25\n1\n1.00\n1.00\n40.56016\n\n\nShredded Wheat\nFALSE\nN\ncold\n80\n2\n0\n0\n3.0\n16.0\n0\n95\n0\n1\n0.83\n1.00\n68.23588\n\n\nShredded Wheat 'n'Bran\nTRUE\nN\ncold\n90\n3\n0\n0\n4.0\n19.0\n0\n140\n0\n1\n1.00\n0.67\n74.47295\n\n\nShredded Wheat spoon size\nFALSE\nN\ncold\n90\n3\n0\n0\n3.0\n20.0\n0\n120\n0\n1\n1.00\n0.67\n72.80179\n\n\nSmacks\nFALSE\nK\ncold\n110\n2\n1\n70\n1.0\n9.0\n15\n40\n25\n2\n1.00\n0.75\n31.23005\n\n\nSpecial K\nFALSE\nK\ncold\n110\n6\n0\n230\n1.0\n16.0\n3\n55\n25\n1\n1.00\n1.00\n53.13132\n\n\nStrawberry Fruit Wheats\nFALSE\nN\ncold\n90\n2\n0\n15\n3.0\n15.0\n5\n90\n25\n2\n1.00\n1.00\n59.36399\n\n\nTotal Corn Flakes\nFALSE\nG\ncold\n110\n2\n1\n200\n0.0\n21.0\n3\n35\n100\n3\n1.00\n1.00\n38.83975\n\n\nTotal Raisin Bran\nTRUE\nG\ncold\n140\n3\n1\n190\n4.0\n15.0\n14\n230\n100\n3\n1.50\n1.00\n28.59278\n\n\nTotal Whole Grain\nFALSE\nG\ncold\n100\n3\n1\n200\n3.0\n16.0\n3\n110\n100\n3\n1.00\n1.00\n46.65884\n\n\nTriples\nFALSE\nG\ncold\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.00\n0.75\n39.10617\n\n\nTrix\nFALSE\nG\ncold\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.00\n1.00\n27.75330\n\n\nWheat Chex\nFALSE\nR\ncold\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.00\n0.67\n49.78744\n\n\nWheaties\nFALSE\nG\ncold\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.00\n1.00\n51.59219\n\n\nWheaties Honey Gold\nFALSE\nG\ncold\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.00\n0.75\n36.18756"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#tips-for-string-success-1",
    "href": "slides/week-5/week-5-strings.html#tips-for-string-success-1",
    "title": "Using stringr to Work with Strings",
    "section": "Tips for String Success",
    "text": "Tips for String Success\nThe real power of these str_xxx functions comes when you specify the pattern using regular expressions!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#regular-expressions",
    "href": "slides/week-5/week-5-strings.html#regular-expressions",
    "title": "Using stringr to Work with Strings",
    "section": "Regular Expressions",
    "text": "Regular Expressions\n\n“Regexps are a very terse language that allow you to describe patterns in strings.”\nR for Data Science\n\n\nUse str_xxx functions + regular expressions!\n\nstr_detect(string  = my_string_vector,\n           pattern = \"p[ei]ck[a-z]\")\n\n\n\n\n\n\n\n\n\nTip\n\n\nYou might encounter gsub(), grep(), etc. from Base R, but I would highly recommending using functions from the stringr package instead."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#regular-expressions-1",
    "href": "slides/week-5/week-5-strings.html#regular-expressions-1",
    "title": "Using stringr to Work with Strings",
    "section": "Regular Expressions",
    "text": "Regular Expressions\n…are tricky!\n\nThere are lots of new symbols to keep straight.\nThere are a lot of cases to think through.\n\n\nThis web app for testing R regular expressions might be handy!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#special-characters",
    "href": "slides/week-5/week-5-strings.html#special-characters",
    "title": "Using stringr to Work with Strings",
    "section": "Special Characters",
    "text": "Special Characters\nThere is a set of characters that have a specific meaning when using regex.\n\nThe stringr package does not read these as normal characters.\nThese characters are:\n\n\n. ^ $ \\ | * + ? { } [ ] ( )"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#wild-card-character-.",
    "href": "slides/week-5/week-5-strings.html#wild-card-character-.",
    "title": "Using stringr to Work with Strings",
    "section": "Wild Card Character: .",
    "text": "Wild Card Character: .\nThis character can match any character.\n\nx &lt;- c(\"She\", \n       \"sells\", \n       \"seashells\", \n       \"by\", \n       \"the\", \n       \"seashore!\")\n\nstr_subset(x, pattern = \".ells\")\n\n[1] \"sells\"     \"seashells\"\n\n\n\n\n\nstr_extract(x, pattern = \".ells\")\n\n[1] NA      \"sells\" \"hells\" NA      NA      NA     \n\n\n\nThis matches strings that contain any character followed by “ells”."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#anchor-characters",
    "href": "slides/week-5/week-5-strings.html#anchor-characters",
    "title": "Using stringr to Work with Strings",
    "section": "Anchor Characters: ^ $",
    "text": "Anchor Characters: ^ $\n\n\n\n^ – looks at the beginning of a string.\n\nx &lt;- c(\"She\", \n       \"sells\", \n       \"seashells\", \n       \"by\", \n       \"the\", \n       \"seashore!\")\n\nstr_subset(x, pattern = \"^s\")\n\n[1] \"sells\"     \"seashells\" \"seashore!\"\n\n\nThis matches strings that start with “s”.\n\n\n\n\n\n\n$ – looks at the end of a string.\n\nx &lt;- c(\"She\", \n       \"sells\", \n       \"seashells\", \n       \"by\", \n       \"the\", \n       \"seashore!\")\n\nstr_subset(x, pattern = \"s$\")\n\n[1] \"sells\"     \"seashells\"\n\n\nThis matches strings that end with “s”."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#quantifier-characters",
    "href": "slides/week-5/week-5-strings.html#quantifier-characters",
    "title": "Using stringr to Work with Strings",
    "section": "Quantifier Characters: ? + *",
    "text": "Quantifier Characters: ? + *\n\n? – matches when the preceding character occurs 0 or 1 times in a row.\n\nx &lt;- c(\"shes\", \n       \"shels\", \n       \"shells\", \n       \"shellls\", \n       \"shelllls\")\n\nstr_subset(x, pattern = \"shel?s\")\n\n[1] \"shes\"  \"shels\"\n\n\n\n\n\n+ – occurs 1 or more times in a row.\n\nstr_subset(x, pattern = \"shel+s\")\n\n[1] \"shels\"    \"shells\"   \"shellls\"  \"shelllls\"\n\n\n\n\n\n\n* – occurs 0 or more times in a row.\n\nstr_subset(x, pattern = \"shel*s\")\n\n[1] \"shes\"     \"shels\"    \"shells\"   \"shellls\"  \"shelllls\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#quantifier-characters-1",
    "href": "slides/week-5/week-5-strings.html#quantifier-characters-1",
    "title": "Using stringr to Work with Strings",
    "section": "Quantifier Characters: {}",
    "text": "Quantifier Characters: {}\n\n{n} – matches when the preceding character occurs exactly n times in a row.\n\nx &lt;- c(\"shes\", \n       \"shels\", \n       \"shells\", \n       \"shellls\", \n       \"shelllls\")\n\nstr_subset(x, pattern = \"shel{2}s\")\n\n[1] \"shells\"\n\n\n\n\n\n{n,} – occurs at least n times in a row.\n\nstr_subset(x, pattern = \"shel{2,}s\")\n\n[1] \"shells\"   \"shellls\"  \"shelllls\"\n\n\n\n\n\n\n{n,m} – occurs between n and m times in a row.\n\nstr_subset(x, pattern = \"shel{1,3}s\")\n\n[1] \"shels\"   \"shells\"  \"shellls\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-groups",
    "href": "slides/week-5/week-5-strings.html#character-groups",
    "title": "Using stringr to Work with Strings",
    "section": "Character Groups: ()",
    "text": "Character Groups: ()\n\nGroups are created with ( ).\n\nWe can specify “either” / “or” within a group using |.\n\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\", \n       \"peck\",\n       \"of\", \n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p(e|i)ck\")\n\n[1] \"picked\"  \"peck\"    \"pickled\"\n\n\n\n\n\nThis matches strings that contain either “peck” or “pick”."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-groups-1",
    "href": "slides/week-5/week-5-strings.html#character-groups-1",
    "title": "Using stringr to Work with Strings",
    "section": "Character Groups: ()",
    "text": "Character Groups: ()\n\nWe can then reference groups in order with escaped numbers (\\\\1) to specify that certain groupings repeat.\n\n\nx &lt;- c(\"hannah\", \n       \"had\", \n       \"a\", \n       \"ball\", \n       \"on\",\n       \"a\", \n       \"race car\")\n\nstr_subset(x, pattern = \"^(.).*\\\\1$\")\n\n[1] \"hannah\"   \"race car\"\n\n\n\n\nThis matches strings that start and end with the same character."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-groups-2",
    "href": "slides/week-5/week-5-strings.html#character-groups-2",
    "title": "Using stringr to Work with Strings",
    "section": "Character Groups: ()",
    "text": "Character Groups: ()\n\nGroups also let us be very precise with extracting strings!\n\n\nshopping_list &lt;- c(\"apples x4\", \n                   \"bag of flour\", \n                   \"bag of sugar\", \n                   \"milk x2\")\n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\")\n\n[1] \"apples x4\" NA          NA          \"milk x2\"  \n\n\n\n\n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\", group = 1)\n\n[1] \"apples\" NA       NA       \"milk\"  \n\n\n\n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\", group = 2)\n\n[1] \"4\" NA  NA  \"2\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-classes",
    "href": "slides/week-5/week-5-strings.html#character-classes",
    "title": "Using stringr to Work with Strings",
    "section": "Character Classes: []",
    "text": "Character Classes: []\n\nCharacter classes let you specify multiple possible characters to match on.\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\",\n       \"peck\",\n       \"of\",\n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p[ei]ck\")\n\n[1] \"picked\"  \"peck\"    \"pickled\"\n\n\n\n\n\n\n\n\n\n\nWhen to use [] or ()?\n\n\n() makes groups of characters, which you can then reference later, plus you can only use a | with ().\n[] is better for referencing multiple characters, plus you can only use a ^ to mean “not” with []…"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#matches-you-dont-want",
    "href": "slides/week-5/week-5-strings.html#matches-you-dont-want",
    "title": "Using stringr to Work with Strings",
    "section": "Matches you don’t want",
    "text": "Matches you don’t want\n[^ ] – specifies characters not to match on (think except)\n\nstr_subset(x, pattern = \"p[^i]ck\")\n\n[1] \"peck\"\n\n\n\n\nBut remember that ^ outside of brackets specifies the first charatcter in a string.\n\nstr_subset(x, pattern = \"^p\")\n\n[1] \"picked\"   \"peck\"     \"pickled\"  \"peppers!\"\n\n\n\n\n\n\nstr_subset(x, pattern = \"^[^p]\")\n\n[1] \"Peter\" \"Piper\" \"a\"     \"of\"   \n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nWhy do “Peter” and “Piper” not match \"^[^p]\"?\nCapitilization matters!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#character-classes-1",
    "href": "slides/week-5/week-5-strings.html#character-classes-1",
    "title": "Using stringr to Work with Strings",
    "section": "Character Classes: []",
    "text": "Character Classes: []\n\n[ - ] – specifies a range of characters.\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\",\n       \"peck\",\n       \"of\",\n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p[ei]ck[a-z]\")\n\n[1] \"picked\"  \"pickled\"\n\n\n\n\n\n\n[A-Z] matches any capital letter.\n[a-z] matches any lowercase letter.\n[A-z] or [:alpha:] matches any letter\n[0-9] or [:digit:] matches any number"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#shortcuts",
    "href": "slides/week-5/week-5-strings.html#shortcuts",
    "title": "Using stringr to Work with Strings",
    "section": "Shortcuts",
    "text": "Shortcuts\n\n\n\\\\w – matches any “word” (\\\\W matches not “word”)\n\nA “word” contains any letters and numbers.\n\n\\\\d – matches any digit (\\\\D matches not digit)\n\\\\s – matches any whitespace (\\\\S matches not whitespace)\n\nWhitespace includes spaces, tabs, newlines, etc.\n\n\n\n\n\n\n\nx &lt;- \"phone number: 1234567899\"\n\nstr_extract(x, pattern = \"\\\\d+\")\n\n[1] \"1234567899\"\n\nstr_extract_all(x, pattern = \"\\\\S+\")\n\n[[1]]\n[1] \"phone\"      \"number:\"    \"1234567899\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#try-it-out-1",
    "href": "slides/week-5/week-5-strings.html#try-it-out-1",
    "title": "Using stringr to Work with Strings",
    "section": "Try it out!",
    "text": "Try it out!\nWhat regular expressions would match words that…\n\n\n\nend with a vowel?\nstart with x, y, or z?\ncontains at least one digit?\ncontains two of the same letters in a row?\n\n\n\n\n\nx &lt;- c(\"zebra\", \n       \"xray\", \n       \"apple\", \n       \"yellow\",\n       \"color\", \n       \"patt3rn\",\n       \"g2g\",\n       \"summarise\")"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#some-possible-solutions",
    "href": "slides/week-5/week-5-strings.html#some-possible-solutions",
    "title": "Using stringr to Work with Strings",
    "section": "Some Possible Solutions…",
    "text": "Some Possible Solutions…\n\nend with a vowel?\n\n\nstr_subset(x, \"[aeiouy]$\")\n\n\nstart with x, y, or z?\n\n\nstr_subset(x, \"^[xyz]\")\n\n\ncontain at least one digit?\n\n\nstr_subset(x, \"[:digit:]\")\n\n\ncontains two of the same letters in a row\n\n\nstr_subset(x, \"([:alpha:])\\\\1\")"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#escape",
    "href": "slides/week-5/week-5-strings.html#escape",
    "title": "Using stringr to Work with Strings",
    "section": "Escape: \\\\",
    "text": "Escape: \\\\\n\nTo match a special character, you need to escape it.\n\nx &lt;- c(\"How\",\n       \"much\", \n       \"wood\",\n       \"could\",\n       \"a\",\n       \"woodchuck\",\n       \"chuck\",\n       \"if\",\n       \"a\",\n       \"woodchuck\",\n       \"could\",\n       \"chuck\",\n       \"wood?\")\n\nstr_subset(x, pattern = \"?\")\n\nError in stri_subset_regex(string, pattern, omit_na = TRUE, negate = negate, : Syntax error in regex pattern. (U_REGEX_RULE_SYNTAX, context=`?`)"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#escape-1",
    "href": "slides/week-5/week-5-strings.html#escape-1",
    "title": "Using stringr to Work with Strings",
    "section": "Escape: \\\\",
    "text": "Escape: \\\\\nUse \\\\ to escape the ? – it is now read as a normal character.\n\nstr_subset(x, pattern = \"\\\\?\")\n\n[1] \"wood?\"\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nAlternatively, you could use []:\n\nstr_subset(x, pattern = \"[?]\")\n\n[1] \"wood?\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#when-in-doubt",
    "href": "slides/week-5/week-5-strings.html#when-in-doubt",
    "title": "Using stringr to Work with Strings",
    "section": "When in Doubt",
    "text": "When in Doubt\n\n\nUse the web app to test R regular expressions."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#tips-for-working-with-regex",
    "href": "slides/week-5/week-5-strings.html#tips-for-working-with-regex",
    "title": "Using stringr to Work with Strings",
    "section": "Tips for working with regex",
    "text": "Tips for working with regex\n\nRead the regular expressions out loud like a request.\n\n\n\nTest out your expressions on small examples first.\n\n\n\n\n\n\n\nstr_view()\n\n\n\nstr_view(c(\"shes\", \"shels\", \"shells\", \"shellls\", \"shelllls\"), \"l+\")\n\n[2] │ she&lt;l&gt;s\n[3] │ she&lt;ll&gt;s\n[4] │ she&lt;lll&gt;s\n[5] │ she&lt;llll&gt;s\n\n\n\n\n\n\n\n\nUse the stringr cheatsheet.\n\n\n\n\nBe kind to yourself!"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#more-practice",
    "href": "slides/week-5/week-5-strings.html#more-practice",
    "title": "Using stringr to Work with Strings",
    "section": "More practice!",
    "text": "More practice!\nI want to join two datasets that have a county variable:\n\n\n\ncounty_pop\n\n\n\n\n\n\ncounty\npop\n\n\n\n\nSTORY\n100000\n\n\nBOONE\n40000\n\n\nMARSHALL\n120000\n\n\nPOLK\n500000\n\n\n\n\n\n\n\ncounty_loc\n\n\n\n\n\n\ncounty\nregion\n\n\n\n\nStory\nCentral\n\n\nBoone\nCentral\n\n\nMarshall\nEast\n\n\nPolk\nCentral\n\n\n\n\n\n\n\n\n\n\n\n\n\nPractice\n\n\nWhat stringr function will help me join the county_pop and county_loc by county?"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#more-practice-1",
    "href": "slides/week-5/week-5-strings.html#more-practice-1",
    "title": "Using stringr to Work with Strings",
    "section": "More practice!",
    "text": "More practice!\nWhat if I want to pull out only the area code in a phone number?\n\nphone_numbers &lt;- c(\"(515)242-1958\", \"(507)598-1395\", \"(805)938-7639\")\n\n\n\n\n\n\n\nPractice\n\n\nYou will need a stringr function and to use regular expressions!\n\n\n\n\n\nstr_extract(phone_numbers, \"\\\\(\\\\d{3}\\\\)\")\n\n[1] \"(515)\" \"(507)\" \"(805)\"\n\n\n\n\nWhat if I want just the numbers in the area code?\n\n\n\nstr_extract(phone_numbers, \"\\\\((\\\\d{3})\\\\)\", group = 1)\n\n[1] \"515\" \"507\" \"805\"\n\n\n\nphone_numbers |&gt; \n  str_extract(pattern = \"\\\\(\\\\d{3}\\\\)\") |&gt; \n  str_remove_all(pattern = \"[:punct:]\")\n\n[1] \"515\" \"507\" \"805\""
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#more-practice-last-one",
    "href": "slides/week-5/week-5-strings.html#more-practice-last-one",
    "title": "Using stringr to Work with Strings",
    "section": "More practice! (last one)",
    "text": "More practice! (last one)\n\n\n\nawards_dat\n\n\n\n\n\n\n\nawards\n\n\n\n\nBeyonce: 35G, 0A, 0E\n\n\nKendrick Lamar: 22G, 0A, 1E\n\n\nCharli XCX: 2G, 0A, 0E\n\n\nCynthia Erivo: 1G, 0A, 1E\n\n\nViola Davis: 1G, 1A, 1E\n\n\nElton John: 6G, 2A, 1E\n\n\n\n\n\n\n\n\n\n\n\n\n\nThat’s annoying…\n\n\nCreate a variable with just the artist name and a variable with the number of Grammys won."
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#more-practice-last-one-1",
    "href": "slides/week-5/week-5-strings.html#more-practice-last-one-1",
    "title": "Using stringr to Work with Strings",
    "section": "More practice! (last one)",
    "text": "More practice! (last one)\n\n\n\nawards_dat\n\n\n\n\n\n\n\nawards\n\n\n\n\nBeyonce: 35G, 0A, 0E\n\n\nKendrick Lamar: 22G, 0A, 1E\n\n\nCharli XCX: 2G, 0A, 0E\n\n\nCynthia Erivo: 1G, 0A, 1E\n\n\nViola Davis: 1G, 1A, 1E\n\n\nElton John: 6G, 2A, 1E\n\n\n\n\n\n\n\n\n\n\n\n\n\nThat’s annoying…\n\n\nCreate a variable with just the artist name and a variable with the number of Grammys won.\n\n\n\n\n\nawards_dat |&gt; \n  mutate(artist = str_extract(awards, \"([A-Za-z\\\\s]+)\\\\:\", \n                              group = 1),\n         grammies = str_extract(awards, \"([1-9]+)G\", \n                                group = 1)) |&gt; \n  select(artist, grammies)\n\n\n\n\n\n\n\nartist\ngrammies\n\n\n\n\nBeyonce\n35\n\n\nKendrick Lamar\n22\n\n\nCharli XCX\n2\n\n\nCynthia Erivo\n1\n\n\nViola Davis\n1\n\n\nElton John\n6"
  },
  {
    "objectID": "slides/week-5/week-5-strings.html#to-do",
    "href": "slides/week-5/week-5-strings.html#to-do",
    "title": "Using stringr to Work with Strings",
    "section": "To do…",
    "text": "To do…\n\nPA 5.1: Scrambled Message\n\nDue Thursday before class\n\nLA 5: Murder in SQL City\n\nDue Monday at 11:59 pm\nYou can use maximum 1 late day on this lab!\n\nLook out for exam information posted on Canvas - we will discuss on Thursday"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#wednesday-febrary-5",
    "href": "slides/week-5/week-5-dates.html#wednesday-febrary-5",
    "title": "Using lubridate to Work with Dates",
    "section": "Wednesday, Febrary 5",
    "text": "Wednesday, Febrary 5\nToday we will…\n\nLab 4 Tips\nMidterm Exam - What to expect\nNew Material\n\nWorking with Date & Time Variables\n\nPA 5.2: Jewel Heist"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-exam---wed-212",
    "href": "slides/week-5/week-5-dates.html#midterm-exam---wed-212",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Exam - Wed 2/12",
    "text": "Midterm Exam - Wed 2/12\n\n\nThis is a three-part exam\nFirst two sections are completed in the one hour and 50 minute class period\n\nYou will first complete a General Questions section on paper and without your computer.\nAfter you turn that in, you will complete a Short Answer section with your computer.\n\nThird section is “takehome” and due 48 hours after the end of class.\n\nThe Open-Ended Analysis is completed out of class (should not take more than 3 hours)"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-exam---wed-212-1",
    "href": "slides/week-5/week-5-dates.html#midterm-exam---wed-212-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Exam - Wed 2/12",
    "text": "Midterm Exam - Wed 2/12\n\n\nReview the “What to Expect” document thoroughly as it includes\n\ndetailed expectations\nthe dataset you will be working with\n\nSet yourself up with a dedicated directory that has the data in it\nMake sure to bring to the exam:\n\nsomething to write with (black/blue pen or pencils)\nyour laptop (& a charging chord)\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\nWhile the coding tasks are open-resource, you will likely run out of time if you have to look everything up. Know what functions you might need and where to find documentation for implementing these functions."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-preparation-suggestions",
    "href": "slides/week-5/week-5-dates.html#midterm-preparation-suggestions",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Preparation Suggestions",
    "text": "Midterm Preparation Suggestions\n\n\nReview course slides & Check-Ins\nQuiz each other on the uses of different functions\nTry to re-do parts of the PAs or LAs from scratch\nStart working with the data\n\nHAVE CODE SET UP THAT READS IN THE DATA\nAsk some questions about the data and try to answer them\n\nSave example code for things you find tricky in a place you can find it\nGet sleep and feed yourself! 🛌🥞🥙🍛"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#project",
    "href": "slides/week-5/week-5-dates.html#project",
    "title": "Using lubridate to Work with Dates",
    "section": "Project",
    "text": "Project\n\n\nDetailed information about the project is posted on Canvas\nYou will complete the project in groups of 4\nThe project is scaffolded into 5 “Checkpoints”\n\nThe bulk of the work will be in Weeks 8-10\n\nFirst Checkpoint due Monday 2/10 at 11:59pm\n\nFill out a survey to form groups\nYou can specify if there are people you want to work with or have me place you in a group"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#lubridate",
    "href": "slides/week-5/week-5-dates.html#lubridate",
    "title": "Using lubridate to Work with Dates",
    "section": "lubridate",
    "text": "lubridate\n\n\n\nConvert a date-like variable (“May 8, 1995”) to a date or date-time object.\nFind the weekday, month, year, etc from a date-time object.\nConvert between time zones.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe lubridate package installs and loads with the tidyverse."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#why-are-dates-and-times-tricky",
    "href": "slides/week-5/week-5-dates.html#why-are-dates-and-times-tricky",
    "title": "Using lubridate to Work with Dates",
    "section": "Why are dates and times tricky?",
    "text": "Why are dates and times tricky?\n\n\nWhen parsing dates and times, we have to consider complicating factors like…\n\nDaylight Savings Time.\n\nOne day a year is 23 hours; one day a year is 25 hours.\nSome places use it, some don’t.\n\nLeap years – most years have 365 days, some have 366.\nTime zones."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#date-time-objects",
    "href": "slides/week-5/week-5-dates.html#date-time-objects",
    "title": "Using lubridate to Work with Dates",
    "section": "date-time Objects",
    "text": "date-time Objects\nThere are multiple data types for dates and times.\n\nA date:\n\ndate or Date\n\nA date and a time (identifies a unique instant in time):\n\ndtm\nPOSIXlt – stores date-times as the number of seconds since January 1, 1970 (“Unix Epoch”)\nPOSIXct – stores date-times as a list with elements for second, minute, hour, day, month, year, etc."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#creating-date-time-objects",
    "href": "slides/week-5/week-5-dates.html#creating-date-time-objects",
    "title": "Using lubridate to Work with Dates",
    "section": "Creating date-time Objects",
    "text": "Creating date-time Objects\n\n\n\n\n\n\nBig Picture\n\n\nThere are a lot of diferent ways to create date-time objects!\n\n\n\n\nCreate a date from individual components:\n\nmake_date(year = 1995, month = 05, day = 08)\n\n[1] \"1995-05-08\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#create-a-date-time-object-from-a-string",
    "href": "slides/week-5/week-5-dates.html#create-a-date-time-object-from-a-string",
    "title": "Using lubridate to Work with Dates",
    "section": "Create a date-time Object from a String",
    "text": "Create a date-time Object from a String\n\n\nmdy(\"August 29, 1991\")\n\n[1] \"1991-08-29\"\n\n\n\n\n\n\ndmy(\"29-August-1991\", \n    tz = \"America/Denver\")\n\n[1] \"1991-08-29 MDT\"\n\n\n\n\n\n\n\ndmy_hms(\"29-August-1991 9:32:12\", \n        tz = \"America/Denver\")\n\n[1] \"1991-08-29 09:32:12 MDT\"\n\n\n\n\n\n\n\nas_datetime(\"91-08-29\", \n            format = \"%y-%m-%d\")\n\n[1] \"1991-08-29 UTC\"\n\n\n\n\n\n\n\nparse_datetime(\"8/29/1991\", \n               format = \"%m/%d/%Y\")\n\n[1] \"1991-08-29 UTC\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#creating-date-time-objects-1",
    "href": "slides/week-5/week-5-dates.html#creating-date-time-objects-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Creating date-time Objects",
    "text": "Creating date-time Objects"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#common-mistake-with-dates",
    "href": "slides/week-5/week-5-dates.html#common-mistake-with-dates",
    "title": "Using lubridate to Work with Dates",
    "section": "Common Mistake with Dates",
    "text": "Common Mistake with Dates\n\n\n\nas_datetime(2023-02-6)\n\n[1] \"1970-01-01 00:33:35 UTC\"\n\n\n\n\n\n\nmy_date &lt;- 2023-02-6\nmy_date\n\n[1] 2015\n\n\n\n\n\nWhat’s wrong here?\n\n\n\nMake sure you use quotes!\n\n2,015 seconds \\(\\approx\\) 33.5 minutes"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#extracting-date-time-components",
    "href": "slides/week-5/week-5-dates.html#extracting-date-time-components",
    "title": "Using lubridate to Work with Dates",
    "section": "Extracting date-time Components",
    "text": "Extracting date-time Components\n\nbday &lt;- ymd_hms(\"1995-02-27 07:03:12\", \n                tz = \"America/Chicago\")\nbday\n\n[1] \"1995-02-27 07:03:12 CST\"\n\n\n\n\n\n\n\n\nyear(bday)\n\n[1] 1995\n\nmonth(bday)\n\n[1] 2\n\nday(bday)\n\n[1] 27\n\n\n\n\n\n\n\nwday(bday)\n\n[1] 2\n\nwday(bday, \n     label = TRUE, \n     abbr = FALSE)\n\n[1] Monday\n7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#subtraction-with-date-time-objects",
    "href": "slides/week-5/week-5-dates.html#subtraction-with-date-time-objects",
    "title": "Using lubridate to Work with Dates",
    "section": "Subtraction with date-time Objects",
    "text": "Subtraction with date-time Objects\nDoing subtraction gives you a difftime object.\ndifftime objects do not always have the same units – it depends on the scale of the objects you are working with.\n\nHow old am I?\n\ntoday() - mdy(\"02-27-1995\")\n\nTime difference of 11013 days\n\n\n\n\n\nHow long did it take me to type this slide?\n\nbegin &lt;- mdy_hms(\"10/21/2024 20:40:34\")\nfinish &lt;- mdy_hms(\"10/21/2024 20:43:11\")\n\nfinish - begin\n\nTime difference of 2.616667 mins"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#durations-and-periods",
    "href": "slides/week-5/week-5-dates.html#durations-and-periods",
    "title": "Using lubridate to Work with Dates",
    "section": "Durations and Periods",
    "text": "Durations and Periods\n\n\nDurations will always give the time span in an exact number of seconds.\n\nas.duration(\n  today() - mdy(\"02-27-1995\")\n            )\n\n[1] \"951523200s (~30.15 years)\"\n\n\n\n\n\n\nPeriods will give the time span in more approximate, but human readable times.\n\nas.period(\n  today() - mdy(\"02-27-1995\")\n  )\n\n[1] \"11013d 0H 0M 0S\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#durations-and-periods-1",
    "href": "slides/week-5/week-5-dates.html#durations-and-periods-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Durations and Periods",
    "text": "Durations and Periods\n\n\nWe can also add time to date-time objects:\n\ndays(), years(), etc. will add a period of time.\nddays(), dyears(), etc. will add a duration of time.\n\n\n\n\n\nBecause durations use the exact number of seconds to represent days and years, you might get unexpected results.\n\nWhen is is my 99th birthday?\n\nmdy(\"02/27/1995\") + years(99)\n\n[1] \"2094-02-27\"\n\n\n\nmdy(\"02/27/1995\") + dyears(99)\n\n[1] \"2094-02-26 18:00:00 UTC\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#time-zones",
    "href": "slides/week-5/week-5-dates.html#time-zones",
    "title": "Using lubridate to Work with Dates",
    "section": "Time Zones…",
    "text": "Time Zones…\n…are complicated!\n\nSpecify time zones in the form:\n\n{continent}/{city} – “America/Denver”, “Africa/Nairobi”\n{ocean}/{city} – “Pacific/Auckland”\n\n\nWhat time zone does R think I’m in?\n\nSys.timezone()\n\n[1] \"America/Los_Angeles\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#time-zones-1",
    "href": "slides/week-5/week-5-dates.html#time-zones-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Time Zones",
    "text": "Time Zones\nYou can change the time zone of a date in two ways:\n\nx &lt;- ymd_hms(\"2024-10-24 18:00:00\", \n             tz = \"Europe/Copenhagen\")\n\n\n\n\nwith_tz()\n\nKeeps the instant in time the same, but changes the visual representation.\n\nx |&gt; \n  with_tz()\n\n[1] \"2024-10-24 09:00:00 PDT\"\n\nx |&gt; \n  with_tz(tzone = \"Asia/Kolkata\")\n\n[1] \"2024-10-24 21:30:00 IST\"\n\n\n\n\n\n\n\nforce_tz()\n\nChanges the instant in time by forcing a time zone change.\n\nx |&gt; \n  force_tz()\n\n[1] \"2024-10-24 18:00:00 PDT\"\n\nx |&gt; \n  force_tz(tzone = \"Asia/Kolkata\")\n\n[1] \"2024-10-24 18:00:00 IST\""
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#common-mistake-with-dates-1",
    "href": "slides/week-5/week-5-dates.html#common-mistake-with-dates-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Common Mistake with Dates",
    "text": "Common Mistake with Dates\nWhen you read data in or create a new date-time object, the default time zone (if not specified) is UTC (Universal Time Coordinated)*.\n\nSo, make sure you specify your desired time zone!\n\nx &lt;- mdy(\"11/20/1993\")\ntz(x)\n\n[1] \"UTC\"\n\n\n\nx &lt;- mdy(\"11/20/1993\", \n         tz = \"America/Los_Angeles\")\ntz(x)\n\n[1] \"America/Los_Angeles\"\n\n\n\n*UTC is the same as GMT (Greenwich Mean Time)"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#tips-for-working-with-dates",
    "href": "slides/week-5/week-5-dates.html#tips-for-working-with-dates",
    "title": "Using lubridate to Work with Dates",
    "section": "Tips for Working with Dates",
    "text": "Tips for Working with Dates\n\nAlways just check that you are getting results that you expect!\nPay attention to time zones\nUse the lubridate cheatsheet"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#pa-5.2-jewel-heist",
    "href": "slides/week-5/week-5-dates.html#pa-5.2-jewel-heist",
    "title": "Using lubridate to Work with Dates",
    "section": "PA 5.2: Jewel Heist",
    "text": "PA 5.2: Jewel Heist\n\n\n\n\nUse dates from clues to find the jewel thief!\nMake sure to pay attention to time zones ⏰"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#la-5-murder-in-sql-city",
    "href": "slides/week-5/week-5-dates.html#la-5-murder-in-sql-city",
    "title": "Using lubridate to Work with Dates",
    "section": "LA 5: Murder in SQL City",
    "text": "LA 5: Murder in SQL City\n\n\n\n\nThis lab looks different!\nYou will need a number of steps to follow the clues - it won’t be done in one pipeline\nRead the instructions carefully\nAt the end, try to delete any code or output that you don’t actually need\nCheck with others if you are stuck! You can see if they get the witness or clues answers at that step."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#to-do",
    "href": "slides/week-5/week-5-dates.html#to-do",
    "title": "Using lubridate to Work with Dates",
    "section": "To do…",
    "text": "To do…\n\nPA 5.2: Jewel Heist\n\ndue Friday (5/2) at 11:59pm\n\nLab 5: Murder in SQL City\n\ndue Monday (5/5) at 11:59pm\n\nRead Chapter 6: Version Control\n\nCheck-in 6.1 - 6.2 due Tuesday (5/6) before class\n\nProject Checkpoint 1: Group Formation Survey\n\ndue Tuesday (5/6) at 11:59pm"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-exam---thu-58",
    "href": "slides/week-5/week-5-dates.html#midterm-exam---thu-58",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Exam - Thu 5/8",
    "text": "Midterm Exam - Thu 5/8\n\n\nThis is a three-part exam\nFirst two sections are completed in the one hour and 50 minute class period\n\nYou will first complete a General Questions section on paper and without your computer.\nAfter you turn that in, you will complete a Short Answer section with your computer.\n\nThird section is “takehome” and due 48 hours after the end of class.\n\nThe Take-Home Analysis is completed out of class (should not take more than 3 hours)"
  },
  {
    "objectID": "slides/week-5/week-5-dates.html#midterm-exam---thu-58-1",
    "href": "slides/week-5/week-5-dates.html#midterm-exam---thu-58-1",
    "title": "Using lubridate to Work with Dates",
    "section": "Midterm Exam - Thu 5/8",
    "text": "Midterm Exam - Thu 5/8\n\n\nReview the “What to Expect” document thoroughly as it includes\n\ndetailed expectations\nthe dataset you will be working with\n\nSet yourself up with a dedicated directory that has the data in it\nMake sure to bring to the exam:\n\nsomething to write with (black/blue pen or pencils)\nyour laptop (& a charging chord)\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\nWhile the coding tasks are open-resource, you will likely run out of time if you have to look everything up. Know what functions you might need and where to find documentation for implementing these functions."
  },
  {
    "objectID": "slides/week-5/week-5-dates.html",
    "href": "slides/week-5/week-5-dates.html",
    "title": "Using lubridate to Work with Dates",
    "section": "",
    "text": "Today we will…\n\nLab 4 Tips\nMidterm Exam - What to expect\nNew Material\n\nWorking with Date & Time Variables\n\nPA 5.2: Jewel Heist"
  },
  {
    "objectID": "slides/week-4/w4-factors.html",
    "href": "slides/week-4/w4-factors.html",
    "title": "Extending Data Joins + Factors",
    "section": "",
    "text": "Today we will…\n\nNotes on Lab 3\nProject Info\nNew Material\n\nExtensions to Data Joins\nFactors with forcats\nClean Variable Names\nLifecycle Stages\n\nLab 4: Childcare Costs in California"
  },
  {
    "objectID": "slides/week-4/w4-factors.html#project",
    "href": "slides/week-4/w4-factors.html#project",
    "title": "Extending Data Joins + Factors",
    "section": "Project",
    "text": "Project\n\n\nDetailed information about the project is posted on Canvas\nYou will complete the project in groups of 4\nThe project is scaffolded into 5 “Checkpoints”\n\nThe bulk of the work will be in Weeks 8-10\n\nFirst Checkpoint due 6th Tuesday (5/6) at 11:59pm\n\nFill out a survey to form groups\nYou can specify if there are people you want to work with or have me place you in a group"
  },
  {
    "objectID": "practice-activities/pa5-2-test.html",
    "href": "practice-activities/pa5-2-test.html",
    "title": "PA 5.2: Jewel Heist",
    "section": "",
    "text": "Download starter qmd file\nlibrary(tidyverse)"
  },
  {
    "objectID": "practice-activities/pa5-2-test.html#solve-the-mystery",
    "href": "practice-activities/pa5-2-test.html#solve-the-mystery",
    "title": "PA 5.2: Jewel Heist",
    "section": "Solve the Mystery",
    "text": "Solve the Mystery\nJust down the road in Montecito, CA several rare jewels went missing. The jewels were stolen and replaced with fakes, but detectives have not been able to solve the case. They are now calling in a data scientist to help parse their clues.\nA camera was located near the building where the jewels went missing, so the detectives have provided you with a list of people who may have entered the building. This list includes the date and time they were spotted on the camera, in Pacific Standard Time (PST).\nUnfortunately, the date and time of the jewel heist is not known. You have been hired to crack the case. Use the clues below to discover the thief’s identity.\n\n# 214 total suspects\nsuspects &lt;- read_csv(\"https://raw.githubusercontent.com/zoerehnberg/STAT331-S23/main/practice_activities/suspects.csv\")\n\n\nWhen data is read into R dates are automatically read in as XX time zone. The first thing that we need to do is tell R that the times listed are in PST.\n\n\nsuspects |&gt; \n  mutate(Time.Spotted = force_tz(Time.Spotted)) |&gt; \n  slice_head() |&gt; \n  pull(Time.Spotted)\n\n[1] \"2022-01-29 12:41:00 PST\"\n\n\n\nsuspects &lt;- suspects |&gt; \n  mutate(Time.Spotted = force_tz(Time.Spotted))\n\n\nBased on the cleaning schedule for the room where the jewels are held, the heist was not committed in the morning (i.e. at 12:00pm or later).\n\n\nsuspects &lt;- suspects |&gt; \n  filter(pm(Time.Spotted) == TRUE)\n# end with 112 suspects left\n\n\nThe room where the heist was committed is closed on Tuesdays and Thursdays (and there were no signs of forced entry), so the heist did not happen on those days.\n\n\n# end with 78 suspects left\nsuspects &lt;- suspects |&gt; \n  mutate(weekday = wday(Time.Spotted, \n                        label = TRUE, \n                        abbr = TRUE)) |&gt; \n  filter(!weekday %in% c(\"Tue\", \"Thu\"))\n\n\nIt is believed that the heist was committed within 5 weeks (35 days) of Thanksgiving 2022 (before or after).\n\n\n\n\n\n\n\nHints\n\n\n\nPay attention to time zones!\nYou will want to look up the date of Thanksgiving 2022.\nI would recommend using an interval\n\n\n\n# thankgiving 2022 in PCT\ntg &lt;- mdy(\"11-24-2022\", tz = \"America/Los_Angeles\")\n\n# create interval of 35 days before / after\ntg_interval &lt;- (tg - days(35)) %--% (tg + days(35))\n\nsuspects &lt;- suspects |&gt; \n  filter(Time.Spotted %within% tg_interval)\n# end with 11 suspects left\n\n\nThe detectives partially decoded a message from the thief to a notorious fence in Iceland. In it, the thief said the job would be done “after the sun sets for you, but before midnight.” In November, the sun sets in Iceland at 4:00pm.\n\n\n\n\n\n\n\nHints\n\n\n\nPay attention to time zones!\n\n\n\n# end with 4 suspects left\n\nsuspects &lt;- suspects |&gt; \n  filter(hour(with_tz(Time.Spotted, tzone = \"UTC\")) &gt; 16) \n\n\nThe thief left behind a receipt at the scene of the crime. The receipt is smudged, but the day of the month is shown to be 22. It is thought that the heist took place no more than three days after the receipt was issued.\n\n\n# end with 2 suspects left\n\nsuspects &lt;- suspects |&gt; \n  filter(day(Time.Spotted) %in% 22:25)\n\n\nThe thief is amused by your efforts and has sent you a cryptic clue:\n\n\n“The exact number of seconds between midnight UTC on Jan 1, 1970 and the time I arrived on the scene is divisible by 6.”\n\n\n\n\n\n\n\nHint\n\n\n\nCheck out how date-time objects are stored on the lubridate cheatsheet.\n\n\n\n# end with 1 suspect left\n\nsuspects |&gt; \n  filter(as.numeric(Time.Spotted) %% 6 == 0)\n\n# A tibble: 1 × 4\n  Name        Occupation Time.Spotted        weekday\n  &lt;chr&gt;       &lt;chr&gt;      &lt;dttm&gt;              &lt;ord&gt;  \n1 Danny Ocean idea man   2022-11-25 12:20:30 Fri    \n\n\n\n\n\n\n\n\nCanvas Quiz Submission\n\n\n\nWho is the thief? Only one name should remain. Remember that you can check with classmates and me about the answer!"
  },
  {
    "objectID": "slides/week-5/w5-notes.html",
    "href": "slides/week-5/w5-notes.html",
    "title": "Week 5 - Strings - Starter Notes",
    "section": "",
    "text": "library(tidyverse)\nlibrary(liver)\nlibrary(knitr)\n\ndata(cereal)"
  },
  {
    "objectID": "slides/week-5/w5-notes.html#stringr-functions",
    "href": "slides/week-5/w5-notes.html#stringr-functions",
    "title": "Week 5 - Strings - Starter Notes",
    "section": "stringr Functions",
    "text": "stringr Functions\n\nmy_vector &lt;- c(\"Hello,\",\n               \"my name is\",\n               \"Bond\",\n               \"James Bond\")\n\nstr_\n\nError: object 'str_' not found\n\n\n\nstr_detect()\n\n\nstr_detect(my_vector, pattern = \"Bond\")\n\n[1] FALSE FALSE  TRUE  TRUE\n\n\n\nstr_match()\n\n\nstr_match(my_vector, pattern = \"Bond\")\n\n     [,1]  \n[1,] NA    \n[2,] NA    \n[3,] \"Bond\"\n[4,] \"Bond\"\n\n\n\nstr_extract\n\n\nstr_extract(my_vector, pattern = \"Bond\")\n\n[1] NA     NA     \"Bond\" \"Bond\"\n\n\n\nalt_vector &lt;- c(\"Hello,\", \n               \"my name is\", \n               \"Bond, James Bond\")\n               \nstr_extract(alt_vector, \n            pattern = \"Bond\")\n\n[1] NA     NA     \"Bond\"\n\nstr_extract_all(alt_vector, \n                pattern = \"Bond\")\n\n[[1]]\ncharacter(0)\n\n[[2]]\ncharacter(0)\n\n[[3]]\n[1] \"Bond\" \"Bond\"\n\n\n\nstr_locate\n\n\nstr_locate(my_vector, pattern = \"Bond\")\n\n     start end\n[1,]    NA  NA\n[2,]    NA  NA\n[3,]     1   4\n[4,]     7  10\n\n\n\nstr_subset\n\n\nstr_subset(my_vector, pattern = \"Bond\")\n\n[1] \"Bond\"       \"James Bond\"\n\n\n\nTry it out!\n\n\n\n\n\n\nNote\n\n\n\nFor each of these functions, write down:\n\nthe object structure of the output.\nthe data type of the output.\na brief explanation of what they do.\n\n\n\n\nmy_vector &lt;- c(\"I scream,\",\n               \"you scream\",\n               \"we all\",\n               \"scream\",\n               \"for\",\n               \"ice cream\")\n\nstr_detect(my_vector, pattern = \"cream\")\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n\nstr_locate(my_vector, pattern = \"cream\")\n\n     start end\n[1,]     4   8\n[2,]     6  10\n[3,]    NA  NA\n[4,]     2   6\n[5,]    NA  NA\n[6,]     5   9\n\nstr_match(my_vector, pattern = \"cream\")\n\n     [,1]   \n[1,] \"cream\"\n[2,] \"cream\"\n[3,] NA     \n[4,] \"cream\"\n[5,] NA     \n[6,] \"cream\"\n\nstr_extract(my_vector, pattern = \"cream\")\n\n[1] \"cream\" \"cream\" NA      \"cream\" NA      \"cream\"\n\nstr_subset(my_vector, pattern = \"cream\")\n\n[1] \"I scream,\"  \"you scream\" \"scream\"     \"ice cream\" \n\n\n\nReplace / Remove Patterns\n\n\nstr_replace(my_vector, \n            pattern = \"Bond\", \n            replace = \"Franco\")\n\n[1] \"I scream,\"  \"you scream\" \"we all\"     \"scream\"     \"for\"       \n[6] \"ice cream\" \n\n\n\nstr_remove(my_vector, \n           pattern = \"Bond\")\n\n[1] \"I scream,\"  \"you scream\" \"we all\"     \"scream\"     \"for\"       \n[6] \"ice cream\" \n\n\n\nEdit string cases\n\n\nstr_to_lower(my_vector)\n\n[1] \"i scream,\"  \"you scream\" \"we all\"     \"scream\"     \"for\"       \n[6] \"ice cream\" \n\nstr_to_upper(my_vector)\n\n[1] \"I SCREAM,\"  \"YOU SCREAM\" \"WE ALL\"     \"SCREAM\"     \"FOR\"       \n[6] \"ICE CREAM\" \n\nstr_to_title(my_vector)\n\n[1] \"I Scream,\"  \"You Scream\" \"We All\"     \"Scream\"     \"For\"       \n[6] \"Ice Cream\" \n\n\n\nCombining Strings\n\n\nprompt &lt;- \"Hello, my name is\"\nfirst  &lt;- \"James\"\nlast   &lt;- \"Bond\"\nstr_c(prompt, last, \",\", first, last, sep = \" \")\n\n[1] \"Hello, my name is Bond , James Bond\"\n\n\n\nstr_flatten(my_vector, collapse = \" \")\n\n[1] \"I scream, you scream we all scream for ice cream\"\n\n\n\nfirst &lt;- \"James\"\nlast &lt;- \"Bond\"\nstr_glue(\"My name is {last}, {first} {last}\")\n\nMy name is Bond, James Bond\n\n\n\nCreating new variables\n\n\ncereal |&gt;\n  mutate(is_bran = str_detect(name, \"Bran\"),\n         .after = name) |&gt; \n  slice_head(n = 5) |&gt; \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nis_bran\nmanuf\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n100% Bran\nTRUE\nN\ncold\n70\n4\n1\n130\n10\n5\n6\n280\n25\n3\n1\n0.33\n68.40297\n\n\n100% Natural Bran\nTRUE\nQ\ncold\n120\n3\n5\n15\n2\n8\n8\n135\n0\n3\n1\n1.00\n33.98368\n\n\nAll-Bran\nTRUE\nK\ncold\n70\n4\n1\n260\n9\n7\n5\n320\n25\n3\n1\n0.33\n59.42551\n\n\nAll-Bran with Extra Fiber\nTRUE\nK\ncold\n50\n4\n0\n140\n14\n8\n0\n330\n25\n3\n1\n0.50\n93.70491\n\n\nAlmond Delight\nFALSE\nR\ncold\n110\n2\n2\n200\n1\n14\n8\n-1\n25\n3\n1\n0.75\n34.38484"
  },
  {
    "objectID": "slides/week-5/w5-notes.html#regular-expressions",
    "href": "slides/week-5/w5-notes.html#regular-expressions",
    "title": "Week 5 - Strings - Starter Notes",
    "section": "Regular Expressions",
    "text": "Regular Expressions\n\nwild card .\n\n\nx &lt;- c(\"She\", \n       \"sells\", \n       \"seashells\", \n       \"by\", \n       \"the\", \n       \"seashore!\")\n\nstr_subset(x, pattern = \".ells\")\n\n[1] \"sells\"     \"seashells\"\n\nstr_extract(x, pattern = \".ells\")\n\n[1] NA      \"sells\" \"hells\" NA      NA      NA     \n\n\n\nanchors\n\n\nstr_subset(x, pattern = \"^s\")\n\n[1] \"sells\"     \"seashells\" \"seashore!\"\n\nstr_subset(x, pattern = \"s$\")\n\n[1] \"sells\"     \"seashells\"\n\n\n\nrepeated characters\n\n\nx &lt;- c(\"shes\", \n       \"shels\", \n       \"shells\", \n       \"shellls\", \n       \"shelllls\")\n\nstr_subset(x, pattern = \"shel?s\")\n\n[1] \"shes\"  \"shels\"\n\nstr_subset(x, pattern = \"shel+s\")\n\n[1] \"shels\"    \"shells\"   \"shellls\"  \"shelllls\"\n\nstr_subset(x, pattern = \"shel*s\")\n\n[1] \"shes\"     \"shels\"    \"shells\"   \"shellls\"  \"shelllls\"\n\nstr_subset(x, pattern = \"shel{2}s\")\n\n[1] \"shells\"\n\nstr_subset(x, pattern = \"shel{2,}s\")\n\n[1] \"shells\"   \"shellls\"  \"shelllls\"\n\nstr_subset(x, pattern = \"shel{1,3}s\")\n\n[1] \"shels\"   \"shells\"  \"shellls\"\n\n\n\ncharacter groups ()\n\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\", \n       \"peck\",\n       \"of\", \n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p(e|i)ck\")\n\n[1] \"picked\"  \"peck\"    \"pickled\"\n\n\n\nx &lt;- c(\"hannah\", \n       \"had\", \n       \"a\", \n       \"ball\", \n       \"on\",\n       \"a\", \n       \"race car\")\n\nstr_subset(x, pattern = \"^(.).*\\\\1$\")\n\n[1] \"hannah\"   \"race car\"\n\n\n\nshopping_list &lt;- c(\"apples x4\", \n                   \"bag of flour\", \n                   \"bag of sugar\", \n                   \"milk x2\")\n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\")\n\n[1] \"apples x4\" NA          NA          \"milk x2\"  \n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\", group = 1)\n\n[1] \"apples\" NA       NA       \"milk\"  \n\nstr_extract(shopping_list, \"([a-z]+) x([1-9])\", group = 2)\n\n[1] \"4\" NA  NA  \"2\"\n\n\n\ncharacter classes []\nanti-match [^]\n\n\nx &lt;- c(\"Peter\", \n       \"Piper\", \n       \"picked\", \n       \"a\",\n       \"peck\",\n       \"of\",\n       \"pickled\",\n       \"peppers!\")\n\nstr_subset(x, pattern = \"p[ei]ck\")\n\n[1] \"picked\"  \"peck\"    \"pickled\"\n\nstr_subset(x, pattern = \"p[^i]ck\")\n\n[1] \"peck\"\n\nstr_subset(x, pattern = \"^p\")\n\n[1] \"picked\"   \"peck\"     \"pickled\"  \"peppers!\"\n\nstr_subset(x, pattern = \"^[^p]\")\n\n[1] \"Peter\" \"Piper\" \"a\"     \"of\"   \n\nstr_subset(x, pattern = \"p[ei]ck[a-z]\")\n\n[1] \"picked\"  \"pickled\"\n\n\n\nshortcuts\n\n\nx &lt;- \"phone number: 1234567899\"\n\nstr_extract(x, pattern = \"\\\\d+\")\n\n[1] \"1234567899\"\n\nstr_extract_all(x, pattern = \"\\\\S+\")\n\n[[1]]\n[1] \"phone\"      \"number:\"    \"1234567899\"\n\n\n\nTry it out!\n\nx &lt;- c(\"zebra\", \n       \"xray\", \n       \"apple\", \n       \"yellow\",\n       \"color\", \n       \"colour\",\n       \"summarize\",\n       \"summarise\")\n\nWhat regular expressions would match words that… + end with a vowel? + start with x, y, or z? + contains two of the same letters in a row? + contain British spelling?\n\nstr_subset(x, pattern = \"[aeiou]$\")\n\n[1] \"zebra\"     \"apple\"     \"summarize\" \"summarise\"\n\nstr_subset(x, pattern = \"^[xyz]\")\n\n[1] \"zebra\"  \"xray\"   \"yellow\"\n\nstr_subset(x, pattern = \"(.)\\\\1\")\n\n[1] \"apple\"     \"yellow\"    \"summarize\" \"summarise\"\n\nstr_subset(x, pattern = \".{2}\")\n\n[1] \"zebra\"     \"xray\"      \"apple\"     \"yellow\"    \"color\"     \"colour\"   \n[7] \"summarize\" \"summarise\"\n\nstr_subset(x, pattern = \"our$|ise$\")\n\n[1] \"colour\"    \"summarise\"\n\nstr_subset(x, pattern = \"our|i[zs]e\")\n\n[1] \"colour\"    \"summarize\" \"summarise\"\n\n\n\nescape characters \\\\\n\n\nx &lt;- c(\"How\",\n       \"much\", \n       \"wood\",\n       \"could\",\n       \"a\",\n       \"woodchuck\",\n       \"chuck\",\n       \"if\",\n       \"a\",\n       \"woodchuck\",\n       \"could\",\n       \"chuck\",\n       \"wood?\")\n\nstr_subset(x, pattern = \"?\")\n\nError in stri_subset_regex(string, pattern, omit_na = TRUE, negate = negate, : Syntax error in regex pattern. (U_REGEX_RULE_SYNTAX, context=`?`)\n\nstr_subset(x, pattern = \"\\\\?\")\n\n[1] \"wood?\"\n\nstr_subset(x, pattern = \"[?]\")\n\n[1] \"wood?\"\n\n\n\ntesting regular expressions\n\n\nstr_view(c(\"shes\", \"shels\", \"shells\", \"shellls\", \"shelllls\"), \"l+\")\n\n[2] │ she&lt;l&gt;s\n[3] │ she&lt;ll&gt;s\n[4] │ she&lt;lll&gt;s\n[5] │ she&lt;llll&gt;s\n\n\n\n\nMore practice 1\n\ncounty_pop &lt;- data.frame(county = c(\"STORY\", \"BOONE\", \"MARSHALL\", \"POLK\"),\n                         pop = c(100000, 40000, 120000, 500000))\n\ncounty_loc &lt;- data.frame(county = c(\"Story\", \"Boone\", \"Marshall\", \"Polk\"),\n                         region = c(\"Central\", \"Central\", \"East\", \"Central\"))\n\nJoin the county_pop and county_loc by county\n\ncounty_pop |&gt; \n  mutate(county = str_to_title(county)) |&gt; \n  left_join(county_loc, by = \"county\")\n\n    county    pop  region\n1    Story 100000 Central\n2    Boone  40000 Central\n3 Marshall 120000    East\n4     Polk 500000 Central\n\n\n\n\nMore practice 2\n\nphone_numbers &lt;- c(\"(515)242-1958\", \"(507)598-1395\", \"(805)938-7639\")\n\nPull out only the area code in a phone number.\n\n# code\n\n\n\nMore practice 3\n\nawards_dat &lt;- data.frame(awards = c(\"Beyonce: 35G,  0A, 0E\",\n                                    \"Kendrick Lamar: 22G, 0A, 1E\",\n                                    \"Charli XCX: 2G, 0A, 0E\",\n                                    \"Cynthia Erivo: 1G, 0A, 1E\",\n                                    \"Viola Davis: 1G, 1A, 1E\",\n                                    \"Elton John: 6G, 2A, 1E\"))\n\nCreate a variable with just the artist name and a variable with the number of Grammys won.\n\nawards_dat |&gt; \n  mutate(artist = str_extract(awards, \".*:\"))\n\n                       awards          artist\n1       Beyonce: 35G,  0A, 0E        Beyonce:\n2 Kendrick Lamar: 22G, 0A, 1E Kendrick Lamar:\n3      Charli XCX: 2G, 0A, 0E     Charli XCX:\n4   Cynthia Erivo: 1G, 0A, 1E  Cynthia Erivo:\n5     Viola Davis: 1G, 1A, 1E    Viola Davis:\n6      Elton John: 6G, 2A, 1E     Elton John:"
  },
  {
    "objectID": "slides/week-5/w5-notes.html#dates",
    "href": "slides/week-5/w5-notes.html#dates",
    "title": "Week 5 - Strings - Starter Notes",
    "section": "Dates",
    "text": "Dates\n\nload(\"ca-childcare.Rdata\")\n\nError in readChar(con, 5L, useBytes = TRUE): cannot open the connection"
  },
  {
    "objectID": "labs/lab5/lab5-murder.html#clean-and-combine-the-data",
    "href": "labs/lab5/lab5-murder.html#clean-and-combine-the-data",
    "title": "Lab 5: Murder in SQL City",
    "section": "Clean and Combine the Data",
    "text": "Clean and Combine the Data\nLet’s set ourselves up to solve this crime lickity-split!\n0.1 Use a stringr function(s) and a regular expression(s) to create address_number and address_street_name columns in the person dataset. Convert the address_number variable to numeric.\n\n# code for Q0.1\n\n0.2 Design and implement a check that you created the address_number and address_street_name columns correctly.\n\n\n\n\n\n\nHint\n\n\n\nFor example, if you re-combine the address_number and address_street_name columns, you should get the same value as original address column exactly.\n\n\n\n# code for Q0.2\n\n0.3 Create two new datasets:\n\nget_fit_now_full\n\nevery row represents one visit to the “Get Fit Now” gym.\nall member information is included (e.g. check in times, names, and membership information)\nshould have 2,703 rows and 8 columns\n\nsuspects_all\n\neach row represents one person\nincludes their address, driver’s licence information, income, and interview with the police, if they have one\ndrop the address column\nshould have 10,011 rows and 16 columns\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t worry about missing values! We are just gathering all of the information that we have about everyone.\n\n\n\n# code to create get_fit_now_full\n\n\n# code to create suspects_all"
  }
]